{
  "Computing": "Computing is any goal-oriented activity requiring, benefiting from, or creating computing machinery. It includes the study and experimentation of algorithmic processes and development of both  hardware and software. It has scientific, engineering, mathematical, technological and social aspects. Major computing disciplines include computer engineering, computer science, cybersecurity, data science, information systems, information technology and software engineering.\n\nThe term computing is also synonymous with counting and calculating. In earlier times, it was used in reference to the action performed by mechanical computing machines, and before that, to human computers.\n\nHistory \n\nThe history of computing is longer than the history of computing hardware and modern computing technology and includes the history of methods intended for pen and paper or for chalk and slate, with or without the aid of tables.\n\nComputing is intimately tied to the representation of numbers. But long before abstractions like the number arose, there were mathematical concepts to serve the purposes of civilization. These concepts include one-to-one correspondence (the basis of counting), comparison to a standard (used for measurement), and the 3-4-5 right triangle (a device for assuring a right angle).\n\nThe earliest known tool for use in computation was the abacus, and it was thought to have been invented in Babylon circa 2400 BC. Its original style of usage was by lines drawn in sand with pebbles. Abaci, of a more modern design, are still used as calculation tools today. This was the first known calculation aid \u2013 preceding Greek methods by 2,000 years{{ computer|reason=What Greek methods?|date=March 2018}}.\n\nThe first recorded idea of using digital electronics for computing was the 1931 paper \"The Use of Thyratrons for High Speed Automatic Counting of Physical Phenomena\" by C. E. Wynn-Williams. Claude Shannon's 1938 paper \"A Symbolic Analysis of Relay and Switching Circuits\" then introduced the idea of using electronics for Boolean algebraic operations.\n\nThe concept of a field-effect transistor was proposed by Julius Edgar Lilienfeld in 1925. John Bardeen and Walter Brattain, while working under William Shockley at Bell Labs, built the first working transistor, the point-contact transistor, in 1947. In 1953, the University of Manchester built the first transistorized computer, called the Transistor Computer. However, early junction transistors were relatively bulky devices that were difficult to manufacture on a mass-production basis, which limited them to a number of specialised applications. The metal\u2013oxide\u2013silicon field-effect transistor (MOSFET, or MOS transistor) was invented by Mohamed Atalla and Dawon Kahng at Bell Labs in 1959. It was the first truly compact transistor that could be miniaturised and mass-produced for a wide range of uses. The MOSFET made it possible to build high-density integrated circuit chips, leading to what is known as the computer revolution or microcomputer revolution.\n\nComputer \n\nA computer is a machine that manipulates data according to a set of instructions called a computer program. The program has an executable form that the computer can use directly to execute the instructions. The same program in its human-readable source code form, enables a programmer to study and develop a sequence of steps known as an algorithm. Because the instructions can be carried out in different types of computers, a single set of source instructions converts to machine instructions according to the CPU type.\n\nThe execution process carries out the instructions in a computer program. Instructions express the computations performed by the computer. They trigger sequences of simple actions on the executing machine. Those actions produce effects according to the semantics of the instructions.\n\nComputer hardware  \nComputer hardware includes the physical parts of a computer, including central processing unit, memory and input/output. Important topics in the field of computer hardware are computational logic and computer architecture.\n\nComputer software \nComputer software, or just \"software\", is a collection of computer programs and related data that provides the instructions for telling a computer what to do and how to do it. Software refers to one or more computer programs and data held in the storage of the computer for some purposes. In other words, software is a set of programs, procedures, algorithms and its documentation concerned with the operation of a data processing system. Program software performs the function of the program it implements, either by directly providing instructions to the computer hardware or by serving as input to another piece of software. The term was coined to contrast with the old term hardware (meaning physical devices). In contrast to hardware, software is intangible. Software is also sometimes used in a more narrow sense, meaning application software only.\n\nSystem software\n\nSystem software, or systems software, is computer software designed to operate and control the computer hardware, and to provide a platform for running application software. System software includes operating systems, utility software, device drivers, window systems, and firmware. Frequently used development tools such as compilers, linkers, and debuggers are classified as system software.\n\nApplication software \n\nApplication software, also known as an \"application\" or an \"app\", is computer software designed to help the user to perform specific tasks. Examples include enterprise software, accounting software, office suites, graphics software and media players. Many application programs deal principally with documents. Apps may be bundled with the computer and its system software, or may be published separately. Some users are satisfied with the bundled apps and need never install additional applications. Application software is contrasted with system software and middleware, which manage and integrate a computer's capabilities, but typically do not directly apply them in the performance of tasks that benefit the user. The system software serves the application, which in turn serves the user. Application software applies the power of a particular computing platform or system software to a particular purpose. Some apps such as Microsoft Office are available in versions for several different platforms; others have narrower requirements and are thus called, for example, a Geography application for Windows or an Android application for education or Linux gaming. Sometimes a new and popular application arises that only runs on one platform, increasing the desirability of that platform. This is called a killer application.\n\nComputer network \n\nA computer network, often simply referred to as a network, is a collection of hardware components and computers interconnected by communication channels that allow sharing of resources and information. Where at least one process in one device is able to send/receive data to/from at least one process residing in a remote device, then the two devices are said to be in a network.\n\nNetworks may be classified according to a wide variety of characteristics such as the medium used to transport the data, communications protocol used, scale, topology, and organizational scope.\n\nCommunications protocols define the rules and data formats for exchanging information in a computer network, and provide the basis for network programming. Well-known communications protocols include Ethernet, a hardware and link layer standard that is ubiquitous in local area networks, and the Internet Protocol Suite, which defines a set of protocols for internetworking, i.e. for data communication between multiple networks, as well as host-to-host data transfer, and application-specific data transmission formats.\n\nComputer networking is sometimes considered a sub-discipline of electrical engineering, telecommunications, computer science, information technology or computer engineering, since it relies upon the theoretical and practical application of these disciplines.\n\nInternet \n\nThe Internet is a global system of interconnected computer networks that use the standard Internet Protocol Suite (TCP/IP) to serve billions of users that consists of millions of private, public, academic, business, and government networks, of local to global scope, that are linked by a broad array of electronic, wireless and optical networking technologies. The Internet carries an extensive range of information resources and services, such as the inter-linked hypertext documents of the World Wide Web and the infrastructure to support email.\n\nComputer programming \n\nComputer programming in general is the process of writing, testing, debugging, and maintaining the source code and documentation of computer programs. This source code is written in a programming language, which is an artificial language often more restrictive or demanding than natural languages, but easily translated by the computer. The purpose of programming is to invoke the desired behavior (customization) from the machine. The process of writing high quality source code requires knowledge of both the application's domain  and the computer science domain. The highest-quality software is thus developed by a team of various domain experts, each person a specialist in some area of development. But the term programmer may apply to a range of program quality, from hacker to open source contributor to professional. And a single programmer could do most or all of the computer programming needed to generate the proof of concept to launch a new \"killer\" application.\n\nComputer programmer \n\nA programmer, computer programmer, or coder is a person who writes computer software. The term computer programmer can refer to a specialist in one area of computer programming or to a generalist who writes code for many kinds of software. One who practices or professes a formal approach to programming may also be known as a programmer analyst. A programmer's primary computer language (C, C++, Java, Lisp, Python, etc.) is often prefixed to the above titles, and those who work in a web environment often prefix their titles with web. The term programmer can be used to refer to a software developer, software engineer, computer scientist, or software analyst. However, members of these professions typically possess other software engineering skills, beyond programming.\n\nComputer industry \n\nThe computer industry is made up of all of the businesses involved in developing computer software, designing computer hardware and computer networking infrastructures, the manufacture of computer components and the provision of information technology services including system administration and maintenance.\n\nSoftware industry \n\nThe software industry includes businesses engaged in development, maintenance and publication of software. The industry also includes software services, such as training, documentation, and consulting.\n\nSub-disciplines of computing\n\nComputer engineering \n\nComputer engineering is a discipline that integrates several fields of electrical engineering and computer science required to develop computer hardware and software. Computer engineers usually have training in electronic engineering (or electrical engineering), software design, and hardware-software integration instead of only software engineering or electronic engineering. Computer engineers are involved in many hardware and software aspects of computing, from the design of individual microprocessors, personal computers, and supercomputers, to circuit design. This field of engineering not only focuses on the design of hardware within its own domain, but as well the interactions between hardware and the world around it.\n\nSoftware engineering \n\nSoftware engineering (SE) is the application of a systematic, disciplined, quantifiable approach to the design, development, operation, and maintenance of software, and the study of these approaches; that is, the application of engineering to software. In layman's terms, it is the act of using insights to conceive, model and scale a solution to a problem. The first reference to the term is the 1968 NATO Software Engineering Conference and was meant to provoke thought regarding the perceived \"software crisis\" at the time. Software development, a much used and more generic term, does not necessarily subsume the engineering paradigm. The generally accepted concepts of Software Engineering as an engineering discipline have been specified in the Guide to the Software Engineering Body of Knowledge (SWEBOK). The SWEBOK has become an internationally accepted standard ISO/IEC TR 19759:2015.\n\nComputer science \n\nComputer science or computing science (abbreviated CS or Comp Sci) is the scientific and practical approach to computation and its applications. A computer scientist specializes in the theory of computation and the design of computational systems.\n\nIts subfields can be divided into practical techniques for its implementation and application in computer systems and purely theoretical areas. Some, such as computational complexity theory, which studies fundamental properties of computational problems, are highly abstract, while others, such as computer graphics, emphasize real-world applications. Still others focus on the challenges in implementing computations. For example, programming language theory studies approaches to description of computations, while the study of computer programming itself investigates various aspects of the use of programming languages and complex systems, and human\u2013computer interaction focuses on the challenges in making computers and computations useful, usable, and universally accessible to humans.\n\nCybersecurity\n\nData science\n\nInformation systems \n\n\"Information systems (IS)\" is the study of complementary networks of hardware and software (see information technology) that people and organizations use to collect, filter, process, create, and distribute data. The ACM's Computing Careers website says \n\nThe study bridges business and computer science using the theoretical foundations of information and computation to study various business models and related algorithmic processes within a computer science discipline.\n\nThe field of Computer Information System(s) (CIS) studies computers and algorithmic processes, including their principles, their software and hardware designs, their applications, and their impact on society while IS emphasizes functionality over design.\n\nInformation technology \n\nInformation technology (IT) is the application of computers and telecommunications equipment to store, retrieve, transmit and manipulate data, often in the context of a business or other enterprise. The term is commonly used as a synonym for computers and computer networks, but it also encompasses other information distribution technologies such as television and telephones. Several industries are associated with information technology, such as computer hardware, software, electronics, semiconductors, internet, telecom equipment, e-commerce and computer services.\n\nResearch and emerging technologies\n\nDNA-based computing and quantum computing are areas of active research in both hardware and software (such as the development of quantum algorithms). Potential infrastructure for future technologies includes DNA origami on photolithography and quantum antennae for transferring information between ion traps. By 2011, researchers had entangled 14 qubits. Fast digital circuits (including those based on Josephson junctions and rapid single flux quantum technology) are becoming more nearly realizable with the discovery of nanoscale superconductors.\n\nFiber-optic and photonic (optical) devices, which already have been used to transport data over long distances, have started being used by data centers, side by side with CPU and semiconductor memory components. This allows the separation of RAM from CPU by optical interconnects. IBM has created an integrated circuit with both electronic and optical information processing in one chip. This is denoted \"CMOS-integrated nanophotonics\" or (CINP). One benefit of optical interconnects is that motherboards which formerly required a certain kind of system on a chip (SoC) can now move formerly dedicated memory and network controllers off the motherboards, spreading the controllers out onto the rack. This allows standardization of backplane interconnects and motherboards for multiple types of SoCs, which allows more timely upgrades of CPUs.\n\nAnother field of research is spintronics. Spintronics can provide computing power and storage, without heat buildup. Some research is being done on hybrid chips, which combine photonics and spintronics. There is also research ongoing on combining plasmonics, photonics, and electronics.\n\nCloud computing \nCloud computing is a model that allows for the use of computing resources, such as servers or applications, without the need for much interaction between the owner of these resources and the user using them. It is typically offered as a service, making it another example of Software as a Service, Platforms as a Service, and Infrastructure as a Service depending on the functionality offered. Key characteristics include on-demand access, broad network access, and the capability of rapid scaling. It allows individual users or small business to benefit from economies of scale.\n\nOne area of interest in this field is its potential to support energy efficiency. Allowing thousands of instances of computation to occur on one single machine instead of thousands of individual machines could help save energy. It could also ease the transition to more renewable energy, since it would suffice to power one server farm with a set of solar panels or wind turbines rather than millions of peoples' homes. \n\nWith centralized computing, the field poses several challenges, especially in security and privacy. Current legislation does not sufficiently protect users from companies mishandling their data on the company servers. This suggests potential for further legislative regulations on cloud computing and tech companies.\n\nQuantum computing \nQuantum computing is an area of research that brings together the disciplines of computer science, information theory, and quantum physics. The idea of information being a basic part of physics is relatively new, but there seems to be a strong tie between information theory and quantum mechanics. Whereas traditional computing operates on a binary system of ones and zeros, quantum computing uses qubits. Qubits are capable of being in a superposition, which means that they are in both states, one and zero, simultaneously. This means the qubit is not somewhere between 1 and 0, but actually the value of the qubit will change depending on when you measure it. This trait of qubits is called quantum entanglement and is the core idea of quantum computing and is what allows quantum computers to do the large scale equations they are used for. Quantum computing is often used for scientific research where a normal computer does not have nearly enough computational power to do the calculations necessary. A good example would be molecular modeling. Large molecules are far too complex for modern computers to calculate what happens to them during a reaction, but the power of quantum computers could open the doors to further understanding these molecules.\n\nSee also\n Computational thinking\n Creative computing\n Electronic data processing\n Index of history of computing articles\n Lehmer sieve\n List of computer term etymologies\n Scientific computing\n Enthusiast computing\n\nReferences\n\nExternal links\n\nFOLDOC: the Free On-Line Dictionary Of Computing",
  "Education": "Education is the process of facilitating learning, or the acquisition of knowledge, skills, values, morals, beliefs, habits, and personal development. Education originated as transmission of cultural heritage from one generation to the next. Today, educational goals increasingly encompass new ideas such as liberation of learners, critical thinking about presented information, skills needed for the modern society, empathy and complex vocational skills.\n\nUNESCO defines three main learning settings. Formal education takes place in education and training institutions, is usually structured by curricular aims and objectives, and learning is typically guided by a teacher. In most regions, formal education is compulsory up to a certain age and commonly divided into educational stages such as kindergarten, primary school and secondary school. Nonformal learning occurs as addition or alternative to formal education.  It may be structured according to educational arrangements, but in a more flexible manner, and usually takes place in community-based, workplace-based or civil society-based settings. Lastly, informal settings occurs in daily life, in the family, any experience that has a formative effect on the way one thinks, feels, or acts may be considered educational, whether unintentional or intentional. In practice there is a continuum from the highly formalized to the highly informalized, and informal learning can occur in all three settings. For instance, homeschooling can be classified as nonformal or informal, depending upon the structure. \n\nRegardless of setting, educational methods include teaching, training, storytelling, discussion, and directed research. The methodology of teaching is called pedagogy. Education is supported by a variety of different philosophies, theories and empirical research agendas. \n\nThere are movements for education reforms, such as for improving quality and efficiency of education towards relevance in students' lives and efficient problem solving in modern or future society at large, or for evidence-based education methodologies. A right to education has been recognized by some governments and the United Nations. Global initiatives aim at achieving the Sustainable Development Goal 4, which promotes quality education for all.\n\nEtymology\nEtymologically, the word \"education\" is derived from the Latin word \u0113duc\u0101ti\u014d (\"A breeding, a bringing up, a rearing\") from \u0113duc\u014d (\"I educate, I train\") which is related to the homonym \u0113d\u016bc\u014d (\"I lead forth, I take out; I raise up, I erect\") from \u0113- (\"from, out of\") and d\u016bc\u014d (\"I lead, I conduct\").\n\nHistory\n\nEducation began in prehistory, as adults trained the young in the knowledge and skills deemed necessary in their society. In pre-literate societies, this was achieved orally and through imitation. Story-telling passed knowledge, values, and skills from one generation to the next. As cultures began to extend their knowledge beyond skills that could be readily learned through imitation, formal education developed. Schools existed in Egypt at the time of the Middle Kingdom. \n\nPlato founded the Academy in Athens, the first institution of higher learning in Europe. The city of Alexandria in Egypt, established in 330 BCE, became the successor to Athens as the intellectual cradle of Ancient Greece. There, the great Library of Alexandria was built in the 3rd century BCE. European civilizations suffered a collapse of literacy and organization following the fall of Rome in CE 476.\n\nIn China, Confucius (551\u2013479 BCE), of the State of Lu, was the country's most influential ancient philosopher, whose educational outlook continues to influence the societies of China and neighbours like Korea, Japan, and Vietnam. Confucius gathered disciples and searched in vain for a ruler who would adopt his ideals for good governance, but his Analects were written down by followers and have continued to influence education in East Asia into the modern era.\n\nThe Aztecs had schools for the noble youths called Calmecac where they would receive rigorous religious and military training. The Aztecs also had a well-developed theory about education, which has an equivalent word in Nahuatl called tlacahuapahualiztli. It means \"the art of raising or educating a person\", or \"the art of strengthening or bringing up men\". This was a broad conceptualization of education, which prescribed that it begins at home, supported by formal schooling, and reinforced by community living. Historians cite that formal education was mandatory for everyone regardless of social class and gender. There was also the word neixtlamachiliztli, which is \"the act of giving wisdom to the face.\" These concepts underscore a complex set of educational practices, which was oriented towards communicating to the next generation the experience and intellectual heritage of the past for the purpose of individual development and his integration into the community.\n\nAfter the Fall of Rome, the Catholic Church became the sole preserver of literate scholarship in Western Europe. The church established cathedral schools in the Early Middle Ages as centres of advanced education. Some of these establishments ultimately evolved into medieval universities and forebears of many of Europe's modern universities. During the High Middle Ages, Chartres Cathedral operated the famous and influential Chartres Cathedral School. The medieval universities of Western Christendom were well-integrated across all of Western Europe, encouraged freedom of inquiry, and produced a great variety of fine scholars and natural philosophers, including Thomas Aquinas of the University of Naples, Robert Grosseteste of the University of Oxford, an early expositor of a systematic method of scientific experimentation, and Saint Albert the Great, a pioneer of biological field research. Founded in 1088, the University of Bologne is considered the first, and the oldest continually operating university.\n\nElsewhere during the Middle Ages, Islamic science and mathematics flourished under the Islamic caliphate which was established across the Middle East, extending from the Iberian Peninsula in the west to the Indus in the east and to the Almoravid Dynasty and Mali Empire in the south.\n\nThe Renaissance in Europe ushered in a new age of scientific and intellectual inquiry and appreciation of ancient Greek and Roman civilizations. Around 1450, Johannes Gutenberg developed a printing press, which allowed works of literature to spread more quickly. The European Age of Empires saw European ideas of education in philosophy, religion, arts and sciences spread out across the globe. Missionaries and scholars also brought back new ideas from other civilizations\u00a0\u2013 as with the Jesuit China missions who played a significant role in the transmission of knowledge, science, and culture between China and Europe, translating works from Europe like Euclid's Elements for Chinese scholars and the thoughts of Confucius for European audiences. The Enlightenment saw the emergence of a more secular educational outlook in Europe. Much of modern traditional Western and Eastern education is based on the Prussian education system.\n\nIn most countries today, full-time education, whether at school or otherwise, is compulsory for all children up to a certain age. Due to this the proliferation of compulsory education, combined with population growth, UNESCO has calculated that in the next 30\u00a0years more people will receive formal education than in all of human history thus far.\n\nFormal\n\nFormal education occurs in a structured environment whose explicit purpose is teaching students. Usually, formal education takes place in a school environment with classrooms of multiple students learning together with a trained, certified teacher of the subject. Most school systems are designed around a set of values or ideals that govern all educational choices in that system. Such choices include curriculum, organizational models, design of the physical learning spaces (e.g. classrooms), student-teacher interactions, methods of assessment, class size, educational activities, and more.\n\nThe International Standard Classification of Education (ISCED) was created by UNESCO as a statistical base to compare education systems. In 1997, it defined 7 levels of education and 25 fields, though the fields were later separated out to form a different project. The current version ISCED 2011 has 9 rather than 7 levels, created by dividing the tertiary pre-doctorate level into three levels. It also extended the lowest level (ISCED 0) to cover a new sub-category of early childhood educational development programmes, which target children below the age of 3 years.\n\nEarly childhood\n\nEducation designed to support early development in preparation for participation in school and society. The programmes are designed for children below the age of 3. This is ISCED level 01. Preschools provide education from ages approximately three to seven, depending on the country when children enter primary education. The children now readily interact with their peers and the educator. These are also known as nursery schools and as kindergarten, except in the US, where the term kindergarten refers to the earliest levels of primary education. Kindergarten \"provides a child-centred, preschool curriculum for three- to seven-year-old children that aim[s] at unfolding the child's physical, intellectual, and moral nature with balanced emphasis on each of them.\" This is ISCED level 02.\n\nPrimary\n\nThis is ISCED level 1. Primary (or elementary) education consists of the first four to seven years of formal, structured education. In general, primary education consists of six to eight years of schooling starting at the age of five to seven, although this varies between, and sometimes within, countries. Globally, in 2008, around 89% of children aged six to twelve were enrolled in primary education, and this proportion was rising. Under the Education For All programs driven by UNESCO, most countries have committed to achieving universal enrollment in primary education by 2015, and in many countries, it is compulsory. The division between primary and secondary education is quite arbitrary, but it generally occurs at about eleven or twelve years of age. Some education systems have separate middle schools, with the transition to the final stage of secondary education taking place at around the age of fifteen. Schools that provide primary education, are mostly referred to as primary schools or elementary schools. Primary schools are often subdivided into infant schools and junior schools.\n\nIn India, for example, compulsory education spans over twelve years, with eight years of elementary education, five years of primary schooling and three years of upper primary schooling. Various states in the republic of India provide 12 years of compulsory school education based on a national curriculum framework designed by the National Council of Educational Research and Training.\n\nSecondary\n\nThis covers the two ISCED levels, ISCED 2: Lower Secondary Education and ISCED 3: Upper Secondary Education.\n\nIn most contemporary educational systems of the world, secondary education comprises the formal education that occurs during adolescence.  In the United States, Canada, and Australia, primary and secondary education together are sometimes referred to as K-12 education, and in New Zealand Year 1\u201313 is used. The purpose of secondary education can be to give common knowledge, to ensure literacy, to prepare for higher education, or to train directly in a profession.\n\nSecondary education in the United States did not emerge until 1910, with the rise of large corporations and advancing technology in factories, which required skilled workers. In order to meet this new job demand, high schools were created, with a curriculum focused on practical job skills that would better prepare students for white collar or skilled blue collar work. This proved beneficial for both employers and employees, since the improved human capital lowered costs for the employer, while skilled employees received higher wages.\n\nSecondary education has a longer history in Europe, where grammar schools or academies date from as early as the 6th century,  in the form of public schools, fee-paying schools, or charitable educational foundations, which themselves date even further back.\n\nIt spans the period between the typically universal compulsory, primary education to the optional, selective tertiary, \"postsecondary\", or \"higher\" education of ISCED 5 and 6 (e.g. university), and the ISCED 4 Further education or vocational school.\n\nDepending on the system, schools for this period, or a part of it, may be called secondary or high schools, gymnasiums, lyceums, middle schools, colleges, or vocational schools. The exact meaning of any of these terms varies from one system to another. The exact boundary between primary and secondary education also varies from country to country and even within them but is generally around the seventh to the tenth year of schooling.\n\nLower\nPrograms at ISCED level 2, lower secondary education are usually organized around a more subject-oriented curriculum; differing from primary education. Teachers typically have\npedagogical training in the specific subjects and, more often than at ISCED level 1, a class of\nstudents will have several teachers, each with specialized knowledge of the subjects they teach. Programmes at ISCED level 2, aim to lay the foundation for lifelong learning and human development upon introducing theoretical concepts across a broad range of subjects which can be developed in future stages. Some education systems may offer vocational education programs during ISCED level 2 providing skills relevant to employment.\n\nUpper\nPrograms at ISCED level 3, or upper secondary education, are typically designed to complete the secondary education process. They lead to skills relevant to employment and the skill necessary to engage in tertiary courses. They offer students more varied, specialized and in-depth instruction. They are more differentiated, with range of options and learning streams.\n\nCommunity colleges offer another option at this transitional stage of education. They provide nonresidential junior college courses to people living in a particular area.\n\nTertiary\n\nHigher education, also called tertiary, third stage, or postsecondary education, is the non-compulsory educational level that follows the completion of a school such as a high school or secondary school. Tertiary education is normally taken to include undergraduate and postgraduate education, as well as vocational education and training. Colleges and universities mainly provide tertiary education. Collectively, these are sometimes known as tertiary institutions. Individuals who complete tertiary education generally receive certificates, diplomas, or academic degrees.\n\nThe ISCED distinguishes 4 levels of tertiary education. ISCED 6 is equivalent to a first degree, ISCED 7 is equivalent to a masters or an advanced professional qualification and ISCED 8 is an advanced research qualification, usually concluding with the submission and defence of a substantive dissertation of publishable quality based on original research. The category ISCED 5 is reserved for short-cycle courses of requiring degree level study.\n\nHigher education typically involves work towards a degree-level or foundation degree qualification. In most developed countries, a high proportion of the population (up to 50%) now enter higher education at some time in their lives. Higher education is therefore very important to national economies, both as a significant industry in its own right and as a source of trained and educated personnel for the rest of the economy.\n\nUniversity education includes teaching, research, and social services activities, and it includes both the undergraduate level (sometimes referred to as tertiary education) and the graduate (or postgraduate) level (sometimes referred to as graduate school). Some universities are composed of several colleges.\n\nOne type of university education is a liberal arts education, which can be defined as a \"college or university curriculum aimed at imparting broad general knowledge and developing general intellectual capacities, in contrast to a professional, vocational, or technical curriculum.\" Although what is known today as liberal arts education began in Europe, the term \"liberal arts college\" is more commonly associated with institutions in the United States such as Williams College or Barnard College.\n\nVocational\n\nVocational education is a form of education focused on direct and practical training for a specific trade or craft. Vocational education may come in the form of an apprenticeship or internship as well as institutions teaching courses such as carpentry, agriculture, engineering, medicine, architecture and the arts.  Post 16 education, adult education and further education involve continued study, but a level no different from that found at upper secondary, and are grouped together as ISCED 4, post-secondary non-tertiary education.\n\nSpecial\n\nIn the past, those who were disabled were often not eligible for public education. Children with disabilities were repeatedly denied an education by physicians or special tutors.  These early physicians (people like Itard, Seguin, Howe, Gallaudet) set the foundation for special education today. They focused on individualized instruction and functional skills.  In its early years, special education was only provided to people with severe disabilities, but more recently it has been opened to anyone who has experienced difficulty learning.\n\nUnconventional forms\n\nAlternative\n\nWhile considered \"alternative\" today, most alternative systems have existed since ancient times.  After the public school system was widely developed beginning in the 19th century, some parents found reasons to be discontented with the new system. Alternative education developed in part as a reaction to perceived limitations and failings of traditional education. A broad range of educational approaches emerged, including alternative schools, self learning, homeschooling, and unschooling. Example alternative schools include Montessori schools, Waldorf schools (or Steiner schools), Friends schools, Sands School, Summerhill School, Walden's Path, The Peepal Grove School, Sudbury Valley School, Krishnamurti schools, and open classroom schools.\n\nCharter schools are another example of alternative education, which have in the recent years grown in numbers in the US and gained greater importance in its public education system.\n\nIn time, some ideas from these experiments and paradigm challenges may be adopted as the norm in education, just as Friedrich Fr\u00f6bel's approach to early childhood education in 19th-century Germany has been incorporated into contemporary kindergarten classrooms. Other influential writers and thinkers have included the Swiss humanitarian Johann Heinrich Pestalozzi; the American transcendentalists Amos Bronson Alcott, Ralph Waldo Emerson, and Henry David Thoreau; the founders of progressive education, John Dewey and Francis Parker; and educational pioneers such as Maria Montessori and Rudolf Steiner, and more recently John Caldwell Holt, Paul Goodman, Frederick Mayer, George Dennison, and Ivan Illich.\n\nIndigenous\n\nIndigenous education refers to the inclusion of indigenous knowledge, models, methods, and content within formal and non-formal educational systems. Often in a post-colonial context, the growing recognition and use of indigenous education methods can be a response to the erosion and loss of indigenous knowledge and language through the processes of colonialism. Furthermore, it can enable indigenous communities to \"reclaim and revalue their languages and cultures, and in so doing, improve the educational success of indigenous students.\"\n\nInformal learning\n\nInformal learning is one of three forms of learning defined by the Organisation for Economic Co-operation and Development (OECD). Informal learning occurs in a variety of places, such as at home, work, and through daily interactions and shared relationships among members of society.  For many learners, this includes language acquisition, cultural norms, and manners.\n\nIn informal learning, there is often a reference person, a peer or expert, to guide the learner.  If learners have a personal interest in what they are informally being taught, learners tend to expand their existing knowledge and conceive new ideas about the topic being learned. For example, a museum is traditionally considered an informal learning environment, as there is room for free choice, a diverse and potentially non-standardized range of topics, flexible structures, socially rich interaction, and no externally imposed assessments.\n\nWhile informal learning often takes place outside educational establishments and does not follow a specified curriculum, it can also occur within educational settings and even during formal learning situations. Educators can structure their lessons to directly utilize their students informal learning skills within the education setting.\n\nIn the late 19th century, education through play began to be recognized as making an important contribution to child development. In the early 20th century, the concept was broadened to include young adults but the emphasis was on physical activities. L.P. Jacks, also an early proponent of lifelong learning, described education through recreation: \"A master in the art of living draws no sharp distinction between his work and his play, his labour, and his leisure, his mind and his body, his education and his recreation. He hardly knows which is which. He simply pursues his vision of excellence through whatever he is doing and leaves others to determine whether he is working or playing. To himself, he always seems to be doing both. Enough for him that he does it well.\" Education through recreation is the opportunity to learn in a seamless fashion through all of life's activities. The concept has been revived by the University of Western Ontario to teach anatomy to medical students.\n\nSelf-directed learning\n\nAutodidacticism (also autodidactism) is self-directed learning. One may become an autodidact at nearly any point in one's life. Notable autodidacts include Abraham Lincoln (U.S. president), Srinivasa Ramanujan (mathematician), Michael Faraday (chemist and physicist), Charles Darwin (naturalist), Thomas Alva Edison (inventor), Tadao Ando (architect), George Bernard Shaw (playwright), Frank Zappa (composer, recording engineer, film director), and Leonardo da Vinci (engineer, scientist, mathematician).\n\nEvidence-based\n\nEvidence-based education is the use of well designed scientific studies to determine which education methods work best. It consists of evidence-based teaching and evidence-based learning. Evidence-based learning methods such as spaced repetition can increase rate of learning. The evidence-based education movement has its roots in the larger movement towards evidence-based-practices.\n\nOpen learning and electronic technology\n\nMany large university institutions are now starting to offer free or almost free full courses, through open education, such as Harvard, MIT and Berkeley teaming up to form edX. Other universities offering open education are prestigious private universities such as Stanford, Princeton, Duke, Johns Hopkins, the University of Pennsylvania, and Caltech, as well as notable public universities including Tsinghua, Peking, Edinburgh, University of Michigan, and University of Virginia.\n\nOpen education has been called the biggest change in the way people learn since the printing press. Despite favourable studies on effectiveness, many people may still desire to choose traditional campus education for social and cultural reasons.\n\nMany open universities are working to have the ability to offer students standardized testing and traditional degrees and credentials.\n\nThe conventional merit-system degree is currently not as common in open education as it is in campus universities, although some open universities do already offer conventional degrees such as the Open University in the United Kingdom. Presently, many of the major open education sources offer their own form of certificate.\n\nOut of 182 colleges surveyed in 2009 nearly half said tuition for online courses was higher than for campus-based ones.\n\nA 2010 meta-analysis found that online and blended educational approaches had better outcomes than methods that used solely face-to-face interaction.\n\nPublic schooling\n\nThe education sector or education system is a group of institutions (ministries of education, local educational authorities, teacher training institutions, schools, universities, etc.) whose primary purpose is to provide education to children and young people in educational settings. It involves a wide range of people (curriculum developers, inspectors, school principals, teachers, school nurses, students, etc.). These institutions can vary according to different contexts.\n\nSchools deliver education, with support from the rest of the education system through various elements such as education policies and guidelines \u2013 to which school policies can refer \u2013 curricula and learning materials, as well as pre- and in-service teacher training programmes. The school environment \u2013 both physical (infrastructures) and psychological (school climate) \u2013 is also guided by school policies that should ensure the well-being of students when they are in school. The Organisation for Economic Co-operation and Development has found that schools tend to perform best when principals have full authority and responsibility for ensuring that students are proficient in core subjects upon graduation. They must also seek feedback from students for quality-assurance and improvement. Governments should limit themselves to monitoring student proficiency.\n\nThe education sector is fully integrated into society, through interactions with numerous stakeholders and other sectors. These include parents, local communities, religious leaders, NGOs, stakeholders involved in health, child protection, justice and law enforcement (police), media and political leadership.\n\nThe shape, methodologies, taught material \u2013 the curriculum \u2013 of formal education is decided by political decision makers along with federal agencies such as the state education agency in the United States.\n\nDevelopment goals\n\nJoseph Chimombo pointed out education's role as a policy instrument, capable of instilling social change and economic advancement in developing countries by giving communities the opportunity to take control of their destinies. The 2030 Agenda for Sustainable Development, adopted by the United Nations (UN) General Assembly in September 2015, calls for a new vision to address the environmental, social and economic concerns facing the world today. The Agenda includes 17 Sustainable Development Goals (SDGs), including SDG 4 on education.\n\nSince 1909, the percentage of children in the developing world attending school has increased. Before then, a small minority of boys attended school. By the start of the twenty-first century, the majority of children in most regions of the world attended some form of school. By 2016, over 91 percent of children are enrolled in formal primary schooling. However, a learning crisis has emerged across the globe, due to the fact that a large proportion of students enrolled in school are not learning. A World Bank study found that \"53 percent of children in low- and middle-income countries cannot read and understand a simple story by the end of primary school.\" While schooling has increased rapidly over the last few decades, learning has not followed suit. \n\nUniversal Primary Education was one of the eight international Millennium Development Goals, towards which progress has been made in the past decade, though barriers still remain. Securing charitable funding from prospective donors is one particularly persistent problem. Researchers at the Overseas Development Institute have indicated that the main obstacles to funding for education include conflicting donor priorities, an immature aid architecture, and a lack of evidence and advocacy for the issue. Additionally, Transparency International has identified corruption in the education sector as a major stumbling block to achieving Universal Primary Education in Africa. Furthermore, demand in the developing world for improved educational access is not as high as foreigners have expected. Indigenous governments are reluctant to take on the ongoing costs involved. There is also economic pressure from some parents, who prefer their children to earn money in the short term rather than work towards the long-term benefits of education.\n\nA study conducted by the UNESCO International Institute for Educational Planning indicates that stronger capacities in educational planning and management may have an important spill-over effect on the system as a whole. Sustainable capacity development requires complex interventions at the institutional, organizational and individual levels that could be based on some foundational principles:\n national leadership and ownership should be the touchstone of any intervention;\n strategies must be context relevant and context specific;\n plans should employ an integrated set of complementary interventions, though implementation may need to proceed in steps;\n partners should commit to a long-term investment in capacity development while working towards some short-term achievements;\n outside intervention should be conditional on an impact assessment of national capacities at various levels;\n a certain percentage of students should be removed for improvisation of academics (usually practiced in schools, after 10th grade).\n\nInternationalisation\nNearly every country now has universal primary education.\n\nSimilarities \u2013 in systems or even in ideas \u2013 that schools share internationally have led to an increase in international student exchanges. The European Socrates-Erasmus Programme facilitates exchanges across European universities. The Soros Foundation provides many opportunities for students from central Asia and eastern Europe. Programs such as the International Baccalaureate have contributed to the internationalization of education. The global campus online, led by American universities, allows free access to class materials and lecture files recorded during the actual classes.\n\nThe Programme for International Student Assessment and the International Association for the Evaluation of Educational Achievement objectively monitor and compare the proficiency of students from a wide range of different nations.\n\nThe internationalization of education is sometimes equated by critics with the westernization of education. These critics say that the internationalization of education leads to the erosion of local education systems and indigenous values and norms, which are replaced with Western systems and cultural and ideological values and orientation.\n\nTechnology in developing countries\n\nTechnology plays an increasingly significant role in improving access to education for people living in impoverished areas and developing countries. However, lack of technological advancement is still causing barriers with regards to quality and access to education in developing countries. Charities like One Laptop per Child are dedicated to providing infrastructures through which the disadvantaged may access educational materials.\n\nThe OLPC foundation, a group out of MIT Media Lab and supported by several major corporations, has a stated mission to develop a $100 laptop for delivering educational software. The laptops were widely available as of 2008. They are sold at cost or given away based on donations.\n\nIn Africa, the New Partnership for Africa's Development (NEPAD) has launched an \"e-school program\" to provide all 600,000 primary and high schools with computer equipment, learning materials and internet access within 10 years. An International Development Agency project called nabuur.com, started with the support of former American President Bill Clinton, uses the Internet to allow co-operation by individuals on issues of social development.\n\nIndia is developing technologies that will bypass land-based telephone and Internet infrastructure to deliver distance learning directly to its students. In 2004, the Indian Space Research Organisation launched EDUSAT, a communications satellite providing access to educational materials that can reach more of the country's population at a greatly reduced cost.\n\nFunding in developing countries\nA survey of literature of the research into low-cost private schools (LCPS) found that over 5-year period to July 2013, debate around LCPSs to achieving Education for All (EFA) objectives was polarized and finding growing coverage in international policy. The polarization was due to disputes around whether the schools are affordable for the poor, reach disadvantaged groups, provide quality education, support or undermine equality, and are financially sustainable. The report examined the main challenges encountered by development organizations which support LCPSs. Surveys suggest these types of schools are expanding across Africa and Asia. This success is attributed to excess demand. These surveys found concern for:\n Equity: This concern is widely found in the literature, suggesting the growth in low-cost private schooling may be exacerbating or perpetuating already existing inequalities in developing countries, between urban and rural populations, lower- and higher-income families, and between girls and boys. The report findings suggest that girls may be under represented and that LCPS are reaching low-income families in smaller numbers than higher-income families.\n Quality and educational outcomes: It is difficult to generalize about the quality of private schools. While most achieve better results than government counterparts, even after their social background is taken into account, some studies find the opposite. Quality in terms of levels of teacher absence, teaching activity, and pupil to teacher ratios in some countries are better in LCPSs than in government schools.\n Choice and affordability for the poor: Parents can choose private schools because of perceptions of better-quality teaching and facilities, and an English language instruction preference. Nevertheless, the concept of 'choice' does not apply in all contexts, or to all groups in society, partly because of limited affordability (which excludes most of the poorest) and other forms of exclusion, related to caste or social status.\n Cost-effectiveness and financial sustainability: There is evidence that private schools operate at low cost by keeping teacher salaries low, and their financial situation may be precarious where they are reliant on fees from low-income households.\n\nThe report showed some cases of successful voucher where there was an oversupply of quality private places and an efficient administrative authority and of subsidy programs. Evaluations of the effectiveness of international support to the sector are rare. Addressing regulatory ineffectiveness is a key challenge. Emerging approaches stress the importance of understanding the political economy of the market for LCPS, specifically how relationships of power and accountability between users, government, and private providers can produce better education outcomes for the poor.\n\nTheory\n\nPsychology\n\nEducational psychology is the study of how humans learn in educational settings, the effectiveness of educational interventions, the psychology of teaching, and the social psychology of schools as organizations. The terms \"educational psychology\" and \"school psychology\" are often used interchangeably. Educational psychology is concerned with the processes of educational attainment in the general population and in sub-populations such as gifted children and those with specific disabilities.\n\nEducational psychology can in part be understood through its relationship with other disciplines. It is informed primarily by psychology, bearing a relationship to that discipline analogous to the relationship between medicine and biology. Educational psychology, in turn, informs a wide range of specialties within educational studies, including instructional design, educational technology, curriculum development, organizational learning, special education and classroom management. Educational psychology both draws from and contributes to cognitive science and the learning sciences. In universities, departments of educational psychology are usually housed within faculties of education, possibly accounting for the lack of representation of educational psychology content in introductory psychology textbooks (Lucas, Blazek, & Raley, 2006).\n\nIntelligence\n\nIntelligence is an important factor in how the individual responds to education. Those who have higher scores of intelligence-metrics tend to perform better at school and go on to higher levels of education. This effect is also observable in the opposite direction, in that education increases measurable intelligence. Studies have shown that while educational attainment is important in predicting intelligence in later life, intelligence at 53 is more closely correlated to intelligence at 8 years old than to educational attainment.\n\nLearning modalities\n\nThere has been much interest in learning modalities and styles over the last two decades. The most commonly employed learning modalities are:\n Visual: learning based on observation and seeing what is being learned.\n Auditory: learning based on listening to instructions/information.\n Kinesthetic: learning based on movement, e.g. hands-on work and engaging in activities.\n\nOther commonly employed modalities include musical, interpersonal, verbal, logical, and intrapersonal.\n\nDunn and Dunn focused on identifying relevant stimuli that may influence learning and manipulating the school environment, at about the same time as Joseph Renzulli recommended varying teaching strategies. Howard Gardner identified a wide range of modalities in his Multiple Intelligences theories. The Myers-Briggs Type Indicator and Keirsey Temperament Sorter, based on the works of Jung, focus on understanding how people's personality affects the way they interact personally, and how this affects the way individuals respond to each other within the learning environment. The work of David Kolb and Anthony Gregorc's Type Delineator follows a similar but more simplified approach.\n\nSome theories propose that all individuals benefit from a variety of learning modalities, while others suggest that individuals may have preferred learning styles, learning more easily through visual or kinesthetic experiences. A consequence of the latter theory is that effective teaching should present a variety of teaching methods which cover all three learning modalities so that different students have equal opportunities to learn in a way that is effective for them. Guy Claxton has questioned the extent that learning styles such as Visual, Auditory and Kinesthetic(VAK) are helpful, particularly as they can have a tendency to label children and therefore restrict learning. Recent research has argued, \"there is no adequate evidence base to justify incorporating learning styles assessments into general educational practice.\"\n\nMind, brain, and education\nEducational neuroscience is an emerging scientific field that brings together researchers in cognitive neuroscience, developmental cognitive neuroscience, educational psychology, educational technology, education theory and other related disciplines to explore the interactions between biological processes and education. Researchers in educational neuroscience investigate the neural mechanisms of reading, numerical cognition, attention, and their attendant difficulties including dyslexia, dyscalculia, and ADHD as they relate to education. Several academic institutions around the world are beginning to devote resources to the establishment of educational neuroscience research.\n\nPhilosophy\n\nAs an academic field, philosophy of education is \"the philosophical study of education and its problems its central subject matter is education, and its methods are those of philosophy\". \"The philosophy of education may be either the philosophy of the process of education or the philosophy of the discipline of education. That is, it may be part of the discipline in the sense of being concerned with the aims, forms, methods, or results of the process of educating or being educated; or it may be metadisciplinary in the sense of being concerned with the concepts, aims, and methods of the discipline.\" As such, it is both part of the field of education and a field of applied philosophy, drawing from fields of metaphysics, epistemology, axiology and the philosophical approaches (speculative, prescriptive or analytic) to address questions in and about pedagogy, education policy, and curriculum, as well as the process of learning, to name a few. For example, it might study what constitutes upbringing and education, the values and norms revealed through upbringing and educational practices, the limits and legitimization of education as an academic discipline, and the relation between education theory and practice.\n\nPurpose\nThere is no broad consensus as to what education's chief aim or aims are or should be. Different places, and at different times, have used educational systems for different purposes.  The Prussian education system in the 19th century, for example, wanted to turn boys and girls into adults who would serve the state's political goals.\n\nSome authors stress its value to the individual, emphasizing its potential for positively influencing students' personal development, promoting autonomy, forming a cultural identity or establishing a career or occupation. Other authors emphasize education's contributions to societal purposes, including good citizenship, shaping students into productive members of society, thereby promoting society's general economic development, and preserving cultural values.\n\nThe purpose of education in a given time and place affects who is taught, what is taught, and how the education system behaves.  For example, in the 21st century, many countries treat education as a positional good. In this competitive approach, people want their own students to get a better education than other students. This approach can lead to unfair treatment of some students, especially those from disadvantaged or marginalized groups. For example, in this system, a city's school system may draw school district boundaries so that nearly all the students in one school are from low-income families, and that nearly all the students in the neighboring schools come from more affluent families, even though concentrating low-income students in one school results in worse educational achievement for the entire school system.\n\nCurriculum\n\nIn formal education, a curriculum is the set of courses and their content offered at a school or university. As an idea, curriculum stems from the Latin word for race course, referring to the course of deeds and experiences through which children grow to become mature adults. A curriculum is prescriptive and is based on a more general syllabus which merely specifies what topics must be understood and to what level to achieve a particular grade or standard.\n\nAn academic discipline is a branch of knowledge which is formally taught, either at the university \u2013 or via some other such method. Each discipline usually has several sub-disciplines or branches, and distinguishing lines are often both arbitrary and ambiguous. Examples of broad areas of academic disciplines include the natural sciences, mathematics, computer science, social sciences, humanities and applied sciences.\n\nInstruction\nInstruction is the facilitation of another's learning. Instructors in primary and secondary institutions are often called teachers, and they direct the education of students and might draw on many subjects like reading, writing, mathematics, science and history. Instructors in post-secondary institutions might be called teachers, instructors, or professors, depending on the type of institution; and they primarily teach only their specific discipline. Studies from the United States suggest that the quality of teachers is the single most important factor affecting student performance, and that countries which score highly on international tests have multiple policies in place to ensure that the teachers they employ are as effective as possible. With the passing of NCLB in the United States (No Child Left Behind), teachers must be highly qualified.\n\nEconomics\n\nIt has been argued that high rates of education are essential for countries to be able to achieve high levels of economic growth. Empirical analyses tend to support the theoretical prediction that poor countries should grow faster than rich countries because they can adopt cutting-edge technologies already tried and tested by rich countries. However, technology transfer requires knowledgeable managers and engineers who are able to operate new machines or production practices borrowed from the leader in order to close the gap through imitation. Therefore, a country's ability to learn from the leader is a function of its stock of \"human capital\". Recent study of the determinants of aggregate economic growth have stressed the importance of fundamental economic institutions and the role of cognitive skills.\n\nAt the level of the individual, there is a large literature, generally related to the work of Jacob Mincer, on how earnings are related to the schooling and other human capital. This work has motivated many studies, but is also controversial. The chief controversies revolve around how to interpret the impact of schooling. Some students who have indicated a high potential for learning, by testing with a high intelligence quotient, may not achieve their full academic potential, due to financial difficulties.\n\nEconomists Samuel Bowles and Herbert Gintis argued in 1976 that there was a fundamental conflict in American schooling between the egalitarian goal of democratic participation and the inequalities implied by the continued profitability of capitalist production.\n\nDevelopment\n\nThe world is changing at an ever quickening rate, which means that a lot of knowledge becomes obsolete and inaccurate more quickly. The emphasis is therefore shifting to teaching the skills of learning: to picking up new knowledge quickly and in as agile a way as possible. Finnish schools have begun to move away from the regular subject-focused curricula, introducing instead developments like phenomenon-based learning, where students study concepts like climate change instead. There are also active educational interventions to implement programs and paths specific to non-traditional students, such as first generation students.\n\nEducation is also becoming a commodity no longer reserved for children; adults need it too. Some governmental bodies, like the Finnish Innovation Fund Sitra in Finland, have proposed compulsory lifelong education.\n\nStudies found that automation is likely to eliminate nearly half the jobs in developed countries during roughly the next two decades. Automation is therefore considered to be a major factor in a \"race between education and technology\". Automation technologies and their application may render certain currently taught skills and knowledge redundant while increasing the need for other curricula \u2013 such as material related to the application of automation. It has been argued that formal education is \"teaching workers the wrong things, and that deep reform is essential to facilitate the development of digital knowledge and technical skills, as well as nonroutine cognitive and noncognitive (or \"soft\") skills\" and that the formal state-organized education system \u2013 which is built on the Industrial Revolution model and focuses on IQ and memorization is losing relevance. FSchools were found rarely teach in forms of \"learning by doing\", and many children above a certain age \"hate school\" in terms of the material and subjects being taught, with much of it being a \"waste of time\" that gets forgotten quickly and is useless in modern society. Moreover, the material currently being taught may not be taught in a highly time-efficient manner and analyzing educational issues over time and using relevant forms of student feedback in efficiency analysis were found to be important. Some research investigates how education can facilitate students' interest in topics \u2013 and jobs \u2013 that scientific research, data, economic players, financial markets, and other economic mechanisms consider important to contemporary and future human civilization and states.\n\nResearch and data indicate future environmental conditions will be \"far more dangerous than currently believed\", with a review concluding that the current challenges that humanity faces are enormous. The effective resolval of such challenges may require novel lesson plans tailored towards skills and knowledge found to be both required and reasonable to be taught at the respective age with the respective methodology despite novel technological computation and information retrieval technologies such as smartphones, mathematical software and the World Wide Web. Environmental education is not widely taught extensively or facilitated while being potentially important to the protection and generation of \u2013 often unquantified \u2013 economic value such as clean air that agents of the economy can breathe. Education is often considered to be a national investment which may not always optimize for cost-efficiency while optimizing only in terms of contemporary economic value metrics or evaluations such as of finance and GDP without consideration of economic values or priorizations beyond these tools such as minimized marine pollution and maximized climate change mitigation. Researchers found that there is a growing disconnect between humans and nature and that schools \"are not properly preparing students to become the scientists of tomorrow\". They also find that critical thought, social responsibility, health and safety are often neglected. According to UNESCO, \"for a country to meet the basic needs of its people, the teaching of science is a strategic imperative\".\n\nOne example of a skill not commonly taught in formal education systems around the world but increasingly critical to both the individuals' lives and modern society at large is digital media literacy \u2013 the ability to access, analyze, evaluate, create, and act using all forms of modern ICTs, with scientists calling for inclusion of it in curricula as well as for adult education.\n\nStudies have shown that active learning rarely applied in schools is highly efficacious. Studies found that massive open online courses offer a pathway to employment that currently bypasses conventional universities and their degree programs while often being more relevant to contemporary economic activities and the students' interests. Such online courses are not commonly part of formal education but are typically both completed and selected entirely on behalf of the student, sometimes with the support of peers over online forums. In contrast, blended learning merges online education with forms of face\u2010to\u2010face communication and traditional class-based education in classrooms, revealing itself to have the general capacity for increasingly relevant, resource-efficient and effective approaches to education. Deploying, using, and managing various tools or platforms for education typically imply an increase in economic investment. Expenses for education are often large with many calling for further increases. Potential policies for the development of international open source educational software using latest technologies may minimize costs, hardware requirements, problem-resolval efforts and deployment-times while increasing robustness, security and functional features of the software.\n\nCOVID-19 pandemic\n\nBeginning in early 2020, the COVID-19 pandemic disrupted education systems throughout the world, affecting nearly 1.6 billion learners in more than 190 countries. Closures of schools and other learning spaces have impacted 94 percent of the world's student population, up to 99 percent in low and lower-middle income countries. Many schools made alternative plans during the pandemic, leading to a variety of in-person, hybrid, and online-only plans, which led to challenges for many students, teachers, and families including children with learning disabilities and those learning in a language that is not their native one. As of September 30, 2020 there were 27 countries that had localized school closures. In the United States, an estimated 55.1 million students were forced to cease in-person instruction as of April 10, 2020. A switch to a virtual learning experience is particularly challenging for families that cannot afford the proper technology, such as laptops, printers, or a reliable Internet connection. When schools close, parents are often asked to facilitate the learning of children at home and can struggle to perform this task. This is especially true for parents with limited education and resources. Students who require special education found it difficult to progress through the curriculum without tools and support that they require. Polling suggests that schools that serve a majority of students of color are far less likely to have access to the technology needed for remote learning. Only 66% of Black households in the U.S. had home broadband service in 2019. Only 45% of Black Americans owned a desktop or laptop computer in 2015. Without access to the internet or a computer, Black parents are at a disadvantage in educating their children. The mental health of students has been greatly impacted due to the pandemic. It is estimated that three in ten participating in school at home have had their emotional and mental health negatively impacted. Similarly, the social lives of students have also been upended and this has been detrimental to the health of students worldwide which has also negatively impacted educational quality. This will be an issue for years to come. COVID-19 has shone a light on opportunity gaps and it will be up to educators and policymakers to direct the necessary resources to mitigating them in the coming years.\n\nSee also\n\n Education for Justice\n\nNotes\n\nReferences\n\nOther references\n\n \n \n \n \n \n \n \n\nAttribution\n\nExternal links\n \n\n \n UNESCO Institute for Statistics: International comparable statistics on education systems\n World Bank Education\n Systems Approach for Better Education Results (SABER)\n Education Statistics (EdStats)\n OECD Education GPS: Statistics and policy analysis, interactive portal\n OECD Statistics\n IIEP Publications on Education Systems\n When Covid-19 closed schools, Black, Hispanic and poor kids took biggest hit in math, reading\n\n \nMain topic articles",
  "Mathematics": "Mathematics (from Greek: ) is an area of knowledge, which includes the study of such topics as numbers (arithmetic and number theory), formulas and related structures (algebra), shapes and spaces in which they are contained (geometry), and quantities and their changes (calculus and analysis). There is no general consensus about its exact scope or epistemological status.\n\nMost of mathematical activity consists of discovering and proving (by pure reasoning) properties of abstract objects. These objects are either abstractions from nature (such as natural numbers or lines), or (in modern mathematics) abstract entities of which certain properties, called axioms, are stipulated. A proof consists of a succession of applications of some deductive rules to already known results, including previously proved theorems, axioms and (in case of abstraction from nature) some basic properties that are considered as true starting points of the theory under consideration. The result of a proof is called a theorem. \n\nMathematics is widely used in science for modeling phenomena. This enables the extraction of quantitative predictions from experimental laws. For example, the movement of planets can be predicted with high accuracy using Newton's law of gravitation combined with mathematical computation. The independence of mathematical truth from any experimentation implies that the accuracy of such predictions depends only on the adequacy of the model for describing the reality. So when some inaccurate predictions arise, it means that the model must be improved or changed, not that the mathematics is wrong. For example, the perihelion precession of Mercury cannot be explained by Newton's law of gravitation, but is accurately explained by Einstein's general relativity. This experimental validation of Einstein's theory shows that Newton's law of gravitation is only an approximation (which still is very accurate in everyday life). \n\nMathematics is essential in many fields, including natural sciences, engineering, medicine, finance, computer science and social sciences.\nSome areas of mathematics, such as statistics and game theory, are developed in direct correlation with their applications, and are often grouped under the name of applied mathematics. Other mathematical areas are developed independently from any application (and are therefore called pure mathematics), but practical applications are often discovered later. A fitting example is the problem of integer factorization, which goes back to Euclid, but which had no practical application before its use in the RSA cryptosystem (for the security of computer networks).\n\nMathematics has been a human activity from as far back as written records exist. However, the concept of a \"proof\" and its associated \"mathematical rigour\" first appeared in Greek mathematics, most notably in Euclid's Elements. Mathematics developed at a relatively slow pace until the Renaissance, when algebra and infinitesimal calculus were added to arithmetic and geometry as main areas of mathematics. Since then the interaction between mathematical innovations and scientific discoveries have led to a rapid increase in the rate of mathematical discoveries. At the end of the 19th century, the foundational crisis of mathematics led to the systematization of the axiomatic method. This, in turn, gave rise to a dramatic increase in the number of mathematics areas and their fields of applications; a witness of this is the Mathematics Subject Classification, which lists more than sixty first-level areas of mathematics.\n\nAreas of mathematics\n\nBefore the Renaissance, mathematics was divided into two main areas: arithmetic, devoted to the manipulation of numbers, and geometry, devoted to the study of shapes. There was also some pseudoscience, such as numerology and astrology, that were not clearly distinguished from mathematics.\n\nAround the Renaissance, two new main areas appeared. The introduction of mathematical notation led to algebra, which, roughly speaking, consists of the study and the manipulation of formulas. Calculus, a shorthand of infinitesimal calculus and integral calculus, is the study of continuous functions, which model the change of, and the relationship between varying quantities (variables). This division into four main areas remained valid until the end of the 19th century, although some areas, such as celestial mechanics and solid mechanics, which were often considered as mathematics, are now considered as belonging to physics. Also, some subjects developed during this period predate mathematics (being divided into different) areas, such as probability theory and combinatorics, which only later became regarded as autonomous areas of their own.\n\nAt the end of the 19th century, the foundational crisis in mathematics and the resulting systematization of the axiomatic method led to an explosion in the amount of areas of mathematics. The Mathematics Subject Classification contains more than 60 first-level areas. Some of these areas correspond to the older division in four main areas. This is the case of number theory (the modern name for higher arithmetic) and Geometry. However, there are several other first-level areas that have \"geometry\" in their name or are commonly considered as belonging to geometry. Algebra and calculus do not appear as first-level areas, but are each split into several first-level areas. Other first-level areas did not exist at all before the 20th century (for example category theory; homological algebra, and computer science) or were not considered before as mathematics, such as 03:Mathematical logic and foundations (including model theory, computability theory, set theory, proof theory, and algebraic logic).\n\nNumber theory\n\nNumber theory started with the manipulation of numbers, that is, natural numbers  and later expanded to integers  and rational numbers  Number theory was formerly called arithmetic, but nowadays this term is mostly used for the methods of calculation with numbers.\n\nA specificity of number theory is that many problems that can be stated very elementarily are very difficult, and, when solved, have a solution that require very sophisticated methods coming from various parts of mathematics. A notable example is Fermat's Last theorem that was stated in 1637 by Pierre de Fermat and proved only in 1994 by Andrew Wiles, using, among other tools, algebraic geometry (more specifically scheme theory), category theory and homological algebra. Another example is Goldbach's conjecture, that asserts that every even integer greater than 2 is the sum of two prime numbers. Stated in 1742 by Christian Goldbach it remains unproven despite considerable effort.\n\nIn view of the diversity of the studied problems and the solving methods, number theory is presently split in several subareas, which include analytic number theory, algebraic number theory, geometry of numbers (method oriented), Diophantine equations and transcendence theory (problem oriented).\n\nGeometry\n\nGeometry is, with arithmetic, one of the oldest branches of mathematics. It started with empirical recipes concerning shapes, such as lines, angles and circles, which were developed mainly for the need of surveying and architecture. \n\nA fundamental innovation was the elaboration of proofs by ancient Greeks: it is not sufficient to verify by measurement that, say, two lengths are equal. Such a property must be proved by abstract reasoning from previously proven results (theorems) and basic properties (which are considered as self-evident because they are too basic for being the subject of a proof (postulates)). This principle, which is foundational for all mathematics, was elaborated for the sake of geometry, and was systematized by Euclid around 300 BC in his book Elements.\n\nThe resulting Euclidean geometry is the study of shapes and their arrangements constructed from lines, planes and circles in the Euclidean plane (plane geometry) and the (three-dimensional) Euclidean space. \n\nEuclidean geometry was developed without a change of methods or scope until the 17th century, when Ren\u00e9 Descartes introduced what is now called Cartesian coordinates. This was a major change of paradigm, since instead of defining real numbers as lengths of line segments (see number line), it allowed the representation of points using numbers (their coordinates), and for the use of algebra and later, calculus for solving geometrical problems. This split geometry in two parts that differ only by their methods, synthetic geometry, which uses purely geometrical methods, and analytic geometry, which uses coordinates systemically.\n\nAnalytic geometry allows the study of new shapes, in particular curves that are not  related to circles and lines; these curves are defined either as graph of functions (whose study led to differential geometry), or by implicit equations, often polynomial equations (which spawned algebraic geometry). Analytic geometry makes it possible to consider spaces dimensions higher than three (it suffices to consider more than three coordinates), which are no longer a model of the physical space. \n\nGeometry expanded quickly during the 19th century. A major event was the discovery (in the second half of the 19th century) of non-Euclidean geometries, which are geometries where the parallel postulate is abandoned. This is, besides Russel's paradox, one of the starting points of the foundational crisis of mathematics, by taking into question the truth of the aforementioned postulate. This aspect of the crisis was solved by systematizing the axiomatic method, and adopting that the truth of the chosen axioms is not a mathematical problem. In turn, the axiomatic method allows for the study of various geometries obtained either by changing the axioms or by considering properties that are invariant under specific transformations of the space. This results in a number of subareas and generalizations of geometry that include:\nProjective geometry, introduced in the 16th century by Girard Desargues, it extends Euclidean geometry by adding points at infinity at which parallel lines intersect. This simplifies many aspects of classical geometry by avoiding to have a different treatment for intersecting and parallel lines.\nAffine geometry, the study of properties relative to parallelism and independent from the concept of length.\nDifferential geometry, the study of curves, surfaces, and their generalizations, which are defined using differentiable functions\nManifold theory, the study of shapes that are not necessarily embedded in a larger space\nRiemannian geometry, the study of distance properties in curved spaces\nAlgebraic geometry, the study of curves, surfaces, and their generalizations, which are defined using polynomials\nTopology, the study of properties that are kept under continuous deformations\nAlgebraic topology, the use in topology of algebraic methods, mainly homological algebra \nDiscrete geometry, the study of finite configurations in geometry\nConvex geometry, the study of convex sets, which takes its importance from its applications in optimization\nComplex geometry, the geometry obtained by replacing real numbers with complex numbers\n\nAlgebra\n\nAlgebra may be viewed as the art of manipulating equations and formulas. Diophantus (3d century) and Al-Khwarizmi (9th century) were two main precursors of algebra. The first one solved some relations between unknown natural numbers (that is, equations) by deducing new relations until getting the solution. The second one introduced systematic methods for transforming equations (such as moving a term from a side of an equation into the other side). The term algebra is derived from the Arabic word that he used for naming one of these methods in the title of his main treatise.\n\nAlgebra began to be a specific area only with Fran\u00e7ois Vi\u00e8te (1540\u20131603), who introduced the use of letters (variables) for representing unknown or unspecified numbers. This allows describing concisely the operations that have to be done on the numbers represented by the variables.\n\nUntil the 19th century, algebra consisted mainly of the study of linear equations that is called presently linear algebra, and polynomial equations in a single unknown, which were called algebraic equations (a term that is still in use, although it may be ambiguous). During the 19th century, variables began to represent other things than numbers (such as matrices, modular integers, and geometric transformations), on which some operations can operate, which are often generalizations of arithmetic operations. For dealing with this, the concept of algebraic structure was introduced, which consist of a set whose elements are unspecified, of operations acting on the elements of the set, and rules that these operations must follow. So, the scope of algebra evolved for becoming essentially the study of algebraic structures. This object of algebra was called modern algebra or abstract algebra, the latter term being still used, mainly in an educational context, in opposition with elementary algebra which is concerned with the older way of manipulating formulas.\n\nSome types of algebraic structures have properties that are useful, and often fundamental, in many areas of mathematics. Their study are nowadays autonomous parts of algebra, which include:\ngroup theory;\nfield theory;\nvector spaces, whose study is essentially the same as linear algebra;\nring theory;\ncommutative algebra, which is the study of commutative rings, includes the study of polynomials, and is a foundational part of algebraic geometry;\nhomological algebra\nLie algebra and Lie group theory;\nBoolean algebra, which is widely used for the study of the logical structure of computers.\n\nThe study of types algebraic structures as mathematical objects is the object of universal algebra and category theory. The latter applies to every mathematical structure (not only the algebraic ones). At its origin, it was introduced, together with homological algebra for allowing the algebraic study of non-algebraic objects such as topological spaces; this particular area of application is called algebraic topology.\n\nCalculus and analysis\n\nCalculus, formerly called infinitesimal calculus, was introduced in the 17th century by Newton and Leibniz, independently and simultaneously. It is fundamentally the study of the relationship of two changing quantities, called variables, such that one depends on the other. Calculus was largely expanded in the 18th century by Euler, with the introduction of the concept of a function, and many other results. Presently \"calculus\" refers mainly to the elementary part of this theory, and \"analysis\" is commonly used for advanced parts.\n\nAnalysis is further subdivided into real analysis, where variables represent real numbers and complex analysis where variables represent complex numbers. Presently there are many subareas of analysis, some being shared with other areas of mathematics; they include:\n Multivariable calculus\n Functional analysis, where variables represent varying functions;\n Integration, measure theory and potential theory, all strongly related with Probability theory;\n Ordinary differential equations;\n Partial differential equations;\n Numerical analysis, mainly devoted to the computation on computers of solutions of ordinary and partial differential equations that arise in many applications of mathematics.\n\nDiscrete mathematics\n\nMathematical logic and set theory\n\nThese subjects belong to mathematics since the end of the 19th century. Before this period, sets were not considered as mathematical objects, and logic, although used for mathematical proofs, belonged to philosophy, and was not specifically studied by mathematicians.\n\nBefore the study of infinite sets by Georg Cantor, mathematicians were reluctant to consider collections that are actually infinite, and considered infinity as the result of an endless enumeration. Cantor's work offended many mathematicians not only by considering actually infinite sets, but also by showing that this implies different sizes of infinity (see Cantor's diagonal argument) and the existence of mathematical objects that cannot be computed, and not even be explicitly described (for example, Hamel bases of the real numbers over the rational numbers). This led to the controversy over Cantor's set theory.\n\nIn the same period, it appeared in various areas of mathematics that the former intuitive definitions of the basic mathematical objects were insufficient for insuring mathematical rigour. Examples of such intuitive definitions are \"a set is a collection of objects\", \"natural number is what is used for counting\", \"a point is a shape with a zero length in every direction\", \"a curve is a trace left by a moving point\", etc.\n\nThis is the origin of the foundational crisis of mathematics. It has been eventually solved in the mainstream of mathematics by systematize the axiomatic method inside a formalized set theory. Roughly speaking, each mathematical object is defined by the set of all similar objects and the properties that these objects must have. For example, in Peano arithmetic, the natural numbers are defined by \"zero is a number\", \"each number as a unique successor\", \"each number but zero has a unique predecessor\", and some rules of reasoning. The \"nature\" of the objects defined this way is a philosophical problem that mathematicians leave to philosophers, even if many mathematicians have opinions on this nature, and use their opinion\u2014sometimes called \"intuition\"\u2014to guide their study and finding proofs.\n\nThis approach allows considering \"logics\" (that is, sets of allowed deducing rules), theorems, proofs, etc. as mathematical objects, and to prove theorems about them. For example, G\u00f6del's incompleteness theorems assert, roughly speaking that, in every theory that contains the natural numbers, there are theorems that are true (that is provable in a larger theory), but not provable inside the theory. \n\nThis approach of the foundations of the mathematics was challenged during the first half of the 20th century by mathematicians leaded by L. E. J. Brouwer who promoted an intuitionistic logic that excludes the law of excluded middle.\n\nThese problems and debates led to a wide expansion of mathematical logic, with subareas such as model theory (modeling some logical theories inside other theory), proof theory, type theory, computability theory and computational complexity theory. Although these aspects of mathematical logic were introduced before the rise of computers, their use in compiler design, program certification, proof assistants and other aspects of computer science, contributed in turn to the expansion of these logical theories.\n\nApplied mathematics\n\nApplied mathematics concerns itself with mathematical methods that are typically used in science, engineering, business, and industry. Thus, \"applied mathematics\" is a mathematical science with specialized knowledge. The term applied mathematics also describes the professional specialty in which mathematicians work on practical problems; as a profession focused on practical problems, applied mathematics focuses on the \"formulation, study, and use of mathematical models\" in science, engineering, and other areas of mathematical practice.\n\nIn the past, practical applications have motivated the development of mathematical theories, which then became the subject of study in pure mathematics, where mathematics is developed primarily for its own sake. Thus, the activity of applied mathematics is vitally connected with research in pure mathematics.\n\nStatistics and other decision sciences\n\nApplied mathematics has significant overlap with the discipline of statistics, whose theory is formulated mathematically, especially with probability theory. Statisticians (working as part of a research project) \"create data that makes sense\" with random sampling and with randomized experiments; the design of a statistical sample or experiment specifies the analysis of the data (before the data becomes available). When reconsidering data from experiments and samples or when analyzing data from observational studies, statisticians \"make sense of the data\" using the art of modelling and the theory of inference\u2014with model selection and estimation; the estimated models and consequential predictions should be tested on new data.\n\nStatistical theory studies decision problems such as minimizing the risk (expected loss) of a statistical action, such as using a procedure in, for example, parameter estimation, hypothesis testing, and selecting the best. In these traditional areas of mathematical statistics, a statistical-decision problem is formulated by minimizing an objective function, like expected loss or cost, under specific constraints: For example, designing a survey often involves minimizing the cost of estimating a population mean with a given level of confidence. Because of its use of optimization, the mathematical theory of statistics shares concerns with other decision sciences, such as operations research, control theory, and mathematical economics.\n\nComputational mathematics\nComputational mathematics proposes and studies methods for solving mathematical problems that are typically too large for human numerical capacity. Numerical analysis studies methods for problems in analysis using functional analysis and approximation theory; numerical analysis broadly includes the study of approximation and discretisation with special focus on rounding errors. Numerical analysis and, more broadly, scientific computing also study non-analytic topics of mathematical science, especially algorithmic-matrix-and-graph theory. Other areas of computational mathematics include computer algebra and symbolic computation.\n\nHistory\n\nThe history of mathematics can be seen as an ever-increasing series of abstractions. Evolutionarily speaking, the first abstraction to ever take place, which is shared by many animals, was probably that of numbers: the realization that a collection of two apples and a collection of two oranges (for example) have something in common, namely the quantity of their members. As evidenced by tallies found on bone, in addition to recognizing how to count physical objects, prehistoric peoples may have also recognized how to count abstract quantities, like time\u2014days, seasons, or years.\n\nEvidence for more complex mathematics does not appear until around 3000\u00a0, when the Babylonians and Egyptians began using arithmetic, algebra, and geometry for taxation and other financial calculations, for building and construction, and for astronomy. The oldest mathematical texts from Mesopotamia and Egypt are from 2000 to 1800\u00a0BC. Many early texts mention Pythagorean triples and so, by inference, the Pythagorean theorem seems to be the most ancient and widespread mathematical concept after basic arithmetic and geometry. It is in Babylonian mathematics that elementary arithmetic (addition, subtraction, multiplication, and division) first appear in the archaeological record. The Babylonians also possessed a place-value system and used a sexagesimal numeral system which is still in use today for measuring angles and time.\n\nBeginning in the 6th century BC with the Pythagoreans, with Greek mathematics the Ancient Greeks began a systematic study of mathematics as a subject in its own right. Around 300 BC, Euclid introduced the axiomatic method still used in mathematics today, consisting of definition, axiom, theorem, and proof. His book, Elements, is widely considered the most successful and influential textbook of all time. The greatest mathematician of antiquity is often held to be Archimedes (c. 287\u2013212 BC) of Syracuse. He developed formulas for calculating the surface area and volume of solids of revolution and used the method of exhaustion to calculate the area under the arc of a parabola with the summation of an infinite series, in a manner not too dissimilar from modern calculus. Other notable achievements of Greek mathematics are conic sections (Apollonius of Perga, 3rd century BC), trigonometry (Hipparchus of Nicaea, 2nd century BC), and the beginnings of algebra (Diophantus, 3rd century AD).\n\nThe Hindu\u2013Arabic numeral system and the rules for the use of its operations, in use throughout the world today, evolved over the course of the first millennium AD in India and were transmitted to the Western world via Islamic mathematics. Other notable developments of Indian mathematics include the modern definition and approximation of sine and cosine, and an early form of infinite series.\n\nDuring the Golden Age of Islam, especially during the 9th and 10th\u00a0centuries, mathematics saw many important innovations building on Greek mathematics. The most notable achievement of Islamic mathematics was the development of algebra. Other achievements of the Islamic period include advances in spherical trigonometry and the addition of the decimal point to the Arabic numeral system. Many notable mathematicians from this period were Persian, such as Al-Khwarismi, Omar Khayyam and Sharaf al-D\u012bn al-\u1e6c\u016bs\u012b.\n\nDuring the early modern period, mathematics began to develop at an accelerating pace in Western Europe. The development of calculus by Isaac Newton and Gottfried Leibniz in the 17th century revolutionized mathematics. Leonhard Euler was the most notable mathematician of the 18th century, contributing numerous theorems and discoveries. Perhaps the foremost mathematician of the 19th century was the German mathematician Carl Gauss, who made numerous contributions to fields such as algebra, analysis, differential geometry, matrix theory, number theory, and statistics. In the early 20th century, Kurt G\u00f6del transformed mathematics by publishing his incompleteness theorems, which show in part that any consistent axiomatic system\u2014if powerful enough to describe arithmetic\u2014will contain true propositions that cannot be proved.\n\nMathematics has since been greatly extended, and there has been a fruitful interaction between mathematics and science, to the benefit of both. Mathematical discoveries continue to be made to this very day. According to Mikhail B. Sevryuk, in the January\u00a02006 issue of the Bulletin of the American Mathematical Society, \"The number of papers and books included in the Mathematical Reviews database since 1940 (the first year of operation of MR) is now more than 1.9\u00a0million, and more than 75\u00a0thousand items are added to the database each year. The overwhelming majority of works in this ocean contain new mathematical theorems and their proofs.\"\n\nEtymology\nThe word mathematics comes from Ancient Greek m\u00e1th\u0113ma (), meaning \"that which is learnt,\" \"what one gets to know,\" hence also \"study\" and \"science\". The word for \"mathematics\" came to have the narrower and more technical meaning \"mathematical study\" even in Classical times. Its adjective is math\u0113matik\u00f3s (), meaning \"related to learning\" or \"studious,\" which likewise further came to mean \"mathematical.\" In particular, math\u0113matik\u1e17 t\u00e9khn\u0113 (; ) meant \"the mathematical art.\"\n\nSimilarly, one of the two main schools of thought in Pythagoreanism was known as the math\u0113matikoi (\u03bc\u03b1\u03b8\u03b7\u03bc\u03b1\u03c4\u03b9\u03ba\u03bf\u03af)\u2014which at the time meant \"learners\" rather than \"mathematicians\" in the modern sense.\n\nIn Latin, and in English until around 1700, the term mathematics more commonly meant \"astrology\" (or sometimes \"astronomy\") rather than \"mathematics\"; the meaning gradually changed to its present one from about 1500 to 1800. This has resulted in several mistranslations. For example, Saint Augustine's warning that Christians should beware of mathematici, meaning astrologers, is sometimes mistranslated as a condemnation of mathematicians.\n\nThe apparent plural form in English, like the French plural form  (and the less commonly used singular derivative ), goes back to the Latin neuter plural  (Cicero), based on the Greek plural ta math\u0113matik\u00e1 (), used by Aristotle (384\u2013322\u00a0BC), and meaning roughly \"all things mathematical\", although it is plausible that English borrowed only the adjective mathematic(al) and formed the noun mathematics anew, after the pattern of physics and metaphysics, which were inherited from Greek. In English, the noun mathematics takes a singular verb. It is often shortened to maths or, in North America, math.\n\nPhilosophy of mathematics\n\nThere is no general consensus about the exact definition or epistemological status of mathematics. Aristotle defined mathematics as \"the science of quantity\" and this definition prevailed until the 18th century. However, Aristotle also noted a focus on quantity alone may not distinguish mathematics from sciences like physics; in his view, abstraction and studying quantity as a property \"separable in thought\" from real instances set mathematics apart.\n\nIn the 19th\u00a0century, when the study of mathematics increased in rigor and began to address abstract topics such as group theory and projective geometry, which have no clear-cut relation to quantity and measurement, mathematicians and philosophers began to propose a variety of new definitions.\n\nA great many professional mathematicians take no interest in a definition of mathematics, or consider it undefinable. There is not even consensus on whether mathematics is an art or a science. Some just say, \"Mathematics is what mathematicians do.\"\n\nThree leading types \nThree leading types of definition of mathematics today are called logicist, intuitionist, and formalist, each reflecting a different philosophical school of thought. All have severe flaws, none has widespread acceptance, and no reconciliation seems possible.\n\nLogicist definitions \nAn early definition of mathematics in terms of logic was that of Benjamin Peirce (1870): \"the science that draws necessary conclusions.\" In the Principia Mathematica, Bertrand Russell and Alfred North Whitehead advanced the philosophical program known as logicism, and attempted to prove that all mathematical concepts, statements, and principles can be defined and proved entirely in terms of symbolic logic. An example of a logicist definition of mathematics is Russell's (1903) \"All Mathematics is Symbolic Logic.\"\n\nIntuitionist definitions \nIntuitionist definitions, developing from the philosophy of mathematician L. E. J. Brouwer, identify mathematics with certain mental phenomena. An example of an intuitionist definition is \"Mathematics is the mental activity which consists in carrying out constructs one after the other.\" A peculiarity of intuitionism is that it rejects some mathematical ideas considered valid according to other definitions. In particular, while other philosophies of mathematics allow objects that can be proved to exist even though they cannot be constructed, intuitionism allows only mathematical objects that one can actually construct. Intuitionists also reject the law of excluded middle (i.e., ). While this stance does force them to reject one common version of proof by contradiction as a viable proof method, namely the inference of  from , they are still able to infer  from . For them,  is a strictly weaker statement than .\n\nFormalist definitions \nFormalist definitions identify mathematics with its symbols and the rules for operating on them. Haskell Curry defined mathematics simply as \"the science of formal systems\". A formal system is a set of symbols, or tokens, and some rules on how the tokens are to be combined into formulas. In formal systems, the word axiom has a special meaning different from the ordinary meaning of \"a self-evident truth\", and is used to refer to a combination of tokens that is included in a given formal system without needing to be derived using the rules of the system.\n\nMathematics as science\n\nThe German mathematician Carl Friedrich Gauss referred to mathematics as \"the Queen of the Sciences\". More recently, Marcus du Sautoy has called mathematics \"the Queen of Science\u00a0... the main driving force behind scientific discovery\". The philosopher Karl Popper observed that \"most mathematical theories are, like those of physics and biology, hypothetico-deductive: pure mathematics therefore turns out to be much closer to the natural sciences whose hypotheses are conjectures, than it seemed even recently.\" Popper also noted that \"I shall certainly admit a system as empirical or scientific only if it is capable of being tested by experience.\"\n\nMathematics shares much in common with many fields in the physical sciences, notably the exploration of the logical consequences of assumptions. Intuition and experimentation also play a role in the formulation of conjectures in both mathematics and the (other) sciences. Experimental mathematics continues to grow in importance within mathematics, and computation and simulation are playing an increasing role in both the sciences and mathematics.\n\nSeveral authors consider that mathematics is not a science because it does not rely on empirical evidence.\nThe opinions of mathematicians on this matter are varied. Many mathematicians feel that to call their area a science is to downplay the importance of its aesthetic side, and its history in the traditional seven liberal arts; others feel that to ignore its connection to the sciences is to turn a blind eye to the fact that the interface between mathematics and its applications in science and engineering has driven much development in mathematics. One way this difference of viewpoint plays out is in the philosophical debate as to whether mathematics is created (as in art) or discovered (as in science). In practice, mathematicians are typically grouped with scientists at the gross level but separated at finer levels. This is one of many issues considered in philosophy of mathematics.\n\nInspiration, pure and applied mathematics, and aesthetics\n\nMathematics arises from many different kinds of problems. At first these were found in commerce, land measurement, architecture and later astronomy; today, all sciences pose problems studied by mathematicians, and many problems arise within mathematics itself. For example, the physicist Richard Feynman invented the path integral formulation of quantum mechanics using a combination of mathematical reasoning and physical insight, and today's string theory, a still-developing scientific theory which attempts to unify the four fundamental forces of nature, continues to inspire new mathematics.\n\nSome mathematics is relevant only in the area that inspired it, and is applied to solve further problems in that area. But often mathematics inspired by one area proves useful in many areas, and joins the general stock of mathematical concepts. A distinction is often made between pure mathematics and applied mathematics. However pure mathematics topics often turn out to have applications, e.g. number theory in cryptography.\n\nThis remarkable fact, that even the \"purest\" mathematics often turns out to have practical applications, is what the physicist Eugene Wigner has named \"the unreasonable effectiveness of mathematics\". The philosopher of mathematics Mark Steiner has written extensively on this matter and acknowledges that the applicability of mathematics constitutes \u201ca challenge to naturalism.\u201d For the philosopher of mathematics Mary Leng, the fact that the physical world acts in accordance with the dictates of non-causal mathematical entities existing beyond the universe is \"a happy coincidence\". On the other hand, for some  anti-realists, connections, which are acquired among mathematical things, just mirror the connections acquiring among objects in the universe, so there is no \"happy coincidence\".\n\nAs in most areas of study, the explosion of knowledge in the scientific age has led to specialization: there are now hundreds of specialized areas in mathematics and the latest Mathematics Subject Classification runs to 46\u00a0pages. Several areas of applied mathematics have merged with related traditions outside of mathematics and become disciplines in their own right, including statistics, operations research, and computer science.\n\nFor those who are mathematically inclined, there is often a definite aesthetic aspect to much of mathematics. Many mathematicians talk about the elegance of mathematics, its intrinsic aesthetics and inner beauty. Simplicity and generality are valued. There is beauty in a simple and elegant proof, such as Euclid's proof that there are infinitely many prime numbers, and in an elegant numerical method that speeds up calculation, such as the fast Fourier transform. G. H. Hardy in A Mathematician's Apology expressed the belief that these aesthetic considerations are, in themselves, sufficient to justify the study of pure mathematics. He identified criteria such as significance, unexpectedness, inevitability, and economy as factors that contribute to a mathematical aesthetic. Mathematical research often seeks critical features of a mathematical object. A theorem expressed as a characterization of an object by these features is the prize. Examples of particularly succinct and revelatory mathematical arguments have been published in Proofs from THE BOOK.\n\nThe popularity of recreational mathematics is another sign of the pleasure many find in solving mathematical questions. At the other social extreme, philosophers continue to find problems in philosophy of mathematics, such as the nature of mathematical proof.\n\nNotation, language, and rigor\n\nMost of the mathematical notation in use today was invented after the 15th century. Before that, mathematics was written out in words, limiting mathematical discovery. Euler (1707\u20131783) was responsible for many of these notations. Modern notation makes mathematics efficient for the professional, while beginners often find it daunting. \n\nMathematical language supplies a more precise meaning for ordinary words such as or and only than they have in everyday speech. Other terms such as open and field are at once precise and also refer to specific concepts present only in mathematics. Mathematical language also includes many technical terms such as homeomorphism and integrable that have no meaning outside of mathematics. Additionally, shorthand phrases such as iff for \"if and only if\" belong to mathematical jargon. This special notation and technical vocabulary is both precise and concise, making it possible to work on ideas of inordinate complexity. Mathematicians refer to this precision of language and logic as \"rigor\".\n\nThe validity of mathematical proofs is fundamentally a matter of rigor. Mathematicians want their theorems to follow from axioms by means of systematic reasoning. This is to avoid mistaken \"theorems\", based on fallible intuitions, which have arisen many times in mathematics' history. The rigor expected in mathematics has varied over time: the Greeks expected detailed arguments, but in  Isaac Newton's heyday, the methods employed were less rigorous. Problems inherent in the definitions used by Newton led to a resurgence of careful analysis and formal proof in the 19th\u00a0century. Misunderstanding rigor is a notable cause for some of the common misconceptions of mathematics. \n\nDespite mathematics' concision, many proofs require hundreds of pages to express. The emergence of computer-assisted proofs has allowed proof lengths to further expand. Assisted proofs may be erroneous if the proving software has flaws and if they are lengthy, difficult to check. On the other hand, proof assistants allow for the verification of details that cannot be given in a hand-written proof, and provide certainty of the correctness of long proofs such as that of the 255-page Feit\u2013Thompson theorem.\n\nTraditionally, axioms were thought of as \"self-evident truths\". However, at a formal level, an axiom is just a string of symbols, which has an intrinsic meaning only in the context of the derivable formulas of an axiomatic system. Hilbert's program attempted to put mathematics on a firm axiomatic basis, but G\u00f6del's incompleteness theorem upended it, showing that every (sufficiently powerful) axiomatic system has undecidable formulas; and so the axiomatization of mathematics is impossible. Nonetheless, mathematics is often imagined to be (as far as its formal content) nothing but set theory in some axiomatization, in the sense that every mathematical statement or proof could be cast into formulas within set theory.\n\nAwards\n\nArguably the most prestigious award in mathematics is the Fields Medal, established in 1936 and awarded every four years (except around World War II) to as many as four individuals. The Fields Medal is often considered a mathematical equivalent to the Nobel Prize.\n\nThe Wolf Prize in Mathematics, instituted in 1978, recognizes lifetime achievement. Another major international award, the Abel Prize, was instituted in 2002 and first awarded in 2003. The Chern Medal was introduced in 2010 to recognize lifetime achievement. These accolades are awarded in recognition of a particular body of work, which may be innovational, or provide a solution to an outstanding problem in an established field.\n\nA famous list of 23 open problems, called \"Hilbert's problems\", was compiled in 1900 by German mathematician David Hilbert. This list achieved great celebrity among mathematicians, and at least thirteen of the problems have now been solved. A new list of seven important problems, titled the \"Millennium Prize Problems\", was published in 2000. Only one of them, the Riemann hypothesis, duplicates one of Hilbert's problems. A solution to any of these problems carries a 1 million dollar reward. Currently, only one of these problems, the Poincar\u00e9 conjecture, has been solved.\n\nSee also\n\n International Mathematical Olympiad\n List of mathematical jargon\n Outline of mathematics\n Lists of mathematics topics\n Mathematical sciences\n Mathematics and art\n Mathematics education\n National Museum of Mathematics\n Philosophy of mathematics\n Relationship between mathematics and physics\n Science, technology, engineering, and mathematics\n\nNotes\n\nReferences\n\nBibliography\n\n \n \n \n \n \n .\n\nFurther reading\n\n \n \n \n \n \n \u00a0\u2013 A translated and expanded version of a Soviet mathematics encyclopedia, in ten volumes. Also in paperback and on CD-ROM, and online .\n \n \n \n\n \nFormal sciences\nMain topic articles",
  "Music": "Music is the art of arranging sounds in time through the elements of melody, harmony, rhythm, and timbre. It is one of the universal cultural aspects of all human societies. General definitions of music include common elements such as pitch (which governs melody and harmony), rhythm (and its associated concepts tempo, meter, and articulation), dynamics (loudness and softness), and the sonic qualities of timbre and texture (which are sometimes termed the \"color\" of a musical sound). Different styles or types of music may emphasize, de-emphasize or omit some of these elements. Music is performed with a vast range of instruments and vocal techniques ranging from singing to rapping; there are solely instrumental pieces, solely vocal pieces (such as songs without instrumental accompaniment) and pieces that combine singing and instruments. The word derives from Greek \u03bc\u03bf\u03c5\u03c3\u03b9\u03ba\u03ae (mousik\u00e9; \"(art) of the Muses\").\n\nIn its most general form, the activities describing music as an art form or cultural activity include the creation of works of music (songs, tunes, symphonies, and so on), the criticism of music, the study of the history of music, and the aesthetic examination of music. Ancient Greek and Indian philosophers defined music in two parts: melodies, as tones ordered horizontally, and harmonies as tones ordered vertically. Common sayings such as \"the harmony of the spheres\" and \"it is music to my ears\" point to the notion that music is often ordered and pleasant to listen to. However, 20th-century composer John Cage thought that any sound can be music, saying, for example, \"There is no noise, only sound.\"\n\nThe creation, performance, significance, and even the definition of music vary according to culture and social context. Indeed, throughout history, some new forms or styles of music have been criticized as \"not being music\", including Beethoven's Grosse Fuge string quartet in 1825, early jazz in the beginning of the 1900s and hardcore punk in the 1980s. There are many types of music, including popular music, traditional music, art music, music written for religious ceremonies, and work songs such as chanteys. Music ranges from strictly organized compositions\u2014such as Classical music symphonies from the 1700s and 1800s\u2014through to spontaneously played improvisational music such as jazz, and avant-garde styles of chance-based contemporary music from the 20th and 21st centuries.\n\nMusic can be divided into genres (e.g., country music) and genres can be further divided into subgenres (e.g., alternative country and country pop are two of the many country subgenres), although the dividing lines and relationships between music genres are often subtle, sometimes open to personal interpretation, and occasionally controversial. For example, it can be hard to draw the line between some early 1980s hard rock and heavy metal. Within the arts, music may be classified as a performing art, a fine art, or as an auditory art. Music may be played or sung and heard live at a rock concert or orchestra performance, heard live as part of a dramatic work (a music theater show or opera), or it may be recorded and listened to on a radio, MP3 player, CD player, smartphone or as film score or TV show.\n\nIn many cultures, music is an important part of people's way of life, as it plays a key role in  religious rituals, rite of passage ceremonies (e.g., graduation and marriage), social activities (e.g., dancing) and cultural activities ranging from amateur karaoke singing to playing in an amateur funk band or singing in a community choir. People may make music as a hobby, like a teen playing cello in a youth orchestra, or work as a professional musician or singer. The music industry includes the individuals who create new songs and musical pieces (such as songwriters and composers), individuals who perform music (which include orchestra, jazz band and rock band musicians, singers and conductors), individuals who record music (music producers and sound engineers), individuals who organize concert tours, and individuals who sell recordings, sheet music, and scores to customers. Even once a song or piece has been performed, music critics, music journalists, and music scholars may assess and evaluate the piece and its performance.\n\nEtymology\n\nThe word 'music' is derived from Ancient Greek  () '(art) of the Muses'. In Greek mythology, the nine Muses were the goddesses who inspired literature, science, and the arts and who were the source of the knowledge embodied in the poetry, song-lyrics, and myths in the Greek culture. According to the Online Etymology Dictionary, the term music is derived from \"mid-13c., , from Old French  (12c.) and directly from Latin  'the art of music', also including poetry (also [the] source of Spanish , Italian , Old High German , German , Dutch , Danish ).\" This is derived from the \"...Greek  (techne) '(art) of the Muses,' from fem. of  'pertaining to the Muses', from  'Muse' (see muse (n.)). Modern spelling [dates] from [the] 1630s. In classical Greece, [the term 'music' refers to] any art in which the Muses presided, but especially music and lyric poetry.\"\n\nArt and entertainment\n\nMusic is composed and performed for many purposes, ranging from aesthetic pleasure, religious or ceremonial purposes, or as an entertainment product for the marketplace. When music was only available through sheet music scores, such as during the Classical and Romantic eras, music lovers would buy the sheet music of their favourite pieces and songs so that they could perform them at home on the piano. With the advent of the phonograph, records of popular songs, rather than sheet music became the dominant way that music lovers would enjoy their favourite songs. With the advent of home tape recorders in the 1980s and digital music in the 1990s, music lovers could make tapes or playlists of their favourite songs and take them with them on a portable cassette player or MP3 player. Some music lovers create mix tapes of their favourite songs, which serve as a \"self-portrait, a gesture of friendship, prescription for an ideal party... [and] an environment consisting solely of what is most ardently loved\".\n\nAmateur musicians can compose or perform music for their own pleasure, and derive their income elsewhere. Professional musicians are employed by a range of institutions and organisations, including armed forces (in marching bands, concert bands and popular music groups), churches and synagogues, symphony orchestras, broadcasting or film production companies, and music schools. Professional musicians sometimes work as freelancers or session musicians, seeking contracts and engagements in a variety of settings. There are often many links between amateur and professional musicians. Beginning amateur musicians take lessons with professional musicians. In community settings, advanced amateur musicians perform with professional musicians in a variety of ensembles such as community concert bands and community orchestras.\n\nA distinction is often made between music performed for a live audience and music that is performed in a studio so that it can be recorded and distributed through the music retail system or the broadcasting system. However, there are also many cases where a live performance in front of an audience is also recorded and distributed. Live concert recordings are popular in both classical music and in popular music forms such as rock, where illegally taped live concerts are prized by music lovers. In the jam band scene, live, improvised jam sessions are preferred to studio recordings.\n\nComposition\n\n\"Composition\" is the act or practice of creating a song, an instrumental music piece, a work with both singing and instruments, or another type of music. In many cultures, including Western classical music, the act of composing also includes the creation of music notation, such as a sheet music \"score\", which is then performed by the composer or by other singers or musicians. In popular music and traditional music, the act of composing, which is typically called songwriting, may involve the creation of a basic outline of the song, called the lead sheet, which sets out the melody, lyrics and chord progression. In classical music, the composer typically orchestrates his or her own compositions, but in musical theatre and in pop music, songwriters may hire an arranger to do the orchestration. In some cases, a songwriter may not use notation at all, and instead, compose the song in her mind and then play or record it from memory. In jazz and popular music, notable recordings by influential performers are given the weight that written scores play in classical music.\n\nEven when music is notated relatively precisely, as in classical music, there are many decisions that a performer has to make, because notation does not specify all of the elements of music precisely. The process of deciding how to perform music that has been previously composed and notated is termed \"interpretation\". Different performers' interpretations of the same work of music can vary widely, in terms of the tempos that are chosen and the playing or singing style or phrasing of the melodies. Composers and songwriters who present their own music are interpreting their songs, just as much as those who perform the music of others. The standard body of choices and techniques present at a given time and a given place is referred to as performance practice, whereas interpretation is generally used to mean the individual choices of a performer.\n\nAlthough a musical composition often uses musical notation and has a single author, this is not always the case. A work of music can have multiple composers, which often occurs in popular music when a band collaborates to write a song, or in musical theatre, when one person writes the melodies, a second person writes the lyrics, and a third person orchestrates the songs. In some styles of music, such as the blues, a composer/songwriter may create, perform and record new songs or pieces without ever writing them down in music notation. A piece of music can also be composed with words, images, or computer programs that explain or notate how the singer or musician should create musical sounds. Examples range from avant-garde music that uses graphic notation, to text compositions such as Aus den sieben Tagen, to computer programs that select sounds for musical pieces. Music that makes heavy use of randomness and chance is called aleatoric music, and is associated with contemporary composers active in the 20th century, such as John Cage, Morton Feldman, and Witold Lutos\u0142awski. A more commonly known example of chance-based music is the sound of wind chimes jingling in a breeze.\n\nThe study of composition has traditionally been dominated by examination of methods and practice of Western classical music, but the definition of composition is broad enough to include the creation of popular music and traditional music songs and instrumental pieces as well as spontaneously improvised works like those of free jazz performers and African percussionists such as Ewe drummers.\n\nNotation\n\nIn the 2000s, music notation typically means the written expression of music notes and rhythms on paper using symbols. When music is written down, the pitches and rhythm of the music, such as the notes of a melody, are notated. Music notation also often provides instructions on how to perform the music. For example, the sheet music for a song may state that the song is a \"slow blues\" or a \"fast swing\", which indicates the tempo and the genre.  To read music notation, a person must have an understanding of music theory, harmony and the performance practice associated with a particular song or piece's genre.\n\nWritten notation varies with the style and period of music. In the 2000s, notated music is produced as sheet music or, for individuals with computer scorewriter programs, as an image on a computer screen. In ancient times, music notation was put onto stone or clay tablets. To perform music from notation, a singer or instrumentalist requires an understanding of the rhythmic and pitch elements embodied in the symbols and the performance practice that is associated with a piece of music or a genre. In genres requiring musical improvisation, the performer often plays from music where only the chord changes and form of the song are written, requiring the performer to have a great understanding of the music's structure, harmony and the styles of a particular genre (e.g., jazz or country music).\n\nIn Western art music, the most common types of written notation are scores, which include all the music parts of an ensemble piece, and parts, which are the music notation for the individual performers or singers. In popular music, jazz, and blues, the standard musical notation is the lead sheet, which notates the melody, chords, lyrics (if it is a vocal piece), and structure of the music. Fake books are also used in jazz; they may consist of lead sheets or simply chord charts, which permit rhythm section members to improvise an accompaniment part to jazz songs. Scores and parts are also used in popular music and jazz, particularly in large ensembles such as jazz \"big bands.\" In popular music, guitarists and electric bass players often read music notated in tablature (often abbreviated as \"tab\"), which indicates the location of the notes to be played on the instrument using a diagram of the guitar or bass fingerboard. Tablature was also used in the Baroque era to notate music for the lute, a stringed, fretted instrument.\n\nImprovisation\n\nMusical improvisation is the creation of spontaneous music, often within (or based on) a pre-existing harmonic framework or chord progression. Improvisers use the notes of the chord, various scales that are associated with each chord, and chromatic ornaments and passing tones which may be neither chord tones nor from the typical scales associated with a chord. Musical improvisation can be done with or without preparation. Improvisation is a major part of some types of music, such as blues, jazz, and jazz fusion, in which instrumental performers improvise solos, melody lines, and accompaniment parts.\n\nIn the Western art music tradition, improvisation was an important skill during the Baroque era and during the Classical era. In the Baroque era, performers improvised ornaments, and basso continuo keyboard players improvised chord voicings based on figured bass notation. As well, the top soloists were expected to be able to improvise pieces such as preludes. In the Classical era, solo performers and singers improvised virtuoso cadenzas during concerts.\n\nHowever, in the 20th and early 21st century, as \"common practice\" Western art music performance became institutionalized in symphony orchestras, opera houses, and ballets, improvisation has played a smaller role, as more and more music was notated in scores and parts for musicians to play. At the same time, some 20th and 21st century art music composers have increasingly included improvisation in their creative work. In Indian classical music, improvisation is a core component and an essential criterion of performances.\n\nTheory\n\nMusic theory encompasses the nature and mechanics of music. It often involves identifying patterns that govern composers' techniques and examining the language and notation of music. In a grand sense, music theory distills and analyzes the parameters or elements of music \u2013 rhythm, harmony (harmonic function), melody, structure, form, and texture. Broadly, music theory may include any statement, belief, or conception of or about music. People who study these properties are known as music theorists, and they typically work as professors in colleges, universities, and music conservatories. Some have applied acoustics, human physiology, and psychology to the explanation of how and why music is perceived. Music theorists publish their research in music theory journals and university press books.\n\nElements\n\nMusic has many different fundamentals or elements. Depending on the definition of \"element\" being used, these can include pitch, beat or pulse, tempo, rhythm, melody, harmony, texture, style, allocation of voices, timbre or color, dynamics, expression, articulation, form, and structure. The elements of music feature prominently in the music curriculums of Australia, the UK, and the US. All three curriculums identify pitch, dynamics, timbre, and texture as elements, but the other identified elements of music are far from universally agreed upon. Below is a list of the three official versions of the \"elements of music\":\n Australia: pitch, timbre, texture, dynamics and expression, rhythm, form and structure.\n UK: pitch, timbre, texture, dynamics, duration, tempo, structure.\n USA: pitch, timbre, texture, dynamics, rhythm, form, harmony, style/articulation.\n\nIn relation to the UK curriculum, in 2013 the term: \"appropriate musical notations\" was added to their list of elements and the title of the list was changed from the \"elements of music\" to the \"inter-related dimensions of music\". The inter-related dimensions of music are listed as: pitch, duration, dynamics, tempo, timbre, texture, structure, and appropriate musical notations.\n\nThe phrase \"the elements of music\" is used in a number of different contexts. The two most common contexts can be differentiated by describing them as the \"rudimentary elements of music\" and the \"perceptual elements of music\".\n\nRudimentary\nIn the 1800s, the phrases \"the elements of music\" and \"the rudiments of music\" were used interchangeably.  The elements described in these documents refer to aspects of music that are needed in order to become a musician, Recent writers such as Espie Estrella seem to be using the phrase \"elements of music\" in a similar manner. A definition which most accurately reflects this usage is: \"the rudimentary principles of an art, science, etc.: the elements of grammar.\" The UK's curriculum switch to the \"inter-related dimensions of music\" seems to be a move back to using the rudimentary elements of music.\n\nPerceptual\nSince the emergence of the study of psychoacoustics in the 1930s, most lists of elements of music have related more to how we hear music than how we learn to play it or study it. C.E. Seashore, in his book Psychology of Music, identified four \"psychological attributes of sound\". These were: \"pitch, loudness, time, and timbre\" (p.\u00a03). He did not call them the \"elements of music\" but referred to them as \"elemental components\" (p.\u00a02). Nonetheless, these elemental components link precisely with four of the most common musical elements: \"Pitch\" and \"timbre\" match exactly, \"loudness\" links with dynamics, and \"time\" links with the time-based elements of rhythm, duration, and tempo. This usage of the phrase \"the elements of music\" links more closely with Webster's New 20th Century Dictionary definition of an element as: \"a substance which cannot be divided into a simpler form by known methods\" and educational institutions' lists of elements generally align with this definition as well.\n\nAlthough writers of lists of \"rudimentary elements of music\" can vary their lists depending on their personal (or institutional) priorities, the perceptual elements of music should consist of an established (or proven) list of discrete elements which can be independently manipulated to achieve an intended musical effect. It seems at this stage that there is still research to be done in this area.\n\nA slightly different way of approaching the identification of the elements of music, is to identify the \"elements of sound\" as:  pitch, duration, loudness, timbre, sonic texture and  spatial location, and then to define the \"elements of music\" as: sound, structure, and artistic intent.\n\nDescriptions\n\nPitch and melody\nPitch is an aspect of a sound that we can hear, reflecting whether one musical sound, note, or tone is \"higher\" or \"lower\" than another musical sound, note, or tone. We can talk about the highness or lowness of pitch in the more general sense, such as the way a listener hears a piercingly high piccolo note or whistling tone as higher in pitch than a deep thump of a bass drum. We also talk about pitch in the precise sense associated with musical melodies, basslines and chords. Precise pitch can only be determined in sounds that have a frequency that is clear and stable enough to distinguish from noise. For example, it is much easier for listeners to discern the pitch of a single note played on a piano than to try to discern the pitch of a crash cymbal that is struck.\n\nA melody (also called a \"tune\") is a series of pitches (notes) sounding in succession (one after the other), often in a rising and falling pattern. The notes of a melody are typically created using pitch systems such as scales or modes. Melodies also often contain notes from the chords used in the song. The melodies in simple folk songs and traditional songs may use only the notes of a single scale, the scale associated with the tonic note or key of a given song. For example, a folk song in the key of C (also referred to as C major) may have a melody that uses only the notes of the C major scale (the individual notes C, D, E, F, G, A, B, and C; these are the \"white notes\" on a piano keyboard. On the other hand, Bebop-era jazz from the 1940s and contemporary music from the 20th and 21st centuries may use melodies with many chromatic notes (i.e., notes in addition to the notes of the major scale; on a piano, a chromatic scale would include all the notes on the keyboard, including the \"white notes\" and \"black notes\" and unusual scales, such as the whole tone scale (a whole tone scale in the key of C would contain the notes C, D, E, F, G and A). A low, deep musical line played by bass instruments such as double bass, electric bass, or tuba is called a bassline.\n\nHarmony and chords\n\nHarmony refers to the \"vertical\" sounds of pitches in music, which means pitches that are played or sung together at the same time to create a chord. Usually, this means the notes are played at the same time, although harmony may also be implied by a melody that outlines a harmonic structure (i.e., by using melody notes that are played one after the other, outlining the notes of a chord). In music written using the system of major-minor tonality (\"keys\"), which includes most classical music written from 1600 to 1900 and most Western pop, rock, and traditional music, the key of a piece determines the \"home note\" or tonic to which the piece generally resolves, and the character (e.g. major or minor) of the scale in use. Simple classical pieces and many pop and traditional music songs are written so that all the music is in a single key. More complex Classical, pop, and traditional music songs and pieces may have two keys (and in some cases three or more keys). Classical music from the Romantic era (written from about 1820\u20131900) often contains multiple keys, as does jazz, especially Bebop jazz from the 1940s, in which the key or \"home note\" of a song may change every four bars or even every two bars.\n\nRhythm\nRhythm is the arrangement of sounds and silences in time. Meter animates time in regular pulse groupings, called measures or bars, which in Western classical, popular, and traditional music often group notes in sets of two (e.g., 2/4 time), three (e.g., 3/4 time, also known as Waltz time, or 3/8 time), or four (e.g., 4/4 time). Meters are made easier to hear because songs and pieces often (but not always) place an emphasis on the first beat of each grouping. Notable exceptions exist, such as the backbeat used in much Western pop and rock, in which a song that uses a measure that consists of four beats (called 4/4 time or common time) will have accents on beats two and four, which are typically performed by the drummer on the snare drum, a loud and distinctive-sounding percussion instrument. In pop and rock, the rhythm parts of a song are played by the rhythm section, which includes chord-playing instruments (e.g., electric guitar, acoustic guitar, piano, or other keyboard instruments), a bass instrument (typically electric bass or for some styles such as jazz and bluegrass, double bass) and a drum kit player.\n\nTexture\nMusical texture is the overall sound of a piece of music or song.  The texture of a piece or song is determined by how the melodic, rhythmic, and harmonic materials are combined in a composition, thus determining the overall nature of the sound in a piece. Texture is often described in regard to the density, or thickness, and range, or width, between lowest and highest pitches, in relative terms as well as more specifically distinguished according to the number of voices, or parts, and the relationship between these voices (see common types below). For example, a thick texture contains many 'layers' of instruments. One of these layers could be a string section or another brass. The thickness also is affected by the amount and the richness of the instruments. Texture is commonly described according to the number of and relationship between parts or lines of music:\n monophony: a single melody (or \"tune\") with neither instrumental accompaniment nor a harmony part. A mother singing a lullaby to her baby would be an example.\n heterophony: two or more instruments or singers playing/singing the same melody, but with each performer slightly varying the rhythm or speed of the melody or adding different ornaments to the melody. Two bluegrass fiddlers playing the same traditional fiddle tune together will typically each vary the melody by some degree and each add different ornaments.\n polyphony: multiple independent melody lines that interweave together, which are sung or played at the same time. Choral music written in the Renaissance music era was typically written in this style. A round, which is a song such as \"Row, Row, Row Your Boat\", which different groups of singers all start to sing at a different time, is an example of polyphony.\n homophony: a clear melody supported by chordal accompaniment. Most Western popular music songs from the 19th century onward are written in this texture.\n\nMusic that contains a large number of independent parts (e.g., a double concerto accompanied by 100 orchestral instruments with many interweaving melodic lines) is generally said to have a \"thicker\" or \"denser\" texture than a work with few parts (e.g., a solo flute melody accompanied by a single cello).\n\nTimbre or \"tone color\"\nTimbre, sometimes called \"color\" or \"tone color\" is the quality or sound of a voice or instrument. Timbre is what makes a particular musical sound different from another, even when they have the same pitch and loudness. For example, a 440\u00a0Hz A note sounds different when it is played on oboe, piano, violin, or electric guitar. Even if different players of the same instrument play the same note, their notes might sound different due to differences in instrumental technique (e.g., different embouchures), different types of accessories (e.g., mouthpieces for brass players, reeds for oboe and bassoon players) or strings made out of different materials for string players (e.g., gut strings versus steel strings). Even two instrumentalists playing the same note on the same instrument (one after the other) may sound different due to different ways of playing the instrument (e.g., two string players might hold the bow differently).\n\nThe physical characteristics of sound that determine the perception of timbre include the spectrum, envelope, and overtones of a note or musical sound. For electric instruments developed in the 20th century, such as electric guitar, electric bass and electric piano, the performer can also change the tone by adjusting equalizer controls, tone controls on the instrument, and by using electronic effects units such as distortion pedals. The tone of the electric Hammond organ is controlled by adjusting drawbars.\n\nExpression\n\nExpressive qualities are those elements in music that create change in music without changing the main pitches or substantially changing the rhythms of the melody and its accompaniment. Performers, including singers and instrumentalists, can add musical expression to a song or piece by adding phrasing, by adding effects such as vibrato (with voice and some instruments, such as guitar, violin, brass instruments, and woodwinds), dynamics (the loudness or softness of piece or a section of it), tempo fluctuations (e.g., ritardando or accelerando, which are, respectively slowing down and speeding up the tempo), by adding pauses or fermatas on a cadence, and by changing the articulation of the notes (e.g., making notes more pronounced or accented, by making notes more legato, which means smoothly connected, or by making notes shorter).\n\nExpression is achieved through the manipulation of pitch (such as inflection, vibrato, slides etc.), volume (dynamics, accent, tremolo etc.), duration (tempo fluctuations, rhythmic changes, changing note duration such as with legato and staccato,  etc.), timbre (e.g. changing vocal timbre from a light to a resonant voice) and sometimes even texture (e.g. doubling the bass note for a richer effect in a piano piece). Expression therefore can be seen as a manipulation of all elements in order to convey \"an indication of mood, spirit, character etc.\" and as such cannot be included as a unique perceptual element of music, although it can be considered an important rudimentary element of music.\n\nForm\n\nIn music, form describes the overall structure or plan of a song or piece of music, and it describes the layout of a composition as divided into sections. In the early 20th century, Tin Pan Alley songs and Broadway musical songs were often in AABA 32 bar form, in which the A sections repeated the same eight bar melody (with variation) and the B section provided a contrasting melody or harmony for eight bars. From the 1960s onward, Western pop and rock songs are often in verse-chorus form, which comprises a sequence of verse and chorus (\"refrain\") sections, with new lyrics for most verses and repeating lyrics for the choruses. Popular music often makes use of strophic form, sometimes in conjunction with the twelve bar blues.\n\nIn the tenth edition of The Oxford Companion to Music, Percy Scholes defines musical form as \"a series of strategies designed to find a successful mean between the opposite extremes of unrelieved repetition and unrelieved alteration.\" Examples of common forms of Western music include the fugue, the invention, sonata-allegro, canon, strophic, theme and variations, and rondo.\n\nScholes states that European classical music had only six stand-alone forms: simple binary, simple ternary, compound binary, rondo, air with variations, and fugue (although musicologist Alfred Mann emphasized that the fugue is primarily a method of composition that has sometimes taken on certain structural conventions.)\n\nWhere a piece cannot readily be broken down into sectional units (though it might borrow some form from a poem, story or programme), it is said to be through-composed. Such is often the case with a fantasia, prelude, rhapsody, etude (or study), symphonic poem, Bagatelle, impromptu, etc. Professor Charles Keil classified forms and formal detail as \"sectional, developmental, or variational.\"\n\nAnalysis of styles\n\nSome styles of music place an emphasis on certain of these fundamentals, while others place less emphasis on certain elements. To give one example, while Bebop-era jazz makes use of very complex chords, including altered dominants and challenging chord progressions, with chords changing two or more times per bar and keys changing several times in a tune, funk places most of its emphasis on rhythm and groove, with entire songs based on a vamp on a single chord. While Romantic era classical music from the mid- to late-1800s makes great use of dramatic changes of dynamics, from whispering pianissimo sections to thunderous fortissimo sections, some entire Baroque dance suites for harpsichord from the early 1700s may use a single dynamic. To give another example, while some art music pieces, such as symphonies are very long, some pop songs are just a few minutes long.\n\nHistory\n\nPrehistory\nPrehistoric music can only be theorized based on findings from paleolithic archaeology sites. Flutes are often discovered, carved from bones in which lateral holes have been pierced; these are thought to have been blown at one end like the Japanese shakuhachi. The Divje Babe flute, carved from a cave bear femur, is thought to be at least 40,000 years old, though there is considerable debate surrounding whether it is truly a musical instrument or an object formed by animals. Instruments such as the seven-holed flute and various types of stringed instruments, such as the Ravanahatha, have been recovered from the Indus Valley Civilization archaeological sites. India has one of the oldest musical traditions in the world\u2014references to Indian classical music (marga) are found in the Vedas, ancient scriptures of the Hindu tradition. The earliest and largest collection of prehistoric musical instruments was found in China and dates back to between 7000 and 6600\u00a0BC. The \"Hurrian Hymn to Nikkal\", found on clay tablets that date back to approximately 1400\u00a0BC, is the oldest surviving notated work of music.\n\nAncient Egypt\n\nThe earliest material and representational evidence of Egyptian musical instruments dates to the Predynastic period, but the evidence is more securely attested in the Old Kingdom when harps, flutes and double clarinets were played. Percussion instruments, lyres and lutes were added to orchestras by the Middle Kingdom. Cymbals frequently accompanied music and dance, much as they still do in Egypt today. Egyptian folk music, including the traditional Sufi dhikr rituals, are the closest contemporary music genre to ancient Egyptian music, having preserved many of its features, rhythms and instruments.\n\nAsian cultures\n\nAsian music covers a vast swath of music cultures surveyed in the articles on Arabia, Central Asia, East Asia, South Asia, and Southeast Asia. Several have traditions reaching into antiquity.\n\nIndian classical music is one of the oldest musical traditions in the world. The Indus Valley civilization has sculptures that show dance and old musical instruments, like the seven holed flute. Various types of stringed instruments and drums have been recovered from Harappa and Mohenjo Daro by excavations carried out by Sir Mortimer Wheeler. The Rigveda has elements of present Indian music, with a musical notation to denote the metre and the mode of chanting. Indian classical music (marga) is monophonic, and based on a single melody line or raga rhythmically organized through talas. Silappadhikaram by Ilango Adigal provides information about how new scales can be formed by modal shifting of the tonic from an existing scale. Present day Hindi music was influenced by Persian traditional music and Afghan Mughals. Carnatic music, popular in the southern states, is largely devotional; the majority of the songs are addressed to the Hindu deities. There are also many songs emphasising love and other social issues.\n\nIndonesian music has been formed since the Bronze Age culture migrated to the Indonesian archipelago in the 2nd to 3rd centuries BC. Indonesian traditional music often uses percussion instruments, especially kendang and gongs. Some of them developed elaborate and distinctive musical instruments, such as the sasando stringed instrument on the island of Rote, the Sundanese angklung, and the complex and sophisticated Javanese and Balinese gamelan orchestras. Indonesia is the home of gong chime, gong chime is a general term for a set of small, high pitched pot gongs. Gongs are usually placed in order of note, with the boss up on a string held in a low wooden frame. The most popular and famous form of Indonesian music is probably gamelan, an ensemble of tuned percussion instruments that include metallophones, drums, gongs and spike fiddles along with bamboo suling.\n\nChinese classical music, the traditional art or court music of China, has a history stretching over around three thousand years. It has its own unique systems of musical notation, as well as musical tuning and pitch, musical instruments and styles or musical genres. Chinese music is pentatonic-diatonic, having a scale of twelve notes to an octave (5\u00a0+\u00a07\u00a0=\u00a012) as does European-influenced music.\n\nAncient Greece\n\nMusic was an important part of social and cultural life in ancient Greece, in fact it was one of the main subjects taught to children. Musical education was considered to be important for the development of an individual's soul. Musicians and singers played a prominent role in Greek theater and the ones who received a musical education were seen as nobles and in perfect harmony (as we can read in the Republic, Plato) Mixed-gender choruses performed for entertainment, celebration, and spiritual ceremonies. Holy Ancient Greek music will be considered an example of perfection and purity. Instruments included the double-reed aulos and a plucked string instrument, the lyre, principally the special kind called a kithara. Music was an important part of education, and boys were taught music starting at age six. Greek musical literacy created a flowering of music development. Greek music theory included the Greek musical modes, that eventually became the basis for Western religious and classical music. Later, influences from the Roman Empire, Eastern Europe, and the Byzantine Empire changed Greek music. The Seikilos epitaph is the oldest surviving example of a complete musical composition, including musical notation, from anywhere in the world. The oldest surviving work written on the subject of music theory is Harmonika Stoicheia by Aristoxenus.\n\nWestern classical\n\nMiddle Ages\n\nThe medieval era (476 to 1400), which took place during the Middle Ages, started with the introduction of monophonic (single melodic line) chanting into Roman Catholic Church services. Musical notation was used since Ancient times in Greek culture, but in the Middle Ages, notation was first introduced by the Catholic church so that the chant melodies could be written down, to facilitate the use of the same melodies for religious music across the entire Catholic empire. The only European Medieval repertory that has been found in written form from before 800 is the monophonic liturgical plainsong chant of the Roman Catholic Church, the central tradition of which was called Gregorian chant. Alongside these traditions of sacred and church music there existed a vibrant tradition of secular song (non-religious songs). Examples of composers from this period are L\u00e9onin, P\u00e9rotin, Guillaume de Machaut, and Walther von der Vogelweide.\n\nRenaissance\n\nRenaissance music (c. 1400 to 1600) was more focused on secular (non-religious) themes, such as courtly love. Around 1450, the printing press was invented, which made printed sheet music much less expensive and easier to mass-produce (prior to the invention of the printing press, all notated music was hand-copied). The increased availability of sheet music helped to spread musical styles more quickly and across a larger area. Musicians and singers often worked for the church, courts and towns. Church choirs grew in size, and the church remained an important patron of music. By the middle of the 15th century, composers wrote richly polyphonic sacred music, in which different melody lines were interwoven simultaneously. Prominent composers from this era include Guillaume Dufay, Giovanni Pierluigi da Palestrina, Thomas Morley, and Orlande de Lassus. As musical activity shifted from the church to the aristocratic courts, kings, queens and princes competed for the finest composers. Many leading important composers came from the Netherlands, Belgium, and northern France. They are called the Franco-Flemish composers. They held important positions throughout Europe, especially in Italy. Other countries with vibrant musical activity included Germany, England, and Spain.\n\nBaroque\n\nThe Baroque era of music took place from 1600 to 1750, as the Baroque artistic style flourished across Europe; and during this time, music expanded in its range and complexity. Baroque music began when the first operas (dramatic solo vocal music accompanied by orchestra) were written. During the Baroque era, polyphonic contrapuntal music, in which multiple, simultaneous independent melody lines were used, remained important (counterpoint was important in the vocal music of the Medieval era). German Baroque composers wrote for small ensembles including strings, brass, and woodwinds, as well as for choirs and keyboard instruments such as pipe organ, harpsichord, and clavichord. During this period several major music forms were defined that lasted into later periods when they were expanded and evolved further, including the fugue, the invention, the sonata, and the concerto. The late Baroque style was polyphonically complex and richly ornamented. Important composers from the Baroque era include Johann Sebastian Bach (Cello suites), George Frideric Handel (Messiah), Georg Philipp Telemann and Antonio Lucio Vivaldi (The Four Seasons).\n\nClassicism\n\nThe music of the Classical period (1730 to 1820) aimed to imitate what were seen as the key elements of the art and philosophy of Ancient Greece and Rome: the ideals of balance, proportion and disciplined expression. (Note: the music from the Classical period should not be confused with Classical music in general, a term which refers to Western art music from the 5th century to the 2000s, which includes the Classical period as one of a number of periods).  Music from the Classical period has a lighter, clearer and considerably simpler texture than the Baroque music which preceded it. The main style was homophony, where a prominent melody and a subordinate chordal accompaniment part are clearly distinct. Classical instrumental melodies tended to be almost voicelike and singable. New genres were developed, and the fortepiano, the forerunner to the modern piano, replaced the Baroque era harpsichord and pipe organ as the main keyboard instrument (though pipe organ continued to be used in sacred music, such as Masses).\n\nImportance was given to instrumental music. It was dominated by further development of musical forms initially defined in the Baroque period: the sonata, the concerto, and the symphony. Others main kinds were the trio, string quartet, serenade and divertimento. The sonata was the most important and developed form. Although Baroque composers also wrote sonatas, the Classical style of sonata is completely distinct. All of the main instrumental forms of the Classical era, from string quartets to symphonies and concertos, were based on the structure of the sonata. The instruments used chamber music and orchestra became more standardized. In place of the basso continuo group of the Baroque era, which consisted of harpsichord, organ or lute along with a number of bass instruments selected at the discretion of the group leader (e.g., viol, cello, theorbo, serpent), Classical chamber groups used specified, standardized instruments (e.g., a string quartet would be performed by two violins, a viola and a cello). The Baroque era improvised chord-playing of the continuo keyboardist or lute player was gradually phased out between 1750 and 1800.\n\nOne of the most important changes made in the Classical period was the development of public concerts. The aristocracy still played a significant role in the sponsorship of concerts and compositions, but it was now possible for composers to survive without being  permanent employees of queens or princes. The increasing popularity of classical music led to a growth in the number and types of orchestras. The expansion of orchestral concerts necessitated the building of large public performance spaces. Symphonic music including symphonies, musical accompaniment to ballet and mixed vocal/instrumental genres such as opera and oratorio became more popular.\n\nThe best known composers of Classicism are Carl Philipp Emanuel Bach, Christoph Willibald Gluck, Johann Christian Bach, Joseph Haydn, Wolfgang Amadeus Mozart, Ludwig van Beethoven and Franz Schubert. Beethoven and Schubert are also considered to be composers in the later part of the Classical era, as it began to move towards Romanticism.\n\nRomanticism\n\nRomantic music (c. 1810 to 1900) from the 19th century had many elements in common with the Romantic styles in literature and painting of the era. Romanticism was an artistic, literary, and intellectual movement was characterized by its emphasis on emotion and individualism as well as glorification of all the past and nature. Romantic music expanded beyond the rigid styles and forms of the Classical era into more passionate, dramatic expressive pieces and songs. Romantic composers such as Wagner and Brahms attempted to increase emotional expression and power in their music to describe deeper truths or human feelings. With symphonic tone poems, composers tried to tell stories and evoke images or landscapes using instrumental music. Some composers promoted nationalistic pride with patriotic orchestral music inspired by folk music. The emotional and expressive qualities of music came to take precedence over tradition.\n\nRomantic composers grew in idiosyncrasy, and went further in the syncretism of exploring different art-forms in a musical context, (such as literature), history (historical figures and legends), or nature itself. Romantic love or longing was a prevalent theme in many works composed during this period. In some cases, the formal structures from the classical period continued to be used (e.g., the sonata form used in string quartets and symphonies), but these forms were expanded and altered. In many cases, new approaches were explored for existing genres, forms, and functions. Also, new forms were created that were deemed better suited to the new subject matter. Composers continued to develop opera and ballet music, exploring new styles and themes.\n\nIn the years after 1800, the music developed by Ludwig van Beethoven and Franz Schubert introduced a more dramatic, expressive style. In Beethoven's case, short motifs, developed organically, came to replace melody as the most significant compositional unit (an example is the distinctive four note figure used in his Fifth Symphony). Later Romantic composers such as Pyotr Ilyich Tchaikovsky, Anton\u00edn Dvo\u0159\u00e1k, and Gustav Mahler used more unusual chords and more dissonance to create dramatic tension. They generated complex and often much longer musical works. During the late Romantic period, composers explored dramatic chromatic alterations of tonality, such as extended chords and altered chords, which created new sound \"colours\". The late 19th century saw a dramatic expansion in the size of the orchestra, and the industrial revolution helped to create better instruments, creating a more powerful sound. Public concerts became an important part of well-to-do urban society. It also saw a new diversity in theatre music, including operetta, and musical comedy and other forms of musical theatre.\n\n20th and 21st century\n\nIn the 19th century, one of the key ways that new compositions became known to the public was by the sales of sheet music, which middle class amateur music lovers would perform at home on their piano or other common instruments, such as violin. With 20th-century music, the invention of new electric technologies such as radio broadcasting and the mass market availability of gramophone records meant that sound recordings of songs and pieces heard by listeners (either on the radio or on their record player) became the main way to learn about new songs and pieces. There was a vast increase in music listening as the radio gained popularity and phonographs were used to replay and distribute music, because whereas in the 19th century, the focus on sheet music restricted access to new music to the middle class and upper-class people who could read music and who owned pianos and instruments, in the 20th century, anyone with a radio or record player could hear operas, symphonies and big bands right in their own living room. This allowed lower-income people, who would never be able to afford an opera or symphony concert ticket to hear this music. It also meant that people could hear music from different parts of the country, or even different parts of the world, even if they could not afford to travel to these locations. This helped to spread musical styles.\n\nThe focus of art music in the 20th century was characterized by exploration of new rhythms, styles, and sounds. The horrors of World War I influenced many of the arts, including music, and some composers began exploring darker, harsher sounds. Traditional music styles such as jazz and folk music were used by composers as a source of ideas for classical music. Igor Stravinsky, Arnold Schoenberg, and John Cage were all influential composers in 20th-century art music. The invention of sound recording and the ability to edit music gave rise to new subgenre of classical music, including the acousmatic and Musique concr\u00e8te schools of electronic composition. Sound recording was also a major influence on the development of popular music genres, because it enabled recordings of songs and bands to be widely distributed. The introduction of the multitrack recording system had a major influence on rock music, because it could do much more than record a band's performance. Using a multitrack system, a band and their music producer could overdub many layers of instrument tracks and vocals, creating new sounds that would not be possible in a live performance.\n\nJazz evolved and became an important genre of music over the course of the 20th century, and during the second half of that century, rock music did the same. Jazz is an American musical artform that originated in the beginning of the 20th century in African American communities in the Southern United States from a confluence of African and European music traditions. The style's West African pedigree is evident in its use of blue notes, improvisation, polyrhythms, syncopation, and the swung note.\n\nRock music is a genre of popular music that developed in the 1960s from 1950s rock and roll, rockabilly, blues, and country music. The sound of rock often revolves around the electric guitar or acoustic guitar, and it uses a strong back beat laid down by a rhythm section. Along with the guitar or keyboards, saxophone and blues-style harmonica are used as soloing instruments. In its \"purest form\", it \"has three chords, a strong, insistent back beat, and a catchy melody\". The traditional rhythm section for popular music is rhythm guitar, electric bass guitar, drums. Some bands also have keyboard instruments such as organ, piano, or, since the 1970s, analog synthesizers. In the 1980s, pop musicians began using digital synthesizers, such as the DX-7 synthesizer, electronic drum machines such as the TR-808 and synth bass devices (such as the TB-303) or synth bass keyboards. In the 1990s, an increasingly large range of computerized hardware musical devices and instruments and software (e.g., digital audio workstations)  were used. In the 2020s, soft synths and computer music apps make it possible for bedroom producers to create and record some types of music, such as electronic dance music in their own home, adding sampled and digital instruments and editing the recording digitally. In the 1990s, some bands in genres such as nu metal began including DJs in their bands. DJs create music by manipulating recorded music on record players or CD players, using a DJ mixer.\n\nInnovation in music technology continued into the 21st century, including the development of isomorphic keyboards and Dynamic Tonality.\n\nPerformance\n\nPerformance is the physical expression of music, which occurs when a song is sung or when a piano piece, electric guitar melody, symphony, drum beat or other musical part is played by musicians. In classical music, a musical work is written in music notation by a composer and then it is performed once the composer is satisfied with its structure and instrumentation. However, as it gets performed, the interpretation of a song or piece can evolve and change. In classical music, instrumental performers, singers or conductors may gradually make changes to the phrasing or tempo of a piece. In popular and traditional music, the performers have a lot more freedom to make changes to the form of a song or piece. As such, in popular and traditional music styles, even when a band plays a cover song, they can make changes to it such as adding a guitar solo to or inserting an introduction.\n\nA performance can either be planned out and rehearsed (practiced)\u2014which is the norm in classical music, with jazz big bands and many popular music styles\u2013or improvised over a chord progression (a sequence of chords), which is the norm in small jazz and blues groups. Rehearsals of orchestras, concert bands and choirs are led by a conductor. Rock, blues and jazz bands are usually led by the bandleader. A rehearsal is a structured repetition of a song or piece by the performers until it can be sung or played correctly and, if it is a song or piece for more than one musician, until the parts are together from a rhythmic and tuning perspective. Improvisation is the creation of a musical idea\u2013a melody or other musical line\u2013created on the spot, often based on scales or pre-existing melodic riffs.\n\nMany cultures have strong traditions of solo performance (in which one singer or instrumentalist performs), such as in Indian classical music, and in the Western art-music tradition. Other cultures, such as in Bali, include strong traditions of group performance. All cultures include a mixture of both, and performance may range from improvised solo playing to highly planned and organised performances such as the modern classical concert, religious processions, classical music festivals or music competitions. Chamber music, which is music for a small ensemble with only a few of each type of instrument, is often seen as more intimate than large symphonic works.\n\nOral and aural tradition\nMany types of music, such as traditional blues and folk music were not written down in sheet music; instead, they were originally preserved in the memory of performers, and the songs were handed down orally, from one musician or singer to another, or aurally, in which a performer learns a song \"by ear\". When the composer of a song or piece is no longer known, this music is often classified as \"traditional\" or as a \"folk song\". Different musical traditions have different attitudes towards how and where to make changes to the original source material, from quite strict, to those that demand improvisation or modification to the music. A culture's history and stories may also be passed on by ear through song.\n\nOrnamentation\n\nIn music, an ornament consists of added notes that provide decoration to a melody, bassline or other musical part. The detail included explicitly in the music notation varies between genres and historical periods. In general, art music notation from the 17th through the 19th centuries required performers to have a great deal of contextual knowledge about performing styles. For example, in the 17th and 18th centuries, music notated for solo performers typically indicated a simple, unadorned melody. Performers were expected to know how to add stylistically appropriate ornaments to add interest to the music, such as trills and turns. Different styles of music use different ornaments. A Baroque flute player might add mordents, which are short notes that are played before the main melody note, either above or below the main melody note. A blues guitarist playing electric guitar might use string bending to add expression; a heavy metal guitar player might use hammer-ons and pull-offs.\n\nIn the 19th century, art music for solo performers may give a general instruction such as to perform the music expressively, without describing in detail how the performer should do this. The performer was expected to know how to use tempo changes, accentuation, and pauses (among other devices) to obtain this \"expressive\" performance style. In the 20th century, art music notation often became more explicit and used a range of markings and annotations to indicate to performers how they should play or sing the piece. In popular music and traditional music styles, performers are expected to know what types of ornaments are stylistically appropriate for a given song or piece, and performers typically add them in an improvised fashion. One exception is note-for-note solos, in which some players precisely recreate a famous version of a solo, such as a guitar solo.\n\nPhilosophy and aesthetics\n\nPhilosophy of music is a subfield of philosophy. The philosophy of music is the study of fundamental questions regarding music. The philosophical study of music has many connections with philosophical questions in metaphysics and aesthetics.\nSome basic questions in the philosophy of music are :\n\n What is the definition of music? (What are the necessary and sufficient conditions for classifying something as music?)\n What is the relationship between music and mind?\n What does music history reveal to us about the world?\n What is the connection between music and emotions?\n What is meaning in relation to music?\n\nIn ancient times, such as with the Ancient Greeks, the aesthetics of music explored the mathematical and cosmological dimensions of rhythmic and harmonic organization. In the 18th century, focus shifted to the experience of hearing music, and thus to questions about its beauty and human enjoyment (plaisir and jouissance) of music. The origin of this philosophic shift is sometimes attributed to Alexander Gottlieb Baumgarten in the 18th century, followed by Immanuel Kant. Through their writing, the ancient term 'aesthetics', meaning sensory perception, received its present-day connotation. In the 2000s, philosophers have tended to emphasize issues besides beauty and enjoyment. For example, music's capacity to express emotion has been a central issue.\n\nIn the 20th century, important contributions were made by Peter Kivy, Jerrold Levinson, Roger Scruton, and Stephen Davies. However, many musicians, music critics, and other non-philosophers have contributed to the aesthetics of music. In the 19th century, a significant debate arose between Eduard Hanslick, a music critic and musicologist, and composer Richard Wagner regarding whether music can express meaning. Harry Partch and some other musicologists, such as Kyle Gann, have studied and tried to popularize microtonal music and the usage of alternate musical scales. Also many modern composers like La Monte Young, Rhys Chatham and Glenn Branca paid much attention to a scale called just intonation.\n\nIt is often thought that music has the ability to affect our emotions, intellect, and psychology; it can assuage our loneliness or incite our passions. The philosopher Plato suggests in The Republic that music has a direct effect on the soul. Therefore, he proposes that in the ideal regime music would be closely regulated by the state (Book VII). In Ancient China, the philosopher Confucius believed that music and rituals or rites are interconnected and harmonious with nature; he stated that music was the harmonization of heaven and earth, while the order was brought by the rites order, making them extremely crucial functions in society.\n\nThere has been a strong tendency in the aesthetics of music to emphasize the paramount importance of compositional structure; however, other issues concerning the aesthetics of music include lyricism, harmony, hypnotism, emotiveness, temporal dynamics, resonance, playfulness, and color (see also musical development).\n\nPsychology\nModern music psychology aims to explain and understand musical behavior and experience. Research in this field and its subfields are primarily empirical; their knowledge tends to advance on the basis of interpretations of data collected by systematic observation of and interaction with human participants. In addition to its focus on fundamental perceptions and cognitive processes, music psychology is a field of research with practical relevance for many areas, including music performance, composition, education, criticism, and therapy, as well as investigations of human aptitude, skill, intelligence, creativity, and social behavior.\n\nNeuroscience\n\nCognitive neuroscience of music is the scientific study of brain-based mechanisms involved in the cognitive processes underlying music. These behaviours include music listening, performing, composing, reading, writing, and ancillary activities. It also is increasingly concerned with the brain basis for musical aesthetics and musical emotion. The field is distinguished by its reliance on direct observations of the brain, using such techniques as functional magnetic resonance imaging (fMRI), transcranial magnetic stimulation (TMS), magnetoencephalography (MEG), electroencephalography (EEG), and positron emission tomography (PET).\n\nCognitive musicology\nCognitive musicology is a branch of cognitive science concerned with computationally modeling musical knowledge with the goal of understanding both music and cognition. The use of computer models provides an exacting, interactive medium in which to formulate and test theories and has roots in artificial intelligence and cognitive science.\n\nThis interdisciplinary field investigates topics such as the parallels between language and music in the brain. Biologically inspired models of computation are often included in research, such as neural networks and evolutionary programs. This field seeks to model how musical knowledge is represented, stored, perceived, performed, and generated. By using a well-structured computer environment, the systematic structures of these cognitive phenomena can be investigated.\n\nPsychoacoustics\n\nPsychoacoustics is the scientific study of sound perception. More specifically, it is the branch of science studying the psychological and physiological responses associated with sound (including speech and music). It can be further categorized as a branch of psychophysics.\n\nEvolutionary musicology\nEvolutionary musicology concerns the \"origins of music, the question of animal song, selection pressures underlying music evolution\", and \"music evolution and human evolution\". It seeks to understand music perception and activity in the context of evolutionary theory. Charles Darwin speculated that music may have held an adaptive advantage and functioned as a protolanguage, a view which has spawned several competing theories of music evolution. An alternate view sees music as a by-product of linguistic evolution; a type of \"auditory cheesecake\" that pleases the senses without providing any adaptive function. This view has been directly countered by numerous music researchers.\n\nCultural effects\n\nAn individual's culture or ethnicity plays a role in their music cognition, including their preferences, emotional reaction, and musical memory. Musical preferences are biased toward culturally familiar musical traditions beginning in infancy, and adults' classification of the emotion of a musical piece depends on both culturally specific and universal structural features. Additionally, individuals' musical memory abilities are greater for culturally familiar music than for culturally unfamiliar music.\n\nSociological aspects\n\nMany ethnographic studies demonstrate that music is a participatory, community-based activity. Music is experienced by individuals in a range of social settings ranging from being alone to attending a large concert, forming a music community, which cannot be understood as a function of individual will or accident; it includes both commercial and non-commercial participants with a shared set of common values. Musical performances take different forms in different cultures and socioeconomic milieus. In Europe and North America, there is often a divide between what types of music are viewed as a \"high culture\" and \"low culture.\" \"High culture\" types of music typically include Western art music such as Baroque, Classical, Romantic, and modern-era symphonies, concertos, and solo works, and are typically heard in formal concerts in concert halls and churches, with the audience sitting quietly in seats.\n\nOther types of music\u2014including, but not limited to, jazz, blues, soul, and country\u2014are often performed in bars, nightclubs, and theatres, where the audience may be able to drink, dance, and express themselves by cheering. Until the later 20th century, the division between \"high\" and \"low\" musical forms was widely accepted as a valid distinction that separated out better quality, more advanced \"art music\" from the popular styles of music heard in bars and dance halls.\n\nHowever, in the 1980s and 1990s, musicologists studying this perceived divide between \"high\" and \"low\" musical genres argued that this distinction is not based on the musical value or quality of the different types of music. Rather, they argued that this distinction was based largely on the socioeconomics standing or social class of the performers or audience of the different types of music. For example, whereas the audience for Classical symphony concerts typically have above-average incomes, the audience for a rap concert in an inner-city area may have below-average incomes. Even though the performers, audience, or venue where non-\"art\" music is performed may have a lower socioeconomic status, the music that is performed, such as blues, rap, punk, funk, or ska may be very complex and sophisticated.\n\nWhen composers introduce styles of music that break with convention, there can be a strong resistance from academic music experts and popular culture. Late-period Beethoven string quartets, Stravinsky ballet scores, serialism, bebop-era jazz, hip hop, punk rock, and electronica have all been considered non-music by some critics when they were first introduced. Such themes are examined in the sociology of music. The sociological study of music, sometimes called sociomusicology, is often pursued in departments of sociology, media studies, or music, and is closely related to the field of ethnomusicology.\n\nRole of women\n\nWomen have played a major role in music throughout history, as composers, songwriters, instrumental performers, singers, conductors, music scholars, music educators, music critics/music journalists and other musical professions. As well, it describes music movements, events and genres related to women, women's issues and feminism. In the 2010s, while women comprise a significant proportion of popular music and classical music singers, and a significant proportion of songwriters (many of them being singer-songwriters), there are few women record producers, rock critics and rock instrumentalists. Although there have been a huge number of women composers in classical music, from the medieval period to the present day, women composers are significantly underrepresented in the commonly performed classical music repertoire, music history textbooks and music encyclopedias; for example, in the Concise Oxford History of Music, Clara Schumann is one of the few female composers who is mentioned.\n\nWomen comprise a significant proportion of instrumental soloists in classical music and the percentage of women in orchestras is increasing. A 2015 article on concerto soloists in major Canadian orchestras, however, indicated that 84% of the soloists with the Orchestre Symphonique de Montreal were men. In 2012, women still made up just 6% of the top-ranked Vienna Philharmonic orchestra. Women are less common as instrumental players in popular music genres such as rock and heavy metal, although there have been a number of notable female instrumentalists and all-female bands. Women are particularly underrepresented in extreme metal genres. In the 1960s pop-music scene, \"[l]ike most aspects of the...music business, [in the 1960s,] songwriting was a male-dominated field. Though there were plenty of female singers on the radio, women ...were primarily seen as consumers:... Singing was sometimes an acceptable pastime for a girl, but playing an instrument, writing songs, or producing records simply wasn't done.\" Young women \"...were not socialized to see themselves as people who create [music].\"\n\nWomen are also underrepresented in orchestral conducting, music criticism/music journalism, music producing, and sound engineering. While women were discouraged from composing in the 19th century, and there are few women musicologists, women became involved in music education \"...to such a degree that women dominated [this field] during the later half of the 19th century and well into the 20th century.\"\n\nAccording to Jessica Duchen, a music writer for London's The Independent, women musicians in classical music are \"...too often judged for their appearances, rather than their talent\" and they face pressure \"...to look sexy onstage and in photos.\" Duchen states that while \"[t]here are women musicians who refuse to play on their looks,...the ones who do tend to be more materially successful.\"\nAccording to the UK's Radio 3 editor, Edwina Wolstencroft, the music industry has long been open to having women in performance or entertainment roles, but women are much less likely to have positions of authority, such as being the conductor of an orchestra. In popular music, while there are many women singers recording songs, there are very few women behind the audio console acting as music producers, the individuals who direct and manage the recording process. One of the most recorded artists is Asha Bhosle, an Indian singer best known as a playback singer in Hindi cinema.\n\nMedia and technology\n\nThe music that composers and songwriters make can be heard through several media; the most traditional way is to hear it live, in the presence of the musicians (or as one of the musicians), in an outdoor or indoor space such as an amphitheatre, concert hall, cabaret room, theatre, pub, or coffeehouse. Since the 20th century, live music can also be broadcast over the radio, television or the Internet, or recorded and listened to on a CD player or Mp3 player.\n\nSome musical styles focus on producing songs and pieces for a live performance, while others focus on producing a recording that mixes together sounds that were never played \"live.\" Even in essentially live styles such as rock, recording engineers often use the ability to edit, splice and mix to produce recordings that may be considered \"better\" than the actual live performance. For example, some singers record themselves singing a melody and then record multiple harmony parts using overdubbing, creating a sound that would be impossible to do live.\n\nTechnology has had an influence on music since prehistoric times, when cave people used simple tools to bore holes into bone flutes 41,000 years ago. Technology continued to influence music throughout the history of music, as it enabled new instruments and music notation reproduction systems to be used, with one of the watershed moments in music notation being the invention of the printing press in the 1400s, which meant music scores no longer had to be hand copied. In the 19th century, music technology led to the development of a more powerful, louder piano and led to the development of new valves brass instruments.\n\nIn the early 20th century (in the late 1920s), as talking pictures emerged in the early 20th century, with their prerecorded musical tracks, an increasing number of moviehouse orchestra musicians found themselves out of work. During the 1920s, live musical performances by orchestras, pianists, and theater organists were common at first-run theaters. With the coming of the talking motion pictures, those featured performances were largely eliminated. The American Federation of Musicians (AFM) took out newspaper advertisements protesting the replacement of live musicians with mechanical playing devices. One 1929 ad that appeared in the Pittsburgh Press features an image of a can labeled \"Canned Music / Big Noise Brand / Guaranteed to Produce No Intellectual or Emotional Reaction Whatever\"\n\nSince legislation introduced to help protect performers, composers, publishers and producers, including the Audio Home Recording Act of 1992 in the United States, and the 1979 revised Berne Convention for the Protection of Literary and Artistic Works in the United Kingdom, recordings and live performances have also become more accessible through computers, devices and Internet in a form that is commonly known as Music-On-Demand.\n\nIn many cultures, there is less distinction between performing and listening to music, since virtually everyone is involved in some sort of musical activity, often in a communal setting. In industrialized countries, listening to music through a recorded form, such as sound recording on record or radio became more common than experiencing live performance, roughly in the middle of the 20th century. By the 1980s, watching music videos was a popular way to listen to music, while also seeing the performers.\n\nSometimes, live performances incorporate prerecorded sounds. For example, a disc jockey uses disc records for scratching, and some 20th-century works have a solo for an instrument or voice that is performed along with music that is prerecorded onto a tape. Some pop bands use recorded backing tracks. Computers and many keyboards can be programmed to produce and play Musical Instrument Digital Interface (MIDI) music. Audiences can also become performers by participating in karaoke, an activity of Japanese origin centered on a device that plays voice-eliminated versions of well-known songs. Most karaoke machines also have video screens that show lyrics to songs being performed; performers can follow the lyrics as they sing over the instrumental tracks.\n\nInternet\n\nThe advent of the Internet and widespread high-speed broadband access has transformed the experience of music, partly through the increased ease of access to recordings of music via streaming video and vastly increased choice of music for consumers. Chris Anderson, in his book The Long Tail: Why the Future of Business Is Selling Less of More, suggests that while the traditional economic model of supply and demand describes scarcity, the Internet retail model is based on abundance. Digital storage costs are low, so a company can afford to make its whole recording inventory available online, giving customers as much choice as possible. It has thus become economically viable to offer music recordings that very few people are interested in. Consumers' growing awareness of their increased choice results in a closer association between listening tastes and social identity, and the creation of thousands of niche markets.\n\nAnother effect of the Internet arose with online communities and social media websites like YouTube and Facebook, a social networking service. These sites make it easier for aspiring singers and amateur bands to distribute videos of their songs, connect with other musicians, and gain audience interest. Professional musicians also use YouTube as a free publisher of promotional material. YouTube users, for example, no longer only download and listen to MP3s, but also actively create their own. According to Don Tapscott and Anthony D. Williams, in their book Wikinomics, there has been a shift from a traditional consumer role to what they call a \"prosumer\" role, a consumer who both creates content and consumes. Manifestations of this in music include the production of mashes, remixes, and music videos by fans.\n\nBusiness\n\nThe music industry refers to the businesses connected with the creation and sale of music. It consists of songwriters and composers who create new songs and musical pieces, music producers and sound engineers who record songs and pieces, record labels and publishers that distribute recorded music products and sheet music internationally and that often control the rights to those products. Some music labels are \"independent,\" while others are subsidiaries of larger corporate entities or international media groups. In the 2000s, the increasing popularity of listening to music as digital music files on MP3 players, iPods, or computers, and of trading music on file sharing websites or buying it online in the form of digital files had a major impact on the traditional music business. Many smaller independent CD stores went out of business as music buyers decreased their purchases of CDs, and many labels had lower CD sales. Some companies did well with the change to a digital format, though, such as Apple's iTunes, an online music store that sells digital files of songs over the Internet.\n\nIntellectual property laws\n\nIn spite of some international copyright treaties, determining which music is in the public domain is complicated by the variety of national copyright laws that may be applicable.  US copyright law formerly protected printed music published after 1923 for 28 years and with renewal for another 28 years, but the Copyright Act of 1976 made renewal automatic, and the Digital Millennium Copyright Act changed the calculation of the copyright term to 70 years after the death of the creator. Recorded sound falls under mechanical licensing, often covered by a confusing patchwork of state laws; most cover versions are licensed through the Harry Fox Agency. Performance rights may be obtained by either performers or the performance venue; the two major organizations for licensing are BMI and ASCAP. Two online sources for public domain music are IMSLP (International Music Score Library Project) and Choral Public Domain Library (CPDL).\n\nEducation\n\nNon-professional\n\nThe incorporation of some music or singing training into general education from preschool to post secondary education is common in North America and Europe. Involvement in playing and singing music is thought to teach basic skills such as concentration, counting, listening, and cooperation while also promoting understanding of language, improving the ability to recall information, and creating an environment more conducive to learning in other areas. In elementary schools, children often learn to play instruments such as the recorder, sing in small choirs, and learn about the history of Western art music and traditional music. Some elementary school children also learn about popular music styles. In religious schools, children sing hymns and other religious music. In secondary schools (and less commonly in elementary schools), students may have the opportunity to perform in some types of musical ensembles, such as choirs (a group of singers), marching bands, concert bands, jazz bands, or orchestras. In some school systems, music lessons on how to play instruments may be provided. Some students also take private music lessons after school with a singing teacher or instrument teacher. Amateur musicians typically learn basic musical rudiments (e.g., learning about musical notation for musical scales and rhythms) and beginner- to intermediate-level singing or instrument-playing techniques.\n\nAt the university level, students in most arts and humanities programs can receive credit for taking a few music courses, which typically take the form of an overview course on the history of music, or a music appreciation course that focuses on listening to music and learning about different musical styles. In addition, most North American and European universities have some types of musical ensembles that students in arts and humanities are able to participate in, such as choirs, marching bands, concert bands, or orchestras. The study of Western art music is increasingly common outside of North America and Europe, such as the Indonesian Institute of the Arts in Yogyakarta, Indonesia, or the classical music programs that are available in Asian countries such as South Korea, Japan, and China. At the same time, Western universities and colleges are widening their curriculum to include music of non-Western cultures, such as the music of Africa or Bali (e.g. Gamelan music).\n\nProfessional\n\nPeople aiming to become professional musicians, singers, composers, songwriters, music teachers and practitioners of other music-related professions such as music history professors, sound engineers, and so on study in specialized post-secondary programs offered by colleges, universities and music conservatories.  Some institutions that train individuals for careers in music offer training in a wide range of professions, as is the case with many of the top U.S. universities, which offer degrees in music performance (including singing and playing instruments), music history, music theory, music composition, music education (for individuals aiming to become elementary or high school music teachers) and, in some cases, conducting. On the other hand, some small colleges may only offer training in a single profession (e.g., sound recording).\n\nWhile most university and conservatory music programs focus on training students in classical music, there are a number of universities and colleges that train musicians for careers as jazz or popular music musicians and composers, with notable U.S. examples including the Manhattan School of Music and the Berklee College of Music. Two important schools in Canada which offer professional jazz training are McGill University and Humber College. Individuals aiming at careers in some types of music, such as heavy metal music, country music or blues are less likely to become professionals by completing degrees or diplomas in colleges or universities. Instead, they typically learn about their style of music by singing or playing in many bands (often beginning in amateur bands, cover bands and tribute bands), studying recordings available on CD, DVD and the Internet and working with already-established professionals in their style of music, either through informal mentoring or regular music lessons. Since the 2000s, the increasing popularity and availability of Internet forums and YouTube \"how-to\" videos have enabled many singers and musicians from metal, blues and similar genres to improve their skills. Many pop, rock and country singers train informally with vocal coaches and singing teachers.\n\nUndergraduate\nUndergraduate university degrees in music, including the Bachelor of Music, the Bachelor of Music Education, and the Bachelor of Arts (with a major in music) typically take about four years to complete. These degrees provide students with a grounding in music theory and music history, and many students also study an instrument or learn singing technique as part of their program. Graduates of undergraduate music programs can seek employment or go on to further study in music graduate programs. Bachelor's degree graduates are also eligible to apply to some graduate programs and professional schools outside of music (e.g., public administration, business administration, library science, and, in some jurisdictions, teacher's college, law school or medical school).\n\nGraduate\nGraduate music degrees include the Master of Music, the Master of Arts (in musicology, music theory or another music field), the Doctor of Philosophy (Ph.D.) (e.g., in musicology or music theory), and more recently, the Doctor of Musical Arts, or DMA. The Master of Music degree, which takes one to two years to complete, is typically awarded to students studying the performance of an instrument, education, voice (singing) or composition. The Master of Arts degree, which takes one to two years to complete and often requires a thesis, is typically awarded to students studying musicology, music history, music theory or ethnomusicology.\n\nThe PhD, which is required for students who want to work as university professors in musicology, music history, or music theory, takes three to five years of study after the master's degree, during which time the student will complete advanced courses and undertake research for a dissertation. The DMA is a relatively new degree that was created to provide a credential for professional performers or composers that want to work as university professors in musical performance or composition. The DMA takes three to five years after a master's degree, and includes advanced courses, projects, and performances. In Medieval times, the study of music was one of the Quadrivium of the seven Liberal Arts and considered vital to higher learning. Within the quantitative Quadrivium, music, or more accurately harmonics, was the study of rational proportions.\n\nMusicology\nMusicology, the academic study of the subject of music, is studied in universities and music conservatories. The earliest definitions from the 19th century defined three sub-disciplines of musicology: systematic musicology, historical musicology, and comparative musicology or ethnomusicology. In 2010-era scholarship, one is more likely to encounter a division of the discipline into music theory, music history, and ethnomusicology. Research in musicology has often been enriched by cross-disciplinary work, for example in the field of psychoacoustics. The study of music of non-Western cultures, and the cultural study of music, is called ethnomusicology. Students can pursue the undergraduate study of musicology, ethnomusicology, music history, and music theory through several different types of degrees, including bachelor's degrees, master's degrees and PhD degrees.\n\nMusic theory\nMusic theory is the study of music, generally in a highly technical manner outside of other disciplines. More broadly it refers to any study of music, usually related in some form with compositional concerns, and may include mathematics, physics, and anthropology. What is most commonly taught in beginning music theory classes are guidelines to write in the style of the common practice period, or tonal music. Theory, even of music of the common practice period, may take many other forms. Musical set theory is the application of mathematical set theory to music, first applied to atonal music. Speculative music theory, contrasted with analytic music theory, is devoted to the analysis and synthesis of music materials, for example tuning systems, generally as preparation for composition.\n\nZoomusicology\nZoomusicology is the study of the music of non-human animals, or the musical aspects of sounds produced by non-human animals. As George Herzog (1941) asked, \"do animals have music?\" Fran\u00e7ois-Bernard M\u00e2che's Musique, mythe, nature, ou les Dauphins d'Arion (1983), a study of \"ornitho-musicology\" using a technique of Nicolas Ruwet's Langage, musique, po\u00e9sie (1972) paradigmatic segmentation analysis, shows that bird songs are organised according to a repetition-transformation principle. Jean-Jacques Nattiez (1990), argues that \"in the last analysis, it is a human being who decides what is and is not musical, even when the sound is not of human origin. If we acknowledge that sound is not organised and conceptualised (that is, made to form music) merely by its producer, but by the mind that perceives it, then music is uniquely human.\"\n\nEthnomusicology\n\nIn the West, much of the history of music that is taught deals with the Western civilization's art music, which is known as classical music. The history of music in non-Western cultures (\"world music\" or the field of \"ethnomusicology\"), which typically covers music from\nAfrica and Asia is also taught in Western universities. This includes the documented classical traditions of Asian countries outside the influence of Western Europe, as well as the folk or indigenous music of various other cultures. Popular or folk styles of music in non-Western countries varied widely from culture to culture, and from period to period. Different cultures emphasised different instruments, techniques, singing styles and uses for music. Music has been used for entertainment, ceremonies, rituals, religious purposes and for practical and artistic communication. Non-Western music has also been used for propaganda purposes, as was the case with Chinese opera during the Cultural Revolution.\n\nThere is a host of music classifications for non-Western music, many of which are caught up in the argument over the definition of music. Among the largest of these is the division between classical music (or \"art\" music), and popular music (or commercial music \u2013 including non-Western styles of rock, country, and pop music-related styles). Some genres do not fit neatly into one of these \"big two\" classifications, (such as folk music, world music, or jazz-related music).\n\nAs world cultures have come into greater global contact, their indigenous musical styles have often merged with other styles, which produces new styles. For example, the United States bluegrass style contains elements from Anglo-Irish, Scottish, Irish, German and African instrumental and vocal traditions, which were able to fuse in the United States' multi-ethnic \"melting pot\" society. Some types of world music contain a mixture of non-Western indigenous styles with Western pop music elements. Genres of music are determined as much by tradition and presentation as by the actual music. Some works, like George Gershwin's Rhapsody in Blue, are claimed by both jazz and classical music, while Gershwin's Porgy and Bess and Leonard Bernstein's West Side Story are claimed by both opera and the Broadway musical tradition. Many current music festivals for non-Western music include bands and singers from a particular musical genre, such as world music.\n\nIndian music, for example, is one of the oldest and longest living types of music, and is still widely heard and performed in South Asia, as well as internationally (especially since the 1960s). Indian music has mainly three forms of classical music, Hindustani, Carnatic, and Dhrupad styles. It has also a large repertoire of styles, which involve only percussion music such as the talavadya performances famous in South India.\n\nTherapy\n\nMusic therapy is an interpersonal process in which a trained therapist uses music and all of its facets\u2014physical, emotional, mental, social, aesthetic, and spiritual\u2014to help clients to improve or maintain their health. In some instances, the client's needs are addressed directly through music; in others they are addressed through the relationships that develop between the client and therapist. Music therapy is used with individuals of all ages and with a variety of conditions, including: psychiatric disorders, medical problems, physical disabilities, sensory impairments, developmental disabilities, substance abuse issues, communication disorders, interpersonal problems, and aging. It is also used to improve learning, build self-esteem, reduce stress, support physical exercise, and facilitate a host of other health-related activities. Music therapists may encourage clients to sing, play instruments, create songs, or do other musical activities.\n\nOne of the earliest mentions of music therapy was in Al-Farabi's (c. 872\u2013950) treatise Meanings of the Intellect, which described the therapeutic effects of music on the soul. Music has long been used to help people deal with their emotions. In the 17th century, the scholar Robert Burton's The Anatomy of Melancholy argued that music and dance were critical in treating mental illness, especially melancholia. He noted that music has an \"excellent power ...to expel many other diseases\" and he called it \"a sovereign remedy against despair and melancholy.\" He pointed out that in Antiquity, Canus, a Rhodian fiddler, used music to \"make a melancholy man merry, ...a lover more enamoured, a religious man more devout.\" In the Ottoman Empire, mental illnesses were treated with music. In November 2006, Dr. Michael J. Crawford and his colleagues also found that music therapy helped schizophrenic patients.\n\nAlbert Einstein had a lifelong love of music (particularly the works of Bach and Mozart), once stating that life without playing music would be inconceivable to him. In some interviews Einstein even attributed much of his scientific intuition to music, with his son Hans recounting that \"whenever he felt that he had come to the end of the road or into a difficult situation in his work, he would take refuge in music, and that would usually resolve all his difficulties.\" Something in the music, according to Michele and Robert Root-Bernstein in Psychology Today, \"would guide his thoughts in new and creative directions.\" It has been said that Einstein considered Mozart's music to reveal a universal harmony that Einstein believed existed in the universe, \"as if the great Wolfgang Amadeus did not 'create' his beautifully clear music at all, but simply discovered it already made. This perspective parallels, remarkably, Einstein\u2019s views on the ultimate simplicity of nature and its explanation and statement via essentially simple mathematical expressions.\" A review suggests that music may be effective for improving subjective sleep quality in adults with insomnia symptoms. Music is also being used in clinical rehabilitation of cognitive and motor disorders.\n\nSee also\n\n Glossary of musical terminology\n History of music\n Internet Archive\n Lists of musicians\n List of musicology topics\n List of music software\n Music and emotion\n Music archaeology\n Music history\n Music-specific disorders\n Safe listening\n Women in music\n\nReferences\n\nSources\n\nFurther reading\n \n \n \n  Online version as Grove Music Online\n Small, Christopher (1977). Music, Society, Education. John Calder Publishers, London.\n\nExternal links\n\n BBC Blast Music For 13- to 19-year-olds interested in learning about, making, performing and talking about music.\nGrove Music Online \u2014 online version of The New Grove Dictionary of Music and Musicians.\n The Virginia Tech Multimedia Music Dictionary, with definitions, pronunciations, examples, quizzes and simulations\n The Music-Web Music Encyclopedia, for musicians, composers and music lovers\n Dolmetsch free online music dictionary, complete, with references to a list of specialised music dictionaries (by continent, by instrument, by genre, etc.)\n Musical Terms \u2013 Glossary of music terms from Naxos\n \"On Hermeneutical Ethics and Education: Bach als Erzieher\", a paper by Prof. Miguel \u00c1ngel Quintana Paz in which he explains the history of the different views hold about music in Western societies, since the Ancient Greece to our days.\n Monthly Online Features From Bloomingdale School of Music, addressing a variety of musical topics for a wide audience\n Arts and Music Uplifting Society towards Transformation and Tolerance Articles meant to stimulate people's awareness about the peace enhancing, transforming, communicative, educational and healing powers of music.\n Scientific American, Musical Chills Related to Brain Dopamine Release\n\n \nMain topic articles\nPerforming arts\nSound",
  "Meteorology": "Meteorology is a branch of the atmospheric sciences (which include atmospheric chemistry and atmospheric physics), with a major focus on weather forecasting. The study of meteorology dates back millennia, though significant progress in meteorology did not begin until the 18th century. The 19th century saw modest progress in the field after weather observation networks were formed across broad regions. Prior attempts at prediction of weather depended on historical data. It was not until after the elucidation of the laws of physics and more particularly, the development of the computer, allowing for the automated solution of a great many equations that model the weather, in the latter half of the 20th century that significant breakthroughs in weather forecasting were achieved. An important branch of weather forecasting is marine weather forecasting as it relates to maritime and coastal safety, in which weather effects also include atmospheric interactions with large bodies of water.\n\nMeteorological phenomena are observable weather events that are explained by the science of meteorology. Meteorological phenomena are described and quantified by the variables of Earth's atmosphere: temperature, air pressure, water vapour, mass flow, and the variations and interactions of these variables, and how they change over time. Different spatial scales are used  to describe and predict weather on local, regional, and global levels.\n \nMeteorology, climatology, atmospheric physics, and atmospheric chemistry are sub-disciplines of the atmospheric sciences. Meteorology and hydrology compose the interdisciplinary field of hydrometeorology. The interactions between Earth's atmosphere and its oceans are part of a coupled ocean-atmosphere system. Meteorology has application in many diverse fields such as the military, energy production, transport, agriculture, and construction.\n\nThe word meteorology is from the Ancient Greek \u03bc\u03b5\u03c4\u03ad\u03c9\u03c1\u03bf\u03c2 met\u00e9\u014dros (meteor) and -\u03bb\u03bf\u03b3\u03af\u03b1 -logia (-(o)logy), meaning \"the study of things high in the air.\"\n\nHistory\n\nThe ability to predict rains and floods based on annual cycles was evidently used by humans at least from the time of agricultural settlement if not earlier. Early approaches to predicting weather were based on astrology and were practiced by priests. Cuneiform inscriptions on Babylonian tablets included associations between thunder and rain. The Chaldeans differentiated the 22\u00b0 and 46\u00b0 halos.\n\nAncient Indian Upanishads contain mentions of clouds and seasons. The Samaveda mentions sacrifices to be performed when certain phenomena were noticed. Var\u0101hamihira's classical work Brihatsamhita, written about 500 AD, provides evidence of weather observation.\n\nIn 350 BC, Aristotle wrote Meteorology. Aristotle is considered the founder of meteorology. One of the most impressive achievements described in the Meteorology is the description of what  is now known as the hydrologic cycle.\n\nThe book De Mundo (composed before 250 BC or between 350 and 200 BC) noted:\nIf the flashing body is set on fire and rushes violently to the Earth it is called a thunderbolt; if it is only half of fire, but violent also and massive, it is called a meteor; if it is entirely free from fire, it is called a smoking bolt. They are all called 'swooping bolts' because they swoop down upon the Earth. Lightning is sometimes smoky, and is then called 'smoldering lightning\"; sometimes it darts quickly along, and is then said to be vivid. At other times, it travels in crooked lines, and is called forked lightning. When it swoops down upon some object it is called 'swooping lightning'.\n\nThe Greek scientist Theophrastus compiled a book on weather forecasting, called the Book of Signs. The work of Theophrastus remained a dominant influence in the study of weather and in weather forecasting for nearly 2,000 years. In 25 AD, Pomponius Mela, a geographer for the Roman Empire, formalized the climatic zone system. According to Toufic Fahd, around the 9th century, Al-Dinawari wrote the Kitab al-Nabat (Book of Plants), in which he deals with the application of meteorology to agriculture during the Arab Agricultural Revolution. He describes the meteorological character of the sky, the planets and constellations, the sun and moon, the lunar phases indicating seasons and rain, the anwa (heavenly bodies of rain), and atmospheric phenomena such as winds, thunder, lightning, snow, floods, valleys, rivers, lakes.\n\nEarly attempts at predicting weather were often related to prophecy and divining, and were sometimes based on astrological ideas. Admiral FitzRoy tried to separate scientific approaches from prophetic ones.\n\nResearch of visual atmospheric phenomena\n\nPtolemy wrote on the atmospheric refraction of light in the context of astronomical observations. In 1021, Alhazen showed that atmospheric refraction is also responsible for twilight; he estimated that twilight begins when the sun is 19 degrees below the horizon, and also used a geometric determination based on this to estimate the maximum possible height of the Earth's atmosphere as 52,000 passim (about 49 miles, or 79\u00a0km).\n\nSt. Albert the Great was the first to propose that each drop of falling rain had the form of a small sphere, and that this form meant that the rainbow was produced by light interacting with each raindrop. Roger Bacon was the first to calculate the angular size of the rainbow. He stated that a rainbow summit can not appear higher than 42 degrees above the horizon. In the late 13th century and early 14th century, Kam\u0101l al-D\u012bn al-F\u0101ris\u012b and Theodoric of Freiberg were the first to give the correct explanations for the primary rainbow phenomenon. Theoderic went further and also explained the secondary rainbow. In 1716, Edmund Halley suggested that aurorae are caused by \"magnetic effluvia\" moving along the Earth's magnetic field lines.\n\nInstruments and classification scales\n\nIn 1441, King Sejong's son, Prince Munjong of Korea, invented the first standardized rain gauge. These were sent throughout the Joseon dynasty of Korea as an official tool to assess land taxes based upon a farmer's potential harvest. In 1450, Leone Battista Alberti developed a swinging-plate anemometer, and was known as the first anemometer. In 1607, Galileo Galilei constructed a thermoscope. In 1611, Johannes Kepler wrote the first scientific treatise on snow crystals: \"Strena Seu de Nive Sexangula (A New Year's Gift of Hexagonal Snow).\" In 1643, Evangelista Torricelli invented the mercury barometer. In 1662, Sir Christopher Wren invented the mechanical, self-emptying, tipping bucket rain gauge. In 1714, Gabriel Fahrenheit created a reliable scale for measuring temperature with a mercury-type thermometer. In 1742, Anders Celsius, a Swedish astronomer, proposed the \"centigrade\" temperature scale, the predecessor of the current Celsius scale. In 1783, the first hair hygrometer was demonstrated by Horace-B\u00e9n\u00e9dict de Saussure. In 1802\u20131803, Luke Howard wrote On the Modification of Clouds, in which he assigns cloud types Latin names. In 1806, Francis Beaufort introduced his system for classifying wind speeds. Near the end of the 19th century the first cloud atlases were published, including the International Cloud Atlas, which has remained in print ever since. The April 1960 launch of the first successful weather satellite, TIROS-1, marked the beginning of the age where weather information became available globally.\n\nAtmospheric composition research\nIn 1648, Blaise Pascal rediscovered that atmospheric pressure decreases with height, and deduced that there is a vacuum above the atmosphere. In 1738, Daniel Bernoulli published Hydrodynamics, initiating the Kinetic theory of gases and established the basic laws for the theory of gases. In 1761, Joseph Black discovered that ice absorbs heat without changing its temperature when melting. In 1772, Black's student Daniel Rutherford discovered nitrogen, which he called phlogisticated air, and together they developed the phlogiston theory. In 1777, Antoine Lavoisier discovered oxygen and developed an explanation for combustion. In 1783, in Lavoisier's essay \"Reflexions sur le phlogistique,\" he deprecates the phlogiston theory and proposes a caloric theory. In 1804, Sir John Leslie observed that a matte black surface radiates heat more effectively than a polished surface, suggesting the importance of black-body radiation. In 1808, John Dalton defended caloric theory in A New System of Chemistry and described how it combines with matter, especially gases; he proposed that the heat capacity of gases varies inversely with atomic weight. In 1824, Sadi Carnot analyzed the efficiency of steam engines using caloric theory; he developed the notion of a reversible process and, in postulating that no such thing exists in nature, laid the foundation for the second law of thermodynamics.\n\nResearch into cyclones and air flow\n\nIn 1494, Christopher Columbus experienced a tropical cyclone, which led to the first written European account of a hurricane. In 1686, Edmund Halley presented a systematic study of the trade winds and monsoons and identified solar heating as the cause of atmospheric motions. In 1735, an ideal explanation of global circulation through study of the trade winds was written by George Hadley. In 1743, when Benjamin Franklin was prevented from seeing a lunar eclipse by a hurricane, he decided that cyclones move in a contrary manner to the winds at their periphery. Understanding the kinematics of how exactly the rotation of the Earth affects airflow was partial at first. Gaspard-Gustave Coriolis published a paper in 1835 on the energy yield of machines with rotating parts, such as waterwheels. In 1856, William Ferrel proposed the existence of a circulation cell in the mid-latitudes, and the air within deflected by the Coriolis force resulting in the prevailing westerly winds. Late in the 19th century, the motion of air masses along isobars was understood to be the result of the large-scale interaction of the pressure gradient force and the deflecting force. By 1912, this deflecting force was named the Coriolis effect. Just after World War I, a group of meteorologists in Norway led by Vilhelm Bjerknes developed the Norwegian cyclone model that explains the generation, intensification and ultimate decay (the life cycle) of mid-latitude cyclones, and introduced the idea of fronts, that is, sharply defined boundaries between air masses. The group included Carl-Gustaf Rossby (who was the first to explain the large scale atmospheric flow in terms of fluid dynamics), Tor Bergeron (who first determined how rain forms) and Jacob Bjerknes.\n\nObservation networks and weather forecasting\n\nIn the late 16th century and first half of the 17th century a range of meteorological instruments were invented \u2013 the thermometer, barometer, hydrometer, as well as wind and rain gauges. In the 1650s natural philosophers started using these instruments to systematically record weather observations. Scientific academies established weather diaries and organised observational networks. In 1654, Ferdinando II de Medici established the first weather observing network, that consisted of meteorological stations in Florence, Cutigliano, Vallombrosa, Bologna, Parma, Milan, Innsbruck, Osnabr\u00fcck, Paris and Warsaw. The collected data were sent to Florence at regular time intervals. In the 1660s Robert Hooke of the Royal Society of London sponsored networks of weather observers. Hippocrates' treatise Airs, Waters, and Places had linked weather to disease. Thus early meteorologists attempted to correlate weather patterns with epidemic outbreaks, and the climate with public health.\n\nDuring the Age of Enlightenment meteorology tried to rationalise traditional weather lore, including astrological meteorology. But there were also attempts to establish a theoretical understanding of weather phenomena. Edmond Halley and George Hadley tried to explain trade winds. They reasoned that the rising mass of heated equator air is replaced by an inflow of cooler air from high latitudes. A flow of warm air at high altitude from equator to poles in turn established an early picture of circulation. Frustration with the lack of discipline among weather observers, and the poor quality of the instruments, led the early modern nation states to organise large observation networks. Thus by the end of the 18th century, meteorologists had access to large quantities of reliable weather data. In 1832, an electromagnetic telegraph was created by Baron Schilling. The arrival of the electrical telegraph in 1837 afforded, for the first time, a practical method for quickly gathering surface weather observations from a wide area.\n\nThis data could be used to produce maps of the state of the atmosphere for a region near the Earth's surface and to study how these states evolved through time. To make frequent weather forecasts based on these data required a reliable network of observations, but it was not until 1849 that the Smithsonian Institution began to establish an observation network across the United States under the leadership of Joseph Henry. Similar observation networks were established in Europe at this time. The Reverend William Clement Ley was key in understanding of cirrus clouds and early understandings of Jet Streams. Charles Kenneth Mackinnon Douglas, known as 'CKM' Douglas read Ley's papers after his death and carried on the early study of weather systems.\nNineteenth century researchers in meteorology were drawn from military or medical backgrounds, rather than trained as dedicated scientists. In 1854, the United Kingdom government appointed Robert FitzRoy to the new office of Meteorological Statist to the Board of Trade with the task of gathering weather observations at sea. FitzRoy's office became the United Kingdom Meteorological Office in 1854, the second oldest national meteorological service in the world (the Central Institution for Meteorology and Geodynamics (ZAMG) in Austria was founded in 1851 and is the oldest weather service in the world). The first daily weather forecasts made by FitzRoy's Office were published in The Times newspaper in 1860. The following year a system was introduced of hoisting storm warning cones at principal ports when a gale was expected.\n\nOver the next 50 years, many countries established national meteorological services. The India Meteorological Department (1875) was established to follow tropical cyclone and monsoon. The Finnish Meteorological Central Office (1881) was formed from part of Magnetic Observatory of Helsinki University. Japan's Tokyo Meteorological Observatory, the forerunner of the Japan Meteorological Agency, began constructing surface weather maps in 1883. The United States Weather Bureau (1890) was established under the United States Department of Agriculture. The Australian Bureau of Meteorology (1906) was established by a Meteorology Act to unify existing state meteorological services.\n\nNumerical weather prediction\n\nIn 1904, Norwegian scientist Vilhelm Bjerknes first argued in his paper Weather Forecasting as a Problem in Mechanics and Physics that it should be possible to forecast weather from calculations based upon natural laws.\n\nIt was not until later in the 20th century that advances in the understanding of atmospheric physics led to the foundation of modern numerical weather prediction. In 1922, Lewis Fry Richardson published \"Weather Prediction By Numerical Process,\" after finding notes and derivations he worked on as an ambulance driver in World War I. He described how small terms in the prognostic fluid dynamics equations that govern atmospheric flow could be neglected, and a numerical calculation scheme that could be devised to allow predictions. Richardson envisioned a large auditorium of thousands of people performing the calculations. However, the sheer number of calculations required was too large to complete without electronic computers, and the size of the grid and time steps used in the calculations led to unrealistic results. Though numerical analysis later found that this was due to numerical instability.\n\nStarting in the 1950s, numerical forecasts with computers became feasible. The first weather forecasts derived this way used barotropic (single-vertical-level) models, and could successfully predict the large-scale movement of midlatitude Rossby waves, that is, the pattern of atmospheric lows and highs. In 1959, the UK Meteorological Office received its first computer, a Ferranti Mercury.\n\nIn the 1960s, the chaotic nature of the atmosphere was first observed and mathematically described by Edward Lorenz, founding the field of chaos theory. These advances have led to the current use of ensemble forecasting in most major forecasting centers, to take into account uncertainty arising from the chaotic nature of the atmosphere. Mathematical models used to predict the long term weather of the Earth (climate models), have been developed that have a resolution today that are as coarse as the older weather prediction models. These climate models are used to investigate long-term climate shifts, such as what effects might be caused by human emission of greenhouse gases.\n\nMeteorologists\n\nMeteorologists are scientists who study and work in the field of meteorology. The American Meteorological Society publishes and continually updates an authoritative electronic Meteorology Glossary. Meteorologists work in government agencies, private consulting and research services, industrial enterprises, utilities, radio and television stations, and in education. In the United States, meteorologists held about 10,000 jobs in 2018.\n\nAlthough weather forecasts and warnings are the best known products of meteorologists for the public, weather presenters on radio and television are not necessarily professional meteorologists. They are most often reporters with little formal meteorological training, using unregulated titles such as weather specialist or weatherman. The American Meteorological Society and National Weather Association issue \"Seals of Approval\" to weather broadcasters who meet certain requirements but this is not mandatory to be hired by the media.\n\nEquipment\n\nEach science has its own unique sets of laboratory equipment. In the atmosphere, there are many things or qualities of the atmosphere that can be measured. Rain, which can be observed, or seen anywhere and anytime was one of the first atmospheric qualities measured historically. Also, two other accurately measured qualities are wind and humidity. Neither of these can be seen but can be felt. The devices to measure these three sprang up in the mid-15th century and were respectively the rain gauge, the anemometer, and the hygrometer. Many attempts had been made prior to the 15th century to construct adequate equipment to measure the many atmospheric variables. Many were faulty in some way or were simply not reliable. Even Aristotle noted this in some of his work as the difficulty to measure the air.\n\nSets of surface measurements are important data to meteorologists. They give a snapshot of a variety of weather conditions at one single location and are usually at a weather station, a ship or a weather buoy. The measurements taken at a weather station can include any number of atmospheric observables. Usually, temperature, pressure, wind measurements, and humidity are the variables that are measured by a thermometer, barometer, anemometer, and hygrometer, respectively. Professional stations may also include air quality sensors (carbon monoxide, carbon dioxide, methane, ozone, dust, and smoke), ceilometer (cloud ceiling), falling precipitation sensor,  flood sensor, lightning sensor, microphone (explosions, sonic booms, thunder), pyranometer/pyrheliometer/spectroradiometer (IR/Vis/UV photodiodes), rain gauge/snow gauge, scintillation counter (background radiation, fallout, radon), seismometer (earthquakes and tremors), transmissometer (visibility), and a GPS clock for data logging. Upper air data are of crucial importance for weather forecasting. The most widely used technique is launches of radiosondes. Supplementing the radiosondes a network of aircraft collection is organized by the World Meteorological Organization.\n\nRemote sensing, as used in meteorology, is the concept of collecting data from remote weather events and subsequently producing weather information. The common types of remote sensing are Radar, Lidar, and satellites (or photogrammetry). Each collects data about the atmosphere from a remote location and, usually, stores the data where the instrument is located. Radar and Lidar are not passive because both use EM radiation to illuminate a specific portion of the atmosphere.  Weather satellites along with more general-purpose Earth-observing satellites circling the earth at various altitudes have become an indispensable tool for studying a wide range of phenomena from forest fires to El Ni\u00f1o.\n\nSpatial scales\nThe study of the atmosphere can be divided into distinct areas that depend on both time and spatial scales. At one extreme of this scale is climatology. In the timescales of hours to days, meteorology separates into micro-, meso-, and synoptic scale meteorology. Respectively, the geospatial size of each of these three scales relates directly with the appropriate timescale.\n\nOther subclassifications are used to describe the unique, local, or broad effects within those subclasses.\n\nMicroscale\n\nMicroscale meteorology is the study of atmospheric phenomena on a scale of about  or less. Individual thunderstorms, clouds, and local turbulence caused by buildings and other obstacles (such as individual hills) are modeled on this scale.\n\nMesoscale\n\nMesoscale meteorology is the study of atmospheric phenomena that has horizontal scales ranging from 1\u00a0km to 1000\u00a0km and a vertical scale that starts at the Earth's surface and includes the atmospheric boundary layer, troposphere, tropopause, and the lower section of the stratosphere. Mesoscale timescales last from less than a day to multiple weeks. The events typically of interest are thunderstorms, squall lines, fronts, precipitation bands in tropical and extratropical cyclones, and topographically generated weather systems such as mountain waves and sea and land breezes.\n\nSynoptic scale\n\nSynoptic scale meteorology predicts atmospheric changes at scales up to 1000\u00a0km and 105 sec (28 days), in time and space. At the synoptic scale, the Coriolis acceleration acting on moving air masses (outside of the tropics) plays a dominant role in predictions. The phenomena typically described by synoptic meteorology include events such as extratropical cyclones, baroclinic troughs and ridges, frontal zones, and to some extent jet streams. All of these are typically given on weather maps for a specific time. The minimum horizontal scale of synoptic phenomena is limited to the spacing between surface observation stations.\n\nGlobal scale\n\nGlobal scale meteorology is the study of weather patterns related to the transport of heat from the tropics to the poles. Very large scale oscillations are of importance at this scale. These oscillations have time periods typically on the order of months, such as the Madden\u2013Julian oscillation, or years, such as the El Ni\u00f1o\u2013Southern Oscillation and the Pacific decadal oscillation. Global scale meteorology pushes into the range of climatology. The traditional definition of climate is pushed into larger timescales and with the understanding of the longer time scale global oscillations, their effect on climate and weather disturbances can be included in the synoptic and mesoscale timescales predictions.\n\nNumerical Weather Prediction is a main focus in understanding air\u2013sea interaction, tropical meteorology, atmospheric predictability, and tropospheric/stratospheric processes. The Naval Research Laboratory in Monterey, California, developed a global atmospheric model called Navy Operational Global Atmospheric Prediction System (NOGAPS). NOGAPS is run operationally at Fleet Numerical Meteorology and Oceanography Center for the United States Military. Many other global atmospheric models are run by national meteorological agencies.\n\nSome meteorological principles\n\nBoundary layer meteorology\nBoundary layer meteorology is the study of processes in the air layer directly above Earth's surface, known as the atmospheric boundary layer (ABL). The effects of the surface\u00a0\u2013 heating, cooling, and friction\u00a0\u2013 cause turbulent mixing within the air layer. Significant movement  of heat, matter, or momentum on time scales of less than a day are caused by turbulent motions.<ref>Garratt, J.R., The atmospheric boundary layer, Cambridge University Press, 1992; .</ref> Boundary layer meteorology includes the study of all types of surface\u2013atmosphere boundary, including ocean, lake, urban land and non-urban land for the study of meteorology.\n\nDynamic meteorology\nDynamic meteorology generally focuses on the fluid dynamics of the atmosphere. The idea of air parcel is used to define the smallest element of the atmosphere, while ignoring the discrete molecular and chemical nature of the atmosphere. An air parcel is defined as a point in the fluid continuum of the atmosphere. The fundamental laws of fluid dynamics, thermodynamics, and motion are used to study the atmosphere. The physical quantities that characterize the state of the atmosphere are temperature, density, pressure, etc. These variables have unique values in the continuum.\n\nApplications\n\nWeather forecasting\n\nWeather forecasting is the application of science and technology to predict the state of the atmosphere at a future time and given location. Humans have attempted to predict the weather informally for millennia and formally since at least the 19th century. Weather forecasts are made by collecting quantitative data about the current state of the atmosphere and using scientific understanding of atmospheric processes to project how the atmosphere will evolve.\n\nOnce an all-human endeavor based mainly upon changes in barometric pressure, current weather conditions, and sky condition, forecast models are now used to determine future conditions. Human input is still required to pick the best possible forecast model to base the forecast upon, which involves pattern recognition skills, teleconnections, knowledge of model performance, and knowledge of model biases. The chaotic nature of the atmosphere, the massive computational power required to solve the equations that describe the atmosphere, error involved in measuring the initial conditions, and an incomplete understanding of atmospheric processes mean that forecasts become less accurate as the difference in current time and the time for which the forecast is being made (the range of the forecast) increases. The use of ensembles and model consensus help narrow the error and pick the most likely outcome.\n\nThere are a variety of end uses to weather forecasts. Weather warnings are important forecasts because they are used to protect life and property. Forecasts based on temperature and precipitation are important to agriculture, and therefore to commodity traders within stock markets. Temperature forecasts are used by utility companies to estimate demand over coming days. On an everyday basis, people use weather forecasts to determine what to wear. Since outdoor activities are severely curtailed by heavy rain, snow, and wind chill, forecasts can be used to plan activities around these events, and to plan ahead and survive them.\n\nAviation meteorology\nAviation meteorology deals with the impact of weather on air traffic management. It is important for air crews to understand the implications of weather on their flight plan as well as their aircraft, as noted by the Aeronautical Information Manual:\nThe effects of ice on aircraft are cumulative\u2014thrust is reduced, drag increases, lift lessens, and weight increases. The results are an increase in stall speed and a deterioration of aircraft performance. In extreme cases, 2 to 3 inches of ice can form on the leading edge of the airfoil in less than 5 minutes. It takes but 1/2 inch of ice to reduce the lifting power of some aircraft by 50 percent and increases the frictional drag by an equal percentage.\n\nAgricultural meteorology\nMeteorologists, soil scientists, agricultural hydrologists, and agronomists are people concerned with studying the effects of weather and climate on plant distribution, crop yield, water-use efficiency, phenology of plant and animal development, and the energy balance of managed and natural ecosystems. Conversely, they are interested in the role of vegetation on climate and weather.\n\nHydrometeorology\nHydrometeorology is the branch of meteorology that deals with the hydrologic cycle, the water budget, and the rainfall statistics of storms. A hydrometeorologist prepares and issues forecasts of accumulating (quantitative) precipitation, heavy rain, heavy snow, and highlights areas with the potential for flash flooding. Typically the range of knowledge that is required overlaps with climatology, mesoscale and synoptic meteorology, and other geosciences.\n\nThe multidisciplinary nature of the branch can result in technical challenges, since tools and solutions from each of the individual disciplines involved may behave slightly differently, be optimized for different hard- and software platforms and use different data formats. There are some initiatives \u2013 such as the DRIHM project \u2013 that are trying to address this issue.\n\nNuclear meteorology\nNuclear meteorology investigates the distribution of radioactive aerosols and gases in the atmosphere.\n\nMaritime meteorology\nMaritime meteorology deals with air and wave forecasts for ships operating at sea. Organizations such as the Ocean Prediction Center, Honolulu National Weather Service forecast office, United Kingdom Met Office, and JMA prepare high seas forecasts for the world's oceans.\n\nMilitary meteorology\n\nMilitary meteorology is the research and application of meteorology for military purposes. In the United States, the United States Navy's Commander, Naval Meteorology and Oceanography Command oversees meteorological efforts for the Navy and Marine Corps while the United States Air Force's Air Force Weather Agency is responsible for the Air Force and Army.\n\nEnvironmental meteorology\nEnvironmental meteorology mainly analyzes industrial pollution dispersion physically and chemically based on meteorological parameters such as temperature, humidity, wind, and various weather conditions.\n\nRenewable energy\nMeteorology applications in renewable energy includes basic research, \"exploration,\" and potential mapping of wind power and solar radiation for wind and solar energy.\n\nSee also\n\nReferences\n\nFurther reading\n\nByers, Horace. General Meteorology. New York:  McGraw-Hill, 1994.\n\n \n\nDictionaries and encyclopedias\n \n \n \n\nExternal linksPlease see weather forecasting for weather forecast sites.Air Quality Meteorology \u2013 Online course that introduces the basic concepts of meteorology and air quality necessary to understand meteorological computer models. Written at a bachelor's degree level.\nThe GLOBE Program \u2013 (Global Learning and Observations to Benefit the Environment) An international environmental science and education program that links students, teachers, and the scientific research community in an effort to learn more about the environment through student data collection and observation.\nGlossary of Meteorology \u2013 From the American Meteorological Society, an excellent reference of nomenclature, equations, and concepts for the more advanced reader.\nJetStream \u2013 An Online School for Weather \u2013 National Weather Service\nLearn About Meteorology \u2013 Australian Bureau of Meteorology\nThe Weather Guide \u2013 Weather Tutorials and News at About.com\nMeteorology Education and Training (MetEd) \u2013 The COMET Program\nNOAA Central Library \u2013 National Oceanic & Atmospheric Administration\nThe World Weather 2010 Project The University of Illinois at Urbana\u2013Champaign\nOgimet \u2013 online data from meteorological stations of the world, obtained through NOAA free services\nNational Center for Atmospheric Research Archives, documents the history of meteorology\nWeather forecasting and Climate science \u2013 United Kingdom Meteorological Office\n Meteorology, BBC Radio 4 discussion with Vladimir Jankovi\u0107, Richard Hambyn and Iba Taub (In Our Time, 6 March 2003)\n Virtual exhibition about meteorology on the digital library of Paris Observatory\n\n \nApplied and interdisciplinary physics\nOceanography\nPhysical geography\nGreek words and phrases",
  "Media": "Media may refer to:\n\nPhysical means\n\nCommunication \n Media (communication), tools used to deliver information or data\n Advertising media, various media, content, buying and placement for advertising\n Broadcast media, communications delivered over mass electronic communication networks\n Digital media, electronic media used to store, transmit, and receive digitized information\n Electronic media, communications delivered via electronic or electromechanical energy\n Hypermedia, media with hyperlinks\n Interactive media, media that is interactive\n Mass media, technologies that reach a large audience via mass communication\n MEDIA Programme, a European Union initiative to support the European audiovisual sector\n Multimedia, communications that incorporate multiple forms of information content and processing\n New media, the combination of traditional media and computer and communications technology\n News media, mass media focused on communicating news\n Print media, communications delivered via paper or canvas\n Published media, any media made available to the public\n Recording medium, devices used to store information\n Social media, media disseminated through social interactions\n\nComputing \n Media player (software), for playing audio and video\n Storage media, in data storage devices\n\nFine art \n List of art media, materials and techniques used by an artist to produce a work of art\n\nLife sciences \n\n Media, a group of insect wing veins in the Comstock-Needham system\n Growth medium, objects in which microorganisms or cells can experience growth\n Media filter, a filter consisting of several different filter materials\n Tunica media, the middle layer of the wall of a blood vessel\n\nPlaces\n\nUnited States\n Media, Illinois\n Media, Kansas\n Media, Pennsylvania\n\nElsewhere\n Media (castra), a fort in the Roman province of Dacia\n Media (region), a region of and former empire based in north-western Iran, best known for having been the political and cultural base of the Medes and other ancient Iranian people\n Media, Africa, an Ancient city and former bishopric, now a Latin Catholic titular see in Algeria\n\nArts, entertainment, and media\n Media (album), the 1998 album by The Faint\n Media, a 2017 American TV thriller film directed by Craig Ross Jr.\n\nTransport\n Media (automobile company)\n Ships:\n , a (never commissioned) World War II  US Navy \n , a Cunard Line cargo liner, in service 1948\u201361\n\nSee also \n Kaus Media, a star system in the constellation Sagittarius\n Medium (disambiguation)\n Common Sense Media, game/movie/book review site\n Attributive usages of the plural noun:\n Media ecology\n Media meshing\n Media psychology\n Media studies\n Multimedia learning\n Ear rhymes and other false-friends\n Medea (disambiguation)\n Midea (disambiguation)",
  "Biology": "Biology is the scientific study of life. It is a natural science with a broad scope but has several unifying themes that tie it together as a single, coherent field. For instance, all organisms are made up of cells that process hereditary information encoded in genes, which can be transmitted to future generations. Another major theme is evolution, which explains the unity and diversity of life. Energy processing is also important to life as it allows organisms to move, grow, and reproduce. Finally, all organisms are able to regulate their own internal environments.\n\nBiologists are able to study life at multiple levels of organization. From the molecular biology of a cell to the anatomy and physiology of plants and animals, and evolution of populations. Hence, there are multiple subdisciplines within biology, each defined by the nature of their research questions and the tools that they use. Like other scientists, biologists use the scientific method to make observations, pose questions, generate hypotheses, perform experiments, and form conclusions about the world around them.\n\nLife on Earth, which emerged more than 3.7 billion years ago, is immensely diverse. Biologists have sought to study and classify the various forms of life, from prokaryotic organisms such as archaea and bacteria to eukaryotic organisms such as protists, fungi, plants, and animals. These various organisms contribute to the biodiversity of an ecosystem, where they play specialized roles in the cycling of nutrients and energy through their biophysical environment.\n\nEtymology\nBiology derives from the Ancient Greek words of  romanized  meaning 'life' and -; romanized - meaning 'branch of study' or 'to speak'. Those combined make the Greek word  romanized  meaning 'biology'. Despite this, the term  as a whole didn't exist in Ancient Greek. The first to borrow it was the English and French (). Historically there was another term for biology in English, lifelore; it is rarely used today.\n\nThe Latin-language form of the term first appeared in 1736 when Swedish scientist Carl Linnaeus () used  in his . It was used again in 1766 in a work entitled , by Michael Christoph Hanov, a disciple of Christian Wolff. The first German use, , was in a 1771 translation of Linnaeus' work. In 1797, Theodor Georg August Roose used the term in the preface of a book, . Karl Friedrich Burdach used the term in 1800 in a more restricted sense of the study of human beings from a morphological, physiological and psychological perspective (). The term came into its modern usage with the six-volume treatise  (1802\u201322) by Gottfried Reinhold Treviranus, who announced:\n\nThe objects of our research will be the different forms and manifestations of life, the conditions and laws under which these phenomena occur, and the causes through which they have been affected. The science that concerns itself with these objects we will indicate by the name biology [] or the doctrine of life [].\nMany other terms used in biology to describe plants, animals, diseases, and drugs have been derived from Greek and Latin due to the historical contributions of the Ancient Greek and Roman civilizations as well as the continued use of these two languages in European universities during the Middle Ages and at the beginning of the Renaissance.\n\nHistory\n\nThe earliest of roots of science, which included medicine, can be traced to ancient Egypt and Mesopotamia in around 3000 to 1200 BCE. Their contributions later entered and shaped Greek natural philosophy of classical antiquity. Ancient Greek philosophers such as Aristotle (384\u2013322 BCE) contributed extensively to the development of biological knowledge. His works such as History of Animals were especially important because they revealed his naturalist leanings, and later more empirical works that focused on biological causation and the diversity of life. Aristotle's successor at the Lyceum, Theophrastus, wrote a series of books on botany that survived as the most important contribution of antiquity to the plant sciences, even into the Middle Ages.\n\nScholars of the medieval Islamic world who wrote on biology included al-Jahiz (781\u2013869), Al-D\u012bnawar\u012b (828\u2013896), who wrote on botany, and Rhazes (865\u2013925) who wrote on anatomy and physiology. Medicine was especially well studied by Islamic scholars working in Greek philosopher traditions, while natural history drew heavily on Aristotelian thought, especially in upholding a fixed hierarchy of life.\n\nBiology began to quickly develop and grow with Anton van Leeuwenhoek's dramatic improvement of the microscope. It was then that scholars discovered spermatozoa, bacteria, infusoria and the diversity of microscopic life. Investigations by Jan Swammerdam led to new interest in entomology and helped to develop the basic techniques of microscopic dissection and staining.\n\nAdvances in microscopy also had a profound impact on biological thinking. In the early 19th century, a number of biologists pointed to the central importance of the cell. Then, in 1838, Schleiden and Schwann began promoting the now universal ideas that (1) the basic unit of organisms is the cell and (2) that individual cells have all the characteristics of life, although they opposed the idea that (3) all cells come from the division of other cells. However, Robert Remak and Rudolf Virchow were able to reify the third tenet, and by the 1860s most biologists accepted all three tenets which consolidated into cell theory.\n\nMeanwhile, taxonomy and classification became the focus of natural historians. Carl Linnaeus published a basic taxonomy for the natural world in 1735 (variations of which have been in use ever since), and in the 1750s introduced scientific names for all his species. Georges-Louis Leclerc, Comte de Buffon, treated species as artificial categories and living forms as malleable\u2014even suggesting the possibility of common descent. Although he was opposed to evolution, Buffon is a key figure in the history of evolutionary thought; his work influenced the evolutionary theories of both Lamarck and Darwin.\n\nSerious evolutionary thinking originated with the works of Jean-Baptiste Lamarck, who was the first to present a coherent theory of evolution. He posited that evolution was the result of environmental stress on properties of animals, meaning that the more frequently and rigorously an organ was used, the more complex and efficient it would become, thus adapting the animal to its environment. Lamarck believed that these acquired traits could then be passed on to the animal's offspring, who would further develop and perfect them. However, it was the British naturalist Charles Darwin, combining the biogeographical approach of Humboldt, the uniformitarian geology of Lyell, Malthus's writings on population growth, and his own morphological expertise and extensive natural observations, who forged a more successful evolutionary theory based on natural selection; similar reasoning and evidence led Alfred Russel Wallace to independently reach the same conclusions. Darwin's theory of evolution by natural selection quickly spread through the scientific community and soon became a central axiom of the rapidly developing science of biology.\n\nThe basis for modern genetics began with the work of Gregor Mendel, who presented his paper, \"Versuche \u00fcber Pflanzenhybriden\" (\"Experiments on Plant Hybridization\"), in 1865, which outlined the principles of biological inheritance, serving as the basis for modern genetics. However, the significance of his work was not realized until the early 20th century when evolution became a unified theory as the modern synthesis reconciled Darwinian evolution with classical genetics. In the 1940s and early 1950s, a series of experiments by Alfred Hershey and Martha Chase pointed to DNA as the component of chromosomes that held the trait-carrying units that had become known as genes. A focus on new kinds of model organisms such as viruses and bacteria, along with the discovery of the double-helical structure of DNA by James Watson and Francis Crick in 1953, marked the transition to the era of molecular genetics. From the 1950s onwards, biology has been vastly extended in the molecular domain. The genetic code was cracked by Har Gobind Khorana, Robert W. Holley and Marshall Warren Nirenberg after DNA was understood to contain codons. Finally, the Human Genome Project was launched in 1990 with the goal of mapping the general human genome. This project was essentially completed in 2003, with further analysis still being published. The Human Genome Project was the first step in a globalized effort to incorporate accumulated knowledge of biology into a functional, molecular definition of the human body and the bodies of other organisms.\n\nFundamentals\n\nChemical basis\n\nAtoms and molecules\n\nAll organisms are made up of matter and all matter is made up of elements. Oxygen, carbon, hydrogen, and nitrogen are the four elements that account for 96% of all organisms, with calcium, phosphorus, sulfur, sodium, chlorine, and magnesium constituting the remaining 3.7%. Different elements can combine to form compounds such as water, which is fundamental to life. Life on Earth began from water and remained there for about three billions years prior to migrating onto land. Matter can exist in different states as a solid, liquid, or gas.\n\nThe smallest unit of an element is an atom, which is composed of an atomic nucleus and one or more electrons moving around the nucleus, as described by the Bohr model. The nucleus is made of one or more protons and a number of neutrons. Protons have a positive electric charge, neutrons are electrically neutral, and electrons have a negative electric charge. Atoms with equal numbers of protons and electrons are electrically neutral. The atom of each specific element contains a unique number of protons, which is known as its atomic number, and the sum of its protons and neutrons is an atom's mass number. The masses of individual protons, neutrons, and electrons can be measured in grams or Daltons (Da), with the mass of each proton or neutron rounded to 1 Da. Although all atoms of a specific element have the same number of protons, they may differ in the number of neutrons, thereby existing as isotopes. Carbon, for example, can exist as a stable isotope (carbon-12 or carbon-13) or as a radioactive isotope (carbon-14), the latter of which can be used in radiometric dating (specifically radiocarbon dating) to determine the age of organic materials.\n\nIndividual atoms can be held together by chemical bonds to form molecules and ionic compounds. Common types of chemical bonds include ionic bonds, covalent bonds, and hydrogen bonds. Ionic bonding involves the electrostatic attraction between oppositely charged ions, or between two atoms with sharply different electronegativities, and is the primary interaction occurring in ionic compounds. Ions are atoms (or groups of atoms) with an electrostatic charge. Atoms that gain electrons make negatively charged ions (called anions) whereas those that lose electrons make positively charged ions (called cations).\n\nUnlike ionic bonds, a covalent bond involves the sharing of electron pairs between atoms. These electron pairs and the stable balance of attractive and repulsive forces between atoms, when they share electrons, is known as covalent bonding.\n\nA hydrogen bond is primarily an electrostatic force of attraction between a hydrogen atom which is covalently bound to a more electronegative atom or group such as oxygen. A ubiquitous example of a hydrogen bond is found between water molecules. In a discrete water molecule, there are two hydrogen atoms and one oxygen atom. Two molecules of water can form a hydrogen bond between them. When more molecules are present, as is the case with liquid water, more bonds are possible because the oxygen of one water molecule has two lone pairs of electrons, each of which can form a hydrogen bond with a hydrogen on another water molecule.\n\nWater\n\nLife arose from the Earth's first ocean, which was formed approximately 3.8 billion years ago. Since then, water continues to be the most abundant molecule in every organism. Water is important to life because it is an effective solvent, capable of dissolving solutes such as sodium and chloride ions or other small molecules to form an aqueous solution. Once dissolved in water, these solutes are more likely to come in contact with one another and therefore take part in chemical reactions that sustain life.\n\nIn terms of its molecular structure, water is a small polar molecule with a bent shape formed by the polar covalent bonds of two hydrogen (H) atoms to one oxygen (O) atom (H2O). Because the O\u2013H bonds are polar, the oxygen atom has a slight negative charge and the two hydrogen atoms have a slight positive charge. This polar property of water allows it to attract other water molecules via hydrogen bonds, which makes water cohesive. Surface tension results from the cohesive force due to the attraction between molecules at the surface of the liquid. Water is also adhesive as it is able to adhere to the surface of any polar or charged non-water molecules.\n\nWater is denser as a liquid than it is as a solid (or ice). This unique property of water allows ice to float above liquid water such as ponds, lakes, and oceans, thereby insulating the liquid below from the cold air above. The lower density of ice compared to liquid water is due to the lower number of water molecules that form the crystal lattice structure of ice, which leaves a large amount of space between water molecules. In contrast, there is no crystal lattice structure in liquid water, which allows more water molecules to occupy the same amount of volume.\n\nWater also has the capacity to absorb energy, giving it a higher specific heat capacity than other solvents such as ethanol. Thus, a large amount of energy is needed to break the hydrogen bonds between water molecules to convert liquid water into gas (or water vapor).\n\nAs a molecule, water is not completely stable as each water molecule continuously dissociates into hydrogen and hydroxyl ions before reforming into a water molecule again. In pure water, the number of hydrogen ions balances (or equals) the number of hydroxyl ions, resulting in a pH that is neutral. If hydrogen ions were to exceed hydroxyl ions, then the pH of the solution would be acidic. Conversely, a solution's pH would turn basic if hydroxyl ions were to exceed hydrogen ions.\n\nOrganic compounds\n\nOrganic compounds are molecules that contain carbon bonded to another element such as hydrogen. With the exception of water, nearly all the molecules that make up each organism contain carbon. Carbon has six electrons, two of which are located in its first shell, leaving four electrons in its valence shell. Thus, carbon can form covalent bonds with up to four other atoms, making it the most versatile atom on Earth as it is able to form diverse, large, and complex molecules. For example, a single carbon atom can form four single covalent bonds such as in methane, two double covalent bonds such as in carbon dioxide (), or a triple covalent bond such as in carbon monoxide (CO). Moreover, carbon can form very long chains of interconnecting carbon\u2013carbon bonds such as octane or ring-like structures such as glucose.\n\nThe simplest form of an organic molecule is the hydrocarbon, which is a large family of organic compounds that are composed of hydrogen atoms bonded to a chain of carbon atoms. A hydrocarbon backbone can be substituted by other elements such as oxygen (O), hydrogen (H), phosphorus (P), and sulfur (S), which can change the chemical behavior of that compound. Groups of atoms that contain these elements (O-, H-, P-, and S-) and are bonded to a central carbon atom or skeleton are called functional groups. There are six prominent functional groups that can be found in organisms: amino group, carboxyl group, carbonyl group, hydroxyl group, phosphate group, and sulfhydryl group.\n\nIn 1953, Stanley Miller and Harold Urey conducted a classic experiment (otherwise known as the Miller-Urey experiment), which showed that organic compounds could be synthesized abiotically within a closed system that mimicked the conditions of early Earth, leading them to conclude that complex organic molecules could have arisen spontaneously in early Earth, most likely near volcanoes, and could have part of the early stages of abiogenesis (or origin of life).\n\nMacromolecules\n\nMacromolecules are large molecules made up of smaller molecular subunits that are joined together. Small molecules such as sugars, amino acids, and nucleotides can act as single repeating units called monomers to form chain-like molecules called polymers via a chemical process called condensation. For example, amino acids can form polypeptides whereas nucleotides can form strands of nucleic acid. Polymers make up three of the four macromolecules (polysaccharides, lipids, proteins, and nucleic acids) that are found in all organisms. Each of these macromolecules plays a specialized role within any given cell.\n\nCarbohydrates (or sugar) are molecules with the molecular formula , with n being the number of carbon-hydrate groups. They include monosaccharides (monomer), oligosaccharides (small polymers), and polysaccharides (large polymers). Monosaccharides can be linked together by glyosidic linkages, a type of covalent bond. When two monosaccharides such as glucose and fructose are linked together, they can form a disaccharide such as sucrose. When many monosaccharides are linked together, they can form an oligosaccharide or a polysaccharide, depending on the number of monosaccharides. Polysaccharides can vary in function. Monosaccharides such as glucose can be a source of energy and some polysaccharides can serve as storage material that can be hydrolyzed to provide cells with sugar.\n\nLipids are the only class of macromolecules that are not made up of polymers. The most biologically important lipids are steroids, phospholipids, and fats. These lipids are organic compounds that are largely nonpolar and hydrophobic. Steroids are organic compounds that consist of four fused rings. Phospholipids consist of glycerol that is linked to a phosphate group and two hydrocarbon chains (or fatty acids). The glycerol and phosphate group together constitute the polar and hydrophilic (or head) region of the molecule whereas the fatty acids make up the nonpolar and hydrophobic (or tail) region. Thus, when in water, phospholipids tend to form a phospholipid bilayer whereby the hydrophobic heads face outwards to interact with water molecules. Conversely, the hydrophobic tails face inwards towards other hydrophobic tails to avoid contact with water.\n\nProteins are the most diverse of the macromolecules, which include enzymes, transport proteins, large signaling molecules, antibodies, and structural proteins. The basic unit (or monomer) of a protein is an amino acid, which has a central carbon atom that is covalently bonded to a hydrogen atom, an amino group, a carboxyl group, and a side chain (or R-group, \"R\" for residue). There are twenty amino acids that make up the building blocks of proteins, with each amino acid having its own unique side chain. The polarity and charge of the side chains affect the solubility of amino acids. An amino acid with a side chain that is polar and electrically charged is soluble as it is hydrophilic whereas an amino acid with a side chain that lacks a charged or an electronegative atom is hydrophobic and therefore tends to coalesce rather than dissolve in water. Proteins have four distinct levels of organization (primary, secondary, tertiary, and quartenary). The primary structure consists of a unique sequence of amino acids that are covalently linked together by peptide bonds. The side chains of the individual amino acids can then interact with each other, giving rise to the secondary structure of a protein. The two common types of secondary structures are alpha helices and beta sheets. The folding of alpha helices and beta sheets gives a protein its three-dimensional or tertiary structure. Finally, multiple tertiary structures can combine to form the quaternary structure of a protein.\n\nNucleic acids are polymers made up of monomers called nucleotides. Their function is to store, transmit, and express hereditary information. Nucleotides consist of a phosphate group, a five-carbon sugar, and a nitrogenous base. Ribonucleotides, which contain ribose as the sugar, are the monomers of ribonucleic acid (RNA). In contrast, deoxyribonucleotides contain deoxyribose as the sugar and are constitute the monomers of deoxyribonucleic acid (DNA). RNA and DNA also differ with respect to one of their bases. There are two types of bases: purines and pyrimidines. The purines include guanine (G) and adenine (A) whereas the pyrimidines consist of cytosine (C), uracil (U), and thymine (T). Uracil is used in RNA whereas thymine is used in DNA. Taken together, when the different sugar and bases are take into consideration, there are eight distinct nucleotides that can form two types of nucleic acids: DNA (A, G, C, and T) and RNA (A, G, C, and U).\n\nCells\n\nCell theory states that cells are the fundamental units of life, that all living things are composed of one or more cells, and that all cells arise from preexisting cells through cell division. Most cells are very small, with diameters ranging from 1 to 100\u00a0micrometers and are therefore only visible under a light or electron microscope. There are generally two types of cells: eukaryotic cells, which contain a nucleus, and prokaryotic cells, which do not. Prokaryotes are single-celled organisms such as bacteria, whereas eukaryotes can be single-celled or multicellular. In multicellular organisms, every cell in the organism's body is derived ultimately from a single cell in a fertilized egg.\n\nCell structure\n\nEvery cell is enclosed within a cell membrane that separates its cytoplasm from the extracellular space. A cell membrane consists of a lipid bilayer, including cholesterols that sit between phospholipids to maintain their fluidity at various temperatures. Cell membranes are semipermeable, allowing small molecules such as oxygen, carbon dioxide, and water to pass through while restricting the movement of larger molecules and charged particles such as ions. Cell membranes also contains membrane proteins, including integral membrane proteins that go across the membrane serving as membrane transporters, and peripheral proteins that loosely attach to the outer side of the cell membrane, acting as enzymes shaping the cell. Cell membranes are involved in various cellular processes such as cell adhesion, storing electrical energy, and cell signalling and serve as the attachment surface for several extracellular structures such as a cell wall, glycocalyx, and cytoskeleton.\n\nWithin the cytoplasm of a cell, there are many biomolecules such as proteins and nucleic acids. In addition to biomolecules, eukaryotic cells have specialized structures called organelles that have their own lipid bilayers or are spatially units. These organelles include the cell nucleus, which contains most of the cell's DNA, or mitochondria, which generates adenosine triphosphate (ATP) to power cellular processes. Other organelles such as endoplasmic reticulum and Golgi apparatus play a role in the synthesis and packaging of proteins, respectively. Biomolecules such as proteins can be engulfed by lysosomes, another specialized organelle. Plant cells have additional organelles that distinguish them from animal cells such as a cell wall that provides support for the plant cell, chloroplasts that harvest sunlight energy to produce sugar, and vacuoles that provide storage and structural support as well as being involved in reproduction and breakdown of plant seeds. Eukaryotic cells also have cytoskeleton that is made up of microtubules, intermediate filaments, and microfilaments, all of which provide support for the cell and are involved in the movement of the cell and its organelles. In terms of their structural composition, the microtubules are made up of tubulin (e.g., \u03b1-tubulin and \u03b2-tubulin whereas intermediate filaments are made up of fibrous proteins. Microfilaments are made up of actin molecules that interact with other strands of proteins.\n\nMetabolism\n\nAll cells require energy to sustain cellular processes. Energy is the capacity to do work, which, in thermodynamics, can be calculated using Gibbs free energy. According to the first law of thermodynamics, energy is conserved, i.e., cannot be created or destroyed. Hence, chemical reactions in a cell do not create new energy but are involved instead in the transformation and transfer of energy. Nevertheless, all energy transfers lead to some loss of usable energy, which increases entropy (or state of disorder) as stated by the second law of thermodynamics. As a result, an organism requires continuous input of energy to maintain a low state of entropy. In cells, energy can be transferred as electrons during redox (reduction\u2013oxidation) reactions, stored in covalent bonds, and generated by the movement of ions (e.g., hydrogen, sodium, potassium) across a membrane.\n\nMetabolism is the set of life-sustaining chemical reactions in organisms. The three main purposes of metabolism are: the conversion of food to energy to run cellular processes; the conversion of food/fuel to building blocks for proteins, lipids, nucleic acids, and some carbohydrates; and the elimination of metabolic wastes. These enzyme-catalyzed reactions allow organisms to grow and reproduce, maintain their structures, and respond to their environments. Metabolic reactions may be categorized as catabolic \u2013 the breaking down of compounds (for example, the breaking down of glucose to pyruvate by cellular respiration); or anabolic \u2013 the building up (synthesis) of compounds (such as proteins, carbohydrates, lipids, and nucleic acids). Usually, catabolism releases energy, and anabolism consumes energy.\n\nThe chemical reactions of metabolism are organized into metabolic pathways, in which one chemical is transformed through a series of steps into another chemical, each step being facilitated by a specific enzyme. Enzymes are crucial to metabolism because they allow organisms to drive desirable reactions that require energy that will not occur by themselves, by coupling them to spontaneous reactions that release energy. Enzymes act as catalysts \u2013 they allow a reaction to proceed more rapidly without being consumed by it \u2013 by reducing the amount of activation energy needed to convert reactants into products. Enzymes also allow the regulation of the rate of a  metabolic reaction, for example in response to changes in the cell's environment or to signals from other cells.\n\nCellular respiration\n\nCellular respiration is a set of metabolic reactions and processes that take place in the cells of organisms to convert chemical energy from nutrients into adenosine triphosphate (ATP), and then release waste products. The reactions involved in respiration are catabolic reactions, which break large molecules into smaller ones, releasing energy because weak high-energy bonds, in particular in molecular oxygen, are replaced by stronger bonds in the products. Respiration is one of the key ways a cell releases chemical energy to fuel cellular activity. The overall reaction occurs in a series of biochemical steps, some of which are redox reactions. Although cellular respiration is technically a combustion reaction, it clearly does not resemble one when it occurs in a cell because of the slow, controlled release of energy from the series of reactions.\n\nSugar in the form of glucose is the main nutrient used by animal and plant cells in respiration. Cellular respiration involving oxygen is called aerobic respiration, which has four stages: glycolysis, citric acid cycle (or Krebs cycle), electron transport chain, and oxidative phosphorylation. Glycolysis is a metabolic process that occurs in the cytoplasm whereby glucose is converted into two pyruvates, with two net molecules of ATP being produced at the same time. Each pyruvate is then oxidized into acetyl-CoA by the pyruvate dehydrogenase complex, which also generates NADH and carbon dioxide. Acetyl-Coa enters the citric acid cycle, which takes places inside the mitochondrial matrix. At the end of the cycle, the total yield from 1 glucose (or 2 pyruvates) is 6 NADH, 2 FADH2, and 2 ATP molecules. Finally, the next stage is oxidative phosphorylation, which in eukaryotes, occurs in the mitochondrial cristae. Oxidative phosphorylation comprises the electron transport chain, which is a series of four protein complexes that transfer electrons from one complex to another, thereby releasing energy from NADH and FADH2 that is coupled to the pumping of protons (hydrogen ions) across the inner mitochondrial membrane (chemiosmosis), which generates a proton motive force. Energy from the proton motive force drives the enzyme ATP synthase to synthesize more ATPs by phosphorylating ADPs. The transfer of electrons terminates with molecular oxygen being the final electron acceptor.\n\nIf oxygen were not present, pyruvate would not be metabolized by cellular respiration but undergoes a process of fermentation. The pyruvate is not transported into the mitochondrion but remains in the cytoplasm, where it is converted to waste products that may be removed from the cell. This serves the purpose of oxidizing the electron carriers so that they can perform glycolysis again and removing the excess pyruvate. Fermentation oxidizes NADH to NAD+ so it can be re-used in glycolysis.  In the absence of oxygen, fermentation prevents the buildup of NADH in the cytoplasm and provides NAD+ for glycolysis.  This waste product varies depending on the organism. In skeletal muscles, the waste product is lactic acid. This type of fermentation is called lactic acid fermentation. In strenuous exercise, when energy demands exceed energy supply, the respiratory chain cannot process all of the hydrogen atoms joined by NADH. During anaerobic glycolysis, NAD+ regenerates when pairs of hydrogen combine with pyruvate to form lactate. Lactate formation is catalyzed by lactate dehydrogenase in a reversible reaction. Lactate can also be used as an indirect precursor for liver glycogen. During recovery, when oxygen becomes available, NAD+ attaches to hydrogen from lactate to form ATP. In yeast, the waste products are ethanol and carbon dioxide. This type of fermentation is known as alcoholic or ethanol fermentation. The ATP generated in this process is made by substrate-level phosphorylation, which does not require oxygen.\n\nPhotosynthesis\n\nPhotosynthesis is a process used by plants and other organisms to convert light energy into chemical energy that can later be released to fuel the organism's metabolic activities via cellular respiration. This chemical energy is stored in carbohydrate molecules, such as sugars, which are synthesized from carbon dioxide and water. In most cases, oxygen is also released as a waste product. Most plants, algae, and cyanobacteria perform photosynthesis, which is largely responsible for producing and maintaining the oxygen content of the Earth's atmosphere, and supplies most of the energy necessary for life on Earth.\n\nPhotosynthesis has four stages: Light absorption, electron transport, ATP synthesis, and carbon fixation. Light absorption is the initial step of photosynthesis whereby light energy is absorbed by chlorophyll pigments attached to proteins in the thylakoid membranes. The absorbed light energy is used to remove electrons from a donor (water) to a primary electron acceptor, a quinone designated as Q. In the second stage, electrons move from the quinone primary electron acceptor through a series of electron carriers until they reach a final electron acceptor, which is usually the oxidized form of NADP+, which is reduced to NADPH, a process that takes place in a protein complex called photosystem I (PSI). The transport of electrons is coupled to the movement of protons (or hydrogen) from the stroma to the thylakoid membrane, which forms a pH gradient across the membrane as hydrogen becomes more concentrated in the lumen than in the stroma. This is analogous to the proton-motive force generated across the inner mitochondrial membrane in aerobic respiration.\n\nDuring the third stage of photosynthesis, the movement of protons down their concentration gradients from the thylakoid lumen to the stroma through the ATP synthase is coupled to the synthesis of ATP by that same ATP synthase. The NADPH and ATPs generated by the light-dependent reactions in the second and third stages, respectively, provide the energy and electrons to drive the synthesis of glucose by fixing atmospheric carbon dioxide into existing organic carbon compounds, such as ribulose bisphosphate (RuBP) in a sequence of light-independent (or dark) reactions called the Calvin cycle.\n\nCell signaling\nCell communication (or signaling) is the ability of cells to receive, process, and transmit signals with its environment and with itself. Signals can be non-chemical such as light, electrical impulses, and heat, or chemical signals (or ligands) that interact with receptors, which can be found embedded in the cell membrane of another cell or located deep inside a cell. There are generally four types of chemical signals: autocrine, paracrine, juxtacrine, and hormones. In autocrine signaling, the ligand affects the same cell that releases it. Tumor cells, for example, can reproduce uncontrollably because they release signals that initiate their own self-division. In paracrine signaling, the ligand diffuses to nearby cells and affect them. For example, brain cells called neurons release ligands called neurotransmitters that diffuse across a synaptic cleft to bind with a receptor on an adjacent cell such as another neuron or muscle cell. In juxtacrine signaling, there is direct contact between the signaling and responding cells. Finally, hormones are ligands that travel through the circulatory systems of animals or vascular systems of plants to reach their target cells. Once a ligand binds with a receptor, it can influence the behavior of another cell, depending on the type of receptor. For instance, neurotransmitters that bind with an inotropic receptor can alter the excitability of a target cell. Other types of receptors include protein kinase receptors (e.g., receptor for the hormone insulin) and G protein-coupled receptors. Activation of G protein-coupled receptors can initiate second messenger cascades. The process by which a chemical or physical signal is transmitted through a cell as a series of molecular events is called signal transduction\n\nCell cycle\n\nThe cell cycle is a series of events that take place in a cell that cause it to divide into two daughter cells. These events include the duplication of its DNA and some of its organelles, and the subsequent partitioning of its cytoplasm into two daughter cells in a process called cell division. In eukaryotes (i.e., animal, plant, fungal, and protist cells), there are two distinct types of cell division: mitosis and meiosis. Mitosis is part of the cell cycle, in which replicated chromosomes are separated into two new nuclei. Cell division gives rise to genetically identical cells in which the total number of chromosomes is maintained. In general, mitosis (division of the nucleus) is preceded by the S stage of interphase (during which the DNA is replicated) and is often followed by telophase and cytokinesis; which divides the cytoplasm, organelles and cell membrane of one cell into two new cells containing roughly equal shares of these cellular components. The different stages of mitosis all together define the mitotic phase of an animal cell cycle\u2014the division of the mother cell into two  genetically identical daughter cells. The cell cycle is a vital process by which a single-celled fertilized egg develops into a mature organism, as well as the process by which hair, skin, blood cells, and some internal organs are renewed. After cell division, each of the daughter cells begin the interphase of a new cycle. In contrast to mitosis, meiosis results in four haploid daughter cells by undergoing one round of DNA replication followed by two divisions. Homologous chromosomes are separated in the first division (meiosis I), and sister chromatids are separated in the second division (meiosis II). Both of these cell division cycles are used in the process of sexual reproduction at some point in their life cycle. Both are believed to be present in the last eukaryotic common ancestor.\n\nProkaryotes (i.e., archaea and bacteria) can also undergo cell division (or binary fission). Unlike the processes of mitosis and meiosis in eukaryotes, binary fission takes in prokaryotes takes place without the formation of a spindle apparatus on the cell. Before binary fission, DNA in the bacterium is tightly coiled. After it has uncoiled and duplicated, it is pulled to the separate poles of the bacterium as it increases the size to prepare for splitting. Growth of a new cell wall begins to separate the bacterium (triggered by FtsZ polymerization and \"Z-ring\" formation) The new cell wall (septum) fully develops, resulting in the complete split of the bacterium. The new daughter cells have tightly coiled DNA rods, ribosomes, and plasmids.\n\nGenetics\n\nInheritance\n\nGenetics is the scientific study of inheritance. Mendelian inheritance, specifically, is the process by which genes and traits are passed on from parents to offspring. It was formulated by Gregor Mendel, based on his work with pea plants in the mid-nineteenth century. Mendel established several principles of inheritance. The first is that genetic characteristics, which are now called alleles, are discrete and have alternate forms (e.g., purple vs. white or tall vs. dwarf), each inherited from one of two parents. Based on his law of dominance and uniformity, which states that some alleles are dominant while others are recessive; an organism with at least one dominant allele will display the phenotype of that dominant allele. Exceptions to this rule include penetrance and expressivity. Mendel noted that during gamete formation, the alleles for each gene segregate from each other so that each gamete carries only one allele for each gene, which is stated by his law of segregation. Heterozygotic individuals produce gametes with an equal frequency of two alleles. Finally, Mendel formulated the law of independent assortment, which states that genes of different traits can segregate independently during the formation of gametes, i.e., genes are unlinked. An exception to this rule would include traits that are sex-linked. Test crosses can be performed to experimentally determine the underlying genotype of an organism with a dominant phenotype. A Punnett square can be used to predict the results of a test cross. The chromosome theory of inheritance, which states that genes are found on chromosomes, was supported by Thomas Morgans's experiments with fruit flies, which established the sex linkage between eye color and sex in these insects. In humans and other mammals (e.g., dogs), it is not feasible or practical to conduct test cross experiments. Instead, pedigrees, which are genetic representations of family trees, are used instead to trace the inheritance of a specific trait or disease through multiple generations.\n\nDNA\n\nA gene is a unit of heredity that corresponds to a region of deoxyribonucleic acid (DNA) that carries genetic information that influences the form or function of an organism in specific ways. DNA is a molecule composed of two polynucleotide chains that coil around each other to form a double helix, which was first described by James Watson and Francis Crick in 1953. It is found as linear chromosomes in eukaryotes, and circular chromosomes in prokaryotes. A chromosome is an organized structure consisting of DNA and histones. The set of chromosomes in a cell and any other hereditary information found in the mitochondria, chloroplasts, or other locations is collectively known as a cell's genome. In eukaryotes, genomic DNA is localized in the cell nucleus, or with small amounts in mitochondria and chloroplasts. In prokaryotes, the DNA is held within an irregularly shaped body in the cytoplasm called the nucleoid. The genetic information in a genome is held within genes, and the complete assemblage of this information in an organism is called its genotype. Genes encode the information needed by cells for the synthesis of proteins, which in turn play a central role in influencing the final phenotype of the organism.\n\nThe two polynucleotide strands that make up DNA run in opposite directions to each other and are thus antiparallel. Each strand is composed of nucleotides, with each nucleotide containing one of four nitrogenous bases (cytosine [C], guanine [G], adenine [A] or thymine [T]), a sugar called deoxyribose, and a phosphate group. The nucleotides are joined to one another in a chain by covalent bonds between the sugar of one nucleotide and the phosphate of the next, resulting in an alternating sugar-phosphate backbone. It is the sequence of these four bases along the backbone that encodes genetic information. Bases of the two polynucleotide strands are bound together by hydrogen bonds, according to base pairing rules (A with T and C with G), to make double-stranded DNA. The bases are divided into two groups: pyrimidines and purines. In DNA, the pyrimidines are thymine and cytosine whereas the purines are adenine and guanine.\n\nThere are grooves that run along the entire length of the double helix due to the uneven spacing of the DNA strands relative to each other. Both grooves differ in size, with the major groove being larger and therefore more accessible to the binding of proteins than the minor groove. The outer edges of the bases are exposed to these grooves and are therefore accessible for additional hydrogen bonding. Because each groove can have two possible base-pair configurations (G-C and A-T), there are four possible base-pair configurations within the entire double helix, each of which is chemically distinct from another. As a result, protein molecules are able to recognize and bind to specific base-pair sequences, which is the basis of specific DNA-protein interactions.\n\nDNA replication is a semiconservative process whereby each strand serves as a template for a new strand of DNA. The process begins with the unwounding of the double helix at an origin of replication, which separates the two strands, thereby making them available as two templates. This is then followed by the binding of the enzyme primase to the template to synthesize a starter RNA (or DNA in some viruses) strand called a primer from the 5\u2019 to 3\u2019 location. Once the primer is completed, the primase is released from the template, followed by the binding of the enzyme DNA polymerase to the same template to synthesize new DNA.\n\nDNA replication is not perfect as the DNA polymerase sometimes insert bases that are not complementary to the template (e.g., putting in A in the strand opposite to G in the template strand). In eukaryotes, the initial error or mutation rate is about 1 in 100,000. Proofreading and mismatch repair are the two mechanisms that repair these errors, which reduces the mutation rate to 10\u221210, particularly before and after a cell cycle.\n\nMutations are heritable changes in DNA. They can arise spontaneously as a result of replication errors that were not corrected by proofreading or can be induced by an environmental mutagen such as a chemical (e.g., nitrous acid, benzopyrene) or radiation (e.g., x-ray, gamma ray, ultraviolet radiation, particles emitted by unstable isotopes). Mutations can appear as a change in single base or at a larger scale involving chromosomal mutations such as deletions, inversions, or translocations.\n\nIn multicellular organisms, mutations can occur in somatic or germline cells. In somatic cells, the mutations are passed on to daughter cells during mitosis. In a germline cell such as a sperm or an egg, the mutation will appear in an organism at fertilization. Mutations can lead to several types of phenotypic effects such as silent, loss-of-function, gain-of-function, and conditional mutations.\n\nSome mutations can be beneficial, as they are a source of genetic variation for evolution. Others can be harmful if they were to result in a loss of function of genes needed for survival. Mutagens such as carcinogens are typically avoided as a matter of public health policy goals. One example is the banning of chlorofluorocarbons (CFC) by the Montreal Protocol, as CFCs tend to deplete the ozone layer, resulting in more ultraviolet radiation from the sun passing through the Earth's upper atmosphere, thereby causing somatic mutations that can lead to skin cancer. Similarly, smoking bans have been enforced throughout the world in an effort to reduce the incidence of lung cancer.\n\nGene expression\n\nGene expression is the molecular process by which a genotype gives rise to a phenotype, i.e., observable trait. The genetic information stored in DNA represents the genotype, whereas the phenotype results from the synthesis of proteins that control an organism's structure and development, or that act as enzymes catalyzing specific metabolic pathways. This process is summarized by the central dogma of molecular biology, which was formulated by Francis Crick in 1958. According to the Central Dogma, genetic information flows from DNA to RNA to protein. Hence, there are two gene expression processes: transcription (DNA to RNA) and translation (RNA to protein). These processes are used by all life\u2014eukaryotes (including multicellular organisms), prokaryotes (bacteria and archaea), and are exploited by viruses\u2014to generate the macromolecular machinery for life.\n\nDuring transcription, messenger RNA (mRNA) strands are created using DNA strands as a template, which is initiated when RNA polymerase binds to a DNA sequence called a promoter, which instructs the RNA to begin transcription of one of the two DNA strands. The DNA bases are exchanged for their corresponding bases except in the case of thymine (T), for which RNA substitutes uracil (U). In eukaryotes, a large part of DNA (e.g., >98% in humans) contain non-coding called introns, which do not serve as patterns for protein sequences. The coding regions or exons are interspersed along with the introns in the primary transcript (or pre-mRNA). Before translation, the pre-mRNA undergoes further processing whereby the introns are removed (or spliced out), leaving only the spliced exons in the mature mRNA strand.\n\nThe translation of mRNA to protein occurs in ribosomes, whereby the transcribed mRNA strand specifies the sequence of amino acids within proteins using the genetic code. Gene products are often proteins, but in non-protein-coding genes such as transfer RNA (tRNA) and small nuclear RNA (snRNA), the product is a functional non-coding RNA.\n\nGene regulation\n\nThe regulation of gene expression (or gene regulation) by environmental factors and during different stages of development can occur at each step of the process such as transcription, RNA splicing, translation, and post-translational modification of a protein.\n\nThe ability of gene transcription to be regulated allows for the conservation of energy as cells will only make proteins when needed. Gene expression can be influenced by positive or negative regulation, depending on which of the two types of regulatory proteins called transcription factors bind to the DNA sequence close to or at a promoter. A cluster of genes that share the same promoter is called an operon, found mainly in prokaryotes and some lower eukaryotes (e.g., Caenorhabditis elegans). It was first identified in Escherichia coli\u2014a prokaryotic cell that can be found in the intestines of humans and other animals\u2014in the 1960s by Fran\u00e7ois Jacob and Jacques Monod. They studied the prokaryotic cell's lac operon, which is part of three genes (lacZ, lacY, and lacA) that encode three lactose-metabolizing enzymes (\u03b2-galactosidase, \u03b2-galactoside permease, and \u03b2-galactoside transacetylase). In positive regulation of gene expression, the activator is the transcription factor that stimulates transcription when it binds to the sequence near or at the promoter. In contrast, negative regulation occurs when another transcription factor called a repressor binds to a DNA sequence called an operator, which is part of an operon, to prevent transcription. When a repressor binds to a repressible operon (e.g., trp operon), it does so only in the presence of a corepressor. Repressors can be inhibited by compounds called inducers (e.g., allolactose), which exert their effects by binding to a repressor to prevent it from binding to an operator, thereby allowing transcription to occur. Specific genes that can be activated by inducers are called inducible genes (e.g., lacZ or lacA in E. coli), which are in contrast to constitutive genes that are almost always active. In contrast to both, structural genes encode proteins that are not involved in gene regulation.\n\nIn prokaryotic cells, transcription is regulated by proteins called sigma factors, which bind to RNA polymerase and direct it to specific promoters. Similarly, transcription factors in eukaryotic cells can also coordinate the expression of a group of genes, even if the genes themselves are located on different chromosomes. Coordination of these genes can occur as long as they share the same regulatory DNA sequence that bind to the same transcription factors. Promoters in eukaryotic cells are more diverse but tend to contain a core sequence that RNA polymerase can bind to, with the most common sequence being the TATA box, which contains multiple repeating A and T bases. Specifically, RNA polymerase II is the RNA polymerase that binds to a promoter to initiate transcription of protein-coding genes in eukaryotes, but only in the presence of multiple general transcription factors, which are distinct from the transcription factors that have regulatory effects, i.e., activators and repressors. In eukaryotic cells, DNA sequences that bind with activators are called enhances whereas those sequences that bind with repressors are called silencers. Transcription factors such as nuclear factor of activated T-cells (NFAT) are able to identify specific nucleotide sequence based on the base sequence (e.g., CGAGGAAAATTG for NFAT) of the binding site, which determines the arrangement of the chemical groups within that sequence that allows for specific DNA-protein interactions. The expression of transcription factors is what underlies cellular differentiation in a developing embryo.\n\nIn addition to regulatory events involving the promoter, gene expression can also be regulated by epigenetic changes to chromatin, which is a complex of DNA and protein found in eukaryotic cells.\n\nPost-transcriptional control of mRNA can involve the alternative splicing of primary mRNA transcripts, resulting in a single gene giving rise to different mature mRNAs that encode a family of different proteins. A well-studied example is the Sxl gene in Drosophila, which determines the sex in these animals. The gene itself contains four exons and alternative splicing of its pre-mRNA transcript can generate two active forms of the Sxl protein in female flies and one in inactive form of the protein in males. Another example is the human immunodeficiency virus (HIV), which has a single pre-mRNA transcript that can generate up to nine proteins as a result of alternative splicing. In humans, eighty percent of all 21,000 genes are alternatively spliced. Given that both chimpanzees and humans have a similar number of genes, it is thought that alternative splicing might have contributed to the latter's complexity due to the greater number of alternative splicing in the human brain than in the brain of chimpanzees.\n\nTranslation can be regulated in three known ways, one of which involves the binding of tiny RNA molecules called microRNA (miRNA) to a target mRNA transcript, which inhibits its translation and causes it to degrade. Translation can also be inhibited by the modification of the 5\u2019 cap by substituting the modified guanosine triphosphate (GTP) at the 5\u2019 end of an mRNA for an unmodified GTP molecule. Finally, translational repressor proteins can bind to mRNAs and prevent them from attaching to a ribosome, thereby blocking translation.\n\nOnce translated, the stability of proteins can be regulated by being targeted for degradation. A common example is when an enzyme attaches a regulatory protein called ubiquitin to the lysine residue of a targeted protein. Other ubiquitins then attached to the primary ubiquitin to form a polyubiquitinated protein, which then enters a much larger protein complex called proteasome. Once the polyubiquitinated protein enters the proteasome, the polyubiquitin detaches from the target protein, which is unfolded by the proteasome in an ATP-dependent manner, allowing it to be hydrolyzed by three proteases.\n\nGenomes\n\nA genome is an organism's complete set of DNA, including all of its genes. Sequencing and analysis of genomes can be done using high throughput DNA sequencing and bioinformatics to assemble and analyze the function and structure of entire genomes. The genomes of prokaryotes are small, compact, and diverse. In contrast, the genomes of eukaryotes are larger and more complex such as having more regulatory sequences and much of its genome are made up of non-coding DNA sequences for functional RNA (rRNA, tRNA, and mRNA) or regulatory sequences. The genomes of various model organisms such as arabidopsis, fruit fly, mice, nematodes, and yeast have been sequenced. The Human Genome Project was a major undertaking by the international scientific community to sequence the entire human genome, which was completed in 2003. The sequencing of the human genome has yielded practical applications such as DNA fingerprinting, which can be used for paternity testing and forensics. In medicine, sequencing of the entire human genome has allowed for the identification of mutations that cause tumors as well as genes that cause a specific genetic disorder. The sequencing of genomes from various organisms has led to the emergence of comparative genomics, which aims to draw comparisons of genes from the genomes of those different organisms.\n\nMany genes encode more than one protein, with posttranslational modifications increasing the diversity of proteins within a cell. An organism's proteome is its entire set of proteins expressed by its genome and proteomics seeks to study the complete set of proteins produced by an organism. Because many proteins are enzymes, their activities tend to affects the concentrations of substrates and products. Thus, as the proteome changes, so do the amount of small molecules or metabolites. The complete set of small molecules in a cell or organism is called a metabolome and metabolomics is the study of the metabolome in relation to the physiological activity of a cell or organism.\n\nBiotechnology\n\nBiotechnology is the use of cells or organisms to develop products for humans. One commonly used technology with wide applications is the creation of recombinant DNA, which is a DNA molecule assembled from two or more sources in a laboratory. Before the advent of polymerase chain reaction, biologists would manipulate DNA by cutting it into smaller fragments using restriction enzymes. They would then purify and analyze the fragments using gel electrophoresis and then later recombine the fragments into a novel DNA sequence using DNA ligase. The recombinant DNA is then cloned by inserting it into a host cell, a process known as transformation if the host cells were bacteria such as E. coli,  or transfection if the host cells were eukaryotic cells like yeast, plant, or animal cells. Once the host cell or organism has received and integrated the recombinant DNA, it is described as transgenic.\n\nA recombinant DNA can be inserted in one of two ways. A common method is to simply insert the DNA into a host chromosome, with the site of insertion being random. Another approach would be to insert the recombinant DNA as part of another DNA sequence called a vector, which then integrates into the host chromosome or has its own origin of DNA replication, thereby allowing to replicate independently of the host chromosome. Plasmids from bacterial cells such as E. coli are typically used as vectors due to their relatively small size (e.g. 2000-6000 base pairs in E. coli), presence of restriction enzymes, genes that are resistant to antibiotics, and the presence of an origin of replication. A gene coding for a selectable marker such as antibiotic resistance is also incorporated into the vector. Inclusion of this market allows for the selection of only those host cells that contained the recombinant DNA while discarding those that do not. Moreover, the marker also serves as a reporter gene that once expressed, can be easily detected and measured.\n\nOnce the recombinant DNA is inside individual bacterial cells, those cells are then plated and allowed to grow into a colony that contains millions of transgenic cells that carry the same recombinant DNA. These transgenic cells then produce large quantities of the transgene product such as human insulin, which was the first medicine to be made using recombinant DNA technology.\n\nOne of the goals of molecular cloning is to identify the function of specific DNA sequences and the proteins they encode. For a specific DNA sequence to be studied and manipulated, millions of copies of DNA fragments containing that DNA sequence need to be made. This involves breaking down an intact genome, which is much too large to be introduced into a host cell, into smaller DNA fragments. Although no longer intact, the collection of these DNA fragments still make up an organism\u2019s genome, with the collection itself being referred to as a genomic library, due to the ability to search and retrieve specific DNA fragments for further study, analogous to the process of retrieving a book from a regular library. DNA fragments can be obtained using restriction enzymes and other processes such as mechanical shearing. Each obtained fragment is then inserted into a vector that is taken up by a bacterial host cell. The host cell is then allowed to proliferate on a selective medium (e.g., antibiotic resistance), which produces a colony of these recombinant cells, each of which contains many copies of the same DNA fragment. These colonies can be grown by spreading them over a solid medium in Petri dishes, which are incubated at a suitable temperature. One dish alone can hold thousands of bacterial colonies, which can be easily screened for a specific DNA sequence. The sequence can be identified by first duplicating a Petri dish with bacterial colonies and then exposing the DNA of the duplicated colonies for hybridization, which involves labeling them with complementary radioactive or fluorescent nucleotides.\n\nSmaller DNA libraries that contain genes from a specific tissue can be created using complementary DNA (cDNA). The collection of these cDNAs from a specific tissue at a particular time is called a cDNA library, which provides a \u201csnapshot\u201d of transcription patterns of cells at a specific location and time.\n\nOther biotechnology tools include DNA microarrays, expression vectors, synthetic genomics, and CRISPR gene editing. Other approaches such as pharming can produce large quantities of medically useful products through the use of genetically modified organisms. Many of these other tools also have wide applications such as creating medically useful proteins, or improving plant cultivation and animal husbandry.\n\nGenes, development, and evolution\n\nDevelopment is the process by which a multicellular organism (plant or animal) goes through a series of a changes, starting from a single cell, and taking on various forms that are characteristic of its life cycle. There are four key processes that underlie development: Determination, differentiation, morphogenesis, and growth. Determination sets the developmental fate of a cell, which becomes more restrictive during development. Differentiation is the process by which specialized cells from less specialized cells such as stem cells. Stem cells are undifferentiated or partially differentiated cells that can differentiate into various types of cells and proliferate indefinitely to produce more of the same stem cell. Cellular differentiation dramatically changes a cell's size, shape, membrane potential, metabolic activity, and responsiveness to signals, which are largely due to highly controlled modifications in gene expression and epigenetics.  With a few exceptions, cellular differentiation almost never involves a change in the DNA sequence itself. Thus, different cells can have very different physical characteristics despite having the same genome. Morphogenesis, or development of body form, is the result of spatial differences in gene expression. Specially, the organization of differentiated tissues into specific structures such as arms or wings, which is known as pattern formation, is governed by morphogens, signaling molecules that move from one group of cells to surrounding cells, creating a morphogen gradient as described by the French flag model. Apoptosis, or programmed cell death, also occurs during morphogenesis, such as the death of cells between digits in human embryonic development, which frees up individual fingers and toes. Expression of transcription factor genes can determine organ placement in a plant and a cascade of transcription factors themselves can establish body segmentation in a fruit fly.\n\nA small fraction of the genes in an organism's genome called the developmental-genetic toolkit control the development of that organism. These toolkit genes are highly conserved among phyla, meaning that they are ancient and very similar in widely separated groups of animals. Differences in deployment of toolkit genes affect the body plan and the number, identity, and pattern of body parts. Among the most important toolkit genes are the Hox genes. Hox genes determine where repeating parts, such as the many vertebrae of snakes, will grow in a developing embryo or larva. Variations in the toolkit may have produced a large part of the morphological evolution of animals. The toolkit can drive evolution in two ways. A toolkit gene can be expressed in a different pattern, as when the beak of Darwin's large ground-finch was enlarged by the BMP gene, or when snakes lost their legs as Distal-less (Dlx) genes became under-expressed or not expressed at all in the places where other reptiles continued to form their limbs. Or, a toolkit gene can acquire a new function, as seen in the many functions of that same gene, distal-less, which controls such diverse structures as the mandible in vertebrates, legs and antennae in the fruit fly, and eyespot pattern in butterfly wings. Given that small changes in toolbox genes can cause significant changes in body structures, they have often enabled convergent or parallel evolution.\n\nEvolution\n\nEvolutionary processes\n\nA central organizing concept in biology is that life changes and develops through evolution, which is the change in heritable characteristics of populations over successive generations. Evolution is now used to explain the great variations of life on Earth. The term evolution was introduced into the scientific lexicon by Jean-Baptiste de Lamarck in 1809. He proposed that evolution occurred as a result of inheritance of acquired characteristics, which was unconvincing but there were no alternative explanations at the time. Charles Darwin, an English naturalist, had returned to England in 1836 from his five-year travels on the HMS Beagle where he studied rocks and collected plants and animals from various parts of the world such as the Gal\u00e1pagos Islands. He had also read Principles of Geology by Charles Lyell and An Essay on the Principle of Population by Thomas Malthus and was influenced by them. Based on his observations and readings, Darwin began to formulate his theory of evolution by natural selection to explain the diversity of plants and animals in different parts of the world. Alfred Russel Wallace, another English naturalist who had studied plants and animals in the Malay Archipelago, also came to the same idea, but later and independently of Darwin. Both Darwin and Wallace jointly presented their essay and manuscript, respectively, at the Linnaean Society of London in 1858, giving them both credit for their discovery of evolution by natural selection. Darwin would later publish his book On the Origin of Species in 1859, which explained in detail how the process of evolution by natural selection works.\n\nTo explain natural selection, Darwin drew an analogy with humans modifying animals through artificial selection, whereby animals were selectively bred for specific traits, which has given rise to individuals that no longer resemble their wild ancestors. Darwin argued that in the natural world, it was nature that played the role of humans in selecting for specific traits. He came to this conclusion based on two observations and two inferences. First, members of any population tend to vary with respect to their heritable traits. Second, all species tend to produce more offspring than can be supported by their respective environments, resulting in many individuals not surviving and reproducing. Based on these observations, Darwin inferred that those individuals who possessed heritable traits that are better adapted to their environments are more likely to survive and produce more offspring than other individuals. He further inferred that the unequal or differential survival and reproduction of certain individuals over others will lead to the accumulation of favorable traits over successive generations, thereby increasing the match between the organisms and their environment. Thus, taken together, natural selection is the differential survival and reproduction of individuals in subsequent generations due to differences in or more heritable traits.\n\nDarwin was not aware of Mendel's work of inheritance and so the exact mechanism of inheritance that underlie natural selection was not well-understood until the early 20th century when the modern synthesis reconciled Darwinian evolution with classical genetics, which established a neo-Darwinian perspective of evolution by natural  selection. This perspective holds that evolution occurs when there are changes in the allele frequencies within a population of interbreeding organisms. In the absence of any evolutionary process acting on a large random mating population, the allele frequencies will remain constant across generations as described by the Hardy\u2013Weinberg principle.\n\nAnother process that drives evolution is genetic drift, which is the random fluctuations of allele frequencies within a population from one generation to the next. When selective forces are absent or relatively weak, allele frequencies are equally likely to drift upward or downward at each successive generation because the alleles are subject to sampling error. This drift halts when an allele eventually becomes fixed, either by disappearing from the population or replacing the other alleles entirely. Genetic drift may therefore eliminate some alleles from a population due to chance alone.\n\nSpeciation\n\nA species is a group of organisms that mate with one another and speciation is the process by which one lineage splits into two lineages as a result of having evolved independently from each other. For speciation to occur, there has to be reproductive isolation. Reproductive isolation can result from incompatibilities between genes as described by Bateson\u2013Dobzhansky\u2013Muller model. Reproductive isolation also tends to increase with genetic divergence. Speciation can occur when there are physical barriers that divide an ancestral species, a process known as allopatric speciation. In contrast, sympatric speciation occurs in the absence of physical barriers.\n\nPre-zygotic isolation such as mechanical, temporal, behavioral, habitat, and gametic isolations can prevent different species from hybridizing. Similarly, post-zygotic isolations can result in hybridization being selected against due to the lower viability of hybrids or hybrid infertility (e.g., mule). Hybrid zones can emerge if there were to be incomplete reproductive isolation between two closely related species.\n\nPhylogeny\n\nA phylogeny is an evolutionary history of a specific group of organisms or their genes. It can be represented using a phylogenetic tree, which is a diagram showing lines of descent among organisms or their genes. Each line drawn on the time axis of a tree represents a lineage of descendants of a particular species or population. When a lineage divides into two, it is represented as a node (or split) on the phylogenetic tree. The more splits there are over time, the more branches there will be on the tree, with the common ancestor of all the organisms in that tree being represented by the root of that tree. Phylogenetic trees may portray the evolutionary history of all life forms, a major evolutionary group (e.g., insects), or an even smaller group of closely related species. Within a tree, any group of species designated by a name is a taxon (e.g., humans, primates, mammals, or vertebrates) and a taxon that consists of all its evolutionary descendants is a clade, otherwise known as a monophyletic taxon. Closely related species are referred to as sister species and closely related clades are sister clades. In contrast to a monophyletic group, a polyphyletic group does not include its common ancestor whereas a paraphyletic group does not include all the descendants of a common ancestor.\n\nPhylogenetic trees are the basis for comparing and grouping different species. Different species that share a feature inherited from a common ancestor are described as having homologous features (or synapomorphy). Homologous features may be any heritable traits such as DNA sequence, protein structures, anatomical features, and behavior patterns. A vertebral column is an example of a homologous feature shared by all vertebrate animals. Traits that have a similar form or function but were not derived from a common ancestor are described as analogous features. Phylogenies can be reconstructed for a group of organisms of primary interests, which are called the ingroup. A species or group that is closely related to the ingroup but is phylogenetically outside of it is called the outgroup, which serves a reference point in the tree. The root of the tree is located between the ingroup and the outgroup. When phylogenetic trees are reconstructed, multiple trees with different evolutionary histories can be generated. Based on the principle of Parsimony (or Occam's razor), the tree that is favored is the one with the fewest evolutionary changes needed to be assumed over all traits in all groups. Computational algorithms can be used to determine how a tree might have evolved given the evidence.\n\nPhylogeny provides the basis of biological classification, which is based on Linnaean taxonomy that was developed by Carl Linnaeus in the 18th century. This classification system is rank-based, with the highest rank being the domain followed by kingdom, phylum, class, order, family, genus, and species. All organisms can be classified as belonging to one of three domains: Archaea (originally Archaebacteria); bacteria (originally eubacteria), or eukarya (includes the protist, fungi, plant, and animal kingdoms). A binomial nomenclature is used to classify different species. Based on this system, each species is given two names, one for its genus and another for its species. For example, humans are Homo sapiens, with Homo being the genus and sapiens being the species. By convention, the scientific names of organisms are italicized, with only the first letter of the genus capitalized.\n\nHistory of life\n\nThe history of life on Earth traces the processes by which organisms have evolved from the earliest emergence of life to present day. Earth formed about 4.5 billion years ago and all life on Earth, both living and extinct, descended from a last universal common ancestor that lived about 3.5 billion years ago. The dating of the Earth's history can be done using several geological methods such as stratigraphy, radiometric dating, and paleomagnetic dating. Based on these methods, geologists have developed a geologic time scale that divides the history of the Earth into major divisions, starting with four eons (Hadean, Archean, Proterozoic, and Phanerozoic), the first three of which are collectively known as the Precambrian, which lasted approximately 4 billion years. Each eon can be divided into eras, with the Phanerozoic eon that began 542 million years ago being subdivided into Paleozoic, Mesozoic, and Cenozoic eras. These three eras together comprise eleven periods (Cambrian, Ordovician, Silurian, Devonian, Carboniferous, Permian, Triassic, Jurassic, Cretaceous, Tertiary, and Quaternary) and each period into epochs.\n\nThe similarities among all known present-day species indicate that they have diverged through the process of evolution from their common ancestor. Biologists regard the ubiquity of the genetic code as evidence of universal common descent for all bacteria, archaea, and eukaryotes. Microbal mats of coexisting bacteria and archaea were the dominant form of life in the early Archean epoch and many of the major steps in early evolution are thought to have taken place in this environment. The earliest evidence of eukaryotes dates from 1.85 billion years ago, and while they may have been present earlier, their diversification accelerated when they started using oxygen in their metabolism. Later, around 1.7 billion years ago, multicellular organisms began to appear, with differentiated cells performing specialised functions.\n\nAlgae-like multicellular land plants are dated back even to about 1 billion years ago, although evidence suggests that microorganisms formed the earliest terrestrial ecosystems, at least 2.7 billion years ago. Microorganisms are thought to have paved the way for the inception of land plants in the Ordovician period. Land plants were so successful that they are thought to have contributed to the Late Devonian extinction event.\n\nEdiacara biota appear during the Ediacaran period, while vertebrates, along with most other modern phyla originated about 525 million years ago during the Cambrian explosion. During the Permian period, synapsids, including the ancestors of mammals, dominated the land, but most of this group became extinct in the Permian\u2013Triassic extinction event 252 million years ago. During the recovery from this catastrophe, archosaurs became the most abundant land vertebrates; one archosaur group, the dinosaurs, dominated the Jurassic and Cretaceous periods. After the Cretaceous\u2013Paleogene extinction event 66 million years ago killed off the non-avian dinosaurs, mammals increased rapidly in size and diversity. Such mass extinctions may have accelerated evolution by providing opportunities for new groups of organisms to diversify.\n\nDiversity\n\nBacteria and Archaea\n\nBacteria are a type of cell that constitute a large domain of prokaryotic microorganisms. Typically a few micrometers in length, bacteria have a number of shapes, ranging from spheres to rods and spirals. Bacteria were among the first life forms to appear on Earth, and are present in most of its habitats. Bacteria inhabit soil, water, acidic hot springs, radioactive waste, and the deep biosphere of the earth's crust. Bacteria also live in symbiotic and parasitic relationships with plants and animals. Most bacteria have not been characterised, and only about 27 percent of the bacterial phyla have species that can be grown in the laboratory.\n\nArchaea constitute the other domain of prokaryotic cells and were initially classified as bacteria, receiving the name archaebacteria (in the Archaebacteria kingdom), a term that has fallen out of use. Archaeal cells have unique properties separating them from the other two domains, Bacteria and Eukaryota. Archaea are further divided into multiple recognized phyla. Archaea and bacteria are generally similar in size and shape, although a few archaea have very different shapes, such as the flat and square cells of Haloquadratum walsbyi. Despite this morphological similarity to bacteria, archaea possess genes and several metabolic pathways that are more closely related to those of eukaryotes, notably for the enzymes involved in transcription and translation. Other aspects of archaeal biochemistry are unique, such as their reliance on ether lipids in their cell membranes, including archaeols. Archaea use more energy sources than eukaryotes: these range from organic compounds, such as sugars, to ammonia, metal ions or even hydrogen gas. Salt-tolerant archaea (the Haloarchaea) use sunlight as an energy source, and other species of archaea fix carbon, but unlike plants and cyanobacteria, no known species of archaea does both. Archaea reproduce asexually by binary fission, fragmentation, or budding; unlike bacteria, no known species of Archaea form endospores.\n\nThe first observed archaea were extremophiles, living in extreme environments, such as hot springs and salt lakes with no other organisms. Improved molecular detection tools led to the discovery of archaea in almost every habitat, including soil, oceans, and marshlands. Archaea are particularly numerous in the oceans, and the archaea in plankton may be one of the most abundant groups of organisms on the planet.\n\nArchaea are a major part of Earth's life. They are part of the microbiota of all organisms. In the human microbiome, they are important in the gut, mouth, and on the skin. Their morphological, metabolic, and geographical diversity permits them to play multiple ecological roles: carbon fixation; nitrogen cycling; organic compound turnover; and maintaining microbial symbiotic and syntrophic communities, for example.\n\nProtists\n\nEukaryotes are hypothesized to have split from archaea, which was followed by their endosymbioses with bacteria (or symbiogenesis) that gave rise to mitochondria and chloroplasts, both of which are now part of modern day eukaryotic cells. The major lineages of eukaryotes diversified in the Precambrian about 1.5 billion years ago and can be classified into eight major clades: alveolates, excavates, stramenopiles, plants, rhizarians, amoebozoans, fungi, and animals. Five of these clades are collectively known as protists, which are mostly microscopic eukaryotic organisms that are not plants, fungi, or animals. While it is likely that protists share a common ancestor (the last eukaryotic common ancestor), protists by themselves do not constitute a separate clade as some protists may be more closely related to plants, fungi, or animals than they are to other protists. Like groupings such as algae, invertebrates, or protozoans, the protist grouping is not a formal taxonomic group but is used for convenience. Most protists are unicellular, which are also known as microbial eukaryotes.\n\nThe alveolates are mostly photosynthetic unicellular protists that possess sacs called alveoli (hence their name alveolates) that are located beneath their cell membrane, providing support for the cell surface. Alveolates comprise several groups such as dinoflagellates, apicomplexans, and ciliates. Dinoflagellates are photosynthetic and can be found in the ocean where they play a role as primary producers of organic matter. Apicomplexans are parasitic alveolates that possess an apical complex, which is a group of organelles located in the apical end of the cell. This complex allows apicomplexans to invade their hosts' tissues. Ciliates are alveolates that possess numerous hair-like structure called cilia. A defining characteristic of ciliates is the presence of two types of nuclei in each ciliate cell. A commonly studied ciliate is the paramecium.\n\nThe excavates are groups of protists that began to diversify approximately 1.5 billion years ago shortly after the origin of the eukaryotes. Some excavates do not possess mitochondria, which are thought to have been lost over the course of evolution as these protists still possess nuclear genes that are associated with mitochondria. The excavates comprise several groups such as diplomonads, parabasalids, heteroloboseans, euglenids, and kinetoplastids.\n\nStramenopiles, most of which can be characterized by the presence of tubular hairs on the longer of their two flagella, include diatoms and brown algae. Diatoms are primary producers and contribute about one-fifth of all photosynthetic carbon fixation, making them a major component of phytoplankton.\n\nRhizarians are mostly unicellular and aquatic protists that typically contain long, thin pseudopods. The rhizarians comprise three main groups: cercozoans, foraminiferans, and radiolarians.\n\nAmoebozoans are protists with a body form characterized by the presence lobe-shaped pseudopods, which help them to move. They include groups such as loboseans and slime molds (e.g., plasmodial slime mold and cellular slime molds).\n\nPlant diversity\n\nPlants are mainly multicellular organisms, predominantly photosynthetic eukaryotes of the kingdom Plantae, which would exclude fungi and some algae. A shared derived trait (or synapomorphy) of Plantae is the primary endosymbiosis of a cyanobacterium into an early eukaryote about one billion years ago, which gave rise to chloroplasts. The first several clades that emerged following primary endosymbiosis were aquatic and most of the aquatic photosynthetic eukaryotic organisms are collectively described as algae, which is a term of convenience as not all algae are closely related. Algae comprise several distinct clades such as glaucophytes, which are microscopic freshwater algae that may have resembled in form to the early unicellular ancestor of Plantae. Unlike glaucophytes, the other algal clades such as red and green algae are multicellular. Green algae comprise three major clades: chlorophytes, coleochaetophytes, and stoneworts.\n\nLand plants (embryophytes) first appeared in terrestrial environments approximately 450 to 500 million years ago. A synapomorphy of land plants is an embryo that develops under the protection of tissues of its parent plant. Land plants comprise ten major clades, seven of which constitute a single clade known as vascular plants (or tracheophytes) as they all have tracheids, which are fluid-conducting cells, and a well-developed system that transports materials throughout their bodies. In contrast, the other three clades are nonvascular plants as they do not have tracheids. They also do not constitute a single clade.\n\nNonvascular plants include liverworts, mosses, and hornworts. They tend to be found in areas where water is readily available. Most live on soil or even on vascular plants themselves. Some can grow on bare rock, tree trunks that are dead or have fallen, and even buildings. Most nonvascular plants are terrestrial, with a few living in freshwater environments and none living in the oceans.\n\nThe seven clades (or divisions) that make up vascular plants include horsetails and ferns, which together can be grouped as a single clade called monilophytes. Seed plants (or spermatophyte) comprise the other five divisions, four of which are grouped as gymnosperms and one is angiosperms. Gymnosperms includes conifers, cycads, Ginkgo, and gnetophytes. Gymnosperm seeds develop either on the surface of scales or leaves, which are often modified to form cones, or solitary as in yew, Torreya, Ginkgo. Angiosperms are the most diverse group of land plants, with 64 orders, 416 families, approximately 13,000 known genera and 300,000 known species. Like gymnosperms, angiosperms are seed-producing plants. They are distinguished from gymnosperms by having characteristics such as flowers, endosperm within their seeds, and production of fruits that contain the seeds.\n\nFungi\n\nFungi are eukaryotic organisms that digest foods outside of their bodies. They do so through a process called absorptive heterotrophy whereby they would first secrete digestive enzymes that break down large food molecules before absorbing them through their cell membranes. Many fungi are also saprobes as they are able to take in nutrients from dead organic matter and are hence, the principal decomposers in ecological systems. Some fungi are parasites by absorbing nutrients from living hosts while others are mutualists. Fungi, along with two other lineages, choanoflagellates and animals, can be grouped as opisthokonts. A synapomorphy that distinguishes fungi from other two opisthokonts is the presence of chitin in their cell walls.\n\nMost fungi are multicellular but some are unicellular such as yeasts, which live in liquid or moist environments and are able to absorb nutrients directly into their cell surfaces. Multicellular fungi, on the other hand, have a body called mycelium, which is composed of a mass of individual tubular filaments called hyphae that allows for nutrient absorption to occur.\n\nFungi can be divided into six major groups based on their life cycles: microsporidia, chytrids, zygospore fungi (Zygomycota), arbuscular mycorrhizal fungi (Glomeromycota), sac fungi (Ascomycota), and club fungi (Basidiomycota).\n\nThe fungus kingdom encompasses an enormous diversity of taxa with varied ecologies, life cycle strategies, and morphologies ranging from unicellular aquatic chytrids to large mushrooms. However, little is known of the true biodiversity of Kingdom Fungi, which has been estimated at 2.2\u00a0million to 3.8\u00a0million species. Of these, only about 148,000 have been described, with over 8,000 species known to be detrimental to plants and at least 300 that can be pathogenic to humans.\n\nAnimal diversity\n\nAnimals are multicellular eukaryotic organisms that form the kingdom Animalia. With few exceptions, animals consume organic material, breathe oxygen, are able to move, can reproduce sexually, and grow from a hollow sphere of cells, the blastula, during embryonic development. Over 1.5 million living animal species have been described\u2014of which around 1 million are insects\u2014but it has been estimated there are over 7 million animal species in total. They have complex interactions with each other and their environments, forming intricate food webs.\n\nAnimals can be distinguished into two groups based on their developmental characteristics. For instance, embryos of diploblastic animals such as ctenophores, placeozoans, and cnidarians have two cell layers (ectoderm and endoderm) whereas the embryos of triploblastic animals have three tissue layers (ectoderm, mesoderm, and endoderm), which is a synapomorphy of these animals. Triploblastic animals can be further divided into two major clades based on based on the pattern of gastrulation, whereby a cavity called a blastopore is formed from the indentation of a blastula. In protostomes, the blastopore gives rise to the mouth, which is then followed by the formation of the anus. In deuterostomes, the blastopore gives rise to the anus, followed by the formation of the mouth.\n\nAnimals can also be differentiated based on their body plan, specifically with respect to four key features: symmetry, body cavity, segmentation, and appendages. The bodies of most animals are symmetrical, with symmetry being either radial or bilateral. Triploblastic animals can be divided into three types based on their body cavity: acoelomate, pseudocoelomate, and coelomate. Segmentation can be observed in the bodies of many animals, which allows for specialization of different parts of the body as well as allowing the animal to change the shape of its body to control its movements. Finally, animals can be distinguished based on the type and location of their appendages such as antennae for sensing the environment or claws for capturing prey.\n\nSponges, the members of the phylum Porifera, are a basal Metazoa (animal) clade as a sister of the diploblasts. They are multicellular organisms that have bodies full of pores and channels allowing water to circulate through them, consisting of jelly-like mesohyl sandwiched between two thin layers of cells.\n\nThe majority (~97%) of animal species are invertebrates, which are animals that do not have a vertebral column (or backbone or spine), derived from the notochord. This includes all animals apart from the subphylum Vertebrata. Familiar examples of invertebrates include sponges, cnidarians (hydras, jellyfishes, sea anemones, and corals), mollusks (chitons, snail, bivalves, squids, and octopuses), annelids (earthworms and leeches), and arthropods (insects, arachnids, crustaceans, and myriapods). Many invertebrate taxa have a greater number and variety of species than the entire subphylum of Vertebrata.\n\nIn contrast, vertebrates comprise all species of animals within the subphylum Vertebrata, which are chordates with vertebral columns. These animals have four key features, which are an anterior skull with a brain, a rigid internal skeleton supported by a vertebral column that encloses a spinal cord, internal organs suspended in a coelom, and a well-developed circulatory system driven by a single large heart. Vertebrates represent the overwhelming majority of the phylum Chordata, with currently about 69,963 species described. Vertebrates comprise different major groups that include jawless fishes (not including hagfishes), jawed vertebrates such as cartilaginous fishes (sharks, rays, and ratfish), bony fishes, tetrapods such as amphibians, reptiles, birds, and mammals.\n\nThe two remaining groups of jawless fishes that have survived beyond the Devonian period are hagfishes and lamprey, which are collectively known as cyclostomes (for circled mouths). Both groups of animals have elongated eel-like bodies with no paired fins. However, because hagfishes have a weak circulatory system with three accessory hearts, a partial skull with no cerebellum, no jaws or stomach, and no jointed vertebrae, some biologists do not classify them as vertebrates but instead as a sister group of vertebrates. In contrast, lampreys have a complete skull and a distinct vertebrae that is cartilaginous.\n\nMammals have four key features that distinguish them from other animals such as sweat glands, mammary glands, hair, and a four-chambered heart. Small and medium-sized mammals used to co-exist with large dinosaurs in much of the Mesozoic era but soon radiated following the mass extinction of dinosaurs at the end of the Cretaceous period. There are approximately 57,000 mammal species, which can be divided into two primary groups: prototherians and therians. Prototherians do not possess nipples on their mammary but instead secrete milk onto their skin, allowing their offspring to lap if off their furs. They also lack a placenta, lays eggs, and have sprawling legs. Currently, there only five known species of prototherians (platypus and four species of echidnas). The therian clade is viviparous and can be further divided into two groups: marsupials and eutherians. Marsupial females have a ventral pouch to carry and feed their offspring. Eutherians form the majority of mammals and include major groups such as rodents, bats, even-toed ungulates and cetaceans, shrews and moles, primates, carnivores, rabbits, African insectivores, spiny insectivores, armadillos, treeshrews, odd-toed ungulates, long-nosed insectivores, anteaters and sloths, pangolins, hyraxes, sirenians, elephants, colugos, and aardvark.\n\nViruses\n\nViruses are submicroscopic infectious agents that replicate inside the cells of organisms. Viruses infect all types of life forms, from animals and plants to microorganisms, including bacteria and archaea. More than 6,000 virus species have been described in detail. Viruses are found in almost every ecosystem on Earth and are the most numerous type of biological entity.\n\nWhen infected, a host cell is forced to rapidly produce thousands of identical copies of the original virus. When not inside an infected cell or in the process of infecting a cell, viruses exist in the form of independent particles, or virions, consisting of the genetic material (DNA or RNA), a protein coat called capsid, and in some cases an outside envelope of lipids. The shapes of these virus particles range from simple helical and icosahedral forms to more complex structures. Most virus species have virions too small to be seen with an optical microscope, as they are one-hundredth the size of most bacteria.\n\nThe origins of viruses in the evolutionary history of life are unclear: some may have evolved from plasmids\u2014pieces of DNA that can move between cells\u2014while others may have evolved from bacteria. In evolution, viruses are an important means of horizontal gene transfer, which increases genetic diversity in a way analogous to sexual reproduction. Because viruses possess some but not all characteristics of life, they have been described as \"organisms at the edge of life\", and as self-replicators.\n\nViruses can spread in many ways. One transmission pathway is through disease-bearing organisms known as vectors: for example, viruses are often transmitted from plant to plant by insects that feed on plant sap, such as aphids; and viruses in animals can be carried by blood-sucking insects. Influenza viruses are spread by coughing and sneezing. Norovirus and rotavirus, common causes of viral gastroenteritis, are transmitted by the faecal\u2013oral route, passed by hand-to-mouth contact or in food or water. Viral infections in animals provoke an immune response that usually eliminates the infecting virus. Immune responses can also be produced by vaccines, which confer an artificially acquired immunity to the specific viral infection.\n\nPlant form and function\n\nPlant body\n\nThe plant body is made up of organs that can be organized into two major organ systems: a  root system and a  shoot system. The root system anchors the plants into place. The roots themselves absorb water and minerals and store photosynthetic products. The shoot system is composed of stem, leaves, and flowers. The stems hold and orient the leaves to the sun, which allow the leaves to conduct photosynthesis. The flowers are shoots that have been modified for reproduction. Shoots are composed of phytomers, which are functional units that consist of a node carrying one or more leaves, internode, and one or more buds.\n\nA plant body has two basic patterns (apical\u2013basal and radial axes) that been established during embryogenesis. Cells and tissues are arranged along the apical-basal axis from root to shoot whereas the three tissue systems (dermal, ground, and vascular) that make up a plant's body are arranged concentrically around its radial axis. The dermal tissue system forms the epidermis (or outer covering) of a plant, which is usually a single cell layer that consists of cells that have differentiated into three specialized structures: stomata for gas exchange in leaves, trichomes (or leaf hair) for protection against insects and solar radiation, and root hairs for increased surface areas and absorption of water and nutrients. The ground tissue makes up virtually all the tissue that lies between the dermal and vascular tissues in the shoots and roots. It consists of three cell types: Parenchyma, collenchyma, and sclerenchyma cells. Finally, the vascular tissues are made up of two constituent tissues: xylem and phloem. The xylem is made up of two conducting cells called tracheids and vessel elements whereas the phloem is characterized by the presence of sieve tube elements and companion cells.\n\nPlant nutrition and transport\n\nLike all other organisms, plants are primarily made up of water and other molecules containing elements that are essential to life. The absence of specific nutrients (or essential elements), many of which have been identified in hydroponic experiments, can disrupt plant growth and reproduction. The majority of plants are able to obtain these nutrients from solutions that surrounds their roots in the soil. Continuous leaching and harvesting of crops can deplete the soil of its nutrients, which can be restored with the use of fertilizers. Carnivorous plants such as Venus flytraps are able to obtain nutrients by digesting other arthropods whereas parasitic plants such as mistletoes can parasitize other plants for water and nutrients.\n\nPlants need water to conduct photosynthesis, transport solutes between organs, cool their leaves by evaporation, and maintain internal pressures that support their bodies. Water is able to diffuse in and out of plant cells by osmosis. The direction of water movement across a semipermeable membrane is determined by the water potential across that membrane. Water is able to diffuse across a root cell's membrane through aquaporins whereas solutes are transported across by the membrane by ion channels and pumps. In vascular plants, water and solutes are able to enter the xylem, a vascular tissue, by way of an apoplast and symplast. Once in the xylem, the water and minerals are distributed upward by transpiration from the soil to the aerial parts of the plant. In contrast, the phloem, another vascular tissue, distributes carbohydrates (e.g., sucrose) and other solutes such as hormones by translocation from a source (e.g., mature leaf or root) in which they were produced to a sink (e.g., root, flower, or developing fruit) in which they will be used and stored. Sources and sinks can switch roles, depending on the amount of carbohydrates accumulated or mobilized for the nourishment of other organs.\n\nPlant development\nPlant development is regulated by environmental cues and the plant's own receptors, hormones, and genome. Morever, they have several characteristics that allow them to obtain resources for growth and reproduction such as meristems, post-embryonic organ formation, and differential growth.\n\nDevelopment begins with a seed, which is an embryonic plant enclosed in a protective outer covering. Most plant seeds are usually dormant, a condition in which the seed's normal activity is suspended. Seed dormancy may last may last weeks, months, years, and even centuries. Dormancy is broken once conditions are favorable for growth, and the seed will begin to sprout, a process called germination. Imbibition is the first step in germination, whereby water is absorbed by the seed. Once water is absorbed, the seed undergoes metabolic changes whereby enzymes are activated and RNA and proteins are synthesized. Once the seed germinates, it obtains carbohydrates, amino acids, and small lipids that serve as building blocks for its development. These monomers are obtained from the hydrolysis of starch, proteins, and lipids that are stored in either the cotyledons or endosperm. Germination is completed once embryonic roots called radicle have emerged from the seed coat. At this point, the developing plant is called a seedling and its growth is regulated by its own photoreceptor proteins and hormones.\n\nUnlike animals in which growth is determinate, i.e., ceases when the adult state is reached, plant growth is indeterminate as it is an open-ended process that could potentially be lifelong. Plants grow in two ways: primary and secondary. In primary growth, the shoots and roots are formed and lengthened. The apical meristem produces the primary plant body, which can be found in all seed plants. During secondary growth, the thickness of the plant increases as the lateral meristem produces the secondary plant body, which can be found in woody eudicots such as trees and shrubs. Monocots do not go through secondary growth. The plant body is generated by a hierarchy of meristems. The apical meristems in the root and shoot systems give rise to primary meristems (protoderm, ground meristem, and procambium), which in turn, give rise to the three tissue systems (dermal, ground, and vascular).\n\nPlant reproduction\n\nMost angiosperms (or flowering plants) engage in sexual reproduction. Their flowers are organs that facilitate reproduction, usually by providing a mechanism for the union of sperm with eggs. Flowers may facilitate two types of pollination: self-pollination and cross-pollination. Self-pollination occurs when the pollen from the anther is deposited on the stigma of the same flower, or another flower on the same plant. Cross-pollination is the transfer of pollen from the anther of one flower to the stigma of another flower on a different individual of the same species. Self-pollination happened in flowers where the stamen and carpel mature at the same time, and are positioned so that the pollen can land on the flower's stigma. This pollination does not require an investment from the plant to provide nectar and pollen as food for pollinators.\n\nPlant responses\n\nLike animals, plants produce hormones in one part of its body to signal cells in another part to respond. The ripening of fruit and loss of leaves in the winter are controlled in part by the production of the gas ethylene by the plant. Stress from water loss, changes in air chemistry, or crowding by other plants can lead to changes in the way a plant functions. These changes may be affected by genetic, chemical, and physical factors.\n\nTo function and survive, plants produce a wide array of chemical compounds not found in other organisms. Because they cannot move, plants must also defend themselves chemically from herbivores, pathogens and competition from other plants. They do this by producing toxins and foul-tasting or smelling chemicals. Other compounds defend plants against disease, permit survival during drought, and prepare plants for dormancy, while other compounds are used to attract pollinators or herbivores to spread ripe seeds.\n\nMany plant organs contain different types of photoreceptor proteins, each of which reacts very specifically to certain wavelengths of light. The photoreceptor proteins relay information such as whether it is day or night, duration of the day, intensity of light available, and the source of light. Shoots generally grow towards light, while roots grow away from it, responses known as phototropism and skototropism, respectively. They are brought about by light-sensitive pigments like phototropins and phytochromes and the plant hormone auxin. Many flowering plants bloom at the appropriate time because of light-sensitive compounds that respond to the length of the night, a phenomenon known as photoperiodism.\n\nIn addition to light, plants can respond to other types of stimuli. For instance, plants can sense the direction of gravity to orient themselves correctly. They can respond to mechanical stimulation.\n\nAnimal form and function\n\nGeneral features\n\nThe cells in each animal body are bathed in interstitial fluid, which make up the cell's environment. This fluid and all its characteristics (e.g., temperature, ionic composition) can be described as the animal's internal environment, which is in contrast to the external environment that encompasses the animal's outside world. Animals can be classified as either regulators or conformers. Animals such as mammals and birds are regulators as they are able to maintain a constant internal environment such as body temperature despite their environments changing. These animals are also described as homeotherms as they exhibit thermoregulation by keeping their internal body temperature constant. In contrast, animals such as fishes and frogs are conformers as they adapt their internal environment (e.g., body temperature) to match their external environments. These animals are also described as poikilotherms or ectotherms as they allow their body temperatures to match their external environments. In terms of energy, regulation is more costly than conformity as an animal expands more energy to maintain a constant internal environment such as increasing its basal metabolic rate, which is the rate of energy consumption. Similarly, homeothermy is more costly than poikilothermy. Homeostasis is the stability of an animal's internal environment, which is maintained by negative feedback loops.\n\nThe body size of terrestrial animals vary across different species but their use of energy does not scale linearly according to their size. Mice, for example, are able to consume three times more food than rabbits in proportion to their weights as the basal metabolic rate per unit weight in mice is greater than in rabbits. Physical activity can also increase an animal's metabolic rate. When an animal runs, its metabolic rate increases linearly with speed. However, the relationship is non-linear in animals that swim or fly. When a fish swims faster, it encounters greater water resistance and so its metabolic rates increases exponential. Alternatively, the relationship of flight speeds and metabolic rates is U-shaped in birds. At low flight speeds, a bird must maintain a high metabolic rates to remain airborne. As it speeds up its flight, its metabolic rate decreases with the aid of air rapidly flows over its wings. However, as it increases in its speed even further, its high metabolic rates rises again due to the increased effort associated with rapid flight speeds. Basal metabolic rates can be measured based on an animal's rate of heat production.\n\nWater and salt balance\n\nAn animal's body fluids have three properties: osmotic pressure, ionic composition, and volume. Osmotic pressures determine the direction of the diffusion of water (or osmosis), which moves from a region where osmotic pressure (total solute concentration) is low to a region where osmotic pressure (total solute concentration) is high. Aquatic animals are diverse with respect to their body fluid compositions and their environments. For example, most invertebrate animals in the ocean have body fluids that are isosmotic with seawater. In contrast, ocean bony fishes have body fluids that are hyposmotic to seawater. Finally, freshwater animals have body fluids that are hyperosmotic to fresh water. Typical ions that can be found in an animal's body fluids are sodium, potassium, calcium, and chloride. The volume of body fluids can be regulated by excretion. Vertebrate animals have kidneys, which are excretory organs made up of tiny tubular structures called nephrons, which make urine from blood plasma. The kidneys' primary function is to regulate the composition and volume of blood plasma by selectively removing material from the blood plasma itself. The ability of xeric animals such as kangaroo rats to minimize water loss by producing urine that is 10-20 times concentrated than their blood plasma allows them to adapt in desert environments that receive very little precipitation.\n\nNutrition and digestion\n\nAnimals are heterotrophs as they feed on other organisms to obtain energy and organic compounds. They are able to obtain food in three major ways such as targeting visible food objects, collecting tiny food particles, or depending on microbes for critical food needs. The amount of energy stored in food can be quantified based on the amount of heat (measured in calories or kilojoules) emitted when the food is burnt in the presence of oxygen. If an animal were to consume food that contains an excess amount of chemical energy, it will store most of that energy in the form of lipids for future use and some of that energy as glycogen for more immediate use (e.g., meeting the brain's energy needs). The molecules in food are chemical building blocks that are needed for growth and development. These molecules include nutrients such as carbohydrates, fats, and proteins. Vitamins and minerals (e.g., calcium, magnesium, sodium, and phosphorus) are also essential. The digestive system, which typically consist of a tubular tract that extends from the mouth to the anus, is involved in the breakdown (or digestion) of food into small molecules as it travels down peristaltically through the gut lumen shortly after it has been ingested. These small food molecules are then absorbed into the blood from the lumen, where they are then distributed to the rest of the body as building blocks (e.g., amino acids) or sources of energy (e.g., glucose).\n\nIn addition to their digestive tracts, vertebrate animals have accessory glands such as a liver and pancreas as part of their digestive systems. The processing of food in these animals begins in the foregut, which includes the mouth, esophagus, and stomach. Mechanical digestion of food starts in the mouth with the esophagus serving as a passageway for food to reach the stomach, where it is stored and disintegrated (by the stomach's acid) for further processing. Upon leaving the stomach, food enters into the midgut, which is the first part of the intestine (or small intestine in mammals) and is the principal site of digestion and absorption. Food that does not get absorbed are stored as indigestible waste (or feces) in the hindgut, which is the second part of the intestine (or large intestine in mammals). The hindgut then completes the reabsorption of needed water and salt prior to eliminating the feces from the rectum.\n\nBreathing\n\nThe respiratory system consists of specific organs and structures used for gas exchange in animals. The anatomy and physiology that make this happen varies greatly, depending on the size of the organism, the environment in which it lives and its evolutionary history. In land animals the respiratory surface is internalized as linings of the lungs. Gas exchange in the lungs occurs in millions of small air sacs; in mammals and reptiles these are called alveoli, and in birds they are known as atria. These microscopic air sacs have a very rich blood supply, thus bringing the air into close contact with the blood. These air sacs communicate with the external environment via a system of airways, or hollow tubes, of which the largest is the trachea, which branches in the middle of the chest into the two main bronchi. These enter the lungs where they branch into progressively narrower secondary and tertiary bronchi that branch into numerous smaller tubes, the bronchioles. In birds the bronchioles are termed parabronchi. It is the bronchioles, or parabronchi that generally open into the microscopic alveoli in mammals and atria in birds. Air has to be pumped from the environment into the alveoli or atria by the process of breathing, which involves the muscles of respiration.\n\nCirculation\n\nA circulatory system usually consists of a muscular pump such as a heart, a fluid (blood), and system of blood vessels that deliver it. Its principal function is to transport blood and other substances to and from cell (biology)s and tissues. There are two types of circulatory systems: open and closed. In open circulatory systems, blood exits blood vessels as it circulates throughout the body whereas in closed circulatory system, blood is contained within the blood vessels as it circulates. Open circulatory systems can be observed in invertebrate animals such as arthropods (e.g., insects, spiders, and lobsters) whereas closed circulatory systems can be found in vertebrate animals such as fishes, amphibians, and mammals. Circulation in animals occur between two types of tissues: systemic tissues and breathing (or pulmonary) organs. Systemic tissues are all the tissues and organs that make up an animal's body other than its breathing organs. Systemic tissues take up oxygen but adds carbon dioxide to the blood whereas a breathing organs takes up carbon dioxide but add oxygen to the blood. In birds and mammals, the systemic and pulmonary systems are connected in series.\n\nIn the circulatory system, blood is important because it is the means by which oxygen, carbon dioxide, nutrients, hormones, agents of immune system, heat, wastes, and other commodities are transported. In annelids such as earthworms and leeches, blood is propelled by peristaltic waves of contractions of the heart muscles that make up the blood vessels. Other animals such as crustaceans (e.g., crayfish and lobsters), have more than one heart to propel blood throughout their bodies. Vertebrate hearts are multichambered and are able to pump blood when their ventricles contract at each cardiac cycle, which propels blood through the blood vessels. Although vertebrate hearts are myogenic, their rate of contraction (or heart rate) can be modulated by neural input from the body's autonomic nervous system.\n\nMuscle and movement\n\nIn vertebrates, the muscular system consists of skeletal, smooth and cardiac muscles. It permits movement of the body, maintains posture and circulates blood throughout the body. Together with the skeletal system, it forms the musculoskeletal system, which is responsible for the movement of vertebrate animals. Skeletal muscle contractions are neurogenic as they require synaptic input from motor neurons. A single motor neuron is able to innervate multiple muscle fibers, thereby causing the fibers to contract at the same time. Once innervated, the protein filaments within each skeletal muscle fiber slide past each other to produce a contraction, which is explained by the sliding filament theory. The contraction produced can be described as a twitch, summation, or tetanus, depending on the frequency of action potentials. Unlike skeletal muscles, contractions of smooth and cardiac muscles are myogenic as they are initiated by the smooth or heart muscle cells themselves instead of a motor neuron. Nevertheless, the strength of their contractions can be modulated by input from the autonomic nervous system. The mechanisms of contraction are similar in all three muscle tissues.\n\nIn invertebrates such as earthworms and leeches, circular and longitudinal muscles cells form the body wall of these animals and are responsible for their movement. In an earthworm that is moving through a soil, for example, contractions of circular and longitudinal muscles occur reciprocally while the coelomic fluid serves as a hydroskeleton by maintaining turgidity of the earthworm. Other animals such as mollusks, and nematodes, possess obliquely striated muscles, which contain bands of thick and thin filaments that are arranged helically rather than transversely, like in vertebrate skeletal or cardiac muscles. Advanced insects such as wasps, flies, bees, and beetles possess asynchronous muscles that constitute the flight muscles in these animals. These flight muscles are often called fibrillar muscles because they contain myofibrils that are thick and conspicuous.\n\nNervous system\n\nMost multicellular animals have nervous systems that allow them to sense from and respond to their environments. A nervous system is a network of cells that processes sensory information and generates behaviors. At the cellular level, the nervous system is defined by the presence of neurons, which are cells specialized to handle information. They can transmit or receive information at sites of contacts called synapses. More specifically, neurons can conduct nerve impulses (or action potentials) that travel along their thin fibers called axons, which can then be transmitted directly to a neighboring cell through electrical synapses or cause chemicals called neurotransmitters to be released at chemical synapses. According to the sodium theory, these action potentials can be generated by the increased permeability of the neuron's cell membrane to sodium ions. Cells such as neurons or muscle cells may be excited or inhibited upon receiving a signal from another neuron. The connections between neurons can form neural pathways, neural circuits, and larger networks that generate an organism's perception of the world and determine its behavior. Along with neurons, the nervous system contains other specialized cells called glia or glial cells, which provide structural and metabolic support.\n\nIn vertebrates, the nervous system comprises the central nervous system (CNS), which includes the brain and spinal cord, and the peripheral nervous system (PNS), which consists of nerves that connect the CNS to every other part of the body. Nerves that transmit signals from the CNS are called motor nerves or efferent nerves, while those nerves that transmit information from the body to the CNS are called sensory nerves or afferent nerves. Spinal nerves are mixed nerves that serve both functions. The PNS is divided into three separate subsystems, the somatic, autonomic, and enteric nervous systems. Somatic nerves mediate voluntary movement. The autonomic nervous system is further subdivided into the sympathetic and the parasympathetic nervous systems. The sympathetic nervous system is activated in cases of emergencies to mobilize energy, while the parasympathetic nervous system is activated when organisms are in a relaxed state. The enteric nervous system functions to control the gastrointestinal system. Both autonomic and enteric nervous systems function involuntarily. Nerves that exit directly from the brain are called cranial nerves while those exiting from the spinal cord are called spinal nerves.\n\nMany animals have sense organs that can detect their environment. These sense organs contain sensory receptors, which are sensory neurons that convert stimuli into electrical signals. Mechanoreceptors, for example, which can be found in skin, muscle, and hearing organs, generate action potentials in response to changes in pressures. Photoreceptor cells such as rods and cones, which are part of the vertebrate retina, can respond to specific wavelengths of light. Chemoreceptors detect chemicals in the mouth (taste) or in the air (smell).\n\nHormonal control\n\nHormones are signaling molecules transported in the blood to distant organs to regulate their function. Hormones are secreted by internal glands that are part of an animal's endocrine system. In vertebrates, the hypothalamus is the neural control center for all endocrine systems. In humans specifically, the major endocrine glands are the thyroid gland and the adrenal glands. Many other organs that are part of other body systems have secondary endocrine functions, including bone, kidneys, liver, heart and gonads. For example, kidneys secrete the endocrine hormone erythropoietin. Hormones can be amino acid complexes, steroids, eicosanoids, leukotrienes, or prostaglandins. The endocrine system can be contrasted to both exocrine glands, which secrete hormones to the outside of the body, and paracrine signaling between cells over a relatively short distance. Endocrine glands have no ducts, are vascular, and commonly have intracellular vacuoles or granules that store their hormones. In contrast, exocrine glands, such as salivary glands, sweat glands, and glands within the gastrointestinal tract, tend to be much less vascular and have ducts or a hollow lumen.\n\nAnimal reproduction\n\nAnimals can reproduce in one of two ways: asexual and sexual. Nearly all animals engage in some form of sexual reproduction. They produce haploid gametes by meiosis. The smaller, motile gametes are spermatozoa and the larger, non-motile gametes are ova. These fuse to form zygotes, which develop via mitosis into a hollow sphere, called a blastula. In sponges, blastula larvae swim to a new location, attach to the seabed, and develop into a new sponge. In most other groups, the blastula  undergoes more complicated rearrangement. It first invaginates to form a gastrula with a digestive chamber and two separate germ layers, an external ectoderm and an internal endoderm. In most cases, a third germ layer, the mesoderm, also develops between them. These germ layers then differentiate to form tissues and organs. Some animals are capable of asexual reproduction, which often results in a genetic clone of the parent. This may take place through fragmentation; budding, such as in Hydra and other cnidarians; or parthenogenesis, where fertile eggs are produced without mating, such as in aphids.\n\nAnimal development\n\nAnimal development begins with the formation of a zygote that results from the fusion of a sperm and egg during fertilization. The zygote undergoes a rapid multiple rounds of mitotic cell period of cell divisions called cleavage, which forms a ball of similar cells called a blastula. Gastrulation occurs, whereby morphogenetic movements convert the cell mass into a three germ layers that comprise the ectoderm, mesoderm and endoderm.\n\nThe end of gastrulation signals the beginning of organogenesis, whereby the three germ layers form the internal organs of the organism. The cells of each of the three germ layers undergo differentiation, a process where less-specialized cells become more-specialized through the expression of a specific set of genes. Cellular differentiation is influenced by extracellular signals such as growth factors that are exchanged to adjacent cells, which is called juxtracrine signaling, or to neighboring cells over short distances, which is called paracrine signaling. Intracellular signals consist of a cell signaling itself (autocrine signaling), also play a role in organ formation. These signaling pathways allows for cell rearrangement and ensures that organs form at specific sites within the organism.\n\nImmune system\n\nThe immune system is a network of biological processes that detects and responds to a wide variety of pathogens. Many species have two major subsystems of the immune system. The innate immune system provides a preconfigured response to broad groups of situations and stimuli. The adaptive immune system provides a tailored response to each stimulus by learning to recognize molecules it has previously encountered. Both use molecules and cells to perform their functions.\n\nNearly all organisms have some kind of immune system. Bacteria have a rudimentary immune system in the form of enzymes that protect against virus infections. Other basic immune mechanisms evolved in ancient plants and animals and remain in their modern descendants. These mechanisms include phagocytosis, antimicrobial peptides called defensins, and the complement system. Jawed vertebrates, including humans, have even more sophisticated defense mechanisms, including the ability to adapt to recognize pathogens more efficiently. Adaptive (or acquired) immunity creates an immunological memory leading to an enhanced response to subsequent encounters with that same pathogen. This process of acquired immunity is the basis of vaccination.\n\nAnimal behavior\n\nBehaviors play a central a role in animals' interaction with each other and with their environment. They are able to use their muscles to approach one another, vocalize, seek shelter, and migrate. An animal's nervous system activates and coordinates its behaviors. Fixed action patterns, for instance, are genetically determined and stereotyped behaviors that occur without learning. These behaviors are under the control of the nervous system and can be quite elaborate. Examples include the pecking of kelp gull chicks at the red dot on their mother's beak. Other behaviors that have emerged as a result of natural selection include foraging, mating, and altruism. In addition to evolved behavior, animals have evolved the ability to learn by modifying their behaviors as a result of early individual experiences.\n\nEcology\n\nEcosystems\n\nEcology is the study of the distribution and abundance of life, the interaction between organisms and their environment. The community of living (biotic) organisms in conjunction with the nonliving (abiotic) components (e.g., water, light, radiation, temperature, humidity, atmosphere, acidity, and soil) of their environment is called an ecosystem. These biotic and abiotic components are linked together through nutrient cycles and energy flows. Energy from the sun enters the system through photosynthesis and is incorporated into plant tissue. By feeding on plants and on one another, animals play an important role in the movement of matter and energy through the system. They also influence the quantity of plant and microbial biomass present. By breaking down dead organic matter, decomposers release carbon back to the atmosphere and facilitate nutrient cycling by converting nutrients stored in dead biomass back to a form that can be readily used by plants and other microbes.\n\nThe Earth's physical environment is shaped by solar energy and topography. The amount of solar energy input varies in space and time due to the spherical shape of the Earth and its axial tilt. Variation in solar energy input drives weather and climate patterns. Weather is the day-to-day temperature and precipitation activity, whereas climate is the long-term average of weather, typically averaged over a period of 30 years. Variation in topography also produces environmental heterogeneity. On the windward side of a mountain, for example, air rises and cools, with water changing from gaseous to liquid or solid form, resulting in precipitation such as rain or snow. As a result, wet environments allow for lush vegetation to grow. In contrast, conditions tend to be dry on the leeward side of a mountain due to the lack of precipitation as air descends and warms, and moisture remains as water vapor in the atmosphere. Temperature and precipitation are the main factors that shape terrestrial biomes.\n\nPopulations\n\nA population is the number of organisms of the same species that occupy an area and reproduce from generation to generation. Its abundance can be measured using population density, which is the number of individuals per unit area (e.g., land or tree) or volume (e.g., sea or air). Given that it is usually impractical to count every individual within a large population to determine its size, population size can be estimated by multiplying population density by the area or volume. Population growth during short-term intervals can be determined using the population growth rate equation, which takes into consideration birth, death, and immigration rates. In the longer term, the exponential growth of a population tends to slow down as it reaches its carrying capacity, which can be modeled using the logistic equation. The carrying capacity of an environment is the maximum population size of a species that can be sustained by that specific environment, given the food, habitat, water, and other resources that are available. The carrying capacity of a population can be affected by changing environmental conditions such as changes in the availability resources and the cost of maintaining them. In human populations, new technologies such as the Green revolution have helped increase the Earth's carrying capacity for humans over time, which has stymied the attempted predictions of impending population decline, the famous of which was by Thomas Malthus in the 18th century.\n\nCommunities\n\nA community is a group of populations of two or more different species occupying the same geographical area at the same time. A biological interaction is the effect that a pair of organisms living together in a community have on each other. They can be either of the same species (intraspecific interactions), or of different species (interspecific interactions). These effects may be short-term, like pollination and predation, or long-term; both often strongly influence the evolution of the species involved. A long-term interaction is called a symbiosis. Symbioses range from mutualism, beneficial to both partners, to competition, harmful to both partners.\n\nEvery species participates as a consumer, resource, or both in consumer\u2013resource interactions, which form the core of food chains or food webs. There are different trophic levels within any food web, with the lowest level being the primary producers (or autotrophs) such as plants and algae that convert energy and inorganic material into organic compounds, which can then be used by the rest of the community. At the next level are the heterotrophs, which are the species that obtain energy by breaking apart organic compounds from other organisms. Heterotrophs that consume plants are primary consumers (or herbivores) whereas heterotrophs that consume herbivores are secondary consumers (or carnivores). And those that eat secondary consumers are tertiary consumers and so on. Omnivorous heterotrophs are able to consume at multiple levels. Finally, there are decomposers that feed on the waste products or dead bodies of organisms.\n\nOn average, the total amount of energy incorporated into the biomass of a trophic level per unit of time is about one-tenth of the energy of the trophic level that it consumes. Waste and dead material used by decomposers as well as heat lost from metabolism make up the other ninety percent of energy that is not consumed by the next trophic level.\n\nBiosphere\n\nIn the global ecosystem (or biosphere), matter exist as different interacting compartments, which can be biotic or abiotic as well as accessible or inaccessible, depending on their forms and locations. For example, matter from terrestrial autotrophs are both biotic and accessible to other organisms whereas the matter in rocks and minerals are abiotic and inaccessible. A biogeochemical cycle is a pathway by which specific elements of matter are turned over or moved through the biotic (biosphere) and the abiotic (lithosphere, atmosphere, and hydrosphere) compartments of Earth. There are biogeochemical cycles for nitrogen, carbon, and water. In some cycles there are reservoirs where a substance remains or is sequestered for a long period of time.\n\nClimate change includes both global warming driven by human-induced emissions of greenhouse gases and the resulting large-scale shifts in weather patterns. Though there have been previous periods of climatic change, since the mid-20th century humans have had an unprecedented impact on Earth's climate system and caused change on a global scale. The largest driver of warming is the emission of greenhouse gases, of which more than 90% are carbon dioxide and methane. Fossil fuel burning (coal, oil, and natural gas) for energy consumption is the main source of these emissions, with additional contributions from agriculture, deforestation, and manufacturing. Temperature rise is accelerated or tempered by climate feedbacks, such as loss of sunlight-reflecting snow and ice cover, increased water vapor (a greenhouse gas itself), and changes to land and ocean carbon sinks.\n\nConservation\n\nConservation biology is the study of the conservation of Earth's biodiversity with the aim of protecting species, their habitats, and ecosystems from excessive rates of extinction and the erosion of biotic interactions. It is concerned with factors that influence the maintenance, loss, and restoration of biodiversity and the science of sustaining evolutionary processes that engender genetic, population, species, and ecosystem diversity. The concern stems from estimates suggesting that up to 50% of all species on the planet will disappear within the next 50 years, which has contributed to poverty, starvation, and will reset the course of evolution on this planet. Biodiversity affects the functioning of ecosystems, which provide a variety of services upon which people depend.\n\nConservation biologists research and educate on the trends of biodiversity loss, species extinctions, and the negative effect these are having on our capabilities to sustain the well-being of human society. Organizations and citizens are responding to the current biodiversity crisis through conservation action plans that direct research, monitoring, and education programs that engage concerns at local through global scales.\n\nSee also \n\n Biology in fiction\n Glossary of biology\n List of biological websites\n List of biologists\n List of biology journals\n List of biology topics\n List of life sciences\n List of omics topics in biology\n National Association of Biology Teachers\n Outline of biology\n Periodic table of life sciences in Tinbergen's four questions\n Reproduction\n Science tourism\n Terminology of biology\n\nNotes\n\nReferences\n\nFurther reading\n\nExternal links \n\n \n OSU's Phylocode\n Biology Online \u2013 Wiki Dictionary\n MIT video lecture series on biology\n OneZoom Tree of Life\n\nJournal links\n PLos Biology A peer-reviewed, open-access journal published by the Public Library of Science\n Current Biology: General journal publishing original research from all areas of biology\n Biology Letters: A high-impact Royal Society journal publishing peer-reviewed Biology papers of general interest\n Science: Internationally renowned AAAS science journal \u2013 see sections of the life sciences\n International Journal of Biological Sciences: A biological journal publishing significant peer-reviewed scientific papers\n Perspectives in Biology and Medicine: An interdisciplinary scholarly journal publishing essays of broad relevance",
  "History": "History (from Greek , historia, meaning \"inquiry; knowledge acquired by investigation\") is the study and the documentation of the past. Events before the invention of writing systems are considered prehistory. \"History\" is an umbrella term comprising past events as well as the memory, discovery, collection, organization, presentation, and interpretation of these events. Historians seek knowledge of the past using historical sources such as written documents, oral accounts, art and material artifacts, and ecological markers.\n\nHistory is also an academic discipline which uses narrative to describe, examine, question, and analyze past events, and investigate their patterns of cause and effect. Historians  often debate which narrative best explains an event, as well as the significance of different causes and effects. Historians also debate the nature of history as an end in itself, as well as its usefulness to give perspective on the problems of the present.\n\nStories common to a particular culture, but not supported by external sources (such as the tales surrounding King Arthur), are usually classified as cultural heritage or legends. History differs from myth in that it is supported by evidence. However, ancient cultural influences have helped spawn variant interpretations of the nature of history which have evolved over the centuries and continue to change today. The modern study of history is wide-ranging, and includes the study of specific regions and the study of certain topical or thematic elements of historical investigation. History is often taught as part of primary and secondary education, and the academic study of history is a major discipline in university studies.\n\nHerodotus, a 5th-century BC Greek historian, is often considered the \"father of history\" in the Western tradition, although he has also been criticized as the \"father of lies\". Along with his contemporary Thucydides, he helped form the foundations for the modern study of past events and societies. Their works continue to be read today, and the gap between the culture-focused Herodotus and the military-focused Thucydides remains a point of contention or approach in modern historical writing. In East Asia, a state chronicle, the Spring and Autumn Annals, was reputed to date from as early as 722BC, although only 2nd-centuryBC texts have survived.\n\nEtymology\n\nThe word history comes from the Ancient Greek \u1f31\u03c3\u03c4\u03bf\u03c1\u03af\u03b1 (histor\u00eda), meaning \"inquiry\", \"knowledge from inquiry\", or \"judge\". It was in that sense that Aristotle used the word in his History of Animals. The ancestor word  is attested early on in Homeric Hymns, Heraclitus, the Athenian ephebes' oath, and in Boiotic inscriptions (in a legal sense, either \"judge\" or \"witness\", or similar). The Greek word was borrowed into Classical Latin as historia, meaning \"investigation, inquiry, research, account, description, written account of past events, writing of history, historical narrative, recorded knowledge of past events, story, narrative\". History was borrowed from Latin (possibly via Old Irish or Old Welsh) into Old English as st\u00e6r (\"history, narrative, story\"), but this word fell out of use in the late Old English period. Meanwhile, as Latin became Old French (and Anglo-Norman), historia developed into forms such as istorie, estoire, and historie, with new developments in the meaning: \"account of the events of a person's life (beginning of the 12th century), chronicle, account of events as relevant to a group of people or people in general (1155), dramatic or pictorial representation of historical events (), body of knowledge relative to human evolution, science (), narrative of real or imaginary events, story ()\".\n\nIt was from Anglo-Norman that history was borrowed into Middle English, and this time the loan stuck. It appears in the 13th-century Ancrene Wisse, but seems to have become a common word in the late 14th century, with an early attestation appearing in John Gower's Confessio Amantis of the 1390s (VI.1383): \"I finde in a bok compiled | To this matiere an old histoire, | The which comth nou to mi memoire\". In Middle English, the meaning of history was \"story\" in general. The restriction to the meaning \"the branch of knowledge that deals with past events; the formal record or study of past events, esp. human affairs\" arose in the mid-15th century. With the Renaissance, older senses of the word were revived, and it was in the Greek sense that Francis Bacon used the term in the late 16th century, when he wrote about natural history. For him, historia was \"the knowledge of objects determined by space and time\", that sort of knowledge provided by memory (while science was provided by reason, and poetry was provided by fantasy).\n\nIn an expression of the linguistic synthetic vs. analytic/isolating dichotomy, English like Chinese (\u53f2 vs. \u8bcc) now designates separate words for human history and storytelling in general. In modern German, French, and most Germanic and Romance languages, which are solidly synthetic and highly inflected, the same word is still used to mean both \"history\" and \"story\". Historian in the sense of a \"researcher of history\" is attested from 1531. In all European languages, the substantive history is still used to mean both \"what happened with men\", and \"the scholarly study of the happened\", the latter sense sometimes distinguished with a capital letter, or the word historiography. The adjective historical is attested from 1661, and historic from 1669.\n\nDescription\n\nHistorians write in the context of their own time, and with due regard to the current dominant ideas of how to interpret the past, and sometimes write to provide lessons for their own society. In the words of Benedetto Croce, \"All history is contemporary history\". History is facilitated by the formation of a \"true discourse of past\" through the production of narrative and analysis of past events relating to the human race. The modern discipline of history is dedicated to the institutional production of this discourse.\n\nAll events that are remembered and preserved in some authentic form constitute the historical record. The task of historical discourse is to identify the sources which can most usefully contribute to the production of accurate accounts of past. Therefore, the constitution of the historian's archive is a result of circumscribing a more general archive by invalidating the usage of certain texts and documents (by falsifying their claims to represent the \"true past\"). Part of the historian's role is to skillfully and objectively utilize the vast amount of sources from the past, most often found in the archives. The process of creating a narrative inevitably generates a silence as historians remember or emphasize different events of the past.\n\nThe study of history has sometimes been classified as part of the humanities and at other times as part of the social sciences. It can also be seen as a bridge between those two broad areas, incorporating methodologies from both. Some individual historians strongly support one or the other classification. In the 20th century, French historian Fernand Braudel revolutionized the study of history, by using such outside disciplines as economics, anthropology, and geography in the study of global history.\n\nTraditionally, historians have recorded events of the past, either in writing or by passing on an oral tradition, and have attempted to answer historical questions through the study of written documents and oral accounts. From the beginning, historians have also used such sources as monuments, inscriptions, and pictures. In general, the sources of historical knowledge can be separated into three categories: what is written, what is said, and what is physically preserved, and historians often consult all three. But writing is the marker that separates history from what comes before.\n\nArchaeology is especially helpful in unearthing buried sites and objects, which contribute to the study of history. Archaeological finds rarely stand alone, with narrative sources complementing its discoveries. Archaeology's methodologies and approaches are independent from the field of history. \"Historical archaeology\" is a specific branch of archaeology which often contrasts its conclusions against those of contemporary textual sources. For example, Mark Leone, the excavator and interpreter of historical Annapolis, Maryland, USA, has sought to understand the contradiction between textual documents idealizing \"liberty\" and the material record, demonstrating the possession of slaves and the inequalities of wealth made apparent by the study of the total historical environment.\n\nThere are varieties of ways in which history can be organized, including chronologically, culturally, territorially, and thematically. These divisions are not mutually exclusive, and significant intersections are often present. It is possible for historians to concern themselves with both the very specific and the very general, although the modern trend has been toward specialization. The area called Big History resists this specialization, and searches for universal patterns or trends. History has often been studied with some practical or theoretical aim, but also may be studied out of simple intellectual curiosity.\n\nHistory and prehistory\n\nThe history of the world is the memory of the past experience of Homo sapiens sapiens around the world, as that experience has been preserved, largely in written records. By \"prehistory\", historians mean the recovery of knowledge of the past in an area where no written records exist, or where the writing of a culture is not understood. By studying painting, drawings, carvings, and other artifacts, some information can be recovered even in the absence of a written record. Since the 20th century, the study of prehistory is considered essential to avoid history's implicit exclusion of certain civilizations, such as those of Sub-Saharan Africa and pre-Columbian America. Historians in the West have been criticized for focusing disproportionately on the Western world. In 1961, British historian E. H. Carr wrote:\n\nThis definition includes within the scope of history the strong interests of peoples, such as Indigenous Australians and New Zealand M\u0101ori in the past, and the oral records maintained and transmitted to succeeding generations, even before their contact with European civilization.\n\nHistoriography\n\nHistoriography has a number of related meanings. Firstly, it can refer to how history has been produced: the story of the development of methodology and practices (for example, the move from short-term biographical narrative towards long-term thematic analysis). Secondly, it can refer to what has been produced: a specific body of historical writing (for example, \"medieval historiography during the 1960s\" means \"Works of medieval history written during the 1960s\"). Thirdly, it may refer to why history is produced: the philosophy of history. As a meta-level analysis of descriptions of the past, this third conception can relate to the first two in that the analysis usually focuses on the narratives, interpretations, world view, use of evidence, or method of presentation of other historians. Professional historians also debate the question of whether history can be taught as a single coherent narrative or a series of competing narratives.\n\nHistorical methods\n\nThe historical method comprises the techniques and guidelines by which historians use primary sources and other evidence to research and then to write history.\n\nHerodotus of Halicarnassus (484 BC) has generally been acclaimed as the \"father of history\". However, his contemporary Thucydides () is credited with having first approached history with a well-developed historical method in his work the History of the Peloponnesian War. Thucydides, unlike Herodotus, regarded history as being the product of the choices and actions of human beings, and looked at cause and effect, rather than as the result of divine intervention (though Herodotus was not wholly committed to this idea himself). In his historical method, Thucydides emphasized chronology, a nominally neutral point of view, and that the human world was the result of the actions of human beings. Greek historians also viewed history as cyclical, with events regularly recurring.\n\nThere were historical traditions and sophisticated use of historical method in ancient and medieval China. The groundwork for professional historiography in East Asia was established by the Han dynasty court historian known as Sima Qian (145\u201390 BC), author of the Records of the Grand Historian (Shiji). For the quality of his written work, Sima Qian is posthumously known as the Father of Chinese historiography. Chinese historians of subsequent dynastic periods in China used his Shiji as the official format for historical texts, as well as for biographical literature.\n\nSaint Augustine was influential in Christian and Western thought at the beginning of the medieval period. Through the Medieval and Renaissance periods, history was often studied through a sacred or religious perspective. Around 1800, German philosopher and historian Georg Wilhelm Friedrich Hegel brought philosophy and a more secular approach in historical study.\n\nIn the preface to his book, the Muqaddimah (1377), the Arab historian and early sociologist, Ibn Khaldun, warned of seven mistakes that he thought that historians regularly committed. In this criticism, he approached the past as strange and in need of interpretation. The originality of Ibn Khaldun was to claim that the cultural difference of another age must govern the evaluation of relevant historical material, to distinguish the principles according to which it might be possible to attempt the evaluation, and lastly, to feel the need for experience, in addition to rational principles, in order to assess a culture of the past. Ibn Khaldun often criticized \"idle superstition and uncritical acceptance of historical data.\" As a result, he introduced a scientific method to the study of history, and he often referred to it as his \"new science\". His historical method also laid the groundwork for the observation of the role of state, communication, propaganda and systematic bias in history, and he is thus considered to be the \"father of historiography\" or the \"father of the philosophy of history\".\n\nIn the West, historians developed modern methods of historiography in the 17th and 18th centuries, especially in France and Germany. In 1851, Herbert Spencer summarized these methods:\n\nBy the \"rich ore\" Spencer meant scientific theory of history. Meanwhile, Henry Thomas Buckle expressed a dream of history becoming one day science:\n\nContrary to Buckle's dream, the 19th-century historian with greatest influence on methods became Leopold von Ranke in Germany. He limited history to \u201cwhat really happened\u201d and by this directed the field further away from science. For Ranke, historical data should be collected carefully, examined objectively and put together with critical rigor. But these procedures \u201care merely the prerequisites and preliminaries of science. The heart of science is searching out order and regularity in the data being examined and in formulating generalizations or laws about them.\u201d\n\nIn the 20th century, academic historians focused less on epic nationalistic narratives, which often tended to glorify the nation or great men, to more objective and complex analyses of social and intellectual forces. A major trend of historical methodology in the 20th century was a tendency to treat history more as a social science rather than as an art, which traditionally had been the case. Some of the leading advocates of history as a social science were a diverse collection of scholars which included Fernand Braudel, E. H. Carr, Fritz Fischer, Emmanuel Le Roy Ladurie, Hans-Ulrich Wehler, Bruce Trigger, Marc Bloch, Karl Dietrich Bracher, Peter Gay, Robert Fogel, Lucien Febvre and Lawrence Stone. Many of the advocates of history as a social science were or are noted for their multi-disciplinary approach. Braudel combined history with geography, Bracher history with political science, Fogel history with economics, Gay history with psychology, Trigger history with archaeology while Wehler, Bloch, Fischer, Stone, Febvre and Le Roy Ladurie have in varying and differing ways amalgamated history with sociology, geography, anthropology, and economics. Nevertheless, these multidisciplinary approaches failed to produce a theory of history. So far only one theory of history came from the pen of a professional Historian. Whatever other theories of history we have, they were written by experts from other fields (for example, Marxian theory of history). More recently, the field of digital history has begun to address ways of using computer technology to pose new questions to historical data and generate digital scholarship.\n\nIn sincere opposition to the claims of history as a social science, historians such as Hugh Trevor-Roper, John Lukacs, Donald Creighton, Gertrude Himmelfarb and Gerhard Ritter argued that the key to the historians' work was the power of the imagination, and hence contended that history should be understood as an art. French historians associated with the Annales School introduced quantitative history, using raw data to track the lives of typical individuals, and were prominent in the establishment of cultural history (cf. histoire des mentalit\u00e9s). Intellectual historians such as Herbert Butterfield, Ernst Nolte and George Mosse have argued for the significance of ideas in history. American historians, motivated by the civil rights era, focused on formerly overlooked ethnic, racial, and socio-economic groups. Another genre of social history to emerge in the post-WWII era was Alltagsgeschichte (History of Everyday Life). Scholars such as Martin Broszat, Ian Kershaw and Detlev Peukert sought to examine what everyday life was like for ordinary people in 20th-century Germany, especially in the Nazi period.\n\nMarxist historians such as Eric Hobsbawm, E. P. Thompson, Rodney Hilton, Georges Lefebvre, Eugene Genovese, Isaac Deutscher, C. L. R. James, Timothy Mason, Herbert Aptheker, Arno J. Mayer and Christopher Hill have sought to validate Karl Marx's theories by analyzing history from a Marxist perspective. In response to the Marxist interpretation of history, historians such as Fran\u00e7ois Furet, Richard Pipes, J. C. D. Clark, Roland Mousnier, Henry Ashby Turner and Robert Conquest have offered anti-Marxist interpretations of history. Feminist historians such as Joan Wallach Scott, Claudia Koonz, Natalie Zemon Davis, Sheila Rowbotham, Gisela Bock, Gerda Lerner, Elizabeth Fox-Genovese, and Lynn Hunt have argued for the importance of studying the experience of women in the past. In recent years, postmodernists have challenged the validity and need for the study of history on the basis that all history is based on the personal interpretation of sources. In his 1997 book In Defence of History, Richard J. Evans defended the worth of history. Another defence of history from post-modernist criticism was the Australian historian Keith Windschuttle's 1994 book, The Killing of History.\n\nToday, most historians begin their research process in the archives, on either a physical or digital platform. They often propose an argument and use their research to support it. John H. Arnold proposed that history is an argument, which creates the possibility of creating change. Digital information companies, such as Google, have sparked controversy over the role of internet censorship in information access.\n\nMarxian theory\n\nThe Marxist theory of historical materialism theorises that society is fundamentally determined by the material conditions at any given time\u00a0\u2013 in other words, the relationships which people have with each other in order to fulfill basic needs such as feeding, clothing and housing themselves and their families. Overall, Marx and Engels claimed to have identified five successive stages of the development of these material conditions in Western Europe. Marxist historiography was once orthodoxy in the Soviet Union, but since the collapse of communism there in 1991, Mikhail Krom says it has been reduced to the margins of scholarship.\n\nPotential shortcomings in the production of history \nMany historians believe that the\u00a0production of history is embedded with bias because events and known facts in history can be interpreted in a variety of ways. Constantin Fasolt suggested that history is linked to politics by the practice of silence itself. He also said:  \u201cA second common view of the link between history and politics rests on the elementary observation that historians are often influenced by politics.\u201d According to Michel-Rolph Trouillot, the historical process is rooted in the archives, therefore silences, or parts of history that are forgotten, may be\u00a0an intentional part of a narrative strategy that dictates how areas of history are remembered. Historical omissions can occur in many ways and can have a profound effect on historical records. Information can also purposely be excluded or left out accidentally. Historians have coined multiple terms that describe the act of omitting historical information, including: \u201csilencing,\u201d \u201cselective memory,\u201d and erasures.\u00a0Gerda Lerner, a twentieth century historian who focused much of her work on historical omissions involving women and their accomplishments, explained the negative impact that these omissions had on minority groups.\n\nEnvironmental historian William Cronon proposed three ways to combat bias and ensure authentic and accurate narratives: narratives must not contradict known fact, they must make ecological sense (specifically for environmental history), and published work must be reviewed by scholarly community and other historians to ensure accountability.\n\nAreas of study\n\nPeriods\n\nHistorical study often focuses on events and developments that occur in particular blocks of time. Historians give these periods of time names in order to allow \"organising ideas and classificatory generalisations\" to be used by historians. The names given to a period can vary with geographical location, as can the dates of the beginning and end of a particular period. Centuries and decades are commonly used periods and the time they represent depends on the dating system used. Most periods are constructed retrospectively and so reflect value judgments made about the past. The way periods are constructed and the names given to them can affect the way they are viewed and studied.\n\nPrehistoric periodisation\nThe field of history generally leaves prehistory to archaeologists, who have entirely different sets of tools and theories. In archaeology, the usual method for periodisation of the distant prehistoric past is to rely on changes in material culture and technology, such as the Stone Age, Bronze Age and Iron Age, with sub-divisions that are also based on different styles of material remains. Here prehistory is divided into a series of \"chapters\" so that periods in history could unfold not only in a relative chronology but also narrative chronology. This narrative content could be in the form of functional-economic interpretation. There are periodisations, however, that do not have this narrative aspect, relying largely on relative chronology, and that are thus devoid of any specific meaning.\n\nDespite the development over recent decades of the ability through radiocarbon dating and other scientific methods to give actual dates for many sites or artefacts, these long-established schemes seem likely to remain in use. In many cases neighbouring cultures with writing have left some history of cultures without it, which may be used. Periodisation, however, is not viewed as a perfect framework, with one account explaining that \"cultural changes do not conveniently start and stop (combinedly) at periodisation boundaries\" and that different trajectories of change need to be studied in their own right before they get intertwined with cultural phenomena.\n\nGeographical locations\nParticular geographical locations can form the basis of historical study, for example, continents, countries, and cities. Understanding why historic events took place is important. To do this, historians often turn to geography. According to Jules Michelet in his book Histoire de France (1833), \"without geographical basis, the people, the makers of history, seem to be walking on air.\" Weather patterns, the water supply, and the landscape of a place all affect the lives of the people who live there. For example, to explain why the ancient Egyptians developed a successful civilization, studying the geography of Egypt is essential. Egyptian civilization was built on the banks of the Nile River, which flooded each year, depositing soil on its banks. The rich soil could help farmers grow enough crops to feed the people in the cities. That meant everyone did not have to farm, so some people could perform other jobs that helped develop the civilization. There is also the case of climate, which historians like Ellsworth Huntington and Ellen Churchill Semple cited as a crucial influence on the course of history. Huntington and Semple further argued that climate has an impact on racial temperament.\n\nRegions\n History of Africa begins with the first emergence of modern human beings on the continent, continuing into its modern present as a patchwork of diverse and politically developing nation states.\n History of the Americas is the collective history of North and South America, including Central America and the Caribbean.\n History of North America is the study of the past passed down from generation to generation on the continent in the Earth's northern and western hemisphere.\n History of Central America is the study of the past passed down from generation to generation on the continent in the Earth's western hemisphere.\n History of the Caribbean begins with the oldest evidence where 7,000-year-old remains have been found.\n History of South America is the study of the past passed down from generation to generation on the continent in the Earth's southern and western hemisphere.\n History of Antarctica emerges from early Western theories of a vast continent, known as Terra Australis, believed to exist in the far south of the globe.\n History of Eurasia is the collective history of several distinct peripheral coastal regions: the Middle East, South Asia, East Asia, Southeast Asia, and Europe, linked by the interior mass of the Eurasian steppe of Central Asia and Eastern Europe.\n History of Europe describes the passage of time from humans inhabiting the European continent to the present day.\n History of Asia can be seen as the collective history of several distinct peripheral coastal regions, East Asia, South Asia, and the Middle East linked by the interior mass of the Eurasian steppe.\n History of East Asia is the study of the past passed down from generation to generation in East Asia.\n History of the Middle East begins with the earliest civilizations in the region now known as the Middle East that were established around 3000 BC, in Mesopotamia (Iraq).\n History of India is the study of the past passed down from generation to generation in the Sub-Himalayan region.\n History of Southeast Asia has been characterized as interaction between regional players and foreign powers.\n History of Oceania is the collective history of Australia, New Zealand and the Pacific Islands.\n History of Australia starts with the documentation of the Makassar trading with Indigenous Australians on Australia's north coast.\n History of New Zealand dates back at least 700 years to when it was discovered and settled by Polynesians, who developed a distinct M\u0101ori culture centred on kinship links and land.\n History of the Pacific Islands covers the history of the islands in the Pacific Ocean.\n\nMilitary\n\nMilitary history concerns warfare, strategies, battles, weapons, and the psychology of combat. The \"new military history\" since the 1970s has been concerned with soldiers more than generals, with psychology more than tactics, and with the broader impact of warfare on society and culture.\n\nReligious\n\nThe history of religion has been a main theme for both secular and religious historians for centuries, and continues to be taught in seminaries and academe. Leading journals include Church History, The Catholic Historical Review, and History of Religions. Topics range widely from political and cultural and artistic dimensions, to theology and liturgy. This subject studies religions from all regions and areas of the world where humans have lived.\n\nSocial\n\nSocial history, sometimes called the new social history, is the field that includes history of ordinary people and their strategies and institutions for coping with life. In its \"golden age\" it was a major growth field in the 1960s and 1970s among scholars, and still is well represented in history departments. In two decades from 1975 to 1995, the proportion of professors of history in American universities identifying with social history rose from 31% to 41%, while the proportion of political historians fell from 40% to 30%. In the history departments of British universities in 2007, of the 5723 faculty members, 1644 (29%)  identified themselves with social history while political history came next with 1425 (25%).\nThe \"old\" social history before the 1960s was a hodgepodge of topics without a central theme, and it often included political movements, like Populism, that were \"social\" in the sense of being outside the elite system. Social history was contrasted with political history, intellectual history and the history of great men. English historian G. M. Trevelyan saw it as the bridging point between economic and political history, reflecting that, \"Without social history, economic history is barren and political history unintelligible.\" While the field has often been viewed negatively as history with the politics left out, it has also been defended as \"history with the people put back in\".\n\nSubfields\nThe chief subfields of social history include:\n Black history\n Demographic history\n Ethnic history\n Gender history\n History of childhood\n History of education\n History of the family\n Labour history\n LGBT history\n Rural history\n Urban history\n American urban history\n Women's history\n\nCultural\n\nCultural history replaced social history as the dominant form in the 1980s and 1990s. It typically combines the approaches of anthropology and history to look at language, popular cultural traditions and cultural interpretations of historical experience. It examines the records and narrative descriptions of past knowledge, customs, and arts of a group of people. How peoples constructed their memory of the past is a major topic.\nCultural history includes the study of art in society as well is the study of images and human visual production (iconography).\n\nDiplomatic\n\nDiplomatic history  focuses on the relationships between nations, primarily regarding diplomacy and the causes of wars. More recently it looks at the causes of peace and human rights. It typically presents the viewpoints of the foreign office, and long-term strategic values, as the driving force of continuity and change in history. This type of political history is the study of the conduct of international relations between states or across state boundaries over time. Historian Muriel Chamberlain notes that after the First World War, \"diplomatic history replaced constitutional history as the flagship of historical investigation, at once the most important, most exact and most sophisticated of historical studies.\" She adds that after 1945, the trend reversed, allowing social history to replace it.\n\nEconomic\n\nAlthough economic history has been well established since the late 19th century, in recent years academic studies have shifted more and more toward economics departments and away from traditional history departments. Business history  deals with the history of individual business organizations, business methods, government regulation, labour relations, and impact on society. It also includes biographies of individual companies, executives, and entrepreneurs. It is related to economic history. Business history is most often taught in business schools.\n\nEnvironmental\n\nEnvironmental history is a new field that emerged in the 1980s to look at the history of the environment, especially in the long run, and the impact of human activities upon it. It is an offshoot of the environmental movement, which was kickstarted by Rachel Carson's Silent Spring in the 1960s.\n\nWorld\n\nWorld history is the study of major civilizations over the last 3000 years or so. World history is primarily a teaching field, rather than a research field. It gained popularity in the United States, Japan and other countries after the 1980s with the realization that students need a broader exposure to the world as globalization proceeds.\n\nIt has led to highly controversial interpretations by Oswald Spengler and Arnold J. Toynbee, among others.\n\nThe World History Association publishes the Journal of World History every quarter since 1990. The H-World discussion list serves as a network of communication among practitioners of world history, with discussions among scholars, announcements, syllabi, bibliographies and book reviews.\n\nPeople's\n\nA people's history is a type of historical work which attempts to account for historical events from the perspective of common people. A people's history is the history of the world that is the story of mass movements and of the outsiders. Individuals or groups not included in the past in other types of writing about history are the primary focus, which includes the disenfranchised, the oppressed, the poor, the nonconformists, and the otherwise forgotten people. The authors are typically on the left and have a socialist model in mind, as in the approach of the History Workshop movement in Britain in the 1960s.\n\nIntellectual\n\nIntellectual history and the history of ideas emerged in the mid-20th century, with the focus on the intellectuals and their books on the one hand, and on the other the study of ideas as disembodied objects with a career of their own.\n\nGender\n\nGender history is a subfield of History and Gender studies, which looks at the past from the perspective of gender. The outgrowth of gender history from women's history stemmed from many non-feminist historians dismissing the importance of women in history. According to Joan W. Scott, \u201cGender is a constitutive element of social relationships based on perceived differences between the sexes, and gender is a primary way of signifying relations of power\u201d, meaning that gender historians study the social effects of perceived differences between the sexes and how all genders utilize allotted power in societal and political structures. Despite being a relatively new field, gender history has had a significant effect on the general study of history. Gender history traditionally differs from women's history in its inclusion of all aspects of gender such as masculinity and femininity, and today's gender history extends to include people who identify outside of that binary. \nLGBT history deals with the first recorded instances of same-sex love and sexuality of ancient civilizations, and involves the history of lesbian, gay, bisexual and transgender (LGBT) peoples and cultures around the world.\n\nPublic\n\nPublic history describes the broad range of activities undertaken by people with some training in the discipline of history who are generally working outside of specialized academic settings. Public history practice has quite deep roots in the areas of historic preservation, archival science, oral history, museum curatorship, and other related fields. The term itself began to be used in the U.S. and Canada in the late 1970s, and the field has become increasingly professionalized since that time. Some of the most common settings for public history are museums, historic homes and historic sites, parks, battlefields, archives, film and television companies, and all levels of government.\n\nHistorians\n\nProfessional and amateur historians discover, collect, organize, and present information about past events. They discover this information through archaeological evidence, written primary sources, verbal stories or oral histories, and other archival material. In lists of historians, historians can be grouped by order of the historical period in which they were writing, which is not necessarily the same as the period in which they specialized. Chroniclers and annalists, though they are not historians in the true sense, are also frequently included.\n\nJudgement\n\nSince the 20th century, Western historians have disavowed the aspiration to provide the \"judgement of history\". The goals of historical judgements or interpretations are separate to those of legal judgements, that need to be formulated quickly after the events and be final. A related issue to that of the judgement of history is that of collective memory.\n\nPseudohistory\n\nPseudohistory is a term applied to texts which purport to be historical in nature but which depart from standard historiographical conventions in a way which undermines their conclusions.\nIt is closely related to deceptive historical revisionism. Works which draw controversial conclusions from new, speculative, or disputed historical evidence, particularly in the fields of national, political, military, and religious affairs, are often rejected as pseudohistory.\n\nTeaching\n\nScholarship vs teaching\nA major intellectual battle took place in Britain in the early twentieth century regarding the place of history teaching in the universities. At Oxford and Cambridge, scholarship was downplayed. Professor Charles Harding Firth, Oxford's Regius Professor of history in 1904 ridiculed the system as best suited to produce superficial journalists. The Oxford tutors, who had more votes than the professors, fought back in defence of their system saying that it successfully produced Britain's outstanding statesmen, administrators, prelates, and diplomats, and that mission was as valuable as training scholars. The tutors dominated the debate until after the Second World War. It forced aspiring young scholars to teach at outlying schools, such as Manchester University, where Thomas Frederick Tout was professionalizing the History undergraduate programme by introducing the study of original sources and requiring the writing of a thesis.\n\nIn the United States, scholarship was concentrated at the major PhD-producing universities, while the large number of other colleges and universities focused on undergraduate teaching. A tendency in the 21st century was for the latter schools to increasingly demand scholarly productivity of their younger tenure-track faculty. Furthermore, universities have increasingly relied on inexpensive part-time adjuncts to do most of the classroom teaching.\n\nNationalism\nFrom the origins of national school systems in the 19th century, the teaching of history to promote national sentiment has been a high priority. In the United States after World War I, a strong movement emerged at the university level to teach courses in Western Civilization, so as to give students a common heritage with Europe. In the U.S. after 1980, attention increasingly moved toward teaching world history or requiring students to take courses in non-western cultures, to prepare students for life in a globalized economy.\n\nAt the university level, historians debate the question of whether history belongs more to social science or to the humanities. Many view the field from both perspectives.\n\nThe teaching of history in French schools was influenced by the Nouvelle histoire as disseminated after the 1960s by Cahiers p\u00e9dagogiques and Enseignement and other journals for teachers. Also influential was the Institut national de recherche et de documentation p\u00e9dagogique, (INRDP). Joseph Leif, the Inspector-general of teacher training, said pupils children should learn about historians' approaches as well as facts and dates. Louis Fran\u00e7ois, Dean of the History/Geography group in the Inspectorate of National Education advised that teachers should provide historic documents and promote \"active methods\" which would give pupils \"the immense happiness of discovery.\" Proponents said it was a reaction against the memorization of names and dates that characterized teaching and left the students bored. Traditionalists protested loudly it was a postmodern innovation that threatened to leave the youth ignorant of French patriotism and national identity.\n\nBias in school teaching\n\nIn several countries\u2019 history textbooks are tools to foster nationalism and patriotism, and give students the official narrative about national enemies.\n\nIn many countries, history textbooks are sponsored by the national government and are written to put the national heritage in the most favourable light. For example, in Japan, mention of the Nanking Massacre has been removed from textbooks and the entire Second World War is given cursory treatment. Other countries have complained. It was standard policy in communist countries to present only a rigid Marxist historiography.\n\nIn the United States, textbooks published by the same company often differ in content from state to state. An example of content that is represented different in different regions of the country is the history of the Southern states, where slavery and the American Civil War are treated as controversial topics. McGraw-Hill Education for example, was criticised for describing Africans brought to American plantations as \"workers\" instead of slaves in a textbook.\n\nAcademic historians have often fought against the politicization of the textbooks, sometimes with success.\n\nIn 21st-century Germany, the history curriculum is controlled by the 16 states, and is characterized not by superpatriotism but rather by an \"almost pacifistic and deliberately unpatriotic undertone\" and reflects \"principles formulated by international organizations such as UNESCO or the Council of Europe, thus oriented towards human rights, democracy and peace.\"  The result is that \"German textbooks usually downplay national pride and ambitions and aim to develop an understanding of citizenship centered on democracy, progress, human rights, peace, tolerance and Europeanness.\"\n\nSee also\n\nMethods\n Auxiliary sciences of history\n Archival research\n Bibliography\n Computational history\n List of history journals\n Popular history\n\nTopics\n Historiography of Argentina\n Atlantic history\n Historiography of Canada\n Classics\n Greek historiography\n Historiography of Alexander the Great\n Roman historiography\n Historiography of the fall of the Western Roman Empire\n Historiography of the Cold War\n Chinese historiography\n Historiography of the French Revolution\n Annales School, in France\n Historiography of Germany\n Bielefeld School, in Germany\n Historiography of early Islam\n Historiography of Japan\n Middle Ages\n Dark Ages (historiography)\n Historiography of the Crusades\n Historiography of Switzerland\n Historiography in the Soviet Union\n Historiography of the United States\n Frontier Thesis\n Historiography of the United Kingdom\n Historiography of Scotland\n Historiography of the British Empire\n World history\n Historiography of the causes of World War I\n Historiography of World War II\n\nOther themes\n List of history awards\n History of the book\n Historiography of science\n Subaltern Studies, Regarding post-colonial India\n Whig history, History portrayed as the story of continuous progress\n\nReferences\n\nFurther reading\n\nExternal links\n\n Best history sites .net\n BBC History Site\n Internet History Sourcebooks Project See also Internet History Sourcebooks Project. Collections of public domain and copy-permitted historical texts for educational use\n The History Channel Online\n History Channel UK\n\n \nHumanities\nMain topic articles",
  "Transport": "Transport (in British English), or transportation (in American English), is the movement of humans, animals, and goods from one location to another. In other words, the action of transport is defined as a particular movement of an organism or thing from a point A (a place in space) to a point B.  \n\nModes of transport include air, land (rail and road), water, cable, pipeline, and space. The field can be divided into infrastructure, vehicles, and operations. Transport enables trade between people, which is essential for the development of civilizations.\n\nTransport infrastructure consists of the fixed installations, including roads, railways, airways, waterways, canals, and pipelines and terminals such as airports, railway stations, bus stations, warehouses, trucking terminals, refueling depots (including fueling docks and fuel stations), and seaports. Terminals may be used both for interchange of passengers and cargo and for maintenance.\n\nMeans of transport are any of the different kinds of transport facilities used to carry people or cargo. They may include vehicles, riding animals, and pack animals. Vehicles may include wagons, automobiles, bicycles, buses, trains, trucks, helicopters, watercraft, spacecraft, and aircraft.\n\nModes\n \n \n\nA mode of transport is a solution that makes use of a particular type of vehicle, infrastructure, and operation. The transport of a person or of cargo may involve one mode or several of the modes, with the latter case being called inter-modal or multi-modal transport. Each mode has its own advantages and disadvantages, and will be chosen on the basis of cost, capability, and route.\n\nGovernments deal with the way the vehicles are operated, and the procedures set for this purpose, including financing, legalities, and policies. In the transport industry, operations and ownership of infrastructure can be either public or private, depending on the country and mode.\n\nPassenger transport may be public, where operators provide scheduled services, or private. Freight transport has become focused on containerization, although bulk transport is used for large volumes of durable items. Transport plays an important part in economic growth and globalization, but most types cause air pollution and use large amounts of land. While it is heavily subsidized by governments, good planning of transport is essential to make traffic flow and restrain urban sprawl.\n\nHuman-powered\n\nHuman-powered transport, a form of sustainable transport, is the transport of people and/or goods using human muscle-power, in the form of walking, running, and swimming. Modern technology has allowed machines to enhance human power. Human-powered transport remains popular for reasons of cost-saving, leisure, physical exercise, and environmentalism; it is sometimes the only type available, especially in underdeveloped or inaccessible regions.\n\nAlthough humans are able to walk without infrastructure, the transport can be enhanced through the use of roads, especially when using the human power with vehicles, such as bicycles and inline skates. Human-powered vehicles have also been developed for difficult environments, such as snow and water, by watercraft rowing and skiing; even the air can be entered with human-powered aircraft.\n\nAnimal-powered\n\nAnimal-powered transport is the use of working animals for the movement of people and commodities. Humans may ride some of the animals directly, use them as pack animals for carrying goods, or harness them, alone or in teams, to pull sleds or wheeled vehicles.\n\nAir\n\nA fixed-wing aircraft, commonly called an airplane, is a heavier-than-air craft where movement of the air in relation to the wings is used to generate lift. The term is used to distinguish this from rotary-wing aircraft, where the movement of the lift surfaces relative to the air generates lift. A gyroplane is both fixed-wing and rotary wing. Fixed-wing aircraft range from small trainers and recreational aircraft to large airliners and military cargo aircraft.\n\nTwo things necessary for aircraft are air flow over the wings for lift and an area for landing. The majority of aircraft also need an airport with the infrastructure for maintenance, restocking, and refueling and for the loading and unloading of crew, cargo, and passengers. While the vast majority of aircraft land and take off on land, some are capable of take-off and landing on ice, snow, and calm water.\n\nThe aircraft is the second fastest method of transport, after the rocket. Commercial jets can reach up to , single-engine aircraft . Aviation is able to quickly transport people and limited amounts of cargo over longer distances, but incurs high costs and energy use; for short distances or in inaccessible places, helicopters can be used. As of April 28, 2009, The Guardian article notes that \"the WHO estimates that up to 500,000 people are on planes at any time.\"\n\nLand\n\nLand transport covers all land-based transport systems that provide for the movement of people, goods, and services. Land transport plays a vital role in linking communities to each other. Land transport is a key factor in urban planning. It consists of two kinds, rail and road.\n\nRail\n\nRail transport is where a train runs along a set of two parallel steel rails, known as a railway or railroad. The rails are anchored perpendicular to ties (or sleepers) of timber, concrete, or steel, to maintain a consistent distance apart, or gauge. The rails and perpendicular beams are placed on a foundation made of concrete or compressed earth and gravel in a bed of ballast. Alternative methods include monorail and maglev.\n\nA train consists of one or more connected vehicles that operate on the rails. Propulsion is commonly provided by a locomotive, that hauls a series of unpowered cars, that can carry passengers or freight. The locomotive can be powered by steam, by diesel, or by electricity supplied by trackside systems. Alternatively, some or all the cars can be powered, known as a multiple unit. Also, a train can be powered by horses, cables, gravity, pneumatics, and gas turbines. Railed vehicles move with much less friction than rubber tires on paved roads, making trains more energy efficient, though not as efficient as ships.\n\nIntercity trains are long-haul services connecting cities; modern high-speed rail is capable of speeds up to , but this requires specially built track. Regional and commuter trains feed cities from suburbs and surrounding areas, while intra-urban transport is performed by high-capacity tramways and rapid transits, often making up the backbone of a city's public transport. Freight trains traditionally used box cars, requiring manual loading and unloading of the cargo. Since the 1960s, container trains have become the dominant solution for general freight, while large quantities of bulk are transported by dedicated trains.\n\nRoad\n \n \n\nA road is an identifiable route, way, or path between two or more places. Roads are typically smoothed, paved, or otherwise prepared to allow easy travel; though they need not be, and historically many roads were simply recognizable routes without any formal construction or maintenance. In urban areas, roads may pass through a city or village and be named as streets, serving a dual function as urban space easement and route.\n\nThe most common road vehicle is the automobile; a wheeled passenger vehicle that carries its own motor. Other users of roads include buses, trucks, motorcycles, bicycles, and pedestrians. As of 2010, there were 1.015 billion automobiles worldwide.\nRoad transport offers complete freedom to road users to transfer the vehicle from one lane to the other and from one road to another according to the need and convenience. This flexibility of changes in location, direction, speed, and timings of travel is not available to other modes of transport. It is possible to provide door-to-door service only by road transport.\n\nAutomobiles provide high flexibility with low capacity, but require high energy and area use, and are the main source of harmful noise and air pollution in cities; buses allow for more efficient travel at the cost of reduced flexibility. Road transport by truck is often the initial and final stage of freight transport.\n\nWater\n \n\nWater transport is movement by means of a watercraft\u2014such as a barge, boat, ship, or sailboat\u2014over a body of water, such as a sea, ocean, lake, canal, or river. The need for buoyancy is common to watercraft, making the hull a dominant aspect of its construction, maintenance, and appearance.\n\nIn the 19th century, the first steam ships were developed, using a steam engine to drive a paddle wheel or propeller to move the ship. The steam was produced in a boiler using wood or coal and fed through a steam external combustion engine. Now most ships have an internal combustion engine using a slightly refined type of petroleum called bunker fuel. Some ships, such as submarines, use nuclear power to produce the steam. Recreational or educational craft still use wind power, while some smaller craft use internal combustion engines to drive one or more propellers or, in the case of jet boats, an inboard water jet. In shallow draft areas, hovercraft are propelled by large pusher-prop fans. (See Marine propulsion.)\n\nAlthough it is slow compared to other transport, modern sea transport is a highly efficient method of transporting large quantities of goods. Commercial vessels, nearly 35,000 in number, carried 7.4\u00a0billion tons of cargo in 2007. Transport by water is significantly less costly than air transport for transcontinental shipping; short sea shipping and ferries remain viable in coastal areas.\n\nOther modes\n\nPipeline transport sends goods through a pipe; most commonly liquid and gases are sent, but pneumatic tubes can also send solid capsules using compressed air. For liquids/gases, any chemically stable liquid or gas can be sent through a pipeline. Short-distance systems exist for sewage, slurry, water, and beer, while long-distance networks are used for petroleum and natural gas.\n\nCable transport is a broad mode where vehicles are pulled by cables instead of an internal power source. It is most commonly used at steep gradient. Typical solutions include aerial tramways, elevators, escalators, and ski lifts; some of these are also categorized as conveyor transport.\n\nSpaceflight is transport out of Earth's atmosphere into outer space by means of a spacecraft. While large amounts of research have gone into technology, it is rarely used except to put satellites into orbit and conduct scientific experiments. However, man has landed on the moon, and probes have been sent to all the planets of the Solar System.\n\nSuborbital spaceflight is the fastest of the existing and planned transport systems from a place on Earth to a distant \"other place\" on Earth. Faster transport could be achieved through part of a low Earth orbit or by following that trajectory even faster, using the propulsion of the rocket to steer it.\n\nElements\n\nInfrastructure\n\nInfrastructure is the fixed installations that allow a vehicle to operate. It consists of a roadway, a terminal, and facilities for parking and maintenance. For rail, pipeline, road, and cable transport, the entire way the vehicle travels must be constructed. Air and watercraft are able to avoid this, since the airway and seaway do not need to be constructed. However, they require fixed infrastructure at terminals.\n\nTerminals such as airports, ports, and stations, are locations where passengers and freight can be transferred from one vehicle or mode to another. For passenger transport, terminals are integrating different modes to allow riders, who are interchanging between modes, to take advantage of each mode's benefits. For instance, airport rail links connect airports to the city centres and suburbs. The terminals for automobiles are parking lots, while buses and coaches can operate from simple stops. For freight, terminals act as transshipment points, though some cargo is transported directly from the point of production to the point of use.\n\nThe financing of infrastructure can either be public or private. Transport is often a natural monopoly and a necessity for the public; roads, and in some countries railways and airports, are funded through taxation. New infrastructure projects can have high costs and are often financed through debt. Many infrastructure owners, therefore, impose usage fees, such as landing fees at airports or toll plazas on roads. Independent of this, authorities may impose taxes on the purchase or use of vehicles. Because of poor forecasting and overestimation of passenger numbers by planners, there is frequently a benefits shortfall for transport infrastructure projects.\n\nMeans of transport\n\nAnimals\nAnimals used in transportation include pack animals and riding animals.\n\nVehicles\n\nA vehicle is a non-living device that is used to move people and goods. Unlike the infrastructure, the vehicle moves along with the cargo and riders. Unless being pulled/pushed by a cable or muscle-power, the vehicle must provide its own propulsion; this is most commonly done through a steam engine, combustion engine, electric motor, jet engine, or rocket, though other means of propulsion also exist. Vehicles also need a system of converting the energy into movement; this is most commonly done through wheels, propellers, and pressure.\n\nVehicles are most commonly staffed by a driver. However, some systems, such as people movers and some rapid transits, are fully automated. For passenger transport, the vehicle must have a compartment, seat, or platform for the passengers. Simple vehicles, such as automobiles, bicycles, or simple aircraft, may have one of the passengers as a driver.\n\nOperation\n\nPrivate transport is only subject to the owner of the vehicle, who operates the vehicle themselves. For public transport and freight transport, operations are done through private enterprise or by governments. The infrastructure and vehicles may be owned and operated by the same company, or they may be operated by different entities. Traditionally, many countries have had a national airline and national railway. Since the 1980s, many of these have been privatized. International shipping remains a highly competitive industry with little regulation, but ports can be public-owned.\n\nPolicy\n\n \nAs the population of the world increases, cities grow in size and population\u2014according to the United Nations, 55% of the world's population live in cities, and by 2050 this number is expected to rise to 68%. Public transport policy must evolve to meet the changing priorities of the urban world. The institution of policy enforces order in transport, which is by nature chaotic as people attempt to travel from one place to another as fast as possible. This policy helps to reduce accidents and save lives.\n\nFunctions\nRelocation of travelers and cargo are the most common uses of transport. However, other uses exist, such as the strategic and tactical relocation of armed forces during warfare, or the civilian mobility construction or emergency equipment.\n\nPassenger\n\nPassenger transport, or travel, is divided into public and private transport. Public transport is scheduled services on fixed routes, while private is vehicles that provide ad hoc services at the riders desire. The latter offers better flexibility, but has lower capacity and a higher environmental impact. Travel may be as part of daily commuting or for business, leisure, or migration.\n\nShort-haul transport is dominated by the automobile and mass transit. The latter consists of buses in rural and small cities, supplemented with commuter rail, trams, and rapid transit in larger cities. Long-haul transport involves the use of the automobile, trains, coaches, and aircraft, the last of which have become predominantly used for the longest, including intercontinental, travel. Intermodal passenger transport is where a journey is performed through the use of several modes of transport; since all human transport normally starts and ends with walking, all passenger transport can be considered intermodal. Public transport may also involve the intermediate change of vehicle, within or across modes, at a transport hub, such as a bus or railway station.\n\nTaxis and buses can be found on both ends of the public transport spectrum. Buses are the cheapest mode of transport but are not necessarily flexible, and taxis are very flexible but more expensive. In the middle is demand-responsive transport, offering flexibility whilst remaining affordable.\n\nInternational travel may be restricted for some individuals due to legislation and visa requirements.\n\nMedical\nAn ambulance is a vehicle used to transport people from or between places of treatment, and in some instances will also provide out-of-hospital medical care to the patient. The word is often associated with road-going \"emergency ambulances\", which form part of emergency medical services, administering emergency care to those with acute medical problems.\n\nAir medical services is a comprehensive term covering the use of air transport to move patients to and from healthcare facilities and accident scenes. Personnel provide comprehensive prehospital and emergency and critical care to all types of patients during aeromedical evacuation or rescue operations, aboard helicopters, propeller aircraft, or jet aircraft.\n\nFreight\n \n\nFreight transport, or shipping, is a key in the value chain in manufacturing. With increased specialization and globalization, production is being located further away from consumption, rapidly increasing the demand for transport. Transport creates place utility by moving the goods from the place of production to the place of consumption. While all modes of transport are used for cargo transport, there is high differentiation between the nature of the cargo transport, in which mode is chosen. Logistics refers to the entire process of transferring products from producer to consumer, including storage, transport, transshipment, warehousing, material-handling, and packaging, with associated exchange of information. Incoterm deals with the handling of payment and responsibility of risk during transport.\n\nContainerization, with the standardization of ISO containers on all vehicles and at all ports, has revolutionized international and domestic trade, offering a huge reduction in transshipment costs. Traditionally, all cargo had to be manually loaded and unloaded into the haul of any ship or car; containerization allows for automated handling and transfer between modes, and the standardized sizes allow for gains in economy of scale in vehicle operation. This has been one of the key driving factors in international trade and globalization since the 1950s.\n\nBulk transport is common with cargo that can be handled roughly without deterioration; typical examples are ore, coal, cereals, and petroleum. Because of the uniformity of the product, mechanical handling can allow enormous quantities to be handled quickly and efficiently. The low value of the cargo combined with high volume also means that economies of scale become essential in transport, and gigantic ships and whole trains are commonly used to transport bulk. Liquid products with sufficient volume may also be transported by pipeline.\n\nAir freight has become more common for products of high value; while less than one percent of world transport by volume is by airline, it amounts to forty percent of the value. Time has become especially important in regards to principles such as postponement and just-in-time within the value chain, resulting in a high willingness to pay for quick delivery of key components or items of high value-to-weight ratio. In addition to mail, common items sent by air include electronics and fashion clothing.\n\nImpact\n\nEconomic\n\nTransport is a key necessity for specialization\u2014allowing production and consumption of products to occur at different locations.  Throughout history, transport has been a spur to expansion; better transport allows more trade and a greater spread of people. Economic growth has always been dependent on increasing the capacity and rationality of transport. But the infrastructure and operation of transport have a great impact on the land, and transport is the largest drainer of energy, making transport sustainability a major issue.\n\nDue to the way modern cities and communities are planned and operated, a physical distinction between home and work is usually created, forcing people to transport themselves to places of work, study, or leisure, as well as to temporarily relocate for other daily activities. Passenger transport is also the essence of tourism, a major part of recreational transport. Commerce requires the transport of people to conduct business, either to allow face-to-face communication for important decisions or to move specialists from their regular place of work to sites where they are needed.\n\nPlanning\n\nTransport planning allows for high utilization and less impact regarding new infrastructure. Using models of transport forecasting, planners are able to predict future transport patterns. On the operative level, logistics allows owners of cargo to plan transport as part of the supply chain. Transport as a field is also studied through transport economics, a component for the creation of regulation policy by authorities. Transport engineering, a sub-discipline of civil engineering, must take into account trip generation, trip distribution, mode choice, and route assignment, while the operative level is handled through traffic engineering.\n\nBecause of the negative impacts incurred, transport often becomes the subject of controversy related to choice of mode, as well as increased capacity. Automotive transport can be seen as a tragedy of the commons, where the flexibility and comfort for the individual deteriorate the natural and urban environment for all. Density of development depends on mode of transport, with public transport allowing for better spatial utilization. Good land use keeps common activities close to people's homes and places higher-density development closer to transport lines and hubs, to minimize the need for transport. There are economies of agglomeration. Beyond transport, some land uses are more efficient when clustered. Transport facilities consume land, and in cities pavement (devoted to streets and parking) can easily exceed 20 percent of the total land use. An efficient transport system can reduce land waste.\n\nToo much infrastructure and too much smoothing for maximum vehicle throughput mean that in many cities there is too much traffic and many\u2014if not all\u2014of the negative impacts that come with it. It is only in recent years that traditional practices have started to be questioned in many places; as a result of new types of analysis which bring in a much broader range of skills than those traditionally relied on\u2014spanning such areas as environmental impact analysis, public health, sociology, and economics\u2014the viability of the old mobility solutions is increasingly being questioned.\n\nEnvironment\n\n \n\nTransport is a major use of energy and burns most of the world's petroleum. This creates air pollution, including nitrous oxides and particulates, and is a significant contributor to global warming through emission of carbon dioxide, for which transport is the fastest-growing emission sector. By sub-sector, road transport is the largest contributor to global warming. Environmental regulations in developed countries have reduced individual vehicles' emissions; however, this has been offset by increases in the numbers of vehicles and in the use of each vehicle. Some pathways to reduce the carbon emissions of road vehicles considerably have been studied. Energy use and emissions vary largely between modes, causing environmentalists to call for a transition from air and road to rail and human-powered transport, as well as increased transport electrification and energy efficiency. \n\nOther environmental impacts of transport systems include traffic congestion and automobile-oriented urban sprawl, which can consume natural habitat and agricultural lands. By reducing transport emissions globally, it is predicted that there will be significant positive effects on Earth's air quality, acid rain, smog, and climate change.\n\nWhile Tesla is an automobile manufacturing company that is building electric cars to cut down CO2 emission at the point of use, an approach that is becoming popular among cities worldwide is to prioritize public transport, bicycles, and pedestrian movement. Redirecting vehicle movement to create 20-minute neighbourhoods that promotes exercise while greatly reducing vehicle dependency and pollution. Some policies are levying a congestion charge to cars for travelling within congested areas during peak time.\n\nSustainable development \nThe United Nation's first formally recognized the role of transport in sustainable development in the 1992 United Nation's Earth summit. In the 2012 United Nation's World Conference, global leaders unanimously recognized that transport and mobility are central to achieving the sustainability targets. In recent years, data has been collected to show that the transport sector contributes to a quarter of the global greenhouse gas emissions, and therefore sustainable transport has been mainstreamed across several of the 2030 Sustainable Development Goals, especially those related to food, security, health, energy, economic growth, infrastructure, and cities and human settlements. Meeting sustainable transport targets is said to be particularly important to achieving the Paris Agreement.\n\nThere are various Sustainable Development Goals (SDGs) that are promoting sustainable transport in order to meet the defined goals. These include SDG 3 on health (increased road safety), SDG 7 on energy, SDG 8 on decent work and economic growth, SDG 9 on resilient infrastructure, SDG 11 on sustainable cities (access to transport and expanded public transport), SDG 12 on sustainable consumption and production (ending fossil fuel subsidies), and SDG 14 on oceans, seas, and marine resources.\n\nHistory\n\nNatural\nHumans' first ways to move included walking, running, and swimming. The domestication of animals introduced a new way to lay the burden of transport on more powerful creatures, allowing the hauling of heavier loads, or humans riding animals for greater speed and duration. Inventions such as the wheel and the sled (U.K. sledge) helped make animal transport more efficient through the introduction of vehicles.\n\nThe first forms of road transport involved animals, such as horses (domesticated in the 4th or the 3rd millennium BCE), oxen (from about 8000 BCE), or humans carrying goods over dirt tracks that often followed game trails.\n\nInfrastructure\nMany early civilizations, including those in Mesopotamia and the Indus Valley, constructed paved roads.  In classical antiquity, the Persian and Roman empires built stone-paved roads to allow armies to travel quickly. Deep roadbeds of crushed stone underneath kept such roads dry. The medieval Caliphate later built tar-paved roads.\n\nWater transport\nWater transport, including rowed and sailed vessels, dates back to time immemorial and was the only efficient way to transport large quantities or over large distances prior to the Industrial Revolution. The first watercraft were canoes cut out from tree trunks. Early water transport was accomplished with ships that were either rowed or used the wind for propulsion, or a combination of the two. The importance of water has led to most cities that grew up as sites for trading being located on rivers or on the sea-shore, often at the intersection of two bodies of water.\n\nMechanical\nUntil the Industrial Revolution, transport remained slow and costly, and production and consumption gravitated as close to each other as feasible. The Industrial Revolution in the 19th century saw several inventions fundamentally change transport. With telegraphy, communication became instant and independent of the transport of physical objects. The invention of the steam engine, closely followed by its application in rail transport, made land transport independent of human or animal muscles. Both speed and capacity increased, allowing specialization through manufacturing being located independently of natural resources. The 19th century also saw the development of the steam ship, which sped up global transport.\n\nWith the development of the combustion engine and the automobile around 1900, road transport became more competitive again, and mechanical private transport originated. The first \"modern\" highways were constructed during the 19th century with macadam. Later, tarmac and concrete became the dominant paving materials. \n\nIn 1903 the Wright brothers demonstrated the first successful controllable airplane, and after World War I (1914\u20131918) aircraft became a fast way to transport people and express goods over long distances.\n\nAfter World War II (1939\u20131945) the automobile and airlines took higher shares of transport, reducing rail and water to freight and short-haul passenger services. Scientific spaceflight began in the 1950s, with rapid growth until the 1970s, when interest dwindled. In the 1950s the introduction of containerization gave massive efficiency gains in freight transport, fostering globalization. International air travel became much more accessible in the 1960s with the commercialization of the jet engine. Along with the growth in automobiles and motorways, rail and water transport declined in relative importance. After the introduction of the Shinkansen in Japan in 1964, high-speed rail in Asia and Europe started attracting passengers on long-haul routes away from the airlines.\n\nEarly in U.S. history, private joint-stock corporations owned most aqueducts, bridges, canals, railroads, roads, and tunnels. Most such transport infrastructure came under government control in the late 19th and early 20th centuries, culminating in the nationalization of inter-city passenger rail-service with the establishment of Amtrak. Recently, however, a movement to privatize roads and other infrastructure has gained some ground and adherents.\n\nSee also\n\n Environmental impact of aviation\n Energy efficiency in transport\n IEEE Intelligent Transportation Systems Society\n List of emerging transportation technologies\n Journal of Transport and Land Use\n Outline of transport\n Public transport\n Rail transport by country\n Speed record\n Taxicabs by country\n Transportation engineering\n\nReferences\n\nBibliography\n\nExternal links\n\n Transportation from UCB Libraries GovPubs\n \n America On the Move An online transportation exhibition from the National Museum of American History, Smithsonian Institution\n World Transportation Organization The world transportation organization (The Non-Profit Advisory Organization)\n\n \nLogistics\nEconomics of transport and utility industries",
  "Law": "Law is a system of rules created and enforced through social or governmental institutions to regulate behavior, with its precise definition a matter of longstanding debate. It has been variously described as a science and the art of justice. State-enforced laws can be made by a group legislature or by a single legislator, resulting in statutes; by the executive through decrees and regulations; or established by judges through precedent, usually in common law jurisdictions. Private individuals may create legally binding contracts, including arbitration agreements that adopt alternative ways of resolving disputes to standard court litigation. The creation of laws themselves may be influenced by a constitution, written or tacit, and the rights encoded therein. The law shapes politics, economics, history and society in various ways and serves as a mediator of relations between people.\n\nLegal systems vary between countries, with their differences analysed in comparative law. In civil law jurisdictions, a legislature or other central body codifies and consolidates the law. In common law systems, judges make binding case law through precedent, although on occasion this may be overturned by a higher court or the legislature. Historically, religious law influenced secular matters, and is still used in some religious communities. Sharia law based on Islamic principles is used as the primary legal system in several countries, including Iran and Saudi Arabia.\n\nLaw's scope can be divided into two domains. Public law concerns government and society, including constitutional law, administrative law, and criminal law. Private law deals with legal disputes between individuals and/or organisations in areas such as contracts, property, torts/delicts and commercial law. This distinction is stronger in civil law countries, particularly those with a separate system of administrative courts; by contrast, the public-private law divide is less pronounced in common law jurisdictions.\n\nLaw provides a source of scholarly inquiry into legal history, philosophy, economic analysis and sociology. Law also raises important and complex issues concerning equality, fairness, and justice.\n\nPhilosophy of law \n\nThe philosophy of law is commonly known as jurisprudence. Normative jurisprudence asks \"what should law be?\", while analytic jurisprudence asks \"what is law?\"\n\nAnalytical jurisprudence \n\nThere have been several attempts to produce \"a universally acceptable definition of law\". In 1972, Baron Hampstead suggested that no such definition could be produced. McCoubrey and White said that the question \"what is law?\" has no simple answer. Glanville Williams said that the meaning of the word \"law\" depends on the context in which that word is used. He said that, for example, \"early customary law\" and \"municipal law\" were contexts where the word \"law\" had two different and irreconcilable meanings. Thurman Arnold said that it is obvious that it is impossible to define the word \"law\" and that it is also equally obvious that the struggle to define that word should not ever be abandoned. It is possible to take the view that there is no need to define the word \"law\" (e.g. \"let's forget about generalities and get down to cases\").\n\nOne definition is that law is a system of rules and guidelines which are enforced through social institutions to govern behaviour. In The Concept of Law Hart argued law is a \"system of rules\"; Austin said law was \"the command of a sovereign, backed by the threat of a sanction\"; Dworkin describes law as an \"interpretive concept\" to achieve justice in his text titled Law's Empire; and Raz argues law is an \"authority\" to mediate people's interests. Holmes said, \"The prophecies of what the courts will do in fact, and nothing more pretentious, are what I mean by the law.\" In his Treatise on Law Aquinas argues that law is a rational ordering of things which concern the common good that is promulgated by whoever is charged with the care of the community. This definition has both positivist and naturalist elements.\n\nConnection to morality and justice \n\nDefinitions of law often raise the question of the extent to which law incorporates morality. John Austin's utilitarian answer was that law is \"commands, backed by threat of sanctions, from a sovereign, to whom people have a habit of obedience\". Natural lawyers on the other side, such as Jean-Jacques Rousseau, argue that law reflects essentially moral and unchangeable laws of nature. The concept of \"natural law\" emerged in ancient Greek philosophy concurrently and in connection with the notion of justice, and re-entered the mainstream of Western culture through the writings of Thomas Aquinas, notably his Treatise on Law.\n\nWhen having completed the first two parts of his book Splendeurs et mis\u00e8res des courtisanes, which he intended to be the end of the entire work, Honor\u00e9 de Balzac visited the Conciergerie. Thereafter, he decided to add a third part, finally named O\u00f9 m\u00e8nent les mauvais chemins (The Ends of Evil Ways), entirely dedicated to describing the conditions in prison. In this third part, he states:\n\nHugo Grotius, the founder of a purely rationalistic system of natural law, argued that law arises from both a social impulse\u2014as Aristotle had indicated\u2014and reason. Immanuel Kant believed a moral imperative requires laws \"be chosen as though they should hold as universal laws of nature\". Jeremy Bentham and his student Austin, following David Hume, believed that this conflated the \"is\" and what \"ought to be\" problem. Bentham and Austin argued for law's positivism; that real law is entirely separate from \"morality\". Kant was also criticised by Friedrich Nietzsche, who rejected the principle of equality, and believed that law emanates from the will to power, and cannot be labeled as \"moral\" or \"immoral\".\n\nIn 1934, the Austrian philosopher Hans Kelsen continued the positivist tradition in his book the Pure Theory of Law. Kelsen believed that although law is separate from morality, it is endowed with \"normativity\", meaning we ought to obey it. While laws are positive \"is\" statements (e.g. the fine for reversing on a highway is \u20ac500); law tells us what we \"should\" do. Thus, each legal system can be hypothesised to have a basic norm (Grundnorm) instructing us to obey. Kelsen's major opponent, Carl Schmitt, rejected both positivism and the idea of the rule of law because he did not accept the primacy of abstract normative principles over concrete political positions and decisions. Therefore, Schmitt advocated a jurisprudence of the exception (state of emergency), which denied that legal norms could encompass all of the political experience.\n\nLater in the 20th century, H. L. A. Hart attacked Austin for his simplifications and Kelsen for his fictions in The Concept of Law. Hart argued law is a system of rules, divided into primary (rules of conduct) and secondary ones (rules addressed to officials to administer primary rules). Secondary rules are further divided into rules of adjudication (to resolve legal disputes), rules of change (allowing laws to be varied) and the rule of recognition (allowing laws to be identified as valid). Two of Hart's students continued the debate: In his book Law's Empire, Ronald Dworkin attacked Hart and the positivists for their refusal to treat law as a moral issue. Dworkin argues that law is an \"interpretive concept\", that requires judges to find the best fitting and most just solution to a legal dispute, given their constitutional traditions. Joseph Raz, on the other hand, defended the positivist outlook and criticised Hart's \"soft social thesis\" approach in The Authority of Law. Raz argues that law is authority, identifiable purely through social sources and without reference to moral reasoning. In his view, any categorisation of rules beyond their role as authoritative instruments in mediation are best left to sociology, rather than jurisprudence.\n\nHistory \n\nThe history of law links closely to the development of civilization. Ancient Egyptian law, dating as far back as 3000\u00a0BC, was based on the concept of Ma'at and characterised by tradition, rhetorical speech, social equality and impartiality. By the 22nd century\u00a0BC, the ancient Sumerian ruler Ur-Nammu had formulated the first law code, which consisted of casuistic statements (\"if \u2026 then ...\"). Around 1760\u00a0BC, King Hammurabi further developed Babylonian law, by codifying and inscribing it in stone. Hammurabi placed several copies of his law code throughout the kingdom of Babylon as stelae, for the entire public to see; this became known as the Codex Hammurabi. The most intact copy of these stelae was discovered in the 19th century by British Assyriologists, and has since been fully transliterated and translated into various languages, including English, Italian, German, and French.\n\nThe Old Testament dates back to 1280\u00a0BC and takes the form of moral imperatives as recommendations for a good society. The small Greek city-state, ancient Athens, from about the 8th century BC was the first society to be based on broad inclusion of its citizenry, excluding women and the slave class. However, Athens had no legal science or single word for \"law\", relying instead on the three-way distinction between divine law (th\u00e9mis), human decree (nomos) and custom (d\u00edk\u0113). Yet Ancient Greek law contained major constitutional innovations in the development of democracy.\n\nRoman law was heavily influenced by Greek philosophy, but its detailed rules were developed by professional jurists and were highly sophisticated. Over the centuries between the rise and decline of the Roman Empire, law was adapted to cope with the changing social situations and underwent major codification under Theodosius II and Justinian I. Although codes were replaced by custom and case law during the Early Middle Ages, Roman law was rediscovered around the 11th century when medieval legal scholars began to research Roman codes and adapt their concepts to the canon law, giving birth to the jus commune. Latin legal maxims (called brocards) were compiled for guidance. In medieval England, royal courts developed a body of precedent which later became the common law. A Europe-wide Law Merchant was formed so that merchants could trade with common standards of practice rather than with the many splintered facets of local laws. The Law Merchant, a precursor to modern commercial law, emphasised the freedom to contract and alienability of property. As nationalism grew in the 18th and 19th centuries, the Law Merchant was incorporated into countries' local law under new civil codes. The Napoleonic and German Codes became the most influential. In contrast to English common law, which consists of enormous tomes of case law, codes in small books are easy to export and easy for judges to apply. However, today there are signs that civil and common law are converging. EU law is codified in treaties, but develops through de facto precedent laid down by the European Court of Justice.\n\nAncient India and China represent distinct traditions of law, and have historically had independent schools of legal theory and practice. The Arthashastra, probably compiled around 100\u00a0AD (although it contains older material), and the Manusmriti (c.\u00a0100\u2013300\u00a0AD) were foundational treatises in India, and comprise texts considered authoritative legal guidance. Manu's central philosophy was tolerance and pluralism, and was cited across Southeast Asia. During the Muslim conquests in the Indian subcontinent, sharia was established by the Muslim sultanates and empires, most notably Mughal Empire's Fatawa-e-Alamgiri, compiled by emperor Aurangzeb and various scholars of Islam. In India, the Hindu legal tradition, along with Islamic law, were both supplanted by common law when India became part of the British Empire. Malaysia, Brunei, Singapore and Hong Kong also adopted the common law system. The eastern Asia legal tradition reflects a unique blend of secular and religious influences. Japan was the first country to begin modernising its legal system along western lines, by importing parts of the French, but mostly the German Civil Code. This partly reflected Germany's status as a rising power in the late 19th century. Similarly, traditional Chinese law gave way to westernisation towards the final years of the Qing Dynasty in the form of six private law codes based mainly on the Japanese model of German law. Today Taiwanese law retains the closest affinity to the codifications from that period, because of the split between Chiang Kai-shek's nationalists, who fled there, and Mao Zedong's communists who won control of the mainland in 1949. The current legal infrastructure in the People's Republic of China was heavily influenced by Soviet Socialist law, which essentially inflates administrative law at the expense of private law rights. Due to rapid industrialisation, today China is undergoing a process of reform, at least in terms of economic, if not social and political, rights. A new contract code in 1999 represented a move away from administrative domination. Furthermore, after negotiations lasting fifteen years, in 2001 China joined the World Trade Organization.\n\nLegal systems \n\nIn general, legal systems can be split between civil law and common law systems. Modern scholars argue that the significance of this distinction has progressively declined; the numerous legal transplants, typical of modern law, result in the sharing by modern legal systems of many features traditionally considered typical of either common law or civil law. The term \"civil law\", referring to the civilian legal system originating in continental Europe, should not be confused with \"civil law\" in the sense of the common law topics distinct from criminal law and public law.\n\nThe third type of legal system\u2014accepted by some countries without separation of church and state\u2014is religious law, based on scriptures. The specific system that a country is ruled by is often determined by its history, connections with other countries, or its adherence to international standards. The sources that jurisdictions adopt as authoritatively binding are the defining features of any legal system. Yet classification is a matter of form rather than substance since similar rules often prevail.\n\nCivil law \n\nCivil law is the legal system used in most countries around the world today. In civil law the sources recognised as authoritative are, primarily, legislation\u2014especially codifications in constitutions or statutes passed by government\u2014and custom. Codifications date back millennia, with one early example being the Babylonian Codex Hammurabi. Modern civil law systems essentially derive from legal codes issued by Byzantine Emperor Justinian I in the 6th century, which were rediscovered by 11th century Italy. Roman law in the days of the Roman Republic and Empire was heavily procedural, and lacked a professional legal class. Instead a lay magistrate, iudex, was chosen to adjudicate. Decisions were not published in any systematic way, so any case law that developed was disguised and almost unrecognised. Each case was to be decided afresh from the laws of the State, which mirrors the (theoretical) unimportance of judges' decisions for future cases in civil law systems today. From 529 to 534 AD the Byzantine Emperor Justinian I codified and consolidated Roman law up until that point, so that what remained was one-twentieth of the mass of legal texts from before. This became known as the Corpus Juris Civilis. As one legal historian wrote, \"Justinian consciously looked back to the golden age of Roman law and aimed to restore it to the peak it had reached three centuries before.\" The Justinian Code remained in force in the East until the fall of the Byzantine Empire. Western Europe, meanwhile, relied on a mix of the Theodosian Code and Germanic customary law until the Justinian Code was rediscovered in the 11th century, and scholars at the University of Bologna used it to interpret their own laws. Civil law codifications based closely on Roman law, alongside some influences from religious laws such as canon law, continued to spread throughout Europe until the Enlightenment; then, in the 19th century, both France, with the Code Civil, and Germany, with the B\u00fcrgerliches Gesetzbuch, modernised their legal codes. Both these codes influenced heavily not only the law systems of the countries in continental Europe (e.g. Greece), but also the Japanese and Korean legal traditions. Today, countries that have civil law systems range from Russia] and Turkey to most of Central and Latin America.\n\nAnarchist law \n\nAnarchism has been practiced in society in much of the world. Mass anarchist communities, ranging from Syria to the United States, exist and vary from hundreds to millions. Anarchism encompasses a broad range of social political philosophies with different tendencies and implementation.\n\nAnarchist law primarily deals with how anarchism is implemented upon a society, the framework based on decentralized organizations and mutual aid, with representation through a form of direct democracy. Laws being based upon their need. A large portion of anarchist ideologies such as anarcho-syndicalism and anarcho-communism primarily focuses on decentralized worker unions, cooperatives and syndicates as the main instrument of society.\n\nSocialist law \n\nSocialist law is the legal systems in communist states such as the former Soviet Union and the People's Republic of China. Academic opinion is divided on whether it is a separate system from civil law, given major deviations based on Marxist\u2013Leninist ideology, such as subordinating the judiciary to the executive ruling party.\n\nCommon law and equity \n\nIn common law legal systems, decisions by courts are explicitly acknowledged as \"law\" on equal footing with statutes adopted through the legislative process and with regulations issued by the executive branch. The \"doctrine of precedent\", or stare decisis (Latin for \"to stand by decisions\") means that decisions by higher courts bind lower courts, and future decisions of the same court, to assure that similar cases reach similar results. In contrast, in \"civil law\" systems, legislative statutes are typically more detailed, and judicial decisions are shorter and less detailed, because the judge or barrister is only writing to decide the single case, rather than to set out reasoning that will guide future courts.\n\nCommon law originated from England and has been inherited by almost every country once tied to the British Empire (except Malta, Scotland, the U.S. state of Louisiana, and the Canadian province of Quebec). In medieval England, the Norman conquest the law varied-shire-to-shire, based on disparate tribal customs. The concept of a \"common law\" developed during the reign of Henry II during the late 12th century, when Henry appointed judges that had authority to create an institutionalised and unified system of law \"common\" to the country. The next major step in the evolution of the common law came when King John was forced by his barons to sign a document limiting his authority to pass laws. This \"great charter\" or Magna Carta of 1215 also required that the King's entourage of judges hold their courts and judgments at \"a certain place\" rather than dispensing autocratic justice in unpredictable places about the country. A concentrated and elite group of judges acquired a dominant role in law-making under this system, and compared to its European counterparts the English judiciary became highly centralised. In 1297, for instance, while the highest court in France had fifty-one judges, the English Court of Common Pleas had five. This powerful and tight-knit judiciary gave rise to a systematised process of developing common law.\n\nHowever, the system became overly systematised\u2014overly rigid and inflexible. As a result, as time went on, increasing numbers of citizens petitioned the King to override the common law, and on the King's behalf the Lord Chancellor gave judgment to do what was equitable in a case. From the time of Sir Thomas More, the first lawyer to be appointed as Lord Chancellor, a systematic body of equity grew up alongside the rigid common law, and developed its own Court of Chancery. At first, equity was often criticised as erratic, that it varied according to the length of the Chancellor's foot. Over time, courts of equity developed solid principles, especially under Lord Eldon. In the 19th century in England, and in 1937 in the U.S., the two systems were merged.\n\nIn developing the common law, academic writings have always played an important part, both to collect overarching principles from dispersed case law, and to argue for change. William Blackstone, from around 1760, was the first scholar to collect, describe, and teach the common law. But merely in describing, scholars who sought explanations and underlying structures slowly changed the way the law actually worked.\n\nReligious law \n\nReligious law is explicitly based on religious precepts. Examples include the Jewish Halakha and Islamic Sharia\u2014both of which translate as the \"path to follow\"\u2014while Christian canon law also survives in some church communities. Often the implication of religion for law is unalterability, because the word of God cannot be amended or legislated against by judges or governments. However, a thorough and detailed legal system generally requires human elaboration. For instance, the Quran has some law, and it acts as a source of further law through interpretation, Qiyas (reasoning by analogy), Ijma (consensus) and precedent. This is mainly contained in a body of law and jurisprudence known as Sharia and Fiqh respectively. Another example is the Torah or Old Testament, in the Pentateuch or Five Books of Moses. This contains the basic code of Jewish law, which some Israeli communities choose to use. The Halakha is a code of Jewish law that summarizes some of the Talmud's interpretations. Nevertheless, Israeli law allows litigants to use religious laws only if they choose. Canon law is only in use by members of the Catholic Church, the Eastern Orthodox Church and the Anglican Communion.\n\nCanon law \n\nCanon law (from Greek kanon, a 'straight measuring rod, ruler') is a set of ordinances and regulations made by ecclesiastical authority (Church leadership), for the government of a Christian organisation or church and its members. It is the internal ecclesiastical law governing the Catholic Church (both the Latin Church and the Eastern Catholic Churches), the Eastern Orthodox and Oriental Orthodox churches, and the individual national churches within the Anglican Communion. The way that such church law is legislated, interpreted and at times adjudicated varies widely among these three bodies of churches. In all three traditions, a canon was originally a rule adopted by a church council; these canons formed the foundation of canon law.\n\nThe Catholic Church has the oldest continuously functioning legal system in the western world, predating the evolution of modern European civil law and common law systems. The 1983 Code of Canon Law governs the Latin Church sui juris. The Eastern Catholic Churches, which developed different disciplines and practices, are governed by the Code of Canons of the Eastern Churches. The canon law of the Catholic Church influenced the common law during the medieval period through its preservation of Roman law doctrine such as the presumption of innocence.\n\nSharia law \n\nUntil the 18th century, Sharia law was practiced throughout the Muslim world in a non-codified form, with the Ottoman Empire's Mecelle code in the 19th century being a first attempt at codifying elements of Sharia law. Since the mid-1940s, efforts have been made, in country after country, to bring Sharia law more into line with modern conditions and conceptions. In modern times, the legal systems of many Muslim countries draw upon both civil and common law traditions as well as Islamic law and custom. The constitutions of certain Muslim states, such as Egypt and Afghanistan, recognise Islam as the religion of the state, obliging legislature to adhere to Sharia. Saudi Arabia recognises Quran as its constitution, and is governed on the basis of Islamic law. Iran has also witnessed a reiteration of Islamic law into its legal system after 1979. During the last few decades, one of the fundamental features of the movement of Islamic resurgence has been the call to restore the Sharia, which has generated a vast amount of literature and affected world politics.\n\nLegal methods \nThere are distinguished methods of legal reasoning (applying the law) and methods of interpreting (construing) the law. The former are legal syllogism, which holds sway in civil law legal systems, analogy, which is present in common law legal systems, especially in the US, and argumentative theories that occur in both systems. The latter are different rules (directives) of legal interpretation such as directives of linguistic interpretation, teleological interpretation or systemic interpretation as well as more specific rules, for instance, golden rule or mischief rule. There are also many other arguments and cannons of interpretation which altogether make statutory interpretation possible.\n\nLaw professor and former United States Attorney General Edward H. Levi noted that the \"basic pattern of legal reasoning is reasoning by example\" - that is, reasoning by comparing outcomes in cases resolving similar legal questions. In a U.S. Supreme Court case regarding procedural efforts taken by a debt collection company to avoid errors, Justice Sotomayor cautioned that \"legal reasoning is not a mechanical or strictly linear process\".\n\nJurimetrics is the formal application of quantitative methods, especially probability and statistics, to legal questions. The use of statistical methods in court cases and law review articles has grown massively in importance in the last few decades.\n\nLegal institutions \n\nThe main institutions of law in industrialised countries are independent courts, representative parliaments, an accountable executive, the military and police, bureaucratic organisation, the legal profession and civil society itself. John Locke, in his Two Treatises of Government, and Baron de Montesquieu in The Spirit of the Laws, advocated for a separation of powers between the political, legislature and executive bodies. Their principle was that no person should be able to usurp all powers of the state, in contrast to the absolutist theory of Thomas Hobbes' Leviathan. Sun Yat-sen's Five Power Constitution for the Republic of China took the separation of powers further by having two additional branches of government - a Control Yuan for auditing oversight and an Examination Yuan to manage the employment of public officials.\n\nMax Weber and others reshaped thinking on the extension of state. Modern military, policing and bureaucratic power over ordinary citizens' daily lives pose special problems for accountability that earlier writers such as Locke or Montesquieu could not have foreseen. The custom and practice of the legal profession is an important part of people's access to justice, whilst civil society is a term used to refer to the social institutions, communities and partnerships that form law's political basis.\n\nJudiciary \n\nA judiciary is a number of judges mediating disputes to determine outcome. Most countries have systems of appeal courts, with an apex court as the ultimate judicial authority. In the United States, this authority is the Supreme Court; in Australia, the High Court; in the UK, the Supreme Court; in Germany, the Bundesverfassungsgericht; and in France, the Cour de Cassation. For most European countries the European Court of Justice in Luxembourg can overrule national law, when EU law is relevant. The European Court of Human Rights in Strasbourg allows citizens of the Council of Europe member states to bring cases relating to human rights issues before it.\n\nSome countries allow their highest judicial authority to overrule legislation they determine to be unconstitutional. For example, in Brown v. Board of Education, the United States Supreme Court nullified many state statutes that had established racially segregated schools, finding such statutes to be incompatible with the Fourteenth Amendment to the United States Constitution.\n\nA judiciary is theoretically bound by the constitution, just as all other government bodies are. In most countries judges may only interpret the constitution and all other laws. But in common law countries, where matters are not constitutional, the judiciary may also create law under the doctrine of precedent. The UK, Finland and New Zealand assert the ideal of parliamentary sovereignty, whereby the unelected judiciary may not overturn law passed by a democratic legislature.\n\nIn communist states, such as China, the courts are often regarded as parts of the executive, or subservient to the legislature; governmental institutions and actors exert thus various forms of influence on the judiciary. In Muslim countries, courts often examine whether state laws adhere to the Sharia: the Supreme Constitutional Court of Egypt may invalidate such laws, and in Iran the Guardian Council ensures the compatibility of the legislation with the \"criteria of Islam\".\n\nLegislature \n\nProminent examples of legislatures are the Houses of Parliament in London, the Congress in Washington D.C., the Bundestag in Berlin, the Duma in Moscow, the Parlamento Italiano in Rome and the Assembl\u00e9e nationale in Paris. By the principle of representative government people vote for politicians to carry out their wishes. Although countries like Israel, Greece, Sweden and China are unicameral, most countries are bicameral, meaning they have two separately appointed legislative houses.\n\nIn the 'lower house' politicians are elected to represent smaller constituencies. The 'upper house' is usually elected to represent states in a federal system (as in Australia, Germany or the United States) or different voting configuration in a unitary system (as in France). In the UK the upper house is appointed by the government as a house of review. One criticism of bicameral systems with two elected chambers is that the upper and lower houses may simply mirror one another. The traditional justification of bicameralism is that an upper chamber acts as a house of review. This can minimise arbitrariness and injustice in governmental action.\n\nTo pass legislation, a majority of the members of a legislature must vote for a bill (proposed law) in each house. Normally there will be several readings and amendments proposed by the different political factions. If a country has an entrenched constitution, a special majority for changes to the constitution may be required, making changes to the law more difficult. A government usually leads the process, which can be formed from Members of Parliament (e.g. the UK or Germany). However, in a presidential system, the government is usually formed by an executive and his or her appointed cabinet officials (e.g. the United States or Brazil).\n\nExecutive \n\nThe executive in a legal system serves as the centre of political authority of the State. In a parliamentary system, as with Britain, Italy, Germany, India, and Japan, the executive is known as the cabinet, and composed of members of the legislature. The executive is led by the head of government, whose office holds power under the confidence of the legislature. Because popular elections appoint political parties to govern, the leader of a party can change in between elections.\n\nThe head of state is apart from the executive, and symbolically enacts laws and acts as representative of the nation. Examples include the President of Germany (appointed by members of federal and state legislatures), the Queen of the United Kingdom (an hereditary office), and the President of Austria (elected by popular vote). The other important model is the presidential system, found in the United States and in Brazil. In presidential systems, the executive acts as both head of state and head of government, and has power to appoint an unelected cabinet. Under a presidential system, the executive branch is separate from the legislature to which it is not accountable.\n\nAlthough the role of the executive varies from country to country, usually it will propose the majority of legislation, and propose government agenda. In presidential systems, the executive often has the power to veto legislation. Most executives in both systems are responsible for foreign relations, the military and police, and the bureaucracy. Ministers or other officials head a country's public offices, such as a foreign ministry or defence ministry. The election of a different executive is therefore capable of revolutionising an entire country's approach to government.\n\nMilitary and police \n\nWhile military organisations have existed as long as government itself, the idea of a standing police force is a relatively modern concept. For example, Medieval England's system of travelling criminal courts, or assizes, used show trials and public executions to instill communities with fear to maintain control. The first modern police were probably those in 17th-century Paris, in the court of Louis XIV, although the Paris Prefecture of Police claim they were the world's first uniformed policemen.\n\nMax Weber famously argued that the state is that which controls the monopoly on the legitimate use of force. The military and police carry out enforcement at the request of the government or the courts. The term failed state refers to states that cannot implement or enforce policies; their police and military no longer control security and order and society moves into anarchy, the absence of government.\n\nBureaucracy \n\nThe etymology of bureaucracy derives from the French word for office (bureau) and the Ancient Greek for word power (kratos). Like the military and police, a legal system's government servants and bodies that make up its bureaucracy carry out the directives of the executive. One of the earliest references to the concept was made by Baron de Grimm, a German author who lived in France. In 1765, he wrote:\nThe real spirit of the laws in France is that bureaucracy of which the late Monsieur de Gournay used to complain so greatly; here the offices, clerks, secretaries, inspectors and intendants are not appointed to benefit the public interest, indeed the public interest appears to have been established so that offices might exist.\n\nCynicism over \"officialdom\" is still common, and the workings of public servants is typically contrasted to private enterprise motivated by profit. In fact private companies, especially large ones, also have bureaucracies. Negative perceptions of \"red tape\" aside, public services such as schooling, health care, policing or public transport are considered a crucial state function making public bureaucratic action the locus of government power.\n\nWriting in the early 20th century, Max Weber believed that a definitive feature of a developed state had come to be its bureaucratic support. Weber wrote that the typical characteristics of modern bureaucracy are that officials define its mission, the scope of work is bound by rules, and management is composed of career experts who manage top down, communicating through writing and binding public servants' discretion with rules.\n\nLegal profession \n\nA corollary of the rule of law is the existence of a legal profession sufficiently autonomous to invoke the authority of the independent judiciary; the right to assistance of a barrister in a court proceeding emanates from this corollary\u2014in England the function of barrister or advocate is distinguished from legal counselor. As the European Court of Human Rights has stated, the law should be adequately accessible to everyone and people should be able to foresee how the law affects them.\n\nIn order to maintain professionalism, the practice of law is typically overseen by either a government or independent regulating body such as a bar association, bar council or law society. Modern lawyers achieve distinct professional identity through specified legal procedures (e.g. successfully passing a qualifying examination), are required by law to have a special qualification (a legal education earning the student a Bachelor of Laws, a Bachelor of Civil Law, or a Juris Doctor degree. Higher academic degrees may also be pursued. Examples include a Master of Laws, a Master of Legal Studies, a Bar Professional Training Course or a Doctor of Laws.), and are constituted in office by legal forms of appointment (being admitted to the bar). There are few titles of respect to signify famous lawyers, such as Esquire, to indicate barristers of greater dignity, and Doctor of law, to indicate a person who obtained a PhD in Law.\n\nMany Muslim countries have developed similar rules about legal education and the legal profession, but some still allow lawyers with training in traditional Islamic law to practice law before personal status law courts. In China and other developing countries there are not sufficient professionally trained people to staff the existing judicial systems, and, accordingly, formal standards are more relaxed.\n\nOnce accredited, a lawyer will often work in a law firm, in a chambers as a sole practitioner, in a government post or in a private corporation as an internal counsel. In addition a lawyer may become a legal researcher who provides on-demand legal research through a library, a commercial service or freelance work. Many people trained in law put their skills to use outside the legal field entirely.\n\nSignificant to the practice of law in the common law tradition is the legal research to determine the current state of the law. This usually entails exploring case-law reports, legal periodicals and legislation. Law practice also involves drafting documents such as court pleadings, persuasive briefs, contracts, or wills and trusts. Negotiation and dispute resolution skills (including ADR techniques) are also important to legal practice, depending on the field.\n\nCivil society \n\nThe Classical republican concept of \"civil society\" dates back to Hobbes and Locke. Locke saw civil society as people who have \"a common established law and judicature to appeal to, with authority to decide controversies between them.\" German philosopher Georg Wilhelm Friedrich Hegel distinguished the \"state\" from \"civil society\" (b\u00fcrgerliche Gesellschaft) in Elements of the Philosophy of Right.\n\nHegel believed that civil society and the state were polar opposites, within the scheme of his dialectic theory of history. The modern dipole state\u2013civil society was reproduced in the theories of Alexis de Tocqueville and Karl Marx. In post-modern theory, civil society is necessarily a source of law, by being the basis from which people form opinions and lobby for what they believe law should be. As Australian barrister and author Geoffrey Robertson QC wrote of international law, \"one of its primary modern sources is found in the responses of ordinary men and women, and of the non-governmental organizations which many of them support, to the human rights abuses they see on the television screen in their living rooms.\"\n\nFreedom of speech, freedom of association and many other individual rights allow people to gather, discuss, criticise and hold to account their governments, from which the basis of a deliberative democracy is formed. The more people are involved with, concerned by and capable of changing how political power is exercised over their lives, the more acceptable and legitimate the law becomes to the people. The most familiar institutions of civil society include economic markets, profit-oriented firms, families, trade unions, hospitals, universities, schools, charities, debating clubs, non-governmental organisations, neighbourhoods, churches, and religious associations.  There is no clear legal definition of the civil society, and of the institutions it includes. Most of the institutions and bodies who try to give a list of institutions (such as the European Economic and Social Committee) exclude the political parties.\n\nAreas of law \nAll legal systems deal with the same basic issues, but jurisdictions categorise and identify their legal topics in different ways. A common distinction is that between \"public law\" (a term related closely to the state, and including constitutional, administrative and criminal law), and \"private law\" (which covers contract, tort and property). In civil law systems, contract and tort fall under a general law of obligations, while trusts law is dealt with under statutory regimes or international conventions. International, constitutional and administrative law, criminal law, contract, tort, property law and trusts are regarded as the \"traditional core subjects\", although there are many further disciplines.\n\nInternational law \n\nInternational law can refer to three things: public international law, private international law or conflict of laws and the law of supranational organisations.\n Public international law concerns relationships between sovereign nations. The sources for public international law development are custom, practice and treaties between sovereign nations, such as the Geneva Conventions. Public international law can be formed by international organisations, such as the United Nations (which was established after the failure of the League of Nations to prevent World War II), the International Labour Organisation, the World Trade Organisation, or the International Monetary Fund. Public international law has a special status as law because there is no international police force, and courts (e.g. the International Court of Justice as the primary UN judicial organ) lack the capacity to penalise disobedience.  The prevailing manner of enforcing international law is still essentially \"self help\"; that is the reaction by states to alleged breaches of international obligations by other states. However, a few bodies, such as the WTO, have effective systems of binding arbitration and dispute resolution backed up by trade sanctions.\n Conflict of laws, or private international law in civil law countries, concerns which jurisdiction a legal dispute between private parties should be heard in and which jurisdiction's law should be applied. Today, businesses are increasingly capable of shifting capital and labour supply chains across borders, as well as trading with overseas businesses, making the question of which country has jurisdiction even more pressing. Increasing numbers of businesses opt for commercial arbitration under the New York Convention 1958.\n European Union law is the first and so far the only example of a supranational law, i.e. an internationally accepted legal system, other than the United Nations and the World Trade Organization. Given the trend of increasing global economic integration, many regional agreements\u2014especially the African Union\u2014seek to follow a similar model. In the EU, sovereign nations have gathered their authority in a system of courts and the European Parliament. These institutions are allowed the ability to enforce legal norms both against or for member states and citizens in a manner which is not possible through public international law. As the European Court of Justice noted in its 1963 Van Gend en Loos decision, European Union law constitutes \"a new legal order of international law\" for the mutual social and economic benefit of the member states.\n\nConstitutional and administrative law \n\nConstitutional and administrative law govern the affairs of the state. Constitutional law concerns both the relationships between the executive, legislature and judiciary and the human rights or civil liberties of individuals against the state. Most jurisdictions, like the United States and France, have a single codified constitution with a bill of rights. A few, like the United Kingdom, have no such document. A \"constitution\" is simply those laws which constitute the body politic, from statute, case law and convention. A case named Entick v Carrington illustrates a constitutional principle deriving from the common law. Entick's house was searched and ransacked by Sheriff Carrington. When Entick complained in court, Sheriff Carrington argued that a warrant from a Government minister, the Earl of Halifax, was valid authority. However, there was no written statutory provision or court authority. The leading judge, Lord Camden, stated:\nThe great end, for which men entered into society, was to secure their property. That right is preserved sacred and incommunicable in all instances, where it has not been taken away or abridged by some public law for the good of the whole ... If no excuse can be found or produced, the silence of the books is an authority against the defendant, and the plaintiff must have judgment.\n\nThe fundamental constitutional principle, inspired by John Locke, holds that the individual can do anything except that which is forbidden by law, and the state may do nothing except that which is authorised by law. Administrative law is the chief method for people to hold state bodies to account. People can sue an agency, local council, public service, or government ministry for judicial review of actions or decisions, to ensure that they comply with the law, and that the government entity observed required procedure. The first specialist administrative court was the Conseil d'\u00c9tat set up in 1799, as Napoleon assumed power in France.\n\nCriminal law \n\nCriminal law, also known as penal law, pertains to crimes and punishment. It thus regulates the definition of and penalties for offences found to have a sufficiently deleterious social impact but, in itself, makes no moral judgment on an offender nor imposes restrictions on society that physically prevent people from committing a crime in the first place. Investigating, apprehending, charging, and trying suspected offenders is regulated by the law of criminal procedure. The paradigm case of a crime lies in the proof, beyond reasonable doubt, that a person is guilty of two things. First, the accused must commit an act which is deemed by society to be criminal, or actus reus (guilty act). Second, the accused must have the requisite malicious intent to do a criminal act, or mens rea (guilty mind). However, for so called \"strict liability\" crimes, an actus reus is enough. Criminal systems of the civil law tradition distinguish between intention in the broad sense (dolus directus and dolus eventualis), and negligence. Negligence does not carry criminal responsibility unless a particular crime provides for its punishment.\n\nExamples of crimes include murder, assault, fraud and theft. In exceptional circumstances defences can apply to specific acts, such as killing in self defence, or pleading insanity. Another example is in the 19th-century English case of R v Dudley and Stephens, which tested a defence of \"necessity\". The Mignonette, sailing from Southampton to Sydney, sank. Three crew members and Richard Parker, a 17-year-old cabin boy, were stranded on a raft. They were starving and the cabin boy was close to death. Driven to extreme hunger, the crew killed and ate the cabin boy. The crew survived and were rescued, but put on trial for murder. They argued it was necessary to kill the cabin boy to preserve their own lives. Lord Coleridge, expressing immense disapproval, ruled, \"to preserve one's life is generally speaking a duty, but it may be the plainest and the highest duty to sacrifice it.\" The men were sentenced to hang, but public opinion was overwhelmingly supportive of the crew's right to preserve their own lives. In the end, the Crown commuted their sentences to six months in jail.\n\nCriminal law offences are viewed as offences against not just individual victims, but the community as well. The state, usually with the help of police, takes the lead in prosecution, which is why in common law countries cases are cited as \"The People v ...\" or \"R (for Rex or Regina) v ...\". Also, lay juries are often used to determine the guilt of defendants on points of fact: juries cannot change legal rules. Some developed countries still condone capital punishment for criminal activity, but the normal punishment for a crime will be imprisonment, fines, state supervision (such as probation), or community service. Modern criminal law has been affected considerably by the social sciences, especially with respect to sentencing, legal research, legislation, and rehabilitation. On the international field, 111 countries are members of the International Criminal Court, which was established to try people for crimes against humanity.\n\nContract law \n\nContract law concerns enforceable promises, and can be summed up in the Latin phrase pacta sunt servanda (agreements must be kept). In common law jurisdictions, three key elements to the creation of a contract are necessary: offer and acceptance, consideration and the intention to create legal relations. In Carlill v Carbolic Smoke Ball Company a medical firm advertised that its new wonder drug, the smokeball, would cure people's flu, and if it did not, the buyers would get \u00a3100. Many people sued for their \u00a3100 when the drug did not work. Fearing bankruptcy, Carbolic argued the advert was not to be taken as a serious, legally binding offer. It was an invitation to treat, mere puffery, a gimmick. But the Court of Appeal held that to a reasonable man Carbolic had made a serious offer, accentuated by their reassuring statement, \"\u00a31000 is deposited\". Equally, people had given good consideration for the offer by going to the \"distinct inconvenience\" of using a faulty product. \"Read the advertisement how you will, and twist it about as you will\", said Lord Justice Lindley, \"here is a distinct promise expressed in language which is perfectly unmistakable\".\n\nConsideration indicates the fact that all parties to a contract have exchanged something of value. Some common law systems, including Australia, are moving away from the idea of consideration as a requirement. The idea of estoppel or culpa in contrahendo, can be used to create obligations during pre-contractual negotiations.\n\nCivil law jurisdictions treat contracts differently in a number of respects, with a more interventionist role for the state in both the formation and enforcement of contracts. Compared to common law jurisdictions, civil law systems incorporate more mandatory terms into contracts, allow greater latitude for courts to interpret and revise contract terms and impose a stronger duty of good faith, but are also more likely to enforce penalty clauses and specific performance of contracts. They also do not require consideration for a contract to be binding. In France, an ordinary contract is said to form simply on the basis of a \"meeting of the minds\" or a \"concurrence of wills\". Germany has a special approach to contracts, which ties into property law. Their 'abstraction principle' (Abstraktionsprinzip) means that the personal obligation of contract forms separately from the title of property being conferred. When contracts are invalidated for some reason (e.g. a car buyer is so drunk that he lacks legal capacity to contract) the contractual obligation to pay can be invalidated separately from the proprietary title of the car. Unjust enrichment law, rather than contract law, is then used to restore title to the rightful owner.\n\nTorts and delicts \n\nCertain civil wrongs are grouped together as torts under common law systems and delicts under civil law systems. To have acted tortiously, one must have breached a duty to another person, or infringed some pre-existing legal right. A simple example might be accidentally hitting someone with a cricket ball. Under the law of negligence, the most common form of tort, the injured party could potentially claim compensation for their injuries from the party responsible. The principles of negligence are illustrated by Donoghue v Stevenson. A friend of Donoghue ordered an opaque bottle of ginger beer (intended for the consumption of Donoghue) in a caf\u00e9 in Paisley. Having consumed half of it, Donoghue poured the remainder into a tumbler. The decomposing remains of a snail floated out. She claimed to have suffered from shock, fell ill with gastroenteritis and sued the manufacturer for carelessly allowing the drink to be contaminated. The House of Lords decided that the manufacturer was liable for Mrs Donoghue's illness. Lord Atkin took a distinctly moral approach and said:\nThe liability for negligence [...] is no doubt based upon a general public sentiment of moral wrongdoing for which the offender must pay. [...] The rule that you are to love your neighbour becomes in law, you must not injure your neighbour; and the lawyer's question, Who is my neighbour? receives a restricted reply. You must take reasonable care to avoid acts or omissions which you can reasonably foresee would be likely to injure your neighbour.\n\nThis became the basis for the four principles of negligence, namely that (1) Stevenson owed Donoghue a duty of care to provide safe drinks; (2) he breached his duty of care; (3) the harm would not have occurred but for his breach; and (4) his act was the proximate cause of her harm. Another example of tort might be a neighbour making excessively loud noises with machinery on his property. Under a nuisance claim the noise could be stopped. Torts can also involve intentional acts such as assault, battery or trespass. A better known tort is defamation, which occurs, for example, when a newspaper makes unsupportable allegations that damage a politician's reputation. More infamous are economic torts, which form the basis of labour law in some countries by making trade unions liable for strikes, when statute does not provide immunity.\n\nProperty law \n\nProperty law governs ownership and possession. Real property, sometimes called 'real estate', refers to ownership of land and things attached to it. Personal property, refers to everything else; movable objects, such as computers, cars, jewelry or intangible rights, such as stocks and shares. A right in rem is a right to a specific piece of property, contrasting to a right in personam which allows compensation for a loss, but not a particular thing back. Land law forms the basis for most kinds of property law, and is the most complex. It concerns mortgages, rental agreements, licences, covenants, easements and the statutory systems for land registration. Regulations on the use of personal property fall under intellectual property, company law, trusts and commercial law. An example of a basic case of most property law is Armory v Delamirie [1722]. A chimney sweep's boy found a jewel encrusted with precious stones. He took it to a goldsmith to have it valued. The goldsmith's apprentice looked at it, sneakily removed the stones, told the boy it was worth three halfpence and that he would buy it. The boy said he would prefer the jewel back, so the apprentice gave it to him, but without the stones. The boy sued the goldsmith for his apprentice's attempt to cheat him. Lord Chief Justice Pratt ruled that even though the boy could not be said to own the jewel, he should be considered the rightful keeper (\"finders keepers\") until the original owner is found. In fact the apprentice and the boy both had a right of possession in the jewel (a technical concept, meaning evidence that something could belong to someone), but the boy's possessory interest was considered better, because it could be shown to be first in time. Possession may be nine-tenths of the law, but not all.\n\nThis case is used to support the view of property in common law jurisdictions, that the person who can show the best claim to a piece of property, against any contesting party, is the owner. By contrast, the classic civil law approach to property, propounded by Friedrich Carl von Savigny, is that it is a right good against the world. Obligations, like contracts and torts, are conceptualised as rights good between individuals. The idea of property raises many further philosophical and political issues. Locke argued that our \"lives, liberties and estates\" are our property because we own our bodies and mix our labour with our surroundings.\n\nEquity and trusts \n\nEquity is a body of rules that developed in England separately from the \"common law\". The common law was administered by judges and barristers. The Lord Chancellor on the other hand, as the King's keeper of conscience, could overrule the judge-made law if he thought it equitable to do so. This meant equity came to operate more through principles than rigid rules. Whereas neither the common law nor civil law systems allow people to split the ownership from the control of one piece of property, equity allows this through an arrangement known as a trust. Trustees control property whereas the beneficial, or equitable, ownership of trust property is held by people known as beneficiaries. Trustees owe duties to their beneficiaries to take good care of the entrusted property. In the early case of Keech v Sandford [1722], a child had inherited the lease on a market in Romford, London. Mr Sandford was entrusted to look after this property until the child matured. But before then, the lease expired. The landlord had (apparently) told Mr Sandford that he did not want the child to have the renewed lease. Yet the landlord was happy (apparently) to give Mr Sandford the opportunity of the lease instead. Mr Sandford took it. When the child (now Mr Keech) grew up, he sued Mr Sandford for the profit that he had been making by getting the market's lease. Mr Sandford was meant to be trusted, but he put himself in a position of conflict of interest. The Lord Chancellor, Lord King, agreed and ordered Mr Sandford should disgorge his profits. He wrote: \"I very well see, if a trustee, on the refusal to renew, might have a lease to himself few trust-estates would be renewed. [...] This may seem very hard, that the trustee is the only person of all mankind who might not have the lease; but it is very proper that the rule should be strictly pursued and not at all relaxed.\"\n\nLord King LC was worried that trustees might exploit opportunities to use trust property for themselves instead of looking after it. Business speculators using trusts had just recently caused a stock market crash. Strict duties for trustees made their way into company law and were applied to directors and chief executive officers. Another example of a trustee's duty might be to invest property wisely or sell it. This is especially the case for pension funds, the most important form of trust, where investors are trustees for people's savings until retirement. But trusts can also be set up for charitable purposes, famous examples being the British Museum or the Rockefeller Foundation.\n\nFurther disciplines \nLaw spreads far beyond the core subjects into virtually every area of life. Three categories are presented for convenience, although the subjects intertwine and overlap.\n\n Law and society\n\n Labour law is the study of a tripartite industrial relationship between worker, employer and trade union. This involves collective bargaining regulation, and the right to strike. Individual employment law refers to workplace rights, such as job security, health and safety or a minimum wage.\n Human rights, civil rights and human rights law are important fields to guarantee everyone basic freedoms and entitlements. These are laid down in codes such as the Universal Declaration of Human Rights, the European Convention on Human Rights (which founded the European Court of Human Rights) and the U.S. Bill of Rights. The Treaty of Lisbon makes the Charter of Fundamental Rights of the European Union legally binding in all member states except Poland and the United Kingdom.\n Civil procedure and criminal procedure concern the rules that courts must follow as a trial and appeals proceed. Both concern a citizen's right to a fair trial or hearing.\n Evidence law involves which materials are admissible in courts for a case to be built.\n Immigration law and nationality law concern the rights of foreigners to live and work in a nation-state that is not their own and to acquire or lose citizenship. Both also involve the right of asylum and the problem of stateless individuals.\n Social security law refers to the rights people have to social insurance, such as jobseekers' allowances or housing benefits.\n Family law covers marriage and divorce proceedings, the rights of children and rights to property and money in the event of separation.\n Transactional law is the practice of law concerning business and money.\n\n Law and commerce\n Company law sprang from the law of trusts, on the principle of separating ownership of property and control. The law of the modern company began with the Joint Stock Companies Act 1856, passed in the United Kingdom, which provided investors with a simple registration procedure to gain limited liability under the separate legal personality of the corporation.\n Commercial law covers complex contract and property law. The law of agency, insurance law, bills of exchange, insolvency and bankruptcy law and sales law are all important, and trace back to the medieval Lex Mercatoria. The UK Sale of Goods Act 1979 and the US Uniform Commercial Code are examples of codified common law commercial principles.\n Admiralty law and the sea law lay a basic framework for free trade and commerce across the world's oceans and seas, where outside of a country's zone of control. Shipping companies operate through ordinary principles of commercial law, generalised for a global market. Admiralty law also encompasses specialised issues such as salvage, maritime liens, and injuries to passengers.\n Intellectual property law aims at safeguarding creators and other producers of intellectual goods and services. These are legal rights (copyrights, trademarks, patents, and related rights) which result from intellectual activity in the industrial, literary and artistic fields.\n Restitution deals with the recovery of someone else's gain, rather than compensation for one's own loss.\n Unjust enrichment When someone has been unjustly enriched (or there is an \"absence of basis\" for a transaction) at another's expense, this event generates the right to restitution to reverse that gain.\n Space law is a relatively new field dealing with aspects of international law regarding human activities in Earth orbit and outer space.  While at first addressing space relations of countries via treaties, increasingly it is addressing areas such as space commercialisation, property, liability, and other issues.\n\n Law and regulation\n\n Tax law involves regulations that concern value added tax, corporate tax, and income tax.\n Banking law and financial regulation set minimum standards on the amounts of capital banks must hold, and rules about best practice for investment. This is to insure against the risk of economic crises, such as the Wall Street Crash of 1929.\n Regulation deals with the provision of public services and utilities. Water law is one example. Especially since privatisation became popular and took management of services away from public law, private companies doing the jobs previously controlled by government have been bound by varying degrees of social responsibility. Energy, gas, telecomms and water are regulated industries in most OECD countries.\n Competition law, known in the United States as antitrust law, is an evolving field that traces as far back as Roman decrees against price fixing and the English restraint of trade doctrine. Modern competition law derives from the U.S. anti-cartel and anti-monopoly statutes (the Sherman Act and Clayton Act) of the turn of the 20th century. It is used to control businesses who attempt to use their economic influence to distort market prices at the expense of consumer welfare.\n Consumer law could include anything from regulations on unfair contractual terms and clauses to directives on airline baggage insurance.\n Environmental law is increasingly important, especially in light of the Kyoto Protocol and the potential danger of climate change. Environmental protection also serves to penalise polluters within domestic legal systems.\n Aviation law deals with all regulations and technical standards applicable to the safe operation of aircraft, and is an essential part both of pilots' training and pilot's operations. Non adherence to Air Law regulations and standards renders a flight operation illegal. It is framed by national civil aviation acts (or laws), themselves mostly aligned with the recommendations or mandatory standards of the International Civil Aviation Organisation or ICAO.  Regulations are often abbreviated as CARS and standards as CATS. They constantly evolve in order to adapt to new technologies or science (for example in medical protocols which pilots have to adhere to in order to be fit to fly or hold a license).\n\nIntersection with other fields\n\nEconomics \n\nIn the 18th century, Adam Smith presented a philosophical foundation for explaining the relationship between law and economics. The discipline arose partly out of a critique of trade unions and U.S. antitrust law. The most influential proponents, such as Richard Posner and Oliver Williamson and the so-called Chicago School of economists and lawyers including Milton Friedman and Gary Becker, are generally advocates of deregulation and privatisation, and are hostile to state regulation or what they see as restrictions on the operation of free markets.\n\nThe most prominent economic analyst of law is 1991 Nobel Prize winner Ronald Coase, whose first major article, The Nature of the Firm (1937), argued that the reason for the existence of firms (companies, partnerships, etc.) is the existence of transaction costs. Rational individuals trade through bilateral contracts on open markets until the costs of transactions mean that using corporations to produce things is more cost-effective. His second major article, The Problem of Social Cost (1960), argued that if we lived in a world without transaction costs, people would bargain with one another to create the same allocation of resources, regardless of the way a court might rule in property disputes. Coase used the example of a nuisance case named Sturges v Bridgman, where a noisy sweetmaker and a quiet doctor were neighbours and went to court to see who should have to move. Coase said that regardless of whether the judge ruled that the sweetmaker had to stop using his machinery, or that the doctor had to put up with it, they could strike a mutually beneficial bargain about who moves that reaches the same outcome of resource distribution. Only the existence of transaction costs may prevent this. So the law ought to pre-empt what would happen, and be guided by the most efficient solution. The idea is that law and regulation are not as important or effective at helping people as lawyers and government planners believe. Coase and others like him wanted a change of approach, to put the burden of proof for positive effects on a government that was intervening in the market, by analysing the costs of action.\n\nSociology \n\nSociology of law is a diverse field of study that examines the interaction of law with society and overlaps with jurisprudence, philosophy of law, social theory and more specialised subjects such as criminology. The institutions of social construction, social norms, dispute processing and legal culture are key areas for inquiry in this knowledge field. Sociology of law is sometimes seen as a sub-discipline of sociology, but its ties to the academic discipline of law are equally strong, and it is best seen as a transdisciplinary and multidisciplinary study focused on the theorisation and empirical study of legal practices and experiences as social phenomena. In the United States the field is usually called law and society studies; in Europe it is more often referred to as socio-legal studies. At first, jurists and legal philosophers were suspicious of sociology of law. Kelsen attacked one of its founders, Eugen Ehrlich, who sought to make clear the differences and connections between positive law, which lawyers learn and apply, and other forms of 'law' or social norms that regulate everyday life, generally preventing conflicts from reaching barristers and courts. Contemporary research in sociology of law is much concerned with the way that law is developing outside discrete state jurisdictions, being produced through social interaction in many different kinds of social arenas, and acquiring a diversity of sources of (often competing or conflicting) authority in communal networks existing sometimes within nation states but increasingly also transnationally.\n\nAround 1900 Max Weber defined his \"scientific\" approach to law, identifying the \"legal rational form\" as a type of domination, not attributable to personal authority but to the authority of abstract norms. Formal legal rationality was his term for the key characteristic of the kind of coherent and calculable law that was a precondition for modern political developments and the modern bureaucratic state. Weber saw this law as having developed in parallel with the growth of capitalism. Another leading sociologist, \u00c9mile Durkheim, wrote in his classic work The Division of Labour in Society that as society becomes more complex, the body of civil law concerned primarily with restitution and compensation grows at the expense of criminal laws and penal sanctions. Other notable early legal sociologists included Hugo Sinzheimer, Theodor Geiger, Georges Gurvitch and Leon Petra\u017cycki in Europe, and William Graham Sumner in the U.S.\n\nSee also \n\n By-law\n Law dictionary\n Legal research in the United States\n Legal treatise\n Natural law\n Political science\n Pseudolaw\n Public interest law\n Social law\n Translating \"law\" to other European languages\n\nReferences\n\nCitations\n\nSources \n\n Printed sources\n \n \n \n \n  See original text in Perseus program .\n Barzilai, Gad (2003), Communities and Law: Politics and Cultures of Legal Identities. The University of Michigan Press, 2003. Second print 2005 \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Hamilton, Michael S., and George W. Spiro (2008). The Dynamics of Law, 4th ed. Armonk, NY: M.E. Sharpe, Inc. .\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Silvestri, Paolo, \"The ideal of good government in Luigi Einaudi\u2019s Thought and Life: Between Law and Freedom\" , in Paolo Heritier, Paolo Silvestri (Eds.), Good government, Governance, Human complexity. Luigi Einaudi's legacy and contemporary societies, Leo Olschki, Firenze, 2012, pp.\u00a055\u201395.\n\n Online sources\n\nExternal links \n\n DRAGNET: Search of free legal databases from New York Law School \n WorldLII \u2013 World Legal Information Institute\n CommonLII \u2013 Commonwealth Legal Information Institute\n AsianLII \u2013 Asian Legal Information Institute (AsianLII)\n AustLII \u2013 Australasian Legal Information Institute\n BaiLII \u2013 British and Irish Legal Information Institute\n CanLII \u2013 Canadian Legal Information Institute\n NZLII \u2013 New Zealand Legal Information Institute\n PacLII \u2013 Pacific Islands Legal Information Institute\n SAfLII \u2013 Southern African Legal Information Institute\n\n \nMain topic articles",
  "Literature": "Literature broadly is any collection of written work, but it is also used more narrowly for writings specifically considered to be an art form, especially prose fiction, drama, and poetry. In recent centuries, the definition has expanded to include oral literature, much of which has been transcribed. Literature is a method of recording, preserving, and transmitting knowledge and entertainment, and  can also have a social, psychological, spiritual, or political role.\n\nLiterature, as an art form, can also include works in various non-fiction genres, such as biography, diaries, memoir, letters, and the essay. Within its broad definition, literature includes non-fictional books, articles or other printed information on a particular subject.\n\nEtymologically, the term derives from Latin literatura/litteratura \"learning, a writing, grammar,\" originally \"writing formed with letters,\" from litera/littera \"letter\". In spite of this, the term has also been applied to spoken or sung texts. Developments in print technology have allowed an ever-growing distribution and proliferation of written works, which now includes electronic literature.\n\nLiterature is classified according to whether it is poetry, prose or drama, and such works are categorized according to historical periods, or their adherence to certain aesthetic features, or genre.\n\nDefinitions \nDefinitions of literature have varied over time. In Western Europe, prior to the 18th century, literature denoted all books and writing literature can be seen as returning to older, more inclusive notions, so that cultural studies, for instance, include, in addition to canonical works, popular and minority genres. The word is also used in reference non-written works: to \"oral literature\" and \"the literature of preliterate culture\".\n\nA value judgment definition of literature considers it as consisting solely of high quality writing that forms part of the belles-lettres (\"fine writing\") tradition. An example of this in the (1910\u201311) Encyclop\u00e6dia Britannica that classified literature as \"the best expression of the best thought reduced to writing\".\n\nHistory\n\nOral literature \nThe use of the term \"literature\" here is a little problematic because of its origins in the Latin littera, \u201cletter,\u201d essentially writing. Alternatives such as \"oral forms\" and \"oral genres\" have been suggested but the word literature is widely used.\n\nOral literature is an ancient human tradition found in \"all corners of the world\". Modern archaeology has been unveiling evidence of the human efforts to preserve and transmit arts and knowledge that depended completely or partially on an oral tradition, across various cultures:\n\nThe earliest poetry is believed to have been recited or sung, employed as a way of remembering history, genealogy, and law.\n\nIn Asia, the transmission of folklore, mythologies as well as scriptures in ancient India, in different Indian religions, was by oral tradition, preserved with precision with the help of elaborate mnemonic techniques.\n\nThe early Buddhist texts are also generally believed to be of oral tradition, with the first by comparing inconsistencies in the transmitted versions of literature from various oral societies such as the Greek, Serbia and other cultures, then noting that the Vedic literature is too consistent and vast to have been composed and transmitted orally across generations, without being written down. According to Goody, the Vedic texts likely involved both a written and oral tradition, calling it a \"parallel products of a literate society\".\n\nAustralian Aboriginal culture has thrived on oral traditions and oral histories passed down through thousands of years.\nIn a study published in February 2020, new evidence showed that both Budj Bim and Tower Hill volcanoes erupted between 34,000 and 40,000 years ago. Significantly, this is a \"minimum age constraint for human presence in Victoria\", and also could be interpreted as evidence for the oral histories of the Gunditjmara people, an Aboriginal Australian people of south-western Victoria, which tell of volcanic eruptions being some of the oldest oral traditions in existence. An axe found underneath volcanic ash in 1947 had already proven that humans inhabited the region before the eruption of Tower Hill.\n\nAll ancient Greek literature was to some degree oral in nature, and the earliest literature was completely so. Homer's epic poetry, states Michael Gagarin, was largely composed, performed and transmitted orally. As folklores and legends were performed in front of distant audiences, the singers would substitute the names in the stories with local characters or rulers to give the stories a local flavor and thus connect with the audience, but making the historicity embedded in the oral tradition as unreliable. The lack of surviving texts about the Greek and Roman religious traditions have led scholars to presume that these were ritualistic and transmitted as oral traditions, but some scholars disagree that the complex rituals in the ancient Greek and Roman civilizations were an exclusive product of an oral tradition.\n\nWriting systems are not known to have existed among Native North Americans before contact with Europeans. Oral storytelling traditions flourished in a context without the use of writing to record and preserve history, scientific knowledge, and social practices. While some stories were told for amusement and leisure, most functioned as practical lessons from tribal experience applied to immediate moral, social, psychological, and environmental issues. Stories fuse fictional, supernatural, or otherwise exaggerated characters and circumstances with real emotions and morals as a means of teaching. Plots often reflect real life situations and may be aimed at particular people known by the story's audience. In this way, social pressure could be exerted without directly causing embarrassment or social exclusion. For example, rather than yelling, Inuit parents might deter their children from wandering too close to the water's edge by telling a story about a sea monster with a pouch for children within its reach.\n\nSee also African literature#Oral literature\n\nOratory \nOratory or the art of public speaking \"was for long considered a literary art\". From Ancient Greece to the late 19th century, rhetoric played a central role in Western education in training orators, lawyers, counsellors, historians, statesmen, and poets.\n\nWriting \n\nAround the 4th millennium BC, the complexity of trade and administration in Mesopotamia outgrew human memory, and writing became a more dependable method of recording and presenting transactions in a permanent form. Though in both ancient Egypt and Mesoamerica, writing may have already emerged because of the need to record historical and environmental events. Subsequent innovations included more uniform, predictable, legal systems, sacred texts, and the origins of modern practices of scientific inquiry and knowledge-consolidation, all largely reliant on portable and easily reproducible forms of writing.\n\nEarly written literature \n\nAncient Egyptian literature, along with Sumerian literature, are considered the world's oldest literatures. The primary genres of the literature of ancient Egypt\u2014didactic texts, hymns and prayers, and tales\u2014were written almost entirely in verse; By the Old Kingdom (26th century BC to 22nd century BC), literary works included funerary texts, epistles and letters, hymns and poems, and commemorative autobiographical texts recounting the careers of prominent administrative officials. It was not until the early Middle Kingdom (21st century BC to 17th century BC) that a narrative Egyptian literature was created.\n\nMany works of early periods, even in narrative form, had a covert moral or didactic purpose, such as the Sanskrit Panchatantra.200 BC \u2013 300 AD, based on older oral tradition. Drama and satire also developed as urban culture provided a larger public audience, and later readership, for literary production. Lyric poetry (as opposed to epic poetry) was often the speciality of courts and aristocratic circles, particularly in East Asia where songs were collected by the Chinese aristocracy as poems, the most notable being the Shijing or Book of Songs (1046\u2013c.600 BC), .\n\nIn ancient China, early literature was primarily focused on philosophy, historiography, military science, agriculture, and poetry. China, the origin of modern paper making and woodblock printing, produced the world's first print cultures. Much of Chinese literature originates with the Hundred Schools of Thought period that occurred during the Eastern Zhou Dynasty (769\u2012269 BC). The most important of these include the Classics of Confucianism, of Daoism, of Mohism, of Legalism, as well as works of military science (e.g. Sun Tzu's The Art of War, c.5th century BC)) and Chinese history (e.g. Sima Qian's Records of the Grand Historian, c.94 BC). Ancient Chinese literature had a heavy emphasis on historiography, with often very detailed court records. An exemplary piece of narrative history of ancient China was the Zuo Zhuan, which was compiled no later than 389 BC, and attributed to the blind 5th-century BC historian Zuo Qiuming.\n\nIn ancient India, literature originated from stories that were originally orally transmitted. Early genres included drama, fables, sutras and epic poetry. Sanskrit literature begins with the Vedas, dating back to 1500\u20131000 BC, and continues with the Sanskrit Epics of Iron Age India. The Vedas are among the oldest sacred texts. The Samhitas (vedic collections) date to roughly 1500\u20131000 BC, and the \"circum-Vedic\" texts, as well as the redaction of the Samhitas, date to c. 1000\u2012500 BC, resulting in a Vedic period, spanning the mid-2nd to mid 1st millennium BC, or the Late Bronze Age and the Iron Age. The period between approximately the 6th to 1st centuries BC saw the composition and redaction of the two most influential Indian epics, the Mahabharata and the Ramayana, with subsequent redaction progressing down to the 4th century AD. Other major literary works are Ramcharitmanas & Krishnacharitmanas.\n\nThe earliest known Greek writings are Mycenaean (c.1600\u20131100 BC), written in the Linear B syllabary on clay tablets. These documents contain prosaic records largely concerned with trade (lists, inventories, receipts, etc.); no real literature has been discovered. Michael Ventris and John Chadwick, the original decipherers of Linear B, state that literature almost certainly existed in Mycenaean Greece, but it was either not written down or, if it was, it was on parchment or wooden tablets, which did not survive the destruction of the Mycenaean palaces in the twelfth century BC.\nHomer's, epic poems the Iliad and the Odyssey, are central works of ancient Greek literature. It is generally accepted that the poems were composed at some point around the late eighth or early seventh century BC. Modern scholars consider these accounts legendary. Most researchers believe that the poems were originally transmitted orally. From antiquity until the present day, the influence of Homeric epic on Western civilization has been great, inspiring many of its most famous works of literature, music, art and film. The Homeric epics were the greatest influence on ancient Greek culture and education; to Plato, Homer was simply the one who \"has taught Greece\" \u2013 ten Hellada pepaideuken. Hesiod's Works and Days (c.700 BC) and Theogony, are some of the earliest, and most influential, of ancient Greek literature. Classical Greek genres included philosophy, poetry, historiography, comedies and dramas. Plato (428/427 or 424/423 \u2013 348/347 BC) and Aristotle (384\u2013322 BC) authored philosophical texts that are the foundation of Western philosophy, Sappho (c. 630 \u2013 c. 570 BC) and Pindar were influential lyric poets, and Herodotus (c.\u2009484 \u2013 c.\u2009425 BC) ) and Thucydides were early Greek historians. Although drama was popular in ancient Greece, of the hundreds of tragedies written and performed during the classical age, only a limited number of plays by three authors still exist: Aeschylus, Sophocles, and Euripides. The plays of Aristophanes (c. 446 \u2013 c. 386 BC) provide the only real examples of a genre of comic drama known as Old Comedy, the earliest form of Greek Comedy, and are in fact used to define the genre.\n\nThe Hebrew religious text, the Torah, is widely seen as a product of the Persian period (539\u2013333 BC, probably 450\u2013350 BC). This consensus echoes a traditional Jewish view which gives Ezra, the leader of the Jewish community on its return from Babylon, a pivotal role in its promulgation. This represents a major source of Christianity's Bible, which has been a major influence on Western literature.\n\nThe beginning of Roman literature dates to 240 BC, when a Roman audience saw a Latin version of a Greek play. Literature in latin would flourish for the next six centuries, and includes essays, histories, poems, plays, and other writings.\n\nThe Qur'an (610 AD to 632 AD) ), the main holy book of Islam, had a significant influence on the Arab language, and marked the beginning of Islamic literature. Muslims believe it was transcribed in the Arabic dialect of the Quraysh, the tribe of Muhammad. As Islam spread, the Quran had the effect of unifying and standardizing Arabic.\n\nTheological works in Latin were the dominant form of literature in Europe typically found in libraries during the Middle Ages. Western Vernacular literature includes the Poetic Edda and the sagas, or heroic epics, of Iceland, the Anglo-Saxon Beowulf, and the German Song of Hildebrandt. A later form of medieval fiction was the romance, an adventurous and sometimes magical narrative with strong popular appeal.\n\nControversial, religious, political and instructional literature proliferated during the European Renaissance as a result of the Johannes Gutenberg's invention of the printing press around 1440, while the Medieval romance developed into the novel,\n\nPublishing \n\nPublishing became possible with the invention of writing, but became more practical with the invention of printing. Prior to printing, distributed works were copied manually, by scribes.\n\nThe Chinese inventor Bi Sheng made movable type of earthenware c. 1045. Then c.1450, separately Johannes Gutenberg invented movable type in Europe. This invention gradually made books less expensive to produce and more widely available.\n\nEarly printed books, single sheets and images which were created before 1501 in Europe are known as incunables or incunabula. \"A man born in 1453, the year of the fall of Constantinople, could look back from his fiftieth year on a lifetime in which about eight million books had been printed, more perhaps than all the scribes of Europe had produced since Constantine founded his city in A.D. 330.\"\n\nEventually, printing enabled other forms of publishing besides books. The history of modern newspaper publishing started in Germany in 1609, with publishing of magazines following in 1663.\n\nUniversity discipline\n\nIn England \n\nIn England in the late 1820s, growing political and social awareness, \"particularly among the utilitarians and Benthamites, promoted the possibility of including courses in English literary study in the newly formed London University\". This further developed into the idea of the study of literature being \"the ideal carrier for the propagation of the humanist cultural myth of a welleducated, culturally harmonious nation\".\n\nAmerica \nAmerican Literature (academic discipline)\n\nWomen and literature \n\nThe widespread education of women was not common until the nineteenth century, and because of this literature until recently was mostly male dominated.\n\nThere are few women poets writing in English, whose names are remembered, until the twentieth century. In the nineteenth century some names that stand out are Emily Bront\u00eb, Elizabeth Barrett Browning, and Emily Dickinson (see American poetry). But while generally women are absent from the European cannon of Romantic literature, there is one notable exception, the French novelist and memoirist Amantine Dupin (1804 \u2013 1876) best known by her pen name George Sand. One of the more popular writers in Europe in her lifetime, being more renowned than both Victor Hugo and Honor\u00e9 de Balzac in England in the 1830s and 1840s, Sand is recognised as one of the most notable writers of the European Romantic era. Jane Austen (1775 \u2013 1817) is the first major English woman novelist, while Aphra Behn is an early female dramatist.\n\nNobel Prizes in Literature have been awarded between 1901 and 2020 to 117 individuals: 101 men and 16 women. Selma Lagerl\u00f6f (1858 \u2013 1940) was the first woman to win the Nobel Prize in Literature, which she was awarded in 1909. Additionally, she was the first woman to be granted a membership in The Swedish Academy in 1914.\n\nFeminist scholars have since the twentieth century sought expand the literary canon to include more women writers.\n\nChildren's literature \n\nA separate genre of children's literature only began to emerge in the eighteenth century, with the development of the concept of childhood. The earliest of these books were educational books, books on conduct, and simple ABCs\u2014often decorated with animals, plants, and anthropomorphic letters.\n\nAesthetics\n\nLiterary theory \n\nA fundamental question of literary theory is \"what is literature?\" \u2013 although many contemporary theorists and literary scholars believe either that \"literature\" cannot be defined or that it can refer to any use of language.\n\nLiterary fiction\n\nLiterary fiction is a term used to describe fiction that explores any facet of the human condition, and may involve social commentary. It is often regarded as having more artistic merit than genre fiction, especially the most commercially oriented types, but this has been contested in recent years, with the serious study of genre fiction within universities.\n\nThe following, by the award-winning British author William Boyd on the short story, might be applied to all prose fiction:\n\n[short stories] seem to answer something very deep in our nature as if, for the duration of its telling, something special has been created, some essence of our experience extrapolated, some temporary sense has been made of our common, turbulent journey towards the grave and oblivion.\n\nThe very best in literature is annually recognized by the Nobel Prize in Literature, which is awarded to an author from any country who has, in the words of the will of Swedish industrialist Alfred Nobel, produced \"in the field of literature the most outstanding work in an ideal direction\" (original Swedish: den som inom litteraturen har producerat det mest framst\u00e5ende verket i en idealisk riktning).\n\nThe value of imaginative literature\n\nSome researchers suggest that literary fiction can play a role in an individual's psychological development. Psychologists have also been using literature as a therapeutic tool. Psychologist Hogan argues for the value of the time and emotion that a person devotes to understanding a character's situation in literature; that it can unite a large community by provoking universal emotions, as well as allowing readers access to different cultures, and new emotional experiences. One study, for example, suggested that the presence of familiar cultural values in literary texts played an important impact on the performance of minority students.\n\nPsychologist Maslow's ideas help literary critics understand how characters in literature reflect their personal culture and the history. The theory suggests that literature helps an individual's struggle for self-fulfilment.\n\nThe influence of religious texts \n\nReligion has had a major influence on literature, through works like the Vedas, the Torah, the Bible,\nand the Qur'an.\n\nThe King James Version of the Bible has been called \"the most influential version of the most influential book in the world, in what is now its most influential language\", \"the most important book in English religion and culture\", and \"the most celebrated book in the English-speaking world\" - principally because of its literary style and widespread distribution. Prominent atheist figures such as the late Christopher Hitchens and Richard Dawkins have praised the King James Version as being \"a giant step in the maturing of English literature\" and \"a great work of literature\", respectively, with Dawkins then adding, \"A native speaker of English who has never read a word of the King James Bible is verging on the barbarian\".\n\nSocieties in which preaching has great importance, and those in which religious structures and  authorities have a near-monopoly of  reading and writing and/or a censorship role, may impart a religious gloss to much of the literature those societies produce or retain - as for example in the European Middle Ages. The traditions of  close study of religious texts has furthered the development of techniques and theories in literary studies.\n\nTypes of literature\n\nPoetry \n\nPoetry has traditionally been distinguished from prose by its greater use of the aesthetic qualities of language, including musical devices such as assonance, alliteration, rhyme, and rhythm, and by being set in lines and verses rather than paragraphs, and more recently its use of other typographical elements. This distinction is complicated by various hybrid forms such as sound poetry, concrete poetry and prose poem, and more generally by the fact that prose possesses rhythm. Abram Lipsky refers to it as an \"open secret\" that \"prose is not distinguished from poetry by lack of rhythm\".\n\nPrior to the 19th century, poetry was commonly understood to be something set in metrical lines: \"any kind of subject consisting of  or Verses\". Possibly as a result of Aristotle's influence (his Poetics), \"poetry\" before the 19th century was usually less a technical designation for verse than a normative category of fictive or rhetorical art. As a form it may pre-date literacy, with the earliest works being composed within and sustained by an oral tradition; hence it constitutes the earliest example of literature.\n\nProse \nAs noted above, prose generally makes far less use of the aesthetic qualities of language than poetry. However, developments in modern literature, including free verse and prose poetry have tended to blur the differences, and American poet T.S. Eliot suggested that while: \"the distinction between verse and prose is clear, the distinction between poetry and prose is obscure\". There are verse novels, a type of narrative poetry in which a novel-length narrative is told through the medium of poetry rather than prose. Eugene Onegin (1831) by Alexander Pushkin is the most famous example.\n\nOn the historical development of prose, Richard Graff notes that \"[In the case of ancient Greece] recent scholarship has emphasized the fact that formal prose was a comparatively late development, an \"invention\" properly associated with the classical period\".\n\nLatin was a major influence on the development of prose in many European countries. Especially important was the great Roman orator Cicero. It was the lingua franca among literate Europeans until quite recent times, and the great works of Descartes (1596 \u2013 1650), Francis Bacon (1561 \u2013 1626), and Baruch Spinoza (1632 \u2013 1677) were published in Latin. Among the last important books written primarily in Latin prose were the works of Swedenborg (d. 1772), Linnaeus (d. 1778), Euler (d. 1783), Gauss (d. 1855), and Isaac Newton (d. 1727).\n\nNovel\n\nA novel is a long fictional prose narrative. In English, the term emerged from the Romance languages in the late 15th century, with the meaning of \"news\"; it came to indicate something new, without a distinction between fact or fiction. The romance is a closely related long prose narrative. Walter Scott defined it as \"a fictitious narrative in prose or verse; the interest of which turns upon marvellous and uncommon incidents\", whereas in the novel \"the events are accommodated to the ordinary train of human events and the modern state of society\". Other European languages do not distinguish between romance and novel: \"a novel is le roman, der Roman, il romanzo\", indicates the proximity of the forms.\n\nAlthough there are many historical prototypes, so-called \"novels before the novel\", the modern novel form emerges late in cultural history\u2014roughly during the eighteenth century. Initially subject to much criticism, the novel has acquired a dominant position amongst literary forms, both popularly and critically.\n\nNovella\n\nThe publisher Melville House classifies the novella as \"too short to be a novel, too long to be a short story\". Publishers and literary award societies typically consider a novella to be between 17,000 and 40,000 words.\n\nShort story\n\nA dilemma in defining the \"short story\" as a literary form is how to, or whether one should, distinguish it from any short narrative and its contested origin, that include the Bible, and Edgar Allan Poe.\n\nGraphic novel \nGraphic novels and comic books present stories told in a combination of artwork, dialogue, and text.\n\nElectronic literature \nElectronic literature is a literary genre consisting of digital works\n\nNonfiction \nCommon literary examples of nonfiction include, the essay; travel literature and nature writing; biography, autobiography and memoir; journalism; letters; journals; history, philosophy, economics; scientific, and technical writings.\n\nNonfiction can fall within the broad category of literature as \"any collection of written work\", but some works fall within the narrower definition \"by virtue of the excellence of their writing, their originality and their general aesthetic and artistic merits\".\n\nDrama \n\nDrama is literature intended for performance. The form is combined with music and dance in opera and musical theatre (see libretto). A play is a written dramatic work by a playwright that is intended for performance in a theatre; it comprises chiefly dialogue between characters. A closet drama, by contrast, is written to be read rather than to be performed; the meaning of which can be realized fully on the page. Nearly all drama took verse form until comparatively recently.\n\nThe earliest form of which there exists substantial knowledge is Greek drama. This developed as a performance associated with religious and civic festivals, typically enacting or developing upon well-known historical, or mythological themes,\n\nIn the twentieth century scripts written for non-stage media have been added to this form, including radio, television and film.\n\nLaw\n\nLaw and literature \nThe law and literature movement focuses on the interdisciplinary connection between law and literature.\n\nCopyright \n\nCopyright is a type of intellectual property that gives its owner the exclusive right to make copies of a creative work, usually for a limited time. The creative work may be in a literary, artistic, educational, or musical form. Copyright is intended to protect the original expression of an idea in the form of a creative work, but not the idea itself.\n\nUnited Kingdom \nLiterary works have been protected by copyright law from unauthorized reproduction since at least 1710. Literary works are defined by copyright law to mean \"any work, other than a dramatic or musical work, which is written, spoken or sung, and accordingly includes (a) a table or compilation (other than a database), (b) a computer program, (c) preparatory design material for a computer program, and (d) a database.\"\n\nLiterary works are all works of literature; that is all works expressed in print or writing (other than dramatic or musical works).\n\nUnited States \nThe copyright law of the United States has a long and complicated history, dating back to colonial times. It was established as federal law with the Copyright Act of 1790. This act was updated many times, including a major revision in 1976.\n\nEuropean Union \nThe copyright law of the European Union is the copyright law applicable within the European Union. Copyright law is largely harmonized in the Union, although country to country differences exist. The body of law was implemented in the EU through a number of directives, which the member states need to enact into their national law. The main copyright directives are the Copyright Term Directive, the Information Society Directive and the Directive on Copyright in the Digital Single Market. Copyright in the Union is furthermore dependent on international conventions to which the European Union is a member (such as the TRIPS Agreement and conventions to which all Member States are parties (such as the Berne Convention)).\n\nCopyright in communist countries\n\nCopyright in Japan\nJapan was a party to the original Berne convention in 1899, so its copyright law is in sync with most international regulations. The convention protected copyrighted works for 50 years after the author's death (or 50 years after publication for unknown authors and corporations). However, in 2004 Japan extended the copyright term to 70 years for cinematographic works. At the end of 2018, as a result of the Trans-Pacific Partnership negotiations, the 70 year term was applied to all works. This new term is not applied retroactively; works that had entered the public domain between 1999 and 2018 by expiration would remain in the public domain.\n\nCensorship \n\nIs a means employed by states, religious organizations, educational institutions, etc, to control what can be portrayed, spoken, performed, or written. Generally such bodies attempt to ban works for political reasons, or because they deal with other controversial matters such as race, or sex.\n\nA notorious example of censorship is James Joyce's novel Ulysses, which has been described by Russian-American novelist Vladimir Nabokov as a \"divine work of art\" and the greatest masterpiece of 20th century prose. It was banned in the United States from 1921 until 1933 on the grounds of obscenity. Nowadays it is a central literary text in English literature courses, throughout the world.\n\nAwards \n\nThere are numerous awards recognizing achievement and contribution in literature. Given the diversity of the field, awards are typically limited in scope, usually on: form, genre, language, nationality and output (e.g. for first-time writers or debut novels).\n\nThe Nobel Prize in Literature was one of the six Nobel Prizes established by the will of Alfred Nobel in 1895, and is awarded to an author on the basis of their body of work, rather than to, or for, a particular work itself. Other literary prizes for which all nationalities are eligible include: the Neustadt International Prize for Literature, the Man Booker International Prize, Pulitzer Prize, Hugo Award, Guardian First Book Award and the Franz Kafka Prize.\n\nSee also\n\nNotes\n\nReferences\n\nBibliography\n\nFurther reading \n\n An overview of several hundred short stories.\n\n Brief summary of major periods in literary history of the Western tradition.\n\nExternal links \n\n Project Gutenberg Online Library\n Internet Book List similar to IMDb but for books\n Internet Archive Digital eBook Collection",
  "Art": "Art is a diverse range of human activity, and resulting product, that involves creative or imaginative talent expressive of technical proficiency, beauty, emotional power, or conceptual ideas.\n\nThere is no generally agreed definition of what constitutes art, and ideas have changed over time. The three classical branches of visual art are painting, sculpture, and architecture. Theatre, dance, and other performing arts, as well as literature, music, film and other media such as interactive media, are included in a broader definition of the arts. Until the 17th century, art referred to any skill or mastery and was not differentiated from crafts or sciences. In modern usage after the 17th century, where aesthetic considerations are paramount, the fine arts are separated and distinguished from acquired skills in general, such as the decorative or applied arts. \n\nThe nature of art and related concepts, such as creativity and interpretation, are explored in a branch of philosophy known as aesthetics. The resulting artworks are studied in the professional fields of art criticism and the history of art.\n\nOverview\n\nIn the perspective of the history of art, artistic works have existed for almost as long as humankind: from early pre-historic art to contemporary art; however, some theorists feel that the typical concept of \"artistic works\" fits less well outside modern Western societies. One early sense of the definition of art is closely related to the older Latin meaning, which roughly translates to \"skill\" or \"craft\", as associated with words such as \"artisan\". English words derived from this meaning include artifact, artificial, artifice, medical arts, and military arts. However, there are many other colloquial uses of the word, all with some relation to its etymology.\n\nOver time, philosophers like Plato, Aristotle, Socrates and Kant, among others, questioned the meaning of art. Several dialogues in Plato tackle questions about art: Socrates says that poetry is inspired by the muses, and is not rational. He speaks approvingly of this, and other forms of divine madness (drunkenness, eroticism, and dreaming) in the Phaedrus (265a\u2013c), and yet in the Republic wants to outlaw Homer's great poetic art, and laughter as well. In Ion, Socrates gives no hint of the disapproval of Homer that he expresses in the Republic. The dialogue Ion suggests that Homer's Iliad functioned in the ancient Greek world as the Bible does today in the modern Christian world: as divinely inspired literary art that can provide moral guidance, if only it can be properly interpreted.\n\nWith regards to the literary art and the musical arts, Aristotle considered epic poetry, tragedy, comedy, Dithyrambic poetry and music to be mimetic or imitative art, each varying in imitation by medium, object, and manner. For example, music imitates with the media of rhythm and harmony, whereas dance imitates with rhythm alone, and poetry with language. The forms also differ in their object of imitation. Comedy, for instance, is a dramatic imitation of men worse than average; whereas tragedy imitates men slightly better than average. Lastly, the forms differ in their manner of imitation\u2014through narrative or character, through change or no change, and through drama or no drama. Aristotle believed that imitation is natural to mankind and constitutes one of mankind's advantages over animals.\n\nThe more recent and specific sense of the word art as an abbreviation for creative art or fine art emerged in the early 17th century. Fine art refers to a skill used to express the artist's creativity, or to engage the audience's aesthetic sensibilities, or to draw the audience towards consideration of more refined or finer work of art.\n\nWithin this latter sense, the word art may refer to several things: (i) a study of a creative skill, (ii) a process of using the creative skill, (iii) a product of the creative skill, or (iv) the audience's experience with the creative skill. The creative arts (art as discipline) are a collection of disciplines which produce artworks (art as objects) that are compelled by a personal drive (art as activity) and convey a message, mood, or symbolism for the perceiver to interpret (art as experience).  Art is something that stimulates an individual's thoughts, emotions, beliefs, or ideas through the senses. Works of art can be explicitly made for this purpose or interpreted on the basis of images or objects. For some scholars, such as Kant, the sciences and the arts could be distinguished by taking science as representing the domain of knowledge and the arts as representing the domain of the freedom of artistic expression.\n\nOften, if the skill is being used in a common or practical way, people will consider it a craft instead of art. Likewise, if the skill is being used in a commercial or industrial way, it may be considered commercial art instead of fine art. On the other hand, crafts and design are sometimes considered applied art. Some art followers have argued that the difference between fine art and applied art has more to do with value judgments made about the art than any clear definitional difference. However, even fine art often has goals beyond pure creativity and self-expression. The purpose of works of art may be to communicate ideas, such as in politically, spiritually, or philosophically motivated art; to create a sense of beauty (see aesthetics); to explore the nature of perception; for pleasure; or to generate strong emotions. The purpose may also be seemingly nonexistent.\n\nThe nature of art has been described by philosopher Richard Wollheim as \"one of the most elusive of the traditional problems of human culture\". Art has been defined as a vehicle for the expression or communication of emotions and ideas, a means for exploring and appreciating formal elements for their own sake, and as mimesis or representation. Art as mimesis has deep roots in the philosophy of Aristotle. Leo Tolstoy identified art as a use of indirect means to communicate from one person to another. Benedetto Croce and R. G. Collingwood advanced the idealist view that art expresses emotions, and that the work of art therefore essentially exists in the mind of the creator. The theory of art as form has its roots in the philosophy of Kant, and was developed in the early 20th century by Roger Fry and Clive Bell.  More recently, thinkers influenced by Martin Heidegger have interpreted art as the means by which a community develops for itself a medium for self-expression and interpretation. George Dickie has offered an institutional theory of art that defines a work of art as any artifact upon which a qualified person or persons acting on behalf of the social institution commonly referred to as \"the art world\" has conferred \"the status of candidate for appreciation\". Larry Shiner has described fine art as \"not an essence or a fate but something we have made. Art as we have generally understood it is a European invention barely two hundred years old.\"\n\nArt may be characterized in terms of mimesis (its representation of reality), narrative (storytelling), expression, communication of emotion, or other qualities. During the Romantic period, art came to be seen as \"a special faculty of the human mind to be classified with religion and science\".\n\nHistory\n\nA shell engraved by Homo erectus was determined to be between 430,000 and 540,000 years old. A set of eight 130,000 years old white-tailed eagle talons bear cut marks and abrasion that indicate manipulation by neanderthals, possibly for using it as jewelry. A series of tiny, drilled snail shells about 75,000 years old\u2014were discovered in a South African cave. Containers that may have been used to hold paints have been found dating as far back as 100,000 years.\n\nSculptures, cave paintings, rock paintings and petroglyphs from the Upper Paleolithic dating to roughly 40,000 years ago have been found, but the precise meaning of such art is often disputed because so little is known about the cultures that produced them. \n\nMany great traditions in art have a foundation in the art of one of the great ancient civilizations: Ancient Egypt, Mesopotamia, Persia, India, China, Ancient Greece, Rome, as well as Inca, Maya, and Olmec. Each of these centers of early civilization developed a unique and characteristic style in its art. Because of the size and duration of these civilizations, more of their art works have survived and more of their influence has been transmitted to other cultures and later times. Some also have provided the first records of how artists worked. For example, this period of Greek art saw a veneration of the human physical form and the development of equivalent skills to show musculature, poise, beauty, and anatomically correct proportions.\n\nIn Byzantine and Medieval art of the Western Middle Ages, much art focused on the expression of subjects about Biblical and religious culture, and used styles that showed the higher glory of a heavenly world, such as the use of gold in the background of paintings, or glass in mosaics or windows, which also presented figures in idealized, patterned (flat) forms. Nevertheless, a classical realist tradition persisted in small Byzantine works, and realism steadily grew in the art of Catholic Europe.\n\nRenaissance art had a greatly increased emphasis on the realistic depiction of the material world, and the place of humans in it, reflected in the corporeality of the human body, and development of a systematic method of graphical perspective to depict recession in a three-dimensional picture space.\n\nIn the east, Islamic art's rejection of iconography led to emphasis on geometric patterns, calligraphy, and architecture. Further east, religion dominated artistic styles and forms too. India and Tibet saw emphasis on painted sculptures and dance, while religious painting borrowed many conventions from sculpture and tended to bright contrasting colors with emphasis on outlines. China saw the flourishing of many art forms: jade carving, bronzework, pottery (including the stunning terracotta army of Emperor Qin), poetry, calligraphy, music, painting, drama, fiction, etc. Chinese styles vary greatly from era to era and each one is traditionally named after the ruling dynasty. So, for example, Tang dynasty paintings are monochromatic and sparse, emphasizing idealized landscapes, but Ming dynasty paintings are busy and colorful, and focus on telling stories via setting and composition. Japan names its styles after imperial dynasties too, and also saw much interplay between the styles of calligraphy and painting. Woodblock printing became important in Japan after the 17th century.\n\nThe western Age of Enlightenment in the 18th century saw artistic depictions of physical and rational certainties of the clockwork universe, as well as politically revolutionary visions of a post-monarchist world, such as Blake's portrayal of Newton as a divine geometer, or David's propagandistic paintings. This led to Romantic rejections of this in favor of pictures of the emotional side and individuality of humans, exemplified in the novels of Goethe. The late 19th century then saw a host of artistic movements, such as academic art, Symbolism, impressionism and fauvism among others.\n\nThe history of 20th-century art is a narrative of endless possibilities and the search for new standards, each being torn down in succession by the next. Thus the parameters of Impressionism, Expressionism, Fauvism, Cubism, Dadaism, Surrealism, etc. cannot be maintained very much beyond the time of their invention. Increasing global interaction during this time saw an equivalent influence of other cultures into Western art. Thus, Japanese woodblock prints (themselves influenced by Western Renaissance draftsmanship) had an immense influence on impressionism and subsequent development. Later, African sculptures were taken up by Picasso and to some extent by Matisse. Similarly, in the 19th and 20th centuries the West has had huge impacts on Eastern art with originally western ideas like Communism and Post-Modernism exerting a powerful influence.\n\nModernism, the idealistic search for truth, gave way in the latter half of the 20th century to a realization of its unattainability. Theodor W. Adorno said in 1970, \"It is now taken for granted that nothing which concerns art can be taken for granted any more: neither art itself, nor art in relationship to the whole, nor even the right of art to exist.\" Relativism was accepted as an unavoidable truth, which led to the period of contemporary art and postmodern criticism, where cultures of the world and of history are seen as changing forms, which can be appreciated and drawn from only with skepticism and irony. Furthermore, the separation of cultures is increasingly blurred and some argue it is now more appropriate to think in terms of a global culture, rather than of regional ones.\n\nIn The Origin of the Work of Art, Martin Heidegger, a German philosopher and a seminal thinker, describes the essence of art in terms of the concepts of being and truth. He argues that art is not only a way of expressing the element of truth in a culture, but the means of creating it and providing a springboard from which \"that which is\" can be revealed. Works of art are not merely representations of the way things are, but actually produce a community's shared understanding. Each time a new artwork is added to any culture, the meaning of what it is to exist is inherently changed.\n\nHistorically, art and artistic skills and ideas have often been spread through trade. An example of this is the Silk Road, where Hellenistic, Iranian, Indian and Chinese influences could mix. Greco Buddhist art is one of the most vivid examples of this interaction. The meeting of different cultures and worldviews also influenced artistic creation. An example of this is the multicultural port metropolis of Trieste at the beginning of the 20th century, where James Joyce met writers from Central Europe and the artistic development of New York City as a cultural melting pot.\n\nForms, genres, media, and styles\n\nThe creative arts are often divided into more specific categories, typically along perceptually distinguishable categories such as media, genre, styles, and form. Art form refers to the elements of art that are independent of its interpretation or significance. It covers the methods adopted by the artist and the physical composition of the artwork, primarily non-semantic aspects of the work (i.e., figurae), such as color, contour, dimension, medium, melody, space, texture, and value. Form may also include visual design principles, such as arrangement, balance, contrast, emphasis, harmony, proportion, proximity, and rhythm.\n\nIn general there are three schools of philosophy regarding art, focusing respectively on form, content, and context. Extreme Formalism is the view that all aesthetic properties of art are formal (that is, part of the art form). Philosophers almost universally reject this view and hold that the properties and aesthetics of art extend beyond materials, techniques, and form. Unfortunately, there is little consensus on terminology for these informal properties. Some authors refer to subject matter and content \u2013 i.e., denotations and connotations \u2013 while others prefer terms like meaning and significance.\n\nExtreme Intentionalism holds that authorial intent plays a decisive role in the meaning of a work of art, conveying the content or essential main idea, while all other interpretations can be discarded. It defines the subject as the persons or idea represented, and the content as the artist's experience of that subject. For example, the composition of Napoleon I on his Imperial Throne is partly borrowed from the Statue of Zeus at Olympia. As evidenced by the title, the subject is Napoleon, and the content is Ingres's representation of Napoleon as \"Emperor-God beyond time and space\". Similarly to extreme formalism, philosophers typically reject extreme intentionalism, because art may have multiple ambiguous meanings and authorial intent may be unknowable and thus irrelevant. Its restrictive interpretation is \"socially unhealthy, philosophically unreal, and politically unwise\".\n\nFinally, the developing theory of post-structuralism studies art's significance in a cultural context, such as the ideas, emotions, and reactions prompted by a work. The cultural context often reduces to the artist's techniques and intentions, in which case analysis proceeds along lines similar to formalism and intentionalism. However, in other cases historical and material conditions may predominate, such as religious and philosophical convictions, sociopolitical and economic structures, or even climate and geography. Art criticism continues to grow and develop alongside art.\n\nSkill and craft\n\nArt can connote a sense of trained ability or mastery of a medium. Art can also simply refer to the developed and efficient use of a language to convey meaning with immediacy or depth. Art can be defined as an act of expressing feelings, thoughts, and observations.\n\nThere is an understanding that is reached with the material as a result of handling it, which facilitates one's thought processes.\nA common view is that the epithet \"art\", particular in its elevated sense, requires a certain level of creative expertise by the artist, whether this be a demonstration of technical ability, an originality in stylistic approach, or a combination of these two. Traditionally skill of execution was viewed as a quality inseparable from art and thus necessary for its success; for Leonardo da Vinci, art, neither more nor less than his other endeavors, was a manifestation of skill. Rembrandt's work, now praised for its ephemeral virtues, was most admired by his contemporaries for its virtuosity. At the turn of the 20th century, the adroit performances of John Singer Sargent were alternately admired and viewed with skepticism for their manual fluency, yet at nearly the same time the artist who would become the era's most recognized and peripatetic iconoclast, Pablo Picasso, was completing a traditional academic training at which he excelled.\n\nA common contemporary criticism of some modern art occurs along the lines of objecting to the apparent lack of skill or ability required in the production of the artistic object. In conceptual art, Marcel Duchamp's \"Fountain\" is among the first examples of pieces wherein the artist used found objects (\"ready-made\") and exercised no traditionally recognised set of skills. Tracey Emin's My Bed, or Damien Hirst's The Physical Impossibility of Death in the Mind of Someone Living follow this example and also manipulate the mass media. Emin slept (and engaged in other activities) in her bed before placing the result in a gallery as work of art. Hirst came up with the conceptual design for the artwork but has left most of the eventual creation of many works to employed artisans. Hirst's celebrity is founded entirely on his ability to produce shocking concepts. The actual production in many conceptual and contemporary works of art is a matter of assembly of found objects. However, there are many modernist and contemporary artists who continue to excel in the skills of drawing and painting and in creating hands-on works of art.\n\nPurpose \n\nArt has had a great number of different functions throughout its history, making its purpose difficult to abstract or quantify to any single concept. This does not imply that the purpose of Art is \"vague\", but that it has had many unique, different reasons for being created. Some of these functions of Art are provided in the following outline. The different purposes of art may be grouped according to those that are non-motivated, and those that are motivated (L\u00e9vi-Strauss).\n\nNon-motivated functions \nThe non-motivated purposes of art are those that are integral to being human, transcend the individual, or do not fulfill a specific external purpose. In this sense, Art, as creativity, is something humans must do by their very nature (i.e.,\u00a0no other species creates art), and is therefore beyond utility.\n Basic human instinct for harmony, balance, rhythm. Art at this level is not an action or an object, but an internal appreciation of balance and harmony (beauty), and therefore an aspect of being human beyond utility.Imitation, then, is one instinct of our nature. Next, there is the instinct for 'harmony' and rhythm, meters being manifestly sections of rhythm. Persons, therefore, starting with this natural gift developed by degrees their special aptitudes, till their rude improvisations gave birth to Poetry. \u2013 Aristotle\n Experience of the mysterious. Art provides a way to experience one's self in relation to the universe. This experience may often come unmotivated, as one appreciates art, music or poetry.The most beautiful thing we can experience is the mysterious. It is the source of all true art and science. \u2013 Albert Einstein\n Expression of the imagination. Art provides a means to express the imagination in non-grammatic ways that are not tied to the formality of spoken or written language. Unlike words, which come in sequences and each of which have a definite meaning, art provides a range of forms, symbols and ideas with meanings that are malleable.Jupiter's eagle [as an example of art] is not, like logical (aesthetic) attributes of an object, the concept of the sublimity and majesty of creation, but rather something else\u2014something that gives the imagination an incentive to spread its flight over a whole host of kindred representations that provoke more thought than admits of expression in a concept determined by words. They furnish an aesthetic idea, which serves the above rational idea as a substitute for logical presentation, but with the proper function, however, of animating the mind by opening out for it a prospect into a field of kindred representations stretching beyond its ken. \u2013 Immanuel Kant\n Ritualistic and symbolic functions. In many cultures, art is used in rituals, performances and dances as a decoration or symbol. While these often have no specific utilitarian (motivated) purpose, anthropologists know that they often serve a purpose at the level of meaning within a particular culture. This meaning is not furnished by any one individual, but is often the result of many generations of change, and of a cosmological relationship within the culture.Most scholars who deal with rock paintings or objects recovered from prehistoric contexts that cannot be explained in utilitarian terms and are thus categorized as decorative, ritual or symbolic, are aware of the trap posed by the term 'art'. \u2013 Silva Tomaskova\n\nMotivated functions \nMotivated purposes of art refer to intentional, conscious actions on the part of the artists or creator. These may be to bring about political change, to comment on an aspect of society, to convey a specific emotion or mood, to address personal psychology, to illustrate another discipline, to (with commercial arts) sell a product, or simply as a form of communication.\n Communication. Art, at its simplest, is a form of communication. As most forms of communication have an intent or goal directed toward another individual, this is a motivated purpose. Illustrative arts, such as scientific illustration, are a form of art as communication. Maps are another example. However, the content need not be scientific. Emotions, moods and feelings are also communicated through art.[Art is a set of] artefacts or images with symbolic meanings as a means of communication. \u2013 Steve Mithen\n Art as entertainment. Art may seek to bring about a particular emotion or mood, for the purpose of relaxing or entertaining the viewer. This is often the function of the art industries of Motion Pictures and Video Games.\n The Avant-Garde. Art for political change. One of the defining functions of early 20th-century art has been to use visual images to bring about political change. Art movements that had this goal\u2014Dadaism, Surrealism, Russian constructivism, and Abstract Expressionism, among others\u2014are collectively referred to as the avant-garde arts.By contrast, the realistic attitude, inspired by positivism, from Saint Thomas Aquinas to Anatole France, clearly seems to me to be hostile to any intellectual or moral advancement. I loathe it, for it is made up of mediocrity, hate, and dull conceit. It is this attitude which today gives birth to these ridiculous books, these insulting plays. It constantly feeds on and derives strength from the newspapers and stultifies both science and art by assiduously flattering the lowest of tastes; clarity bordering on stupidity, a dog's life. \u2013 Andr\u00e9 Breton (Surrealism)\n Art as a \"free zone\", removed from the action of the social censure. Unlike the avant-garde movements, which wanted to erase cultural differences in order to produce new universal values, contemporary art has enhanced its tolerance towards cultural differences as well as its critical and liberating functions (social inquiry, activism, subversion, deconstruction ...), becoming a more open place for research and experimentation.\n Art for social inquiry, subversion or anarchy. While similar to art for political change, subversive or deconstructivist art may seek to question aspects of society without any specific political goal. In this case, the function of art may be simply to criticize some aspect of society. Graffiti art and other types of street art are graphics and images that are spray-painted or stencilled on publicly viewable walls, buildings, buses, trains, and bridges, usually without permission. Certain art forms, such as graffiti, may also be illegal when they break laws (in this case vandalism).\n Art for social causes. Art can be used to raise awareness for a large variety of causes. A number of art activities were aimed at raising awareness of autism, cancer, human trafficking, and a variety of other topics, such as ocean conservation, human rights in Darfur, murdered and missing Aboriginal women, elder abuse, and pollution. Trashion, using trash to make fashion, practiced by artists such as Marina DeBris is one example of using art to raise awareness about pollution.\n Art for psychological and healing purposes. Art is also used by art therapists, psychotherapists and clinical psychologists as art therapy. The Diagnostic Drawing Series, for example, is used to determine the personality and emotional functioning of a patient. The end product is not the principal goal in this case, but rather a process of healing, through creative acts, is sought. The resultant piece of artwork may also offer insight into the troubles experienced by the subject and may suggest suitable approaches to be used in more conventional forms of psychiatric therapy.\n Art for propaganda, or commercialism. Art is often utilized as a form of propaganda, and thus can be used to subtly influence popular conceptions or mood. In a similar way, art that tries to sell a product also influences mood and emotion. In both cases, the purpose of art here is to subtly manipulate the viewer into a particular emotional or psychological response toward a particular idea or object.\n Art as a fitness indicator. It has been argued that the ability of the human brain by far exceeds what was needed for survival in the ancestral environment. One evolutionary psychology explanation for this is that the human brain and associated traits (such as artistic ability and creativity) are the human equivalent of the peacock's tail. The purpose of the male peacock's extravagant tail has been argued to be to attract females (see also Fisherian runaway and handicap principle). According to this theory superior execution of art was evolutionarily important because it attracted mates.\n\nThe functions of art described above are not mutually exclusive, as many of them may overlap. For example, art for the purpose of entertainment may also seek to sell a product, i.e. the movie or video game.\n\nPublic access\n\nSince ancient times, much of the finest art has represented a deliberate display of wealth or power, often achieved by using massive scale and expensive materials. Much art has been commissioned by political rulers or religious establishments, with more modest versions only available to the most wealthy in society.\n\nNevertheless, there have been many periods where art of very high quality was available, in terms of ownership, across large parts of society, above all in cheap media such as pottery, which persists in the ground, and perishable media such as textiles and wood. In many different cultures, the ceramics of indigenous peoples of the Americas are found in such a wide range of graves that they were clearly not restricted to a social elite, though other forms of art may have been. Reproductive methods such as moulds made mass-production easier, and were used to bring high-quality Ancient Roman pottery and Greek Tanagra figurines to a very wide market. Cylinder seals were both artistic and practical, and very widely used by what can be loosely called the middle class in the Ancient Near East. Once coins were widely used, these also became an art form that reached the widest range of society.\n\nAnother important innovation came in the 15th century in Europe, when printmaking began with small woodcuts, mostly religious, that were often very small and hand-colored, and affordable even by peasants who glued them to the walls of their homes. Printed books were initially very expensive, but fell steadily in price until by the 19th century even the poorest could afford some with printed illustrations. Popular prints of many different sorts have decorated homes and other places for centuries.\n\nIn 1661, the city of Basel, in Switzerland, opened the first public museum of art in the world, the Kunstmuseum Basel. Today, its collection is distinguished by an impressively wide historic span, from the early 15th century up to the immediate present. Its various areas of emphasis give it international standing as one of the most significant museums of its kind. These encompass: paintings and drawings by artists active in the Upper Rhine region between 1400 and 1600, and on the art of the 19th to 21st centuries.\n\nPublic buildings and monuments, secular and religious, by their nature normally address the whole of society, and visitors as viewers, and display to the general public has long been an important factor in their design. Egyptian temples are typical in that the most largest and most lavish decoration was placed on the parts that could be seen by the general public, rather than the areas seen only by the priests. Many areas of royal palaces, castles and the houses of the social elite were often generally accessible, and large parts of the art collections of such people could often be seen, either by anybody, or by those able to pay a small price, or those wearing the correct clothes, regardless of who they were, as at the Palace of Versailles, where the appropriate extra accessories (silver shoe buckles and a sword) could be hired from shops outside.\n\nSpecial arrangements were made to allow the public to see many royal or private collections placed in galleries, as with the Orleans Collection mostly housed in a wing of the Palais Royal in Paris, which could be visited for most of the 18th century. In Italy the art tourism of the Grand Tour became a major industry from the Renaissance onwards, and governments and cities made efforts to make their key works accessible. The British Royal Collection remains distinct, but large donations such as the Old Royal Library were made from it to the British Museum, established in 1753. The Uffizi in Florence opened entirely as a gallery in 1765, though this function had been gradually taking the building over from the original civil servants' offices for a long time before. The building now occupied by the Prado in Madrid was built before the French Revolution for the public display of parts of the royal art collection, and similar royal galleries open to the public existed in Vienna, Munich and other capitals. The opening of the Mus\u00e9e du Louvre during the French Revolution (in 1793) as a public museum for much of the former French royal collection certainly marked an important stage in the development of public access to art, transferring ownership to a republican state, but was a continuation of trends already well established.\n\nMost modern public museums and art education programs for children in schools can be traced back to this impulse to have art available to everyone. However, museums do not only provide availability to art, but do also influence the way art is being perceived by the audience, as studies found. Thus, the museum itself is not only a blunt stage for the presentation of art, but plays an active and vital role in the overall perception of art in modern society.\n\nMuseums in the United States tend to be gifts from the very rich to the masses. (The Metropolitan Museum of Art in New York City, for example, was created by John Taylor Johnston, a railroad executive whose personal art collection seeded the museum.) But despite all this, at least one of the important functions of art in the 21st century remains as a marker of wealth and social status.\n\nThere have been attempts by artists to create art that can not be bought by the wealthy as a status object. One of the prime original motivators of much of the art of the late 1960s and 1970s was to create art that could not be bought and sold. It is \"necessary to present something more than mere objects\" said the major post war German artist Joseph Beuys. This time period saw the rise of such things as performance art, video art, and conceptual art. The idea was that if the artwork was a performance that would leave nothing behind, or was simply an idea, it could not be bought and sold. \"Democratic precepts revolving around the idea that a work of art is a commodity impelled the aesthetic innovation which germinated in the mid-1960s and was reaped throughout the 1970s. Artists broadly identified under the heading of Conceptual art ... substituting performance and publishing activities for engagement with both the material and materialistic concerns of painted or sculptural form ... [have] endeavored to undermine the art object qua object.\"\nIn the decades since, these ideas have been somewhat lost as the art market has learned to sell limited edition DVDs of video works, invitations to exclusive performance art pieces, and the objects left over from conceptual pieces. Many of these performances create works that are only understood by the elite who have been educated as to why an idea or video or piece of apparent garbage may be considered art. The marker of status becomes understanding the work instead of necessarily owning it, and the artwork remains an upper-class activity. \"With the widespread use of DVD recording technology in the early 2000s, artists, and the gallery system that derives its profits from the sale of artworks, gained an important means of controlling the sale of video and computer artworks in limited editions to collectors.\"\n\nControversies\n\nArt has long been controversial, that is to say disliked by some viewers, for a wide variety of reasons, though most pre-modern controversies are dimly recorded, or completely lost to a modern view. Iconoclasm is the destruction of art that is disliked for a variety of reasons, including religious ones. Aniconism is a general dislike of either all figurative images, or often just religious ones, and has been a thread in many major religions. It has been a crucial factor in the history of Islamic art, where depictions of Muhammad remain especially controversial. Much art has been disliked purely because it depicted or otherwise stood for unpopular rulers, parties or other groups. Artistic conventions have often been conservative and taken very seriously by art critics, though often much less so by a wider public. The iconographic content of art could cause controversy, as with late medieval depictions of the new motif of the Swoon of the Virgin in scenes of the Crucifixion of Jesus. The Last Judgment by Michelangelo was controversial for various reasons, including breaches of decorum through nudity and the Apollo-like pose of Christ.\n\nThe content of much formal art through history was dictated by the patron or commissioner rather than just the artist, but with the advent of Romanticism, and economic changes in the production of art, the artists' vision became the usual determinant of the content of his art, increasing the incidence of controversies, though often reducing their significance. Strong incentives for perceived originality and publicity also encouraged artists to court controversy. Th\u00e9odore G\u00e9ricault's Raft of the Medusa (c. 1820), was in part a political commentary on a recent event. \u00c9douard Manet's Le D\u00e9jeuner sur l'Herbe (1863), was considered scandalous not because of the nude woman, but because she is seated next to men fully dressed in the clothing of the time, rather than in robes of the antique world. John Singer Sargent's Madame Pierre Gautreau (Madam\u00a0X) (1884), caused a controversy over the reddish pink used to color the woman's ear lobe, considered far too suggestive and supposedly ruining the high-society model's reputation.\nThe gradual abandonment of naturalism and the depiction of realistic representations of the visual appearance of subjects in the 19th and 20th centuries led to a rolling controversy lasting for over a century.\n\nIn the 20th century, Pablo Picasso's Guernica (1937) used arresting cubist techniques and stark monochromatic oils, to depict the harrowing consequences of a contemporary bombing of a small, ancient Basque town. Leon Golub's Interrogation III (1981), depicts a female nude, hooded detainee strapped to a chair, her legs open to reveal her sexual organs, surrounded by two tormentors dressed in everyday clothing. Andres Serrano's Piss Christ (1989) is a photograph of a crucifix, sacred to the Christian religion and representing Christ's sacrifice and final suffering, submerged in a glass of the artist's own urine. The resulting uproar led to comments in the United States Senate about public funding of the arts.\n\nTheory\n\nBefore Modernism, aesthetics in Western art was greatly concerned with achieving the appropriate balance between different aspects of realism or truth to nature and the ideal; ideas as to what the appropriate balance is have shifted to and fro over the centuries.  This concern is largely absent in other traditions of art.  The aesthetic theorist John Ruskin, who championed what he saw as the naturalism of J.\u00a0M.\u00a0W. Turner, saw art's role as the communication by artifice of an essential truth that could only be found in nature.\n\nThe definition and evaluation of art has become especially problematic since the 20th century. Richard Wollheim distinguishes three approaches to assessing the aesthetic value of art: the Realist, whereby aesthetic quality is an absolute value independent of any human view; the Objectivist, whereby it is also an absolute value, but is dependent on general human experience; and the Relativist position, whereby it is not an absolute value, but depends on, and varies with, the human experience of different humans.\n\nArrival of Modernism\n\nThe arrival of Modernism in the late 19th century lead to a radical break in the conception of the function of art, and then again in the late 20th century with the advent of postmodernism. Clement Greenberg's 1960 article \"Modernist Painting\" defines modern art as \"the use of characteristic methods of a discipline to criticize the discipline itself\". Greenberg originally applied this idea to the Abstract Expressionist movement and used it as a way to understand and justify flat (non-illusionistic) abstract painting:\n After Greenberg, several important art theorists emerged, such as Michael Fried, T.\u00a0J.\u00a0Clark, Rosalind Krauss, Linda Nochlin and Griselda Pollock among others. Though only originally intended as a way of understanding a specific set of artists, Greenberg's definition of modern art is important to many of the ideas of art within the various art movements of the 20th century and early 21st century.\n\nPop artists like Andy Warhol became both noteworthy and influential through work including and possibly critiquing popular culture, as well as the art world. Artists of the 1980s, 1990s, and 2000s expanded this technique of self-criticism beyond high art to all cultural image-making, including fashion images, comics, billboards and pornography.\n\nDuchamp once proposed that art is any activity of any kind-everything. However, the way that only certain activities are classified today as art is a social construction. There is evidence that there may be an element of truth to this. In The Invention of Art: A Cultural History, Larry Shiner examines the construction of the modern system of the arts, i.e. fine art. He finds evidence that the older system of the arts before our modern system (fine art) held art to be any skilled human activity; for example, Ancient Greek society did not possess the term art, but techne. Techne can be understood neither as art or craft, the reason being that the distinctions of art and craft are historical products that came later on in human history. Techne included painting, sculpting and music, but also cooking, medicine, horsemanship, geometry, carpentry, prophecy, and farming, etc.\n\nNew Criticism and the \"intentional fallacy\"\nFollowing Duchamp during the first half of the 20th century, a significant shift to general aesthetic theory took place which attempted to apply aesthetic theory between various forms of art, including the literary arts and the visual arts, to each other. This resulted in the rise of the New Criticism school and debate concerning the intentional fallacy. At issue was the question of whether the aesthetic intentions of the artist in creating the work of art, whatever its specific form, should be associated with the criticism and evaluation of the final product of the work of art, or, if the work of art should be evaluated on its own merits independent of the intentions of the artist.\n\nIn 1946, William K. Wimsatt and Monroe Beardsley published a classic and controversial New Critical essay entitled \"The Intentional Fallacy\", in which they argued strongly against the relevance of an author's intention, or \"intended meaning\" in the analysis of a literary work. For Wimsatt and Beardsley, the words on the page were all that mattered; importation of meanings from outside the text was considered irrelevant, and potentially distracting.\n\nIn another essay, \"The Affective Fallacy\", which served as a kind of sister essay to \"The Intentional Fallacy\" Wimsatt and Beardsley also discounted the reader's personal/emotional reaction to a literary work as a valid means of analyzing a text. This fallacy would later be repudiated by theorists from the reader-response school of literary theory. Ironically, one of the leading theorists from this school, Stanley Fish, was himself trained by New Critics. Fish criticizes Wimsatt and Beardsley in his 1970 essay \"Literature in the Reader\".\n\nAs summarized by Gaut and Livingston in their essay \"The Creation of Art\": \"Structuralist and post-structuralists theorists and critics were sharply critical of many aspects of New Criticism, beginning with the emphasis on aesthetic appreciation and the so-called autonomy of art, but they reiterated the attack on biographical criticisms' assumption that the artist's activities and experience were a privileged critical topic.\" These authors contend that: \"Anti-intentionalists, such as formalists, hold that the intentions involved in the making of art are irrelevant or peripheral to correctly interpreting art. So details of the act of creating a work, though possibly of interest in themselves, have no bearing on the correct interpretation of the work.\"\n\nGaut and Livingston define the intentionalists as distinct from formalists stating that: \"Intentionalists, unlike formalists, hold that reference to intentions is essential in fixing the correct interpretation of works.\" They quote Richard Wollheim as stating that, \"The task of criticism is the reconstruction of the creative process, where the creative process must in turn be thought of as something not stopping short of, but terminating on, the work of art itself.\"\n\n\"Linguistic turn\" and its debate\nThe end of the 20th century fostered an extensive debate known as the linguistic turn controversy, or the \"innocent eye debate\" in the philosophy of art. This debate discussed the encounter of the work of art as being determined by the relative extent to which the conceptual encounter with the work of art dominates over the perceptual encounter with the work of art.\n\nDecisive for the linguistic turn debate in art history and the humanities were the works of yet another tradition, namely the structuralism of Ferdinand de Saussure and the ensuing movement of poststructuralism. In 1981, the artist Mark Tansey created a work of art titled \"The Innocent Eye\" as a criticism of the prevailing climate of disagreement in the philosophy of art during the closing decades of the 20th century. Influential theorists include Judith Butler, Luce Irigaray, Julia Kristeva, Michel Foucault and Jacques Derrida. The power of language, more specifically of certain rhetorical tropes, in art history and historical discourse was explored by Hayden White. The fact that language is not a transparent medium of thought had been stressed by a very different form of philosophy of language which originated in the works of Johann Georg Hamann and Wilhelm von Humboldt. Ernst Gombrich and Nelson Goodman in his book Languages of Art: An Approach to a Theory of Symbols came to hold that the conceptual encounter with the work of art predominated exclusively over the perceptual and visual encounter with the work of art during the 1960s and 1970s. He was challenged on the basis of research done by the Nobel prize winning psychologist Roger Sperry who maintained that the human visual encounter was not limited to concepts represented in language alone (the linguistic turn) and that other forms of psychological representations of the work of art were equally defensible and demonstrable. Sperry's view eventually prevailed by the end of the 20th century with aesthetic philosophers such as Nick Zangwill strongly defending a return to moderate aesthetic formalism among other alternatives.\n\nClassification disputes\n\n Disputes as to whether or not to classify something as a work of art are referred to as classificatory disputes about art. Classificatory disputes in the 20th century have included cubist and impressionist paintings, Duchamp's Fountain, the movies, superlative imitations of banknotes, conceptual art, and video games. Philosopher David Novitz has argued that disagreement about the definition of art are rarely the heart of the problem. Rather, \"the passionate concerns and interests that humans vest in their social life\" are \"so much a part of all classificatory disputes about art.\" According to Novitz, classificatory disputes are more often disputes about societal values and where society is trying to go than they are about theory proper. For example, when the Daily Mail criticized Hirst's and Emin's work by arguing \"For 1,000 years art has been one of our great civilising forces. Today, pickled sheep and soiled beds threaten to make barbarians of us all\" they are not advancing a definition or theory about art, but questioning the value of Hirst's and Emin's work. In 1998, Arthur Danto, suggested a thought experiment showing that \"the status of an artifact as work of art results from the ideas a culture applies to it, rather than its inherent physical or perceptible qualities. Cultural interpretation (an art theory of some kind) is therefore constitutive of an object's arthood.\"\n\nAnti-art is a label for art that intentionally challenges the established parameters and values of art; it is term associated with Dadaism and attributed to Marcel Duchamp just before World War I, when he was making art from found objects. One of these,  Fountain (1917), an ordinary urinal, has achieved considerable prominence and influence on art. Anti-art is a feature of work by Situationist International, the lo-fi Mail art movement, and the Young British Artists, though it is a form still rejected by the Stuckists, who describe themselves as anti-anti-art.\n\nArchitecture is often included as one of the visual arts; however, like the decorative arts, or advertising, it involves the creation of objects where the practical considerations of use are essential in a way that they usually are not in a painting, for example.\n\nValue judgment\n\nSomewhat in relation to the above, the word art is also used to apply judgments of value, as in such expressions as \"that meal was a work of art\" (the cook is an artist), or \"the art of deception\" (the highly attained level of skill of the deceiver is praised). It is this use of the word as a measure of high quality and high value that gives the term its flavor of subjectivity. Making judgments of value requires a basis for criticism. At the simplest level, a way to determine whether the impact of the object on the senses meets the criteria to be considered art is whether it is perceived to be attractive or repulsive. Though perception is always colored by experience, and is necessarily subjective, it is commonly understood that what is not somehow aesthetically satisfying cannot be art. However, \"good\" art is not always or even regularly aesthetically appealing to a majority of viewers. In other words, an artist's prime motivation need not be the pursuit of the aesthetic. Also, art often depicts terrible images made for social, moral, or thought-provoking reasons. For example, Francisco Goya's painting depicting the Spanish shootings of 3 May 1808 is a graphic depiction of a firing squad executing several pleading civilians. Yet at the same time, the horrific imagery demonstrates Goya's keen artistic ability in composition and execution and produces fitting social and political outrage. Thus, the debate continues as to what mode of aesthetic satisfaction, if any, is required to define 'art'.\n\nThe assumption of new values or the rebellion against accepted notions of what is aesthetically superior need not occur concurrently with a complete abandonment of the pursuit of what is aesthetically appealing. Indeed, the reverse is often true, that the revision of what is popularly conceived of as being aesthetically appealing allows for a re-invigoration of aesthetic sensibility, and a new appreciation for the standards of art itself. Countless schools have proposed their own ways to define quality, yet they all seem to agree in at least one point: once their aesthetic choices are accepted, the value of the work of art is determined by its capacity to transcend the limits of its chosen medium to strike some universal chord by the rarity of the skill of the artist or in its accurate reflection in what is termed the zeitgeist. Art is often intended to appeal to and connect with human emotion. It can arouse aesthetic or moral feelings, and can be understood as a way of communicating these feelings. Artists express something so that their audience is aroused to some extent, but they do not have to do so consciously. Art may be considered an exploration of the human condition; that is, what it is to be human. By extension, it has been argued by Emily L. Spratt that the development of artificial intelligence, especially in regard to its uses with images, necessitates a re-evaluation of aesthetic theory in art history today and a reconsideration of the limits of human creativity.\n\nArt and law\nAn essential legal issue are art forgeries, plagiarism, replicas and works that are strongly based on other works of art.\n\nThe trade in works of art or the export from a country may be subject to legal regulations. Internationally there are also extensive efforts to protect the works of art created. The UN, UNESCO and Blue Shield International try to ensure effective protection at the national level and to intervene directly in the event of armed conflicts or disasters. This can particularly affect museums, archives, \nart collections and excavation sites. This should also secure the economic basis of a country, especially because works of art are often of tourist importance. The founding president of Blue Shield International, Karl von Habsburg, explained an additional connection between the destruction of cultural property and the cause of flight during a mission in Lebanon in April 2019: \u201cCultural goods are part of the identity of the people who live in a certain place. If you destroy their culture, you also destroy their identity. Many people are uprooted, often no longer have any prospects and as a result flee from their homeland.\u201d\n\nSee also\n\n Applied arts\n Art movement\n Artist in residence\n Artistic freedom\n Cultural tourism\n Craftivism\n Formal analysis\n History of art\n List of artistic media\n List of art techniques\n Mathematics and art\n Street art (or \"independent public art\")\n Outline of the visual arts, a guide to the subject of art presented as a tree structured list of its subtopics.\nVisual impairment in art\n\nNotes\n\nBibliography\n Oscar Wilde, Intentions, 1891\n Stephen Davies, Definitions of Art, 1991\n Nina Felshin, ed. But is it Art?, 1995\n Catherine de Zegher (ed.). Inside the Visible. MIT Press, 1996\n Evelyn Hatcher, ed. Art as Culture: An Introduction to the Anthropology of Art, 1999\n Noel Carroll, Theories of Art Today, 2000\n John Whitehead. Grasping for the Wind, 2001\n Michael Ann Holly and Keith Moxey (eds.) Art History Aesthetics Visual Studies. New Haven: Yale University Press, 2002. \n Shiner, Larry. The Invention of Art: A Cultural History. Chicago: University of Chicago Press, 2003. \n Arthur Danto, The Abuse of Beauty: Aesthetics and the Concept of Art. 2003\n Dana Arnold and Margaret Iverson, eds. Art and Thought. London: Blackwell, 2003. \n Jean Robertson and Craig McDaniel, Themes of Contemporary Art, Visual Art after 1980, 2005\n\nFurther reading\n Antony Briant and Griselda Pollock, eds. Digital and Other Virtualities: Renegotiating the image. London and NY: I.B.Tauris, 2010. \n Augros, Robert M., Stanciu, George N. The New Story of Science: mind and the universe, Lake Bluff, Ill.: Regnery Gateway, 1984.  (this book has significant material on art and science)\n Benedetto Croce. Aesthetic as Science of Expression and General Linguistic, 2002\n Botar, Oliver A.I. Technical Detours: The Early Moholy-Nagy Reconsidered. Art Gallery of The Graduate Center, The City University of New York and The Salgo Trust for Education, 2006. \n Burguete, Maria, and Lam, Lui, eds. (2011). Arts: A Science Matter. World Scientific: Singapore. \n Carol Armstrong and Catherine de Zegher, eds. Women Artists at the Millennium. Massachusetts: October Books/The MIT Press, 2006. \n Carl Jung, Man and His Symbols. London: Pan Books, 1978. \n E.H. Gombrich, The Story of Art. London: Phaidon Press, 1995. \n Florian Dombois, Ute Meta Bauer, Claudia Mareis and Michael Schwab, eds. Intellectual Birdhouse. Artistic Practice as Research. London: Koening Books, 2012. \n Katharine Everett Gilbert and Helmut Kuhn, A History of Esthetics. Edition 2, revised. Indiana: Indiana University Press, 1953.\n Kristine Stiles and Peter Selz, eds. Theories and Documents of Contemporary Art. Berkeley: University of California Press, 1986\n Kleiner, Gardner, Mamiya and Tansey. Art Through the Ages, Twelfth Edition (2 volumes) Wadsworth, 2004.  (vol 1) and  (vol 2)\n Richard Wollheim, Art and its Objects: An introduction to aesthetics. New York: Harper & Row, 1968. \n Will Gompertz. What Are You Looking At?: 150 Years of Modern Art in the Blink of an Eye. New York: Viking, 2012. \n W\u0142adys\u0142aw Tatarkiewicz, A History of Six Ideas: an Essay in Aesthetics, translated from the Polish by Christopher Kasparek, The Hague, Martinus Nijhoff, 1980\n\nExternal links\n\n Art and Play from the Dictionary of the History of ideas\n In-depth directory of art\n Art and Artist Files in the Smithsonian Libraries Collection (2005) Smithsonian Digital Libraries\n Visual Arts Data Service (VADS) \u2013 online collections from UK museums, galleries, universities\n RevolutionArt \u2013 Art magazines with worldwide exhibitions, callings and competitions\n \n \n\n \nAesthetics\nVisual arts",
  "Chemistry": "Chemistry is the scientific study of the properties and behavior of matter. It is a natural science that covers the elements that make up matter to the compounds composed of atoms, molecules and ions: their composition, structure, properties, behavior and the changes they undergo during a reaction with other substances.\n\nIn the scope of its subject, chemistry occupies an intermediate position between physics and biology. It is sometimes called the central science because it provides a foundation for understanding both basic and applied scientific disciplines at a fundamental level. For example, chemistry explains aspects of plant chemistry (botany), the formation of igneous rocks (geology), how atmospheric ozone is formed and how environmental pollutants are degraded (ecology), the properties of the soil on the moon (cosmochemistry), how medications work (pharmacology), and how to collect DNA evidence at a crime scene (forensics).\n\nChemistry addresses topics such as how atoms and molecules interact via chemical bonds to form new chemical compounds. There are two types of chemical bonds: 1. primary chemical bonds e.g covalent bonds, in which atoms share one or more electron(s); ionic bonds, in which an atom donates one or more electrons to another atom to produce ions (cations and anions); metallic bonds and 2. secondary chemical bonds e.g. hydrogen bonds; Van der Waals force bonds, ion-ion interaction, ion-dipole interaction etc.\n\nEtymology\nThe word chemistry comes from a modification of the word alchemy, which referred to an earlier set of practices that encompassed elements of chemistry, metallurgy, philosophy, astrology, astronomy, mysticism and medicine. Alchemy is often seen as linked to the quest to turn lead or other base metals into gold, though alchemists were also interested in many of the questions of modern chemistry.\n\nThe modern word alchemy in turn is derived from the Arabic word  (). This may have Egyptian origins since  is derived from the Ancient Greek , which is in turn derived from the word , which is the ancient name of Egypt in the Egyptian language. Alternately,  may derive from   'cast together'.\n\nModern principles\n\nThe current model of atomic structure is the quantum mechanical model. Traditional chemistry starts with the study of elementary particles, atoms, molecules, substances, metals, crystals and other aggregates of matter. Matter can be studied in solid, liquid, gas and plasma states, in isolation or in combination. The interactions, reactions and transformations that are studied in chemistry are usually the result of interactions between atoms, leading to rearrangements of the chemical bonds which hold atoms together. Such behaviors are studied in a chemistry laboratory.\n\nThe chemistry laboratory stereotypically uses various forms of laboratory glassware. However glassware is not central to chemistry, and a great deal of experimental (as well as applied/industrial) chemistry is done without it.\n\nA chemical reaction is a transformation of some substances into one or more different substances. The basis of such a chemical transformation is the rearrangement of electrons in the chemical bonds between atoms. It can be symbolically depicted through a chemical equation, which usually involves atoms as subjects. The number of atoms on the left and the right in the equation for a chemical transformation is equal. (When the number of atoms on either side is unequal, the transformation is referred to as a nuclear reaction or radioactive decay.) The type of chemical reactions a substance may undergo and the energy changes that may accompany it are constrained by certain basic rules, known as chemical laws.\n\nEnergy and entropy considerations are invariably important in almost all chemical studies. Chemical substances are classified in terms of their structure, phase, as well as their chemical compositions. They can be analyzed using the tools of chemical analysis, e.g. spectroscopy and chromatography. Scientists engaged in chemical research are known as chemists. Most chemists specialize in one or more sub-disciplines. Several concepts are essential for the study of chemistry; some of them are:\n\nMatter\n\nIn chemistry, matter is defined as anything that has rest mass and volume (it takes up space) and is made up of particles. The particles that make up matter have rest mass as well \u2013 not all particles have rest mass, such as the photon. Matter can be a pure chemical substance or a mixture of substances.\n\nAtom\n\nThe atom is the basic unit of chemistry. It consists of a dense core called the atomic nucleus surrounded by a space occupied by an electron cloud. The nucleus is made up of positively charged protons and uncharged neutrons (together called nucleons), while the electron cloud consists of negatively charged electrons which orbit the nucleus. In a neutral atom, the negatively charged electrons balance out the positive charge of the protons. The nucleus is dense; the mass of a nucleon is approximately 1,836 times that of an electron, yet the radius of an atom is about 10,000 times that of its nucleus.\n\nThe atom is also the smallest entity that can be envisaged to retain the chemical properties of the element, such as electronegativity, ionization potential, preferred oxidation state(s), coordination number, and preferred types of bonds to form (e.g., metallic, ionic, covalent).\n\nElement\n\nA chemical element is a pure substance which is composed of a single type of atom, characterized by its particular number of protons in the nuclei of its atoms, known as the atomic number and represented by the symbol Z. The mass number is the sum of the number of protons and neutrons in a nucleus. Although all the nuclei of all atoms belonging to one element will have the same atomic number, they may not necessarily have the same mass number; atoms of an element which have different mass numbers are known as isotopes. For example, all atoms with 6 protons in their nuclei are atoms of the chemical element carbon, but atoms of carbon may have mass numbers of 12 or 13.\n\nThe standard presentation of the chemical elements is in the periodic table, which orders elements by atomic number. The periodic table is arranged in groups, or columns, and periods, or rows. The periodic table is useful in identifying periodic trends.\n\nCompound\n\nA compound is a pure chemical substance composed of more than one element. The properties of a compound bear little similarity to those of its elements. The standard nomenclature of compounds is set by the International Union of Pure and Applied Chemistry (IUPAC). Organic compounds are named according to the organic nomenclature system. The names for inorganic compounds are created according to the inorganic nomenclature system. When a compound has more than one component, then they are divided into two classes, the electropositive and the electronegative components. In addition the Chemical Abstracts Service has devised a method to index chemical substances. In this scheme each chemical substance is identifiable by a number known as its CAS registry number.\n\nMolecule\n\nA molecule is the smallest indivisible portion of a pure chemical substance that has its unique set of chemical properties, that is, its potential to undergo a certain set of chemical reactions with other substances. However, this definition only works well for substances that are composed of molecules, which is not true of many substances (see below). Molecules are typically a set of atoms bound together by covalent bonds, such that the structure is electrically neutral and all valence electrons are paired with other electrons either in bonds or in lone pairs.\n\nThus, molecules exist as electrically neutral units, unlike ions. When this rule is broken, giving the \"molecule\" a charge, the result is sometimes named a molecular ion or a polyatomic ion. However, the discrete and separate nature of the molecular concept usually requires that molecular ions be present only in well-separated form, such as a directed beam in a vacuum in a mass spectrometer. Charged polyatomic collections residing in solids (for example, common sulfate or nitrate ions) are generally not considered \"molecules\" in chemistry. Some molecules contain one or more unpaired electrons, creating radicals. Most radicals are comparatively reactive, but some, such as nitric oxide (NO) can be stable.\n\nThe \"inert\" or noble gas elements (helium, neon, argon, krypton, xenon and radon) are composed of lone atoms as their smallest discrete unit, but the other isolated chemical elements consist of either molecules or networks of atoms bonded to each other in some way. Identifiable molecules compose familiar substances such as water, air, and many organic compounds like alcohol, sugar, gasoline, and the various pharmaceuticals.\n\nHowever, not all substances or chemical compounds consist of discrete molecules, and indeed most of the solid substances that make up the solid crust, mantle, and core of the Earth are chemical compounds without molecules. These other types of substances, such as ionic compounds and network solids, are organized in such a way as to lack the existence of identifiable molecules per se. Instead, these substances are discussed in terms of formula units or unit cells as the smallest repeating structure within the substance. Examples of such substances are mineral salts (such as table salt), solids like carbon and diamond, metals, and familiar silica and silicate minerals such as quartz and granite.\n\nOne of the main characteristics of a molecule is its geometry often called its structure. While the structure of diatomic, triatomic or tetra-atomic molecules may be trivial, (linear, angular pyramidal etc.) the structure of polyatomic molecules, that are constituted of more than six atoms (of several elements) can be crucial for its chemical nature.\n\nSubstance and mixture\n\nA chemical substance is a kind of matter with a definite composition and set of properties. A collection of substances is called a mixture. Examples of mixtures are air and alloys.\n\nMole and amount of substance\n\nThe mole is a unit of measurement that denotes an amount of substance (also called chemical amount). One mole is defined to contain exactly  particles (atoms, molecules, ions, or electrons), where the number of particles per mole is known as the Avogadro constant. Molar concentration is the amount of a particular substance per volume of solution, and is commonly reported in mol/dm3.\n\nPhase\n\nIn addition to the specific chemical properties that distinguish different chemical classifications, chemicals can exist in several phases. For the most part, the chemical classifications are independent of these bulk phase classifications; however, some more exotic phases are incompatible with certain chemical properties. A phase is a set of states of a chemical system that have similar bulk structural properties, over a range of conditions, such as pressure or temperature.\n\nPhysical properties, such as density and refractive index tend to fall within values characteristic of the phase. The phase of matter is defined by the phase transition, which is when energy put into or taken out of the system goes into rearranging the structure of the system, instead of changing the bulk conditions.\n\nSometimes the distinction between phases can be continuous instead of having a discrete boundary' in this case the matter is considered to be in a supercritical state. When three states meet based on the conditions, it is known as a triple point and since this is invariant, it is a convenient way to define a set of conditions.\n\nThe most familiar examples of phases are solids, liquids, and gases. Many substances exhibit multiple solid phases. For example, there are three phases of solid iron (alpha, gamma, and delta) that vary based on temperature and pressure. A principal difference between solid phases is the crystal structure, or arrangement, of the atoms. Another phase commonly encountered in the study of chemistry is the aqueous phase, which is the state of substances dissolved in aqueous solution (that is, in water).\n\nLess familiar phases include plasmas, Bose\u2013Einstein condensates and fermionic condensates and the paramagnetic and ferromagnetic phases of magnetic materials. While most familiar phases deal with three-dimensional systems, it is also possible to define analogs in two-dimensional systems, which has received attention for its relevance to systems in biology.\n\nBonding\n\nAtoms sticking together in molecules or crystals are said to be bonded with one another. A chemical bond may be visualized as the multipole balance between the positive charges in the nuclei and the negative charges oscillating about them. More than simple attraction and repulsion, the energies and distributions characterize the availability of an electron to bond to another atom.\n\nThe chemical bond can be a covalent bond, an ionic bond, a hydrogen bond or just because of Van der Waals force. Each of these kinds of bonds is ascribed to some potential. These potentials create the interactions which hold atoms together in molecules or crystals. In many simple compounds, valence bond theory, the Valence Shell Electron Pair Repulsion model (VSEPR), and the concept of oxidation number can be used to explain molecular structure and composition.\n\nAn ionic bond is formed when a metal loses one or more of its electrons, becoming a positively charged cation, and the electrons are then gained by the non-metal atom, becoming a negatively charged anion. The two oppositely charged ions attract one another, and the ionic bond is the electrostatic force of attraction between them. For example, sodium (Na), a metal, loses one electron to become an Na+ cation while chlorine (Cl), a non-metal, gains this electron to become Cl\u2212. The ions are held together due to electrostatic attraction, and that compound sodium chloride (NaCl), or common table salt, is formed.\n\nIn a covalent bond, one or more pairs of valence electrons are shared by two atoms: the resulting electrically neutral group of bonded atoms is termed a molecule. Atoms will share valence electrons in such a way as to create a noble gas electron configuration (eight electrons in their outermost shell) for each atom. Atoms that tend to combine in such a way that they each have eight electrons in their valence shell are said to follow the octet rule. However, some elements like hydrogen and lithium need only two electrons in their outermost shell to attain this stable configuration; these atoms are said to follow the duet rule, and in this way they are reaching the electron configuration of the noble gas helium, which has two electrons in its outer shell.\n\nSimilarly, theories from classical physics can be used to predict many ionic structures. With more complicated compounds, such as metal complexes, valence bond theory is less applicable and alternative approaches, such as the molecular orbital theory, are generally used. See diagram on electronic orbitals.\n\nEnergy\n\nIn the context of chemistry, energy is an attribute of a substance as a consequence of its atomic, molecular or aggregate structure. Since a chemical transformation is accompanied by a change in one or more of these kinds of structures, it is invariably accompanied by an increase or decrease of energy of the substances involved. Some energy is transferred between the surroundings and the reactants of the reaction in the form of heat or light; thus the products of a reaction may have more or less energy than the reactants.\n\nA reaction is said to be exergonic if the final state is lower on the energy scale than the initial state; in the case of endergonic reactions the situation is the reverse. A reaction is said to be exothermic if the reaction releases heat to the surroundings; in the case of endothermic reactions, the reaction absorbs heat from the surroundings.\n\nChemical reactions are invariably not possible unless the reactants surmount an energy barrier known as the activation energy. The speed of a chemical reaction (at given temperature T) is related to the activation energy E, by the Boltzmann's population factor  \u2013 that is the probability of a molecule to have energy greater than or equal to E at the given temperature T. This exponential dependence of a reaction rate on temperature is known as the Arrhenius equation.\nThe activation energy necessary for a chemical reaction to occur can be in the form of heat, light, electricity or mechanical force in the form of ultrasound.\n\nA related concept free energy, which also incorporates entropy considerations, is a very useful means for predicting the feasibility of a reaction and determining the state of equilibrium of a chemical reaction, in chemical thermodynamics. A reaction is feasible only if the total change in the Gibbs free energy is negative, ; if it is equal to zero the chemical reaction is said to be at equilibrium.\n\nThere exist only limited possible states of energy for electrons, atoms and molecules. These are determined by the rules of quantum mechanics, which require quantization of energy of a bound system. The atoms/molecules in a higher energy state are said to be excited. The molecules/atoms of substance in an excited energy state are often much more reactive; that is, more amenable to chemical reactions.\n\nThe phase of a substance is invariably determined by its energy and the energy of its surroundings. When the intermolecular forces of a substance are such that the energy of the surroundings is not sufficient to overcome them, it occurs in a more ordered phase like liquid or solid as is the case with water (H2O); a liquid at room temperature because its molecules are bound by hydrogen bonds. Whereas hydrogen sulfide (H2S) is a gas at room temperature and standard pressure, as its molecules are bound by weaker dipole-dipole interactions.\n\nThe transfer of energy from one chemical substance to another depends on the size of energy quanta emitted from one substance. However, heat energy is often transferred more easily from almost any substance to another because the phonons responsible for vibrational and rotational energy levels in a substance have much less energy than photons invoked for the electronic energy transfer. Thus, because vibrational and rotational energy levels are more closely spaced than electronic energy levels, heat is more easily transferred between substances relative to light or other forms of electronic energy. For example, ultraviolet electromagnetic radiation is not transferred with as much efficacy from one substance to another as thermal or electrical energy.\n\nThe existence of characteristic energy levels for different chemical substances is useful for their identification by the analysis of spectral lines. Different kinds of spectra are often used in chemical spectroscopy, e.g. IR, microwave, NMR, ESR, etc. Spectroscopy is also used to identify the composition of remote objects \u2013 like stars and distant galaxies \u2013 by analyzing their radiation spectra.\n\nThe term chemical energy is often used to indicate the potential of a chemical substance to undergo a transformation through a chemical reaction or to transform other chemical substances.\n\nReaction\n\nWhen a chemical substance is transformed as a result of its interaction with another substance or with energy, a chemical reaction is said to have occurred. A chemical reaction is therefore a concept related to the \"reaction\" of a substance when it comes in close contact with another, whether as a mixture or a solution; exposure to some form of energy, or both. It results in some energy exchange between the constituents of the reaction as well as with the system environment, which may be designed vessels\u2014often laboratory glassware.\n\nChemical reactions can result in the formation or dissociation of molecules, that is, molecules breaking apart to form two or more molecules or rearrangement of atoms within or across molecules. Chemical reactions usually involve the making or breaking of chemical bonds. Oxidation, reduction, dissociation, acid\u2013base neutralization and molecular rearrangement are some of the commonly used kinds of chemical reactions.\n\nA chemical reaction can be symbolically depicted through a chemical equation. While in a non-nuclear chemical reaction the number and kind of atoms on both sides of the equation are equal, for a nuclear reaction this holds true only for the nuclear particles viz. protons and neutrons.\n\nThe sequence of steps in which the reorganization of chemical bonds may be taking place in the course of a chemical reaction is called its mechanism. A chemical reaction can be envisioned to take place in a number of steps, each of which may have a different speed. Many reaction intermediates with variable stability can thus be envisaged during the course of a reaction. Reaction mechanisms are proposed to explain the kinetics and the relative product mix of a reaction. Many physical chemists specialize in exploring and proposing the mechanisms of various chemical reactions. Several empirical rules, like the Woodward\u2013Hoffmann rules often come in handy while proposing a mechanism for a chemical reaction.\n\nAccording to the IUPAC gold book, a chemical reaction is \"a process that results in the interconversion of chemical species.\" Accordingly, a chemical reaction may be an elementary reaction or a stepwise reaction. An additional caveat is made, in that this definition includes cases where the interconversion of conformers is experimentally observable. Such detectable chemical reactions normally involve sets of molecular entities as indicated by this definition, but it is often conceptually convenient to use the term also for changes involving single molecular entities (i.e. 'microscopic chemical events').\n\nIons and salts\n\nAn ion is a charged species, an atom or a molecule, that has lost or gained one or more electrons. When an atom loses an electron and thus has more protons than electrons, the atom is a positively charged ion or cation. When an atom gains an electron and thus has more electrons than protons, the atom is a negatively charged ion or anion. Cations and anions can form a crystalline lattice of neutral salts, such as the Na+ and Cl\u2212 ions forming sodium chloride, or NaCl. Examples of polyatomic ions that do not split up during acid\u2013base reactions are hydroxide (OH\u2212) and phosphate (PO43\u2212).\n\nPlasma is composed of gaseous matter that has been completely ionized, usually through high temperature.\n\nAcidity and basicity\n\nA substance can often be classified as an acid or a base. There are several different theories which explain acid\u2013base behavior. The simplest is Arrhenius theory, which states that acid is a substance that produces hydronium ions when it is dissolved in water, and a base is one that produces hydroxide ions when dissolved in water. According to Br\u00f8nsted\u2013Lowry acid\u2013base theory, acids are substances that donate a positive hydrogen ion to another substance in a chemical reaction; by extension, a base is the substance which receives that hydrogen ion.\n\nA third common theory is Lewis acid\u2013base theory, which is based on the formation of new chemical bonds. Lewis theory explains that an acid is a substance which is capable of accepting a pair of electrons from another substance during the process of bond formation, while a base is a substance which can provide a pair of electrons to form a new bond. According to this theory, the crucial things being exchanged are charges. There are several other ways in which a substance may be classified as an acid or a base, as is evident in the history of this concept.\n\nAcid strength is commonly measured by two methods. One measurement, based on the Arrhenius definition of acidity, is pH, which is a measurement of the hydronium ion concentration in a solution, as expressed on a negative logarithmic scale. Thus, solutions that have a low pH have a high hydronium ion concentration and can be said to be more acidic. The other measurement, based on the Br\u00f8nsted\u2013Lowry definition, is the acid dissociation constant (Ka), which measures the relative ability of a substance to act as an acid under the Br\u00f8nsted\u2013Lowry definition of an acid. That is, substances with a higher Ka are more likely to donate hydrogen ions in chemical reactions than those with lower Ka values.\n\nRedox\n\nRedox (reduction-oxidation) reactions include all chemical reactions in which atoms have their oxidation state changed by either gaining electrons (reduction) or losing electrons (oxidation). Substances that have the ability to oxidize other substances are said to be oxidative and are known as oxidizing agents, oxidants or oxidizers. An oxidant removes electrons from another substance. Similarly, substances that have the ability to reduce other substances are said to be reductive and are known as reducing agents, reductants, or reducers.\n\nA reductant transfers electrons to another substance and is thus oxidized itself. And because it \"donates\" electrons it is also called an electron donor. Oxidation and reduction properly refer to a change in oxidation number\u2014the actual transfer of electrons may never occur. Thus, oxidation is better defined as an increase in oxidation number, and reduction as a decrease in oxidation number.\n\nEquilibrium\n\nAlthough the concept of equilibrium is widely used across sciences, in the context of chemistry, it arises whenever a number of different states of the chemical composition are possible, as for example, in a mixture of several chemical compounds that can react with one another, or when a substance can be present in more than one kind of phase.\n\nA system of chemical substances at equilibrium, even though having an unchanging composition, is most often not static; molecules of the substances continue to react with one another thus giving rise to a dynamic equilibrium. Thus the concept describes the state in which the parameters such as chemical composition remain unchanged over time.\n\nChemical laws\n\nChemical reactions are governed by certain laws, which have become fundamental concepts in chemistry. Some of them are:\n\n Avogadro's law\n Beer\u2013Lambert law\n Boyle's law (1662, relating pressure and volume)\n Charles's law (1787, relating volume and temperature)\n Fick's laws of diffusion\n Gay-Lussac's law (1809, relating pressure and temperature)\n Le Chatelier's principle\n Henry's law\n Hess's law\n Law of conservation of energy leads to the important concepts of equilibrium, thermodynamics, and kinetics.\n Law of conservation of mass continues to be conserved in isolated systems, even in modern physics. However, special relativity shows that due to mass\u2013energy equivalence, whenever non-material \"energy\" (heat, light, kinetic energy) is removed from a non-isolated system, some mass will be lost with it. High energy losses result in loss of weighable amounts of mass, an important topic in nuclear chemistry.\n Law of definite composition, although in many systems (notably biomacromolecules and minerals) the ratios tend to require large numbers, and are frequently represented as a fraction.\n Law of multiple proportions\n Raoult's law\n\nHistory\n\nThe history of chemistry spans a period from very old times to the present. Since several millennia BC, civilizations were using technologies that would eventually form the basis of the various branches of chemistry. Examples include extracting metals from ores, making pottery and glazes, fermenting beer and wine, extracting chemicals from plants for medicine and perfume, rendering fat into soap, making glass, and making alloys like bronze. Chemistry was preceded by its protoscience, alchemy, which is an intuitive but non-scientific approach to understanding the constituents of matter and their interactions. It was unsuccessful in explaining the nature of matter and its transformations, but, by performing experiments and recording the results, alchemists set the stage for modern chemistry. Chemistry as a body of knowledge distinct from alchemy began to emerge when a clear differentiation was made between them by Robert Boyle in his work The Sceptical Chymist (1661). While both alchemy and chemistry are concerned with matter and its transformations, the crucial difference was given by the scientific method that chemists employed in their work. Chemistry is considered to have become an established science with the work of Antoine Lavoisier, who developed a law of conservation of mass that demanded careful measurement and quantitative observations of chemical phenomena. The history of chemistry is intertwined with the history of thermodynamics, especially through the work of Willard Gibbs.\n\nDefinition\nThe definition of chemistry has changed over time, as new discoveries and theories add to the functionality of the science. The term \"chymistry\", in the view of noted scientist Robert Boyle in 1661, meant the subject of the material principles of mixed bodies. In 1663, the chemist Christopher Glaser described \"chymistry\" as a scientific art, by which one learns to dissolve bodies, and draw from them the different substances on their composition, and how to unite them again, and exalt them to a higher perfection.\n\nThe 1730 definition of the word \"chemistry\", as used by Georg Ernst Stahl, meant the art of resolving mixed, compound, or aggregate bodies into their principles; and of composing such bodies from those principles. In 1837, Jean-Baptiste Dumas considered the word \"chemistry\" to refer to the science concerned with the laws and effects of molecular forces. This definition further evolved until, in 1947, it came to mean the science of substances: their structure, their properties, and the reactions that change them into other substances \u2013 a characterization accepted by Linus Pauling. More recently, in 1998, Professor Raymond Chang broadened the definition of \"chemistry\" to mean the study of matter and the changes it undergoes.\n\nDiscipline\n\nEarly civilizations, such as the Egyptians Babylonians and Indians amassed practical knowledge concerning the arts of metallurgy, pottery and dyes, but didn't develop a systematic theory.\n\nA basic chemical hypothesis first emerged in Classical Greece with the theory of four elements as propounded definitively by Aristotle stating that fire, air, earth and water were the fundamental elements from which everything is formed as a combination. Greek atomism dates back to 440 BC, arising in works by philosophers such as Democritus and Epicurus. In 50 BCE, the Roman philosopher Lucretius expanded upon the theory in his book De rerum natura (On The Nature of Things). Unlike modern concepts of science, Greek atomism was purely philosophical in nature, with little concern for empirical observations and no concern for chemical experiments.\n\nAn early form of the idea of conservation of mass is the notion that \"Nothing comes from nothing\" in Ancient Greek philosophy, which can be found in Empedocles (approx. 4th century BC): \"For it is impossible for anything to come to be from what is not, and it cannot be brought about or heard of that what is should be utterly destroyed.\" and Epicurus (3rd century BC), who, describing the nature of the Universe, wrote that \"the totality of things was always such as it is now, and always will be\".\n\nIn the Hellenistic world the art of alchemy first proliferated, mingling magic and occultism into the study of natural substances with the ultimate goal of transmuting elements into gold and discovering the elixir of eternal life. Work, particularly the development of distillation, continued in the early Byzantine period with the most famous practitioner being the 4th century Greek-Egyptian Zosimos of Panopolis. Alchemy continued to be developed and practised throughout the Arab world after the Muslim conquests, and from there, and from the Byzantine remnants, diffused into medieval and Renaissance Europe through Latin translations.\n\nThe Arabic works attributed to Jabir ibn Hayyan introduced a systematic classification of chemical substances, and provided instructions for deriving an inorganic compound (sal ammoniac or ammonium chloride) from organic substances (such as plants, blood, and hair) by chemical means. Some Arabic Jabirian works (e.g., the \"Book of Mercy\", and the \"Book of Seventy\") were later translated into Latin under the Latinized name \"Geber\", and in 13th-century Europe an anonymous writer, usually referred to as pseudo-Geber, started to produce alchemical and metallurgical writings under this name. Later influential Muslim philosophers, such as Ab\u016b al-Rayh\u0101n al-B\u012br\u016bn\u012b and Avicenna disputed the theories of alchemy, particularly the theory of the transmutation of metals.\n\nUnder the influence of the new empirical methods propounded by Sir Francis Bacon and others, a group of chemists at Oxford, Robert Boyle, Robert Hooke and John Mayow began to reshape the old alchemical traditions into a scientific discipline. Boyle in particular is regarded as the founding father of chemistry due to his most important work, the classic chemistry text The Sceptical Chymist where the differentiation is made between the claims of alchemy and the empirical scientific discoveries of the new chemistry. He formulated Boyle's law, rejected the classical \"four elements\" and proposed a mechanistic alternative of atoms and chemical reactions that could be subject to rigorous experiment.\n\nThe theory of phlogiston (a substance at the root of all combustion) was propounded by the German Georg Ernst Stahl in the early 18th century and was only overturned by the end of the century by the French chemist Antoine Lavoisier, the chemical analogue of Newton in physics; who did more than any other to establish the new science on proper theoretical footing, by elucidating the principle of conservation of mass and developing a new system of chemical nomenclature used to this day.\n\nBefore his work, though, many important discoveries had been made, specifically relating to the nature of 'air' which was discovered to be composed of many different gases. The Scottish chemist Joseph Black (the first experimental chemist) and the Flemish Jan Baptist van Helmont discovered carbon dioxide, or what Black called 'fixed air' in 1754; Henry Cavendish discovered hydrogen and elucidated its properties and Joseph Priestley and, independently, Carl Wilhelm Scheele isolated pure oxygen.\n\nEnglish scientist John Dalton proposed the modern theory of atoms; that all substances are composed of indivisible 'atoms' of matter and that different atoms have varying atomic weights.\n\nThe development of the electrochemical theory of chemical combinations occurred in the early 19th century as the result of the work of two scientists in particular, J\u00f6ns Jacob Berzelius and Humphry Davy, made possible by the prior invention of the voltaic pile by Alessandro Volta. Davy discovered nine new elements including the alkali metals by extracting them from their oxides with electric current.\n\nBritish William Prout first proposed ordering all the elements by their atomic weight as all atoms had a weight that was an exact multiple of the atomic weight of hydrogen. J.A.R. Newlands devised an early table of elements, which was then developed into the modern periodic table of elements in the 1860s by Dmitri Mendeleev and independently by several other scientists including Julius Lothar Meyer. The inert gases, later called the noble gases were discovered by William Ramsay in collaboration with Lord Rayleigh at the end of the century, thereby filling in the basic structure of the table.\n\nAt the turn of the twentieth century the theoretical underpinnings of chemistry were finally understood due to a series of remarkable discoveries that succeeded in probing and discovering the very nature of the internal structure of atoms. In 1897, J.J. Thomson of Cambridge University discovered the electron and soon after the French scientist Becquerel as well as the couple Pierre and Marie Curie investigated the phenomenon of radioactivity. In a series of pioneering scattering experiments Ernest Rutherford at the University of Manchester discovered the internal structure of the atom and the existence of the proton, classified and explained the different types of radioactivity and successfully transmuted the first element by bombarding nitrogen with alpha particles.\n\nHis work on atomic structure was improved on by his students, the Danish physicist Niels Bohr and Henry Moseley. The electronic theory of chemical bonds and molecular orbitals was developed by the American scientists Linus Pauling and Gilbert N. Lewis.\n\nThe year 2011 was declared by the United Nations as the International Year of Chemistry. It was an initiative of the International Union of Pure and Applied Chemistry, and of the United Nations Educational, Scientific, and Cultural Organization and involves chemical societies, academics, and institutions worldwide and relied on individual initiatives to organize local and regional activities.\n\nOrganic chemistry was developed by Justus von Liebig and others, following Friedrich W\u00f6hler's synthesis of urea which proved that living organisms were, in theory, reducible to chemistry. Other crucial 19th century advances were; an understanding of valence bonding (Edward Frankland in 1852) and the application of thermodynamics to chemistry (J. W. Gibbs and Svante Arrhenius in the 1870s).\n\nPractice\n\nSubdisciplines\n\nChemistry is typically divided into several major sub-disciplines. There are also several main cross-disciplinary and more specialized fields of chemistry.\n Analytical chemistry is the analysis of material samples to gain an understanding of their chemical composition and structure. Analytical chemistry incorporates standardized experimental methods in chemistry. These methods may be used in all subdisciplines of chemistry, excluding purely theoretical chemistry.\n Biochemistry is the study of the chemicals, chemical reactions and chemical interactions that take place in living organisms. Biochemistry and organic chemistry are closely related, as in medicinal chemistry or neurochemistry. Biochemistry is also associated with molecular biology and genetics.\n Inorganic chemistry is the study of the properties and reactions of inorganic compounds. The distinction between organic and inorganic disciplines is not absolute and there is much overlap, most importantly in the sub-discipline of organometallic chemistry.\n Materials chemistry is the preparation, characterization, and understanding of substances with a useful function. The field is a new breadth of study in graduate programs, and it integrates elements from all classical areas of chemistry with a focus on fundamental issues that are unique to materials. Primary systems of study include the chemistry of condensed phases (solids, liquids, polymers) and interfaces between different phases.\n Neurochemistry is the study of neurochemicals; including transmitters, peptides, proteins, lipids, sugars, and nucleic acids; their interactions, and the roles they play in forming, maintaining, and modifying the nervous system.\n Nuclear chemistry is the study of how subatomic particles come together and make nuclei. Modern Transmutation is a large component of nuclear chemistry, and the table of nuclides is an important result and tool for this field.\n Organic chemistry is the study of the structure, properties, composition, mechanisms, and reactions of organic compounds. An organic compound is defined as any compound based on a carbon skeleton.\n Physical chemistry is the study of the physical and fundamental basis of chemical systems and processes. In particular, the energetics and dynamics of such systems and processes are of interest to physical chemists. Important areas of study include chemical thermodynamics, chemical kinetics, electrochemistry, statistical mechanics, spectroscopy, and more recently, astrochemistry. Physical chemistry has large overlap  with molecular physics. Physical chemistry involves the use of infinitesimal calculus in deriving equations. It is usually associated with quantum chemistry and theoretical chemistry. Physical chemistry is a distinct discipline from chemical physics, but again, there is very strong overlap.\n Theoretical chemistry is the study of chemistry via fundamental theoretical reasoning (usually within mathematics or physics). In particular the application of quantum mechanics to chemistry is called quantum chemistry. Since the end of the Second World War, the development of computers has allowed a systematic development of computational chemistry, which is the art of developing and applying computer programs for solving chemical problems. Theoretical chemistry has large overlap with (theoretical and experimental) condensed matter physics and molecular physics.\n\nOther disciplines within chemistry are traditionally grouped by the type of matter being studied or the kind of study. These include inorganic chemistry, the study of inorganic matter; organic chemistry, the study of organic (carbon-based) matter; biochemistry, the study of substances found in biological organisms; physical chemistry, the study of chemical processes using physical concepts such as thermodynamics and quantum mechanics; and analytical chemistry, the analysis of material samples to gain an understanding of their chemical composition and structure. Many more specialized disciplines have emerged in recent years, e.g. neurochemistry the chemical study of the nervous system (see subdisciplines).\n\nOther fields include agrochemistry, astrochemistry (and cosmochemistry), atmospheric chemistry, chemical engineering, chemical biology, chemo-informatics, electrochemistry, environmental chemistry, femtochemistry, flavor chemistry, flow chemistry, geochemistry, green chemistry, histochemistry, history of chemistry, hydrogenation chemistry, immunochemistry, marine chemistry, materials science, mathematical chemistry, mechanochemistry, medicinal chemistry, molecular biology, molecular mechanics, nanotechnology, natural product chemistry, oenology, organometallic chemistry, petrochemistry, pharmacology, photochemistry, physical organic chemistry, phytochemistry, polymer chemistry, radiochemistry, solid-state chemistry, sonochemistry, supramolecular chemistry, surface chemistry, synthetic chemistry, thermochemistry, and many others.\n\nIndustry\n\nThe chemical industry represents an important economic activity worldwide. The global top 50 chemical producers in 2013 had sales of US$980.5 billion with a profit margin of 10.3%.\n\nProfessional societies\n\n American Chemical Society\n American Society for Neurochemistry\n Chemical Institute of Canada\n Chemical Society of Peru\n International Union of Pure and Applied Chemistry\n Royal Australian Chemical Institute\n Royal Netherlands Chemical Society\n Royal Society of Chemistry\n Society of Chemical Industry\n World Association of Theoretical and Computational Chemists\n List of chemistry societies\n\nSee also\n\n Comparison of software for molecular mechanics modeling\n Glossary of chemistry terms\n International Year of Chemistry\n List of chemists\n List of compounds\n List of important publications in chemistry\n List of unsolved problems in chemistry\n Outline of chemistry\n Periodic systems of small molecules\n Philosophy of chemistry\n Science tourism\n\nReferences\n\nBibliography\n\nFurther reading\n Popular reading\n Atkins, P.W. Galileo's Finger (Oxford University Press) \n Atkins, P.W. Atkins' Molecules (Cambridge University Press) \n Kean, Sam. The Disappearing Spoon \u2013 and Other True Tales from the Periodic Table (Black Swan) London, 2010 \n Levi, Primo The Periodic Table (Penguin Books) [1975] translated from the Italian by Raymond Rosenthal (1984) \n Stwertka, A. A Guide to the Elements (Oxford University Press) \n \n \n\n Introductory undergraduate textbooks\n Atkins, P.W., Overton, T., Rourke, J., Weller, M. and Armstrong, F. Shriver and Atkins Inorganic Chemistry (4th edition) 2006 (Oxford University Press) \n Chang, Raymond. Chemistry 6th ed. Boston: James M. Smith, 1998. .\n \n Voet and Voet. Biochemistry (Wiley) \n\n Advanced undergraduate-level or graduate textbooks\n\n Atkins, P. W. Physical Chemistry (Oxford University Press) \n Atkins, P. W. et al. Molecular Quantum Mechanics (Oxford University Press)\n McWeeny, R. Coulson's Valence (Oxford Science Publications) \n Pauling, L. The Nature of the chemical bond (Cornell University Press) \n Pauling, L., and Wilson, E.B. Introduction to Quantum Mechanics with Applications to Chemistry (Dover Publications) \n Smart and Moore. Solid State Chemistry: An Introduction (Chapman and Hall) \n Stephenson, G. Mathematical Methods for Science Students (Longman)\n\nExternal links\n\n General Chemistry principles, patterns and applications.",
  "Economics": "Economics () is \"the social science that studies the production, distribution, and consumption of goods and services.\"\n\nEconomics focuses on the behaviour and interactions of economic agents and how economies work. Microeconomics is a field which analyzes what's viewed as basic elements in the economy, including individual agents and markets, their interactions, and the outcomes of interactions. Individual agents may include, for example, households, firms, buyers, and sellers. Macroeconomics analyzes the economy as a system where production, consumption, saving, and investment interact, and factors affecting it: employment of the resources of labour, capital, and land, currency inflation, economic growth, and public policies that have impact on these elements.\n\nOther broad distinctions within economics include those between positive economics, describing \"what is\", and normative economics, advocating \"what ought to be\"; between economic theory and applied economics; between rational and behavioural economics; and between mainstream economics and heterodox economics.\n\nEconomic analysis can be applied throughout society, including real estate, business, finance, health care, engineering and government. It is also applied to such diverse subjects as crime, education, the family, feminism, law, philosophy, politics, religion, social institutions, war, science, and the environment.\n\nDefinitions of economics over time \n\nThe earlier term for the discipline was 'political economy'.Since the late 19th century, it has commonly been called 'economics'., cited to the Ancient Greek  (oikonomikos), \"practiced in the management of a household or family\" and therefore \"frugal, thrifty\", which in turn comes from  (oikonomia) \"household management\" which in turn comes from  ( \"house\") and  (, \"custom\" or \"law\").}}\n\nThere are a variety of modern definitions of economics; some reflect evolving views of the subject or different views among economists. Scottish philosopher Adam Smith (1776) defined what was then called political economy as \"an inquiry into the nature and causes of the wealth of nations\", in particular as:\n\nJean-Baptiste Say (1803), distinguishing the subject from its public-policy uses, defines it as the science of production, distribution, and consumption of wealth. On the satirical side, Thomas Carlyle (1849) coined \"the dismal science\" as an epithet for classical economics, in this context, commonly linked to the pessimistic analysis of Malthus (1798). John Stuart Mill (1844) defines the subject in a social context as:\n\nAlfred Marshall provides a still widely cited definition in his textbook Principles of Economics (1890) that extends analysis beyond wealth and from the societal to the microeconomic level:\n\nLionel Robbins (1932) developed implications of what has been termed \"[p]erhaps the most commonly accepted current definition of the subject\":\n\nRobbins describes the definition as not classificatory in \"pick[ing] out certain kinds of behaviour\" but rather analytical in \"focus[ing] attention on a particular aspect of behaviour, the form imposed by the influence of scarcity.\" He affirmed that previous economists have usually centred their studies on the analysis of wealth: how wealth is created (production), distributed, and consumed; and how wealth can grow. But he said that economics can be used to study other things, such as war, that are outside its usual focus.  This is because war has as the goal winning it (as a sought after end), generates both cost and benefits; and, resources (human life and other costs) are used to attain the goal.  If the war is not winnable or if the expected costs outweigh the benefits, the deciding actors (assuming they are rational) may never go to war (a decision) but rather explore other alternatives. We cannot define economics as the science that studies wealth, war, crime, education, and any other field economic analysis can be applied to; but, as the science that studies a particular common aspect of each of those subjects (they all use scarce resources to attain a sought after end).\n\nSome subsequent comments criticized the definition as overly broad in failing to limit its subject matter to analysis of markets. From the 1960s, however, such comments abated as the economic theory of maximizing behaviour and rational-choice modelling expanded the domain of the subject to areas previously treated in other fields. There are other criticisms as well, such as in scarcity not accounting for the macroeconomics of high unemployment.\n\nGary Becker, a contributor to the expansion of economics into new areas, describes the approach he favours as \"combin[ing the] assumptions of maximizing behaviour, stable preferences, and market equilibrium, used relentlessly and unflinchingly.\" One commentary characterizes the remark as making economics an approach rather than a subject matter but with great specificity as to the \"choice process and the type of social interaction that [such] analysis involves.\" The same source reviews a range of definitions included in principles of economics textbooks and concludes that the lack of agreement need not affect the subject-matter that the texts treat. Among economists more generally, it argues that a particular definition presented may reflect the direction toward which the author believes economics is evolving, or should evolve.\n\nAccording to economist Ha-Joon Chang economics should be defined not in terms of its methodology or theoretical approach but in terms of its subject matter. Ha-Joon Chang finds a definition like \"the science which studies human behavior as a relationship between ends and scarce means which have alternative uses\" very peculiar because all other sciences define themselves in terms of the area of inquiry or object of inquiry rather than the methodology. In the biology department, they don\u2019t say that all biology should be studied with DNA analysis. People study living organisms in many different ways, so some people will do DNA analysis, others might do anatomy, and still others might build game theoretic models of animal behavior. But they are all called biology because they all study living organisms. According to Ha Joon Chang, this view that you can and should study the economy in only one way (for example by studying only rational choices), and going even one step further and basically redefining economics as a theory of everything, is very peculiar.\n\nHistory of economic thought\n\nFrom antiquity through the physiocrats \n\"Economic\" writings date from earlier Mesopotamian, Greek, Roman, Indian subcontinent, Chinese, Persian, and Arab civilizations. Questions regarding distribution of resources are found throughout the writings of the Boeotian poet Hesiod and several economic historians have described Hesiod himself as the \"first economist\". However, the word Oikos, the greek word from which the word economy derives, was used for issues regarding how to manage a household, rather than to refer to some normative societal system of distribution of resources, which is a much more recent phenomenon. Other notable writers from Antiquity through to the Renaissance include Aristotle, Xenophon, Chanakya (also known as Kautilya), Qin Shi Huang, Ibn Khaldun, and Thomas Aquinas.  Joseph Schumpeter described 16th and 17th century scholastic writers, including Tom\u00e1s de Mercado, Luis de Molina, and Juan de Lugo, as \"coming nearer than any other group to being the 'founders' of scientific economics\" as to monetary, interest, and value theory within a natural-law perspective.\n\nTwo groups, who later were called \"mercantilists\" and \"physiocrats\", more directly influenced the subsequent development of the subject. Both groups were associated with the rise of economic nationalism and modern capitalism in Europe. Mercantilism was an economic doctrine that flourished from the 16th to 18th century in a prolific pamphlet literature, whether of merchants or statesmen. It held that a nation's wealth depended on its accumulation of gold and silver. Nations without access to mines could obtain gold and silver from trade only by selling goods abroad and restricting imports other than of gold and silver. The doctrine called for importing cheap raw materials to be used in manufacturing goods, which could be exported, and for state regulation to impose protective tariffs on foreign manufactured goods and prohibit manufacturing in the colonies.\n\nPhysiocrats, a group of 18th-century French thinkers and writers, developed the idea of the economy as a circular flow of income and output. Physiocrats believed that only agricultural production generated a clear surplus over cost, so that agriculture was the basis of all wealth. Thus, they opposed the mercantilist policy of promoting manufacturing and trade at the expense of agriculture, including import tariffs. Physiocrats advocated replacing administratively costly tax collections with a single tax on income of land owners. In reaction against copious mercantilist trade regulations, the physiocrats advocated a policy of laissez-faire, which called for minimal government intervention in the economy.\n\nAdam Smith (1723\u20131790) was an early economic theorist. Smith was harshly critical of the mercantilists but described the physiocratic system \"with all its imperfections\" as \"perhaps the purest approximation to the truth that has yet been published\" on the subject.\n\nClassical political economy \n\nThe publication of Adam Smith's The Wealth of Nations in 1776, has been described as \"the effective birth of economics as a separate discipline.\" The book identified land, labour, and capital as the three factors of production and the major contributors to a nation's wealth, as distinct from the physiocratic idea that only agriculture was productive.\n\nSmith discusses potential benefits of specialization by division of labour, including increased labour productivity and gains from trade, whether between town and country or across countries. His \"theorem\" that \"the division of labor is limited by the extent of the market\" has been described as the \"core of a theory of the functions of firm and industry\" and a \"fundamental principle of economic organization.\" To Smith has also been ascribed \"the most important substantive proposition in all of economics\" and foundation of resource-allocation theory \u2013 that, under competition, resource owners (of labour, land, and capital) seek their most profitable uses, resulting in an equal rate of return for all uses in equilibrium (adjusted for apparent differences arising from such factors as training and unemployment).\n\nIn an argument that includes \"one of the most famous passages in all economics,\" Smith represents every individual as trying to employ any capital they might command for their own advantage, not that of the society, and for the sake of profit, which is necessary at some level for employing capital in domestic industry, and positively related to the value of produce. In this:\n\nThe Rev. Thomas Robert Malthus (1798) used the concept of diminishing returns to explain low living standards. Human population, he argued, tended to increase geometrically, outstripping the production of food, which increased arithmetically. The force of a rapidly growing population against a limited amount of land meant diminishing returns to labour. The result, he claimed, was chronically low wages, which prevented the standard of living for most of the population from rising above the subsistence level. Economist Julian Lincoln Simon has criticized Malthus's conclusions.\n\nWhile Adam Smith emphasized the production of income, David Ricardo (1817) focused on the distribution of income among landowners, workers, and capitalists. Ricardo saw an inherent conflict between landowners on the one hand and labour and capital on the other. He posited that the growth of population and capital, pressing against a fixed supply of land, pushes up rents and holds down wages and profits. Ricardo was the first to state and prove the principle of comparative advantage, according to which each country should specialize in producing and exporting goods in that it has a lower relative cost of production, rather relying only on its own production. It has been termed a \"fundamental analytical explanation\" for gains from trade.\n\nComing at the end of the classical tradition, John Stuart Mill (1848) parted company with the earlier classical economists on the inevitability of the distribution of income produced by the market system. Mill pointed to a distinct difference between the market's two roles: allocation of resources and distribution of income. The market might be efficient in allocating resources but not in distributing income, he wrote, making it necessary for society to intervene.\n\nValue theory was important in classical theory. Smith wrote that the \"real price of every thing\u00a0... is the toil and trouble of acquiring it\". Smith maintained that, with rent and profit, other costs besides wages also enter the price of a commodity. Other classical economists presented variations on Smith, termed the 'labour theory of value'. Classical economics focused on the tendency of any market economy to settle in a final stationary state made up of a constant stock of physical wealth (capital) and a constant population size.\n\nMarxian economics \n\nMarxist (later, Marxian) economics descends from classical economics and it derives from the work of Karl Marx. The first volume of Marx's major work, Das Kapital, was published in German in 1867. In it, Marx focused on the labour theory of value and the theory of surplus value which, he believed, explained the exploitation of labour by capital. The labour theory of value held that the value of an exchanged commodity was determined by the labour that went into its production and the theory of surplus value demonstrated how the workers only got paid a proportion of the value their work had created.\n\nNeoclassical economics \n\nAt the dawn as a social science, economics was defined and discussed at length as the study of production, distribution, and consumption of wealth by Jean-Baptiste Say in his Treatise on Political Economy or, The Production, Distribution, and Consumption of Wealth (1803). These three items are considered by the science only in relation to the increase or diminution of wealth, and not in reference to their processes of execution. Say's definition has prevailed up to our time, saved by substituting the word \"wealth\" for \"goods and services\" meaning that wealth may include non-material objects as well. One hundred and thirty years later, Lionel Robbins noticed that this definition no longer sufficed, because many economists were making theoretical and philosophical inroads in other areas of human activity. In his Essay on the Nature and Significance of Economic Science, he proposed a definition of economics as a study of a particular aspect of human behaviour, the one that falls under the influence of scarcity, which forces people to choose, allocate scarce resources to competing ends, and economize (seeking the greatest welfare while avoiding the wasting of scarce resources). For Robbins, the insufficiency was solved, and his definition allows us to proclaim, with an easy conscience, education economics, safety and security economics, health economics, war economics, and of course, production, distribution and consumption economics as valid subjects of the economic science.\"  Citing Robbins: \"Economics is the science which studies human behavior as a relationship between ends and scarce means which have alternative uses\". After discussing it for decades, Robbins' definition became widely accepted by mainstream economists, and it has opened way into current textbooks. Although far from unanimous, most mainstream economists would accept some version of Robbins' definition, even though many have raised serious objections to the scope and method of economics, emanating from that definition. Due to the lack of strong consensus, and that production, distribution and consumption of goods and services is the prime area of study of economics, the old definition still stands in many quarters.\n\nA body of theory later termed \"neoclassical economics\" or \"marginalism\" formed from about 1870 to 1910. The term \"economics\" was popularized by such neoclassical economists as Alfred Marshall as a concise synonym for \"economic science\" and a substitute for the earlier \"political economy\". This corresponded to the influence on the subject of mathematical methods used in the natural sciences.\n\nNeoclassical economics systematized supply and demand as joint determinants of price and quantity in market equilibrium, affecting both the allocation of output and the distribution of income. It dispensed with the labour theory of value inherited from classical economics in favour of a marginal utility theory of value on the demand side and a more general theory of costs on the supply side. In the 20th century, neoclassical theorists moved away from an earlier notion suggesting that total utility for a society could be measured in favour of ordinal utility, which hypothesizes merely behaviour-based relations across persons.\n\nIn microeconomics, neoclassical economics represents incentives and costs as playing a pervasive role in shaping decision making. An immediate example of this is the consumer theory of individual demand, which isolates how prices (as costs) and income affect quantity demanded. In macroeconomics it is reflected in an early and lasting neoclassical synthesis with Keynesian macroeconomics.\n\nNeoclassical economics is occasionally referred as orthodox economics whether by its critics or sympathizers. Modern mainstream economics builds on neoclassical economics but with many refinements that either supplement or generalize earlier analysis, such as econometrics, game theory, analysis of market failure and imperfect competition, and the neoclassical model of economic growth for analysing long-run variables affecting national income.\n\nNeoclassical economics studies the behaviour of individuals, households, and organizations (called economic actors, players, or agents), when they manage or use scarce resources, which have alternative uses, to achieve desired ends. Agents are assumed to act rationally, have multiple desirable ends in sight, limited resources to obtain these ends, a set of stable preferences, a definite overall guiding objective, and the capability of making a choice. There exists an economic problem, subject to study by economic science, when a decision (choice) is made by one or more resource-controlling players to attain the best possible outcome under bounded rational conditions. In other words, resource-controlling agents maximize value subject to the constraints imposed by the information the agents have, their cognitive limitations, and the finite amount of time they have to make and execute a decision. Economic science centres on the activities of the economic agents that comprise society. They are the focus of economic analysis.\n\nAn approach to understanding these processes, through the study of agent behaviour under scarcity, may go as follows:\n\nThe continuous interplay (exchange or trade) done by economic actors in all markets sets the prices for all goods and services which, in turn, make the rational managing of scarce resources possible. At the same time, the decisions (choices) made by the same actors, while they are pursuing their own interest, determine the level of output (production), consumption, savings, and investment, in an economy, as well as the remuneration (distribution) paid to the owners of labour (in the form of wages), capital (in the form of profits) and land (in the form of rent). Each period, as if they were in a giant feedback system, economic players influence the pricing processes and the economy, and are in turn influenced by them until a steady state (equilibrium) of all variables involved is reached or until an external shock throws the system toward a new equilibrium point. Because of the autonomous actions of rational interacting agents, the economy is a complex adaptive system.\n\nKeynesian economics \n\nKeynesian economics derives from John Maynard Keynes, in particular his book The General Theory of Employment, Interest and Money (1936), which ushered in contemporary macroeconomics as a distinct field. The book focused on determinants of national income in the short run when prices are relatively inflexible. Keynes attempted to explain in broad theoretical detail why high labour-market unemployment might not be self-correcting due to low \"effective demand\" and why even price flexibility and monetary policy might be unavailing. The term \"revolutionary\" has been applied to the book in its impact on economic analysis.\n\nKeynesian economics has two successors. Post-Keynesian economics also concentrates on macroeconomic rigidities and adjustment processes. Research on micro foundations for their models is represented as based on real-life practices rather than simple optimizing models. It is generally associated with the University of Cambridge and the work of Joan Robinson.\n\nNew-Keynesian economics is also associated with developments in the Keynesian fashion. Within this group researchers tend to share with other economists the emphasis on models employing micro foundations and optimizing behaviour but with a narrower focus on standard Keynesian themes such as price and wage rigidity. These are usually made to be endogenous features of the models, rather than simply assumed as in older Keynesian-style ones.\n\nChicago school of economics \n\nThe Chicago School of economics is best known for its free market advocacy and monetarist ideas. According to Milton Friedman and monetarists, market economies are inherently stable if the money supply does not greatly expand or contract. Ben Bernanke, former Chairman of the Federal Reserve, is among the economists today generally accepting Friedman's analysis of the causes of the Great Depression.\n\nMilton Friedman effectively took many of the basic principles set forth by Adam Smith and the classical economists and modernized them. One example of this is his article in the 13 September 1970 issue of The New York Times Magazine, in which he claims that the social responsibility of business should be \"to use its resources and engage in activities designed to increase its profits\u00a0... (through) open and free competition without deception or fraud.\"\n\nAustrian School of Economics \n\nThe Austrian school emphasizes human action, property rights and the freedom to contract and transact to have a thriving and successful economy. It also emphasizes that the state should play an infinitesimally small role (if any role) in the regulation of economic activity between two transacting parties. A key component of Austrian economics is the principle of sound money. As Ludwig Von Mises, one of the most prominent 20th century Austrian economists, stated, \"Ideologically it (sound money) belongs in the same class with political constitutions and bills of rights.\" Austrian economists assert that sound money prevents government actors from debasing the currency, disrupting the savings rate of the population and artificially distorting the economic choices of individual actors.\n\nThe influence of this strain of economic thought resulted in the creation of the Mises Institute, an economic think tank inspired by the works of Ludwig Von Mises, Murray Rothbard, Hans Hermann Hoppe, and others. The mission of the institute is to stress the importance of sound money, property rights, and individual human action in a healthy economy.\n\nOther schools and approaches \n\nOther well-known schools or trends of thought referring to a particular style of economics practised at and disseminated from well-defined groups of academicians that have become known worldwide, include the Freiburg School, the School of Lausanne, post-Keynesian economics and the Stockholm school. Contemporary mainstream economics is sometimes separated into the Saltwater approach of those universities along the Eastern and Western coasts of the US, and the Freshwater, or Chicago-school approach.\n\nWithin macroeconomics there is, in general order of their historical appearance in the literature; classical economics, neoclassical economics, Keynesian economics, the neoclassical synthesis, monetarism, new classical economics, New Keynesian economics and the new neoclassical synthesis. In general, alternative developments include ecological economics, constitutional economics, institutional economics, evolutionary economics, dependency theory, structuralist economics, world systems theory, econophysics, econodynamics, feminist economics and biophysical economics.\n\nMethodology\n\nTheoretical research \n\nMainstream economic theory relies upon a priori quantitative economic models, which employ a variety of concepts. Theory typically proceeds with an assumption of ceteris paribus, which means holding constant explanatory variables other than the one under consideration. When creating theories, the objective is to find ones which are at least as simple in information requirements, more precise in predictions, and more fruitful in generating additional research than prior theories. While neoclassical economic theory constitutes both the dominant or orthodox theoretical as well as methodological framework, economic theory can also take the form of other schools of thought such as in heterodox economic theories.\n\nIn microeconomics, principal concepts include supply and demand, marginalism, rational choice theory, opportunity cost, budget constraints, utility, and the theory of the firm. Early macroeconomic models focused on modelling the relationships between aggregate variables, but as the relationships appeared to change over time macroeconomists, including new Keynesians, reformulated their models in microfoundations.\n\nThe aforementioned microeconomic concepts play a major part in macroeconomic models\u00a0\u2013 for instance, in monetary theory, the quantity theory of money predicts that increases in the growth rate of the money supply increase inflation, and inflation is assumed to be influenced by rational expectations. In development economics, slower growth in developed nations has been sometimes predicted because of the declining marginal returns of investment and capital, and this has been observed in the Four Asian Tigers. Sometimes an economic hypothesis is only qualitative, not quantitative.\n\nExpositions of economic reasoning often use two-dimensional graphs to illustrate theoretical relationships. At a higher level of generality, mathematical economics is the application of mathematical methods to represent theories and analyze problems in economics. Paul Samuelson's treatise Foundations of Economic Analysis (1947) exemplifies the method, particularly as to maximizing behavioral relations of agents reaching equilibrium. The book focused on examining the class of statements called operationally meaningful theorems in economics, which are theorems that can conceivably be refuted by empirical data.\n\nEmpirical research \n\nEconomic theories are frequently tested empirically, largely through the use of econometrics using economic data. The controlled experiments common to the physical sciences are difficult and uncommon in economics, and instead broad data is observationally studied; this type of testing is typically regarded as less rigorous than controlled experimentation, and the conclusions typically more tentative. However, the field of experimental economics is growing, and increasing use is being made of natural experiments.\n\nStatistical methods such as regression analysis are common. Practitioners use such methods to estimate the size, economic significance, and statistical significance (\"signal strength\") of the hypothesized relation(s) and to adjust for noise from other variables. By such means, a hypothesis may gain acceptance, although in a probabilistic, rather than certain, sense. Acceptance is dependent upon the falsifiable hypothesis surviving tests. Use of commonly accepted methods need not produce a final conclusion or even a consensus on a particular question, given different tests, data sets, and prior beliefs.\n\nCriticisms based on professional standards and non-replicability of results serve as further checks against bias, errors, and over-generalization, although much economic research has been accused of being non-replicable, and prestigious journals have been accused of not facilitating replication through the provision of the code and data. Like theories, uses of test statistics are themselves open to critical analysis, although critical commentary on papers in economics in prestigious journals such as the American Economic Review has declined precipitously in the past 40 years. This has been attributed to journals' incentives to maximize citations in order to rank higher on the Social Science Citation Index (SSCI).\n\nIn applied economics, input\u2013output models employing linear programming methods are quite common. Large amounts of data are run through computer programs to analyse the impact of certain policies; IMPLAN is one well-known example.\n\nExperimental economics has promoted the use of scientifically controlled experiments. This has reduced the long-noted distinction of economics from natural sciences because it allows direct tests of what were previously taken as axioms. In some cases these have found that the axioms are not entirely correct; for example, the ultimatum game has revealed that people reject unequal offers.\n\nIn behavioural economics, psychologist Daniel Kahneman won the Nobel Prize in economics in 2002 for his and Amos Tversky's empirical discovery of several cognitive biases and heuristics. Similar empirical testing occurs in neuroeconomics. Another example is the assumption of narrowly selfish preferences versus a model that tests for selfish, altruistic, and cooperative preferences. These techniques have led some to argue that economics is a \"genuine science\".\n\nBranches of economics\n\nMicroeconomics \n\nMicroeconomics examines how entities, forming a market structure, interact within a market to create a market system. These entities include private and public players with various classifications, typically operating under scarcity of tradable units and light government regulation. The item traded may be a tangible product such as apples or a service such as repair services, legal counsel, or entertainment.\n\nIn theory, in a free market the aggregates (sum of) of quantity demanded by buyers and quantity supplied by sellers may reach economic equilibrium over time in reaction to price changes; in practice, various issues may prevent equilibrium, and any equilibrium reached may not necessarily be morally equitable. For example, if the supply of healthcare services is limited by external factors, the equilibrium price may be unaffordable for many who desire it but cannot pay for it.\n\nVarious market structures exist. In perfectly competitive markets, no participants are large enough to have the market power to set the price of a homogeneous product. In other words, every participant is a \"price taker\" as no participant influences the price of a product. In the real world, markets often experience imperfect competition.\n\nForms include monopoly (in which there is only one seller of a good), duopoly (in which there are only two sellers of a good), oligopoly (in which there are few sellers of a good), monopolistic competition (in which there are many sellers producing highly differentiated goods), monopsony (in which there is only one buyer of a good), and oligopsony (in which there are few buyers of a good). Unlike perfect competition, imperfect competition invariably means market power is unequally distributed. Firms under imperfect competition have the potential to be \"price makers\", which means that, by holding a disproportionately high share of market power, they can influence the prices of their products.\n\nMicroeconomics studies individual markets by simplifying the economic system by assuming that activity in the market being analysed does not affect other markets. This method of analysis is known as partial-equilibrium analysis (supply and demand). This method aggregates (the sum of all activity) in only one market. General-equilibrium theory studies various markets and their behaviour. It aggregates (the sum of all activity) across all markets. This method studies both changes in markets and their interactions leading towards equilibrium.\n\nProduction, cost, and efficiency \n\nIn microeconomics, production is the conversion of inputs into outputs. It is an economic process that uses inputs to create a commodity or a service for exchange or direct use. Production is a flow and thus a rate of output per period of time. Distinctions include such production alternatives as for consumption (food, haircuts, etc.) vs. investment goods (new tractors, buildings, roads, etc.), public goods (national defence, smallpox vaccinations, etc.) or private goods (new computers, bananas, etc.), and \"guns\" vs \"butter\".\n\nOpportunity cost is the economic cost of production: the value of the next best opportunity foregone. Choices must be made between desirable yet mutually exclusive actions. It has been described as expressing \"the basic relationship between scarcity and choice\". For example, if a baker uses a sack of flour to make pretzels one morning, then the baker cannot use either the flour or the morning to make bagels instead.  Part of the cost of making pretzels is that neither the flour nor the morning are available any longer, for use in some other way.  The opportunity cost of an activity is an element in ensuring that scarce resources are used efficiently, such that the cost is weighed against the value of that activity in deciding on more or less of it. Opportunity costs are not restricted to monetary or financial costs but could be measured by the real cost of output forgone, leisure, or anything else that provides the alternative benefit (utility).\n\nInputs used in the production process include such primary factors of production as labour services, capital (durable produced goods used in production, such as an existing factory), and land (including natural resources). Other inputs may include intermediate goods used in production of final goods, such as the steel in a new car.\n\nEconomic efficiency measures how well a system generates desired output with a given set of inputs and available technology. Efficiency is improved if more output is generated without changing inputs, or in other words, the amount of \"waste\" is reduced. A widely accepted general standard is Pareto efficiency, which is reached when no further change can make someone better off without making someone else worse off.\n\nThe production\u2013possibility frontier (PPF) is an expository figure for representing scarcity, cost, and efficiency. In the simplest case an economy can produce just two goods (say \"guns\" and \"butter\"). The PPF is a table or graph (as at the right) showing the different quantity combinations of the two goods producible with a given technology and total factor inputs, which limit feasible total output. Each point on the curve shows potential total output for the economy, which is the maximum feasible output of one good, given a feasible output quantity of the other good.\n\nScarcity is represented in the figure by people being willing but unable in the aggregate to consume beyond the PPF (such as at X) and by the negative slope of the curve. If production of one good increases along the curve, production of the other good decreases, an inverse relationship. This is because increasing output of one good requires transferring inputs to it from production of the other good, decreasing the latter.\n\nThe slope of the curve at a point on it gives the trade-off between the two goods. It measures what an additional unit of one good costs in units forgone of the other good, an example of a real opportunity cost. Thus, if one more Gun costs 100 units of butter, the opportunity cost of one Gun is 100 Butter. Along the PPF, scarcity implies that choosing more of one good in the aggregate entails doing with less of the other good. Still, in a market economy, movement along the curve may indicate that the choice of the increased output is anticipated to be worth the cost to the agents.\n\nBy construction, each point on the curve shows productive efficiency in maximizing output for given total inputs. A point inside the curve (as at A), is feasible but represents production inefficiency (wasteful use of inputs), in that output of one or both goods could increase by moving in a northeast direction to a point on the curve. Examples cited of such inefficiency include high unemployment during a business-cycle recession or economic organization of a country that discourages full use of resources. Being on the curve might still not fully satisfy allocative efficiency (also called Pareto efficiency) if it does not produce a mix of goods that consumers prefer over other points.\n\nMuch applied economics in public policy is concerned with determining how the efficiency of an economy can be improved. Recognizing the reality of scarcity and then figuring out how to organize society for the most efficient use of resources has been described as the \"essence of economics\", where the subject \"makes its unique contribution.\"\n\nSpecialization \n\nSpecialization is considered key to economic efficiency based on theoretical and empirical considerations. Different individuals or nations may have different real opportunity costs of production, say from differences in stocks of human capital per worker or capital/labour ratios. According to theory, this may give a comparative advantage in production of goods that make more intensive use of the relatively more abundant, thus relatively cheaper, input.\n\nEven if one region has an absolute advantage as to the ratio of its outputs to inputs in every type of output, it may still specialize in the output in which it has a comparative advantage and thereby gain from trading with a region that lacks any absolute advantage but has a comparative advantage in producing something else.\n\nIt has been observed that a high volume of trade occurs among regions even with access to a similar technology and mix of factor inputs, including high-income countries. This has led to investigation of economies of scale and agglomeration to explain specialization in similar but differentiated product lines, to the overall benefit of respective trading parties or regions.\n\nThe general theory of specialization applies to trade among individuals, farms, manufacturers, service providers, and economies. Among each of these production systems, there may be a corresponding division of labour with different work groups specializing, or correspondingly different types of capital equipment and differentiated land uses.\n\nAn example that combines features above is a country that specializes in the production of high-tech knowledge products, as developed countries do, and trades with developing nations for goods produced in factories where labour is relatively cheap and plentiful, resulting in different in opportunity costs of production. More total output and utility thereby results from specializing in production and trading than if each country produced its own high-tech and low-tech products.\n\nTheory and observation set out the conditions such that market prices of outputs and productive inputs select an allocation of factor inputs by comparative advantage, so that (relatively) low-cost inputs go to producing low-cost outputs. In the process, aggregate output may increase as a by-product or by design. Such specialization of production creates opportunities for gains from trade whereby resource owners benefit from trade in the sale of one type of output for other, more highly valued goods. A measure of gains from trade is the increased income levels that trade may facilitate.\n\nSupply and demand \n\nPrices and quantities have been described as the most directly observable attributes of goods produced and exchanged in a market economy. The theory of supply and demand is an organizing principle for explaining how prices coordinate the amounts produced and consumed. In microeconomics, it applies to price and output determination for a market with perfect competition, which includes the condition of no buyers or sellers large enough to have price-setting power.\n\nFor a given market of a commodity, demand is the relation of the quantity that all buyers would be prepared to purchase at each unit price of the good. Demand is often represented by a table or a graph showing price and quantity demanded (as in the figure). Demand theory describes individual consumers as rationally choosing the most preferred quantity of each good, given income, prices, tastes, etc. A term for this is \"constrained utility maximization\" (with income and wealth as the constraints on demand). Here, utility refers to the hypothesized relation of each individual consumer for ranking different commodity bundles as more or less preferred.\n\nThe law of demand states that, in general, price and quantity demanded in a given market are inversely related. That is, the higher the price of a product, the less of it people would be prepared to buy (other things unchanged). As the price of a commodity falls, consumers move toward it from relatively more expensive goods (the substitution effect). In addition, purchasing power from the price decline increases ability to buy (the income effect). Other factors can change demand; for example an increase in income will shift the demand curve for a normal good outward relative to the origin, as in the figure. All determinants are predominantly taken as constant factors of demand and supply.\n\nSupply is the relation between the price of a good and the quantity available for sale at that price. It may be represented as a table or graph relating price and quantity supplied. Producers, for example business firms, are hypothesized to be profit maximizers, meaning that they attempt to produce and supply the amount of goods that will bring them the highest profit. Supply is typically represented as a function relating price and quantity, if other factors are unchanged.\n\nThat is, the higher the price at which the good can be sold, the more of it producers will supply, as in the figure. The higher price makes it profitable to increase production. Just as on the demand side, the position of the supply can shift, say from a change in the price of a productive input or a technical improvement. The \"Law of Supply\" states that, in general, a rise in price leads to an expansion in supply and a fall in price leads to a contraction in supply. Here as well, the determinants of supply, such as price of substitutes, cost of production, technology applied and various factors inputs of production are all taken to be constant for a specific time period of evaluation of supply.\n\nMarket equilibrium occurs where quantity supplied equals quantity demanded, the intersection of the supply and demand curves in the figure above. At a price below equilibrium, there is a shortage of quantity supplied compared to quantity demanded. This is posited to bid the price up. At a price above equilibrium, there is a surplus of quantity supplied compared to quantity demanded. This pushes the price down. The model of supply and demand predicts that for given supply and demand curves, price and quantity will stabilize at the price that makes quantity supplied equal to quantity demanded. Similarly, demand-and-supply theory predicts a new price-quantity combination from a shift in demand (as to the figure), or in supply.\n\nFirms \n\nPeople frequently do not trade directly on markets. Instead, on the supply side, they may work in and produce through firms. The most obvious kinds of firms are corporations, partnerships and trusts. According to Ronald Coase, people begin to organize their production in firms when the costs of doing business becomes lower than doing it on the market. Firms combine labour and capital, and can achieve far greater economies of scale (when the average cost per unit declines as more units are produced) than individual market trading.\n\nIn perfectly competitive markets studied in the theory of supply and demand, there are many producers, none of which significantly influence price. Industrial organization generalizes from that special case to study the strategic behaviour of firms that do have significant control of price. It considers the structure of such markets and their interactions. Common market structures studied besides perfect competition include monopolistic competition, various forms of oligopoly, and monopoly.\n\nManagerial economics applies microeconomic analysis to specific decisions in business firms or other management units. It draws heavily from quantitative methods such as operations research and programming and from statistical methods such as regression analysis in the absence of certainty and perfect knowledge. A unifying theme is the attempt to optimize business decisions, including unit-cost minimization and profit maximization, given the firm's objectives and constraints imposed by technology and market conditions.\n\nUncertainty and game theory \n\nUncertainty in economics is an unknown prospect of gain or loss, whether quantifiable as risk or not. Without it, household behaviour would be unaffected by uncertain employment and income prospects, financial and capital markets would reduce to exchange of a single instrument in each market period, and there would be no communications industry. Given its different forms, there are various ways of representing uncertainty and modelling economic agents' responses to it.\n\nGame theory is a branch of applied mathematics that considers strategic interactions between agents, one kind of uncertainty. It provides a mathematical foundation of industrial organization, discussed above, to model different types of firm behaviour, for example in a solipsistic industry (few sellers), but equally applicable to wage negotiations, bargaining, contract design, and any situation where individual agents are few enough to have perceptible effects on each other. In behavioural economics, it has been used to model the strategies agents choose when interacting with others whose interests are at least partially adverse to their own.\n\nIn this, it generalizes maximization approaches developed to analyse market actors such as in the supply and demand model and allows for incomplete information of actors. The field dates from the 1944 classic Theory of Games and Economic Behavior by John von Neumann and Oskar Morgenstern. It has significant applications seemingly outside of economics in such diverse subjects as formulation of nuclear strategies, ethics, political science, and evolutionary biology.\n\nRisk aversion may stimulate activity that in well-functioning markets smooths out risk and communicates information about risk, as in markets for insurance, commodity futures contracts, and financial instruments. Financial economics or simply finance describes the allocation of financial resources. It also analyses the pricing of financial instruments, the financial structure of companies, the efficiency and fragility of financial markets, financial crises, and related government policy or regulation.\n\nSome market organizations may give rise to inefficiencies associated with uncertainty. Based on George Akerlof's \"Market for Lemons\" article, the paradigm example is of a dodgy second-hand car market. Customers without knowledge of whether a car is a \"lemon\" depress its price below what a quality second-hand car would be. Information asymmetry arises here, if the seller has more relevant information than the buyer but no incentive to disclose it. Related problems in insurance are adverse selection, such that those at most risk are most likely to insure (say reckless drivers), and moral hazard, such that insurance results in riskier behaviour (say more reckless driving).\n\nBoth problems may raise insurance costs and reduce efficiency by driving otherwise willing transactors from the market (\"incomplete markets\"). Moreover, attempting to reduce one problem, say adverse selection by mandating insurance, may add to another, say moral hazard. Information economics, which studies such problems, has relevance in subjects such as insurance, contract law, mechanism design, monetary economics, and health care. Applied subjects include market and legal remedies to spread or reduce risk, such as warranties, government-mandated partial insurance, restructuring or bankruptcy law, inspection, and regulation for quality and information disclosure.\n\nMarket failure \n\nThe term \"market failure\" encompasses several problems which may undermine standard economic assumptions. Although economists categorize market failures differently, the following categories emerge in the main texts.\n\nAuthors critical of economics tend to view the talk of \"market failiures\", as a term which is used when economic theories don't correspond with reality, making these theories and paradigms in which these terms are used unfalsifiable.\n\nInformation asymmetries and incomplete markets may result in economic inefficiency but also a possibility of improving efficiency through market, legal, and regulatory remedies, as discussed above.\n\nNatural monopoly, or the overlapping concepts of \"practical\" and \"technical\" monopoly, is an extreme case of failure of competition as a restraint on producers. Extreme economies of scale are one possible cause.\n\nPublic goods are goods which are under-supplied in a typical market. The defining features are that people can consume public goods without having to pay for them and that more than one person can consume the good at the same time.\n\nExternalities occur where there are significant social costs or benefits from production or consumption that are not reflected in market prices. For example, air pollution may generate a negative externality, and education may generate a positive externality (less crime, etc.). Governments often tax and otherwise restrict the sale of goods that have negative externalities and subsidize or otherwise promote the purchase of goods that have positive externalities in an effort to correct the price distortions caused by these externalities. Elementary demand-and-supply theory predicts equilibrium but not the speed of adjustment for changes of equilibrium due to a shift in demand or supply.\n\nIn many areas, some form of price stickiness is postulated to account for quantities, rather than prices, adjusting in the short run to changes on the demand side or the supply side. This includes standard analysis of the business cycle in macroeconomics. Analysis often revolves around causes of such price stickiness and their implications for reaching a hypothesized long-run equilibrium. Examples of such price stickiness in particular markets include wage rates in labour markets and posted prices in markets deviating from perfect competition.\n\nSome specialized fields of economics deal in market failure more than others. The economics of the public sector is one example. Much environmental economics concerns externalities or \"public bads\".\n\nPolicy options include regulations that reflect cost-benefit analysis or market solutions that change incentives, such as emission fees or redefinition of property rights.\n\nWelfare \n\nWelfare economics uses microeconomics techniques to evaluate well-being from allocation of productive factors as to desirability and economic efficiency within an economy, often relative to competitive general equilibrium. It analyzes social welfare, however measured, in terms of economic activities of the individuals that compose the theoretical society considered.  Accordingly, individuals, with associated economic activities, are the basic units for aggregating to social welfare, whether of a group, a community, or a society, and there is no \"social welfare\" apart from the \"welfare\" associated with its individual units.\n\nMacroeconomics \n\nMacroeconomics examines the economy as a whole to explain broad aggregates and their interactions \"top down\", that is, using a simplified form of general-equilibrium theory. Such aggregates include national income and output, the unemployment rate, and price inflation and subaggregates like total consumption and investment spending and their components. It also studies effects of monetary policy and fiscal policy.\n\nSince at least the 1960s, macroeconomics has been characterized by further integration as to micro-based modelling of sectors, including rationality of players, efficient use of market information, and imperfect competition. This has addressed a long-standing concern about inconsistent developments of the same subject.\n\nMacroeconomic analysis also considers factors affecting the long-term level and growth of national income. Such factors include capital accumulation, technological change and labour force growth.\n\nGrowth \n\nGrowth economics studies factors that explain economic growth\u00a0\u2013 the increase in output per capita of a country over a long period of time. The same factors are used to explain differences in the level of output per capita between countries, in particular why some countries grow faster than others, and whether countries converge at the same rates of growth.\n\nMuch-studied factors include the rate of investment, population growth, and technological change. These are represented in theoretical and empirical forms (as in the neoclassical and endogenous growth models) and in growth accounting.\n\nBusiness cycle \n\nThe economics of a depression were the spur for the creation of \"macroeconomics\" as a separate discipline. During the Great Depression of the 1930s, John Maynard Keynes authored a book entitled The General Theory of Employment, Interest and Money outlining the key theories of Keynesian economics. Keynes contended that aggregate demand for goods might be insufficient during economic downturns, leading to unnecessarily high unemployment and losses of potential output.\n\nHe therefore advocated active policy responses by the public sector, including monetary policy actions by the central bank and fiscal policy actions by the government to stabilize output over the business cycle.\nThus, a central conclusion of Keynesian economics is that, in some situations, no strong automatic mechanism moves output and employment towards full employment levels. John Hicks' IS/LM model has been the most influential interpretation of The General Theory.\n\nOver the years, understanding of the business cycle has branched into various research programmes, mostly related to or distinct from Keynesianism. The neoclassical synthesis refers to the reconciliation of Keynesian economics with neoclassical economics, stating that Keynesianism is correct in the short run but qualified by neoclassical-like considerations in the intermediate and long run.\n\nNew classical macroeconomics, as distinct from the Keynesian view of the business cycle, posits market clearing with imperfect information. It includes Friedman's permanent income hypothesis on consumption and \"rational expectations\" theory, led by Robert Lucas, and real business cycle theory.\n\nIn contrast, the new Keynesian approach retains the rational expectations assumption, however it assumes a variety of market failures. In particular, New Keynesians assume prices and wages are \"sticky\", which means they do not adjust instantaneously to changes in economic conditions.\n\nThus, the new classicals assume that prices and wages adjust automatically to attain full employment, whereas the new Keynesians see full employment as being automatically achieved only in the long run, and hence government and central-bank policies are needed because the \"long run\" may be very long.\n\nUnemployment \n\nThe amount of unemployment in an economy is measured by the unemployment rate, the percentage of workers without jobs in the labour force. The labour force only includes workers actively looking for jobs. People who are retired, pursuing education, or discouraged from seeking work by a lack of job prospects are excluded from the labour force. Unemployment can be generally broken down into several types that are related to different causes.\n\nClassical models of unemployment occurs when wages are too high for employers to be willing to hire more workers. Consistent with classical unemployment, frictional unemployment occurs when appropriate job vacancies exist for a worker, but the length of time needed to search for and find the job leads to a period of unemployment.\n\nStructural unemployment covers a variety of possible causes of unemployment including a mismatch between workers' skills and the skills required for open jobs. Large amounts of structural unemployment can occur when an economy is transitioning industries and workers find their previous set of skills are no longer in demand. Structural unemployment is similar to frictional unemployment since both reflect the problem of matching workers with job vacancies, but structural unemployment covers the time needed to acquire new skills not just the short term search process.\n\nWhile some types of unemployment may occur regardless of the condition of the economy, cyclical unemployment occurs when growth stagnates. Okun's law represents the empirical relationship between unemployment and economic growth. The original version of Okun's law states that a 3% increase in output would lead to a 1% decrease in unemployment.\n\nInflation and monetary policy \n\nMoney is a means of final payment for goods in most price system economies, and is the unit of account in which prices are typically stated. Money has general acceptability, relative consistency in value, divisibility, durability, portability, elasticity in supply, and longevity with mass public confidence. It includes currency held by the nonbank public and checkable deposits. It has been described as a social convention, like language, useful to one largely because it is useful to others. In the words of Francis Amasa Walker, a well-known 19th-century economist, \"Money is what money does\" (\"Money is that money does\" in the original).\n\nAs a medium of exchange, money facilitates trade. It is essentially a measure of value and more importantly, a store of value being a basis for credit creation. Its economic function can be contrasted with barter (non-monetary exchange). Given a diverse array of produced goods and specialized producers, barter may entail a hard-to-locate double coincidence of wants as to what is exchanged, say apples and a book. Money can reduce the transaction cost of exchange because of its ready acceptability. Then it is less costly for the seller to accept money in exchange, rather than what the buyer produces.\n\nAt the level of an economy, theory and evidence are consistent with a positive relationship running from the total money supply to the nominal value of total output and to the general price level. For this reason, management of the money supply is a key aspect of monetary policy.\n\nFiscal policy \n\nGovernments implement fiscal policy to influence macroeconomic conditions by adjusting spending and taxation policies to alter aggregate demand. When aggregate demand falls below the potential output of the economy, there is an output gap where some productive capacity is left unemployed. Governments increase spending and cut taxes to boost aggregate demand. Resources that have been idled can be used by the government.\n\nFor example, unemployed home builders can be hired to expand highways. Tax cuts allow consumers to increase their spending, which boosts aggregate demand. Both tax cuts and spending have multiplier effects where the initial increase in demand from the policy percolates through the economy and generates additional economic activity.\n\nThe effects of fiscal policy can be limited by crowding out. When there is no output gap, the economy is producing at full capacity and there are no excess productive resources. If the government increases spending in this situation, the government uses resources that otherwise would have been used by the private sector, so there is no increase in overall output. Some economists think that crowding out is always an issue while others do not think it is a major issue when output is depressed.\n\nSceptics of fiscal policy also make the argument of Ricardian equivalence. They argue that an increase in debt will have to be paid for with future tax increases, which will cause people to reduce their consumption and save money to pay for the future tax increase. Under Ricardian equivalence, any boost in demand from tax cuts will be offset by the increased saving intended to pay for future higher taxes.\n\nPublic economics \n\nPublic economics is the field of economics that deals with economic activities of a public sector, usually government. The subject addresses such matters as tax incidence (who really pays a particular tax), cost-benefit analysis of government programmes, effects on economic efficiency and income distribution of different kinds of spending and taxes, and fiscal politics. The latter, an aspect of public choice theory, models public-sector behaviour analogously to microeconomics, involving interactions of self-interested voters, politicians, and bureaucrats.\n\nMuch of economics is positive, seeking to describe and predict economic phenomena. Normative economics seeks to identify what economies ought to be like.\n\nWelfare economics is a normative branch of economics that uses microeconomic techniques to simultaneously determine the allocative efficiency within an economy and the income distribution associated with it. It attempts to measure social welfare by examining the economic activities of the individuals that comprise society.\n\nInternational economics \n\nInternational trade studies determinants of goods-and-services flows across international boundaries. It also concerns the size and distribution of gains from trade. Policy applications include estimating the effects of changing tariff rates and trade quotas. International finance is a macroeconomic field which examines the flow of capital across international borders, and the effects of these movements on exchange rates. Increased trade in goods, services and capital between countries is a major effect of contemporary globalization.\n\nLabor economics \n\nLabor economics seeks to understand the functioning and dynamics of the markets for wage labor. Labor markets function through the interaction of workers and employers. Labor economics looks at the suppliers of labor services (workers), the demands of labor services (employers), and attempts to understand the resulting pattern of wages, employment, and income.  In economics, labor  is a measure of the work done by human beings. It is conventionally contrasted with such other factors of production as land and capital. There are theories which have developed a concept called human capital (referring to the skills that workers possess, not necessarily their actual work), although there are also counter posing macro-economic system theories that think human capital is a contradiction in terms.\n\nDevelopment economics \n\nDevelopment economics examines economic aspects of the economic development process in relatively low-income countries focusing on structural change, poverty, and economic growth. Approaches in development economics frequently incorporate social and political factors.\n\nCriticisms\n\nGeneral criticisms \n\"The dismal science\" is a derogatory alternative name for economics devised by the Victorian historian Thomas Carlyle in the 19th century. It is often stated that Carlyle gave economics the nickname \"the dismal science\" as a response to the late 18th century writings of The Reverend Thomas Robert Malthus, who grimly predicted that starvation would result, as projected population growth exceeded the rate of increase in the food supply. However, the actual phrase was coined by Carlyle in the context of a debate with John Stuart Mill on slavery, in which Carlyle argued for slavery, while Mill opposed it.\n\nIn The Wealth of Nations, Adam Smith addressed many issues that are currently also the subject of debate and dispute. Smith repeatedly attacks groups of politically aligned individuals who attempt to use their collective influence to manipulate a government into doing their bidding. In Smith's day, these were referred to as factions, but are now more commonly called special interests, a term which can comprise international bankers, corporate conglomerations, outright oligopolies, monopolies, trade unions and other groups.\n\nEconomics per se, as a social science, is independent of the political acts of any government or other decision-making organization; however, many policymakers or individuals holding highly ranked positions that can influence other people's lives are known for arbitrarily using a plethora of economic concepts and rhetoric as vehicles to legitimize agendas and value systems, and do not limit their remarks to matters relevant to their responsibilities. The close relation of economic theory and practice with politics is a focus of contention that may shade or distort the most unpretentious original tenets of economics, and is often confused with specific social agendas and value systems.\n\nNotwithstanding, economics legitimately has a role in informing government policy. It is, indeed, in some ways an outgrowth of the older field of political economy. Some academic economic journals have increased their efforts to gauge the consensus of economists regarding certain policy issues in hopes of effecting a more informed political environment. Often there exists a low approval rate from professional economists regarding many public policies. Policy issues featured in one survey of American Economic Association economists include trade restrictions, social insurance for those put out of work by international competition, genetically modified foods, curbside recycling, health insurance (several questions), medical malpractice, barriers to entering the medical profession, organ donations, unhealthy foods, mortgage deductions, taxing internet sales, Wal-Mart, casinos, ethanol subsidies, and inflation targeting.\n\nIssues like central bank independence, central bank policies and rhetoric in central bank governors discourse or the premises of macroeconomic policies (monetary and fiscal policy) of the state, are focus of contention and criticism.\n\nDeirdre McCloskey has argued that many empirical economic studies are poorly reported, and she and Stephen Ziliak argue that although her critique has been well-received, practice has not improved. This latter contention is controversial.\n\nCriticisms of assumptions \nEconomics has historically been subject to criticism that it relies on unrealistic, unverifiable, or highly simplified assumptions, in some cases because these assumptions simplify the proofs of desired conclusions. Examples of such assumptions include perfect information, profit maximization and rational choices, axioms of neoclassical economics. Such criticisms often conflate neoclassical economics with all of contemporary economics. The field of information economics includes both mathematical-economical research and also behavioural economics, akin to studies in behavioural psychology, and confounding factors to the neoclassical assumptions are the subject of substantial study in many areas of economics.\n\nProminent historical mainstream economists such as Keynes and Joskow observed that much of the economics of their time was conceptual rather than quantitative, and difficult to model and formalize quantitatively. In a discussion on oligopoly research, Paul Joskow pointed out in 1975 that in practice, serious students of actual economies tended to use \"informal models\" based upon qualitative factors specific to particular industries. Joskow had a strong feeling that the important work in oligopoly was done through informal observations while formal models were \"trotted out ex post\". He argued that formal models were largely not important in the empirical work, either, and that the fundamental factor behind the theory of the firm, behaviour, was neglected.  Michael Woodford noted in 2009 that in macroeconomics this was no longer the case, and that modelling had improved significantly in both theoretical rigour and empiricism, with a strong focus on testable quantitative work.\n\nIn the 1990s, feminist critiques of neoclassical economic models gained prominence, leading to the formation of feminist economics. Feminist economists call attention to the social construction of economics and claims to highlight the ways in which its models and methods reflect masculine preferences. Primary criticisms focus on alleged failures to account for: the selfish nature of actors (homo economicus); exogenous tastes; the impossibility of utility comparisons; the exclusion of unpaid work; and the exclusion of class and gender considerations.\n\nRelated subjects\n\nEconomics is one social science among several and has fields bordering on other areas, including economic geography, economic history, public choice, energy economics, cultural economics, family economics and institutional economics.\n\nLaw and economics, or economic analysis of law, is an approach to legal theory that applies methods of economics to law. It includes the use of economic concepts to explain the effects of legal rules, to assess which legal rules are economically efficient, and to predict what the legal rules will be. A seminal article by Ronald Coase published in 1961 suggested that well-defined property rights could overcome the problems of externalities.\n\nPolitical economy is the interdisciplinary study that combines economics, law, and political science in explaining how political institutions, the political environment, and the economic system (capitalist, socialist, mixed) influence each other. It studies questions such as how monopoly, rent-seeking behaviour, and externalities should impact government policy. Historians have employed political economy to explore the ways in the past that persons and groups with common economic interests have used politics to effect changes beneficial to their interests.\n\nEnergy economics is a broad scientific subject area which includes topics related to energy supply and energy demand. Georgescu-Roegen reintroduced the concept of entropy in relation to economics and energy from thermodynamics, as distinguished from what he viewed as the mechanistic foundation of neoclassical economics drawn from Newtonian physics. His work contributed significantly to thermoeconomics and to ecological economics. He also did foundational work which later developed into evolutionary economics.\n\nThe sociological subfield of economic sociology arose, primarily through the work of \u00c9mile Durkheim, Max Weber and Georg Simmel, as an approach to analysing the effects of economic phenomena in relation to the overarching social paradigm (i.e. modernity). Classic works include Max Weber's The Protestant Ethic and the Spirit of Capitalism (1905) and Georg Simmel's The Philosophy of Money (1900). More recently, the works of James S. Coleman, Mark Granovetter, Peter Hedstrom and Richard Swedberg have been influential in this field.\n\nGary Becker in 1974 presented an economic theory of social interactions, whose applications included the family, charity, merit goods and multiperson interactions, and envy and hatred.\n He and Kevin Murphy authored a book in 2001 that analyzed market behavior in a social environment.\n\nProfession \n\nThe professionalization of economics, reflected in the growth of graduate programmes on the subject, has been described as \"the main change in economics since around 1900\". Most major universities and many colleges have a major, school, or department in which academic degrees are awarded in the subject, whether in the liberal arts, business, or for professional study.\nSee Bachelor of Economics and Master of Economics.\n\nIn the private sector, professional economists are employed as consultants and in industry, including banking and finance. Economists also work for various government departments and agencies, for example, the national treasury, central bank or National Bureau of Statistics.\n\nThere are dozens of prizes awarded to economists each year for outstanding intellectual contributions to the field, the most prominent of which is the Nobel Memorial Prize in Economic Sciences, though it is not a Nobel Prize.\n\nContemporary economics uses mathematics. Economists draw on the tools of calculus, linear algebra, statistics, game theory, and computer science. Professional economists are expected to be familiar with these tools, while a minority specialize in econometrics and mathematical methods.\n\nSee also\n\n Critical juncture theory\n Economics terminology that differs from common usage\n Economic ideology\n Economic policy\n Economic union\n Free trade\n Happiness economics\n Humanistic economics\n List of academic fields#Economics\n List of economics films\n List of economics awards\n Socioeconomics\n\nGeneral\n Glossary of economics\n Index of economics articles\n JEL classification codes for classifying articles in economics journals and books on economics by subject matter from 1886 to the present.\n Outline of economics\n\nNotes\n\nReferences\n\nFurther reading\n Anderson, David A. (2019) Survey of Economics. New York: Worth.Survey of Economics, 1st Edition | Macmillan Learning for Instructors \n \n McCann, Charles Robert, Jr., 2003. The Elgar Dictionary of Economic Quotations, Edward Elgar. Preview.\n\nExternal links\n\nGeneral information\n\n \n Economic journals on the web.\n Economics at Encyclop\u00e6dia Britannica\n Economics A-Z. Definitions from The Economist.\n Economics Online (UK-based), with drop-down menus at top, incl. Definitions. \n Intute: Economics: Internet directory of UK universities.\n Research Papers in Economics (RePEc)\n Resources For Economists: American Economic Association-sponsored guide to 2,000+ Internet resources from \"Data\" to \"Neat Stuff\", updated quarterly.\n\nInstitutions and organizations\n\n Economics Departments, Institutes and Research Centers in the World\n Organization For Co-operation and Economic Development (OECD) Statistics\n United Nations Statistics Division\n World Bank Data\n American Economic Association\n\nStudy resources\n\n \n \n Economics at About.com\n Economics textbooks on Wikibooks\n MERLOT Learning Materials: Economics: US-based database of learning materials\n Online Learning and Teaching Materials UK Economics Network's database of text, slides, glossaries and other resources",
  "Engineering": "Engineering is the use of scientific principles to design and build machines, structures, and other items, including bridges, tunnels, roads, vehicles, and buildings. The discipline of engineering encompasses a broad range of more specialized fields of engineering, each with a more specific emphasis on particular areas of applied mathematics, applied science, and types of application. See glossary of engineering.\n\nThe term engineering is derived from the Latin ingenium, meaning \"cleverness\" and  ingeniare, meaning \"to contrive, devise\".\n\nDefinition\nThe American Engineers' Council for Professional Development (ECPD, the predecessor of ABET) has defined \"engineering\" as:\nThe creative application of scientific principles to design or develop structures, machines, apparatus, or manufacturing processes, or works utilizing them singly or in combination; or to construct or operate the same with full cognizance of their design; or to forecast their behavior under specific operating conditions; all as respects an intended function, economics of operation and safety to life and property.  (Includes Britannica article on Engineering)\n\nHistory\n\nEngineering has existed since ancient times, when humans devised inventions such as the wedge, lever, wheel and pulley, etc.\n\nThe term engineering  is derived from the word engineer, which itself dates back to the 14th century when an engine'er (literally, one who builds or operates a siege engine) referred to \"a constructor of military engines.\" In this context, now obsolete, an \"engine\" referred to a military machine, i.e., a mechanical contraption used in war (for example, a catapult). Notable examples of the obsolete usage which have survived to the present day are military engineering corps, e.g., the U.S. Army Corps of Engineers.\n\nThe word \"engine\" itself is of even older origin, ultimately deriving from the Latin ingenium (c. 1250), meaning \"innate quality, especially mental power, hence a clever invention.\"\n\nLater, as the design of civilian structures, such as bridges and buildings, matured as a technical discipline, the term civil engineering entered the lexicon as a way to distinguish between those specializing in the construction of such non-military projects and those involved in the discipline of military engineering.\n\nAncient era\n\nThe pyramids in ancient Egypt, ziggurats of Mesopotamia, the Acropolis and Parthenon in Greece, the Roman aqueducts, Via Appia and Colosseum, Teotihuac\u00e1n, and the Brihadeeswarar Temple of Thanjavur, among many others, stand as a testament to the ingenuity and skill of ancient civil and military engineers. Other monuments, no longer standing, such as the Hanging Gardens of Babylon and the Pharos of Alexandria, were important engineering achievements of their time and were considered among the Seven Wonders of the Ancient World.\n\nThe six classic simple machines were known in the ancient Near East. The wedge and the inclined plane (ramp) were known since prehistoric times. The wheel, along with the wheel and axle mechanism, was invented in Mesopotamia (modern Iraq) during the 5th millennium BC. The lever mechanism first appeared around 5,000 years ago in the Near East, where it was used in a simple balance scale, and to move large objects in ancient Egyptian technology. The lever was also used in the shadoof water-lifting device, the first crane machine, which appeared in Mesopotamia circa 3000 BC, and then in ancient Egyptian technology circa 2000 BC. The earliest evidence of pulleys date back to Mesopotamia in the early 2nd millennium BC, and ancient Egypt during the Twelfth Dynasty (1991-1802 BC). The screw, the last of the simple machines to be invented, first appeared in Mesopotamia during the Neo-Assyrian period (911-609) BC. The Egyptian pyramids were built using three of the six simple machines, the inclined plane, the wedge, and the lever, to create structures like the Great Pyramid of Giza.\n\nThe earliest civil engineer known by name is Imhotep. As one of the officials of the Pharaoh, Djos\u00e8r, he probably designed and supervised the construction of the Pyramid of Djoser (the Step Pyramid) at Saqqara in Egypt around 2630\u20132611 BC. The earliest practical water-powered machines, the water wheel and watermill, first appeared in the Persian Empire, in what are now Iraq and Iran, by the early 4th century BC.\n\nKush developed the Sakia during the 4th century BC, which relied on animal power instead of human energy.Hafirs were developed as a type of reservoir in Kush to store and contain water as well as boost irrigation. Sappers were employed to build causeways during military campaigns. Kushite ancestors built speos during the Bronze Age between 3700 and 3250 BC.Bloomeries and blast furnaces were also created during the 7th centuries BC in Kush.\n\nAncient Greece developed machines in both civilian and military domains. The Antikythera mechanism, an early known mechanical analog computer, and the mechanical inventions of Archimedes, are examples of Greek mechanical engineering. Some of Archimedes' inventions as well as the Antikythera mechanism required sophisticated knowledge of differential gearing or epicyclic gearing, two key principles in machine theory that helped design the gear trains of the Industrial Revolution, and are still widely used today in diverse fields such as robotics and automotive engineering.\n\nAncient Chinese, Greek, Roman and Hunnic armies employed military machines and inventions such as artillery which was developed by the Greeks around the 4th century BC, the trireme, the ballista and the catapult. In the Middle Ages, the trebuchet was developed.\n\nMiddle Ages\nThe earliest practical wind-powered machines, the windmill and wind pump, first appeared in the Muslim world during the Islamic Golden Age, in what are now Iran, Afghanistan, and Pakistan, by the 9th century AD. The earliest practical steam-powered machine was a steam jack driven by a steam turbine, described in 1551 by Taqi al-Din Muhammad ibn Ma'ruf in Ottoman Egypt.\n\nThe cotton gin was invented in India by the 6th century AD, and the spinning wheel was invented in the Islamic world by the early 11th century, both of which were fundamental to the growth of the cotton industry. The spinning wheel was also a precursor to the spinning jenny, which was a key development during the early Industrial Revolution in the 18th century. \n\nThe earliest programmable machines were developed in the Muslim world. A music sequencer, a programmable musical instrument, was the earliest type of programmable machine. The first music sequencer was an automated flute player invented by the Banu Musa brothers, described in their Book of Ingenious Devices, in the 9th century. In 1206, Al-Jazari invented programmable automata/robots. He described four automaton musicians, including drummers operated by a programmable drum machine, where they could be made to play different rhythms and different drum patterns. The castle clock, a hydropowered mechanical astronomical clock invented by Al-Jazari, was the first programmable analog computer.\n\nBefore the development of modern engineering, mathematics was used by artisans and craftsmen, such as millwrights, clockmakers, instrument makers and surveyors.  Aside from these professions, universities were not believed to have had much practical significance to technology.\n\nA standard reference for the state of mechanical arts during the Renaissance is given in the mining engineering treatise De re metallica (1556), which also contains sections on geology, mining, and chemistry.  De re metallica was the standard chemistry reference for the next 180 years.\n\nModern era\n\nThe science of classical mechanics, sometimes called Newtonian mechanics, formed the scientific basis of much of modern engineering. With the rise of engineering as a profession in the 18th century, the term became more narrowly applied to fields in which mathematics and science were applied to these ends. Similarly, in addition to military and civil engineering, the fields then known as the mechanic arts became incorporated into engineering.\n\nCanal building was an important engineering work during the early phases of the Industrial Revolution.\n\nJohn Smeaton was the first self-proclaimed civil engineer and is often regarded as the \"father\" of civil engineering. He was an English civil engineer responsible for the design of bridges, canals, harbors, and lighthouses. He was also a capable mechanical engineer and an eminent physicist. Using a model water wheel, Smeaton conducted experiments for seven years, determining ways to increase efficiency.   Smeaton introduced iron axles and gears to water wheels. Smeaton also made mechanical improvements to the Newcomen steam engine. Smeaton designed the third Eddystone Lighthouse (1755\u201359) where he pioneered the use of 'hydraulic lime' (a form of mortar which will set under water) and developed a technique involving dovetailed blocks of granite in the building of the lighthouse. He is important in the history, rediscovery of, and development of modern cement, because he identified the compositional requirements needed to obtain \"hydraulicity\" in lime; work which led ultimately to the invention of Portland cement.\n\nApplied science lead to the development of the steam engine.  The sequence of events began with the invention of the barometer and the measurement of atmospheric pressure by Evangelista Torricelli in 1643, demonstration of the force of atmospheric pressure by Otto von Guericke using the Magdeburg hemispheres in 1656, laboratory experiments by Denis Papin, who built experimental model steam engines and demonstrated the use of a piston, which he published in 1707.  Edward Somerset, 2nd Marquess of Worcester published a book of 100 inventions containing a method for raising waters similar to a coffee percolator.  Samuel Morland, a mathematician and inventor who worked on pumps, left notes at the Vauxhall Ordinance Office on a steam pump design that Thomas Savery read. In 1698 Savery built a steam pump called \"The Miner's Friend.\" It employed both vacuum and pressure. Iron merchant Thomas Newcomen, who built the first commercial piston steam engine in 1712, was not known to have any scientific training.\n\nThe application of steam-powered cast iron blowing cylinders for providing pressurized air for blast furnaces lead to a large increase in iron production in the late 18th century.  The higher furnace temperatures made possible with steam-powered blast allowed for the use of more lime in blast furnaces, which enabled the transition from charcoal to coke. These innovations lowered the cost of iron, making horse railways and iron bridges practical.  The puddling process, patented by Henry Cort in 1784 produced large scale quantities of wrought iron.  Hot blast, patented by James Beaumont Neilson in 1828, greatly lowered the amount of fuel needed to smelt iron.  With the development of the high pressure steam engine, the power to weight ratio of steam engines made practical steamboats and locomotives possible. New steel making processes, such as the Bessemer process and the open hearth furnace, ushered in an area of heavy engineering in the late 19th century.\n\nOne of the most famous engineers of the mid 19th century was Isambard Kingdom Brunel, who built railroads, dockyards and steamships.\n\nThe Industrial Revolution created a demand for machinery with metal parts, which led to the development of several machine tools. Boring cast iron cylinders with precision was not possible until John Wilkinson invented his boring machine, which is considered the first machine tool. Other machine tools included the screw cutting lathe, milling machine, turret lathe and the metal planer.  Precision machining techniques were developed in the first half of the 19th century.  These included the use of gigs to guide the machining tool over the work and fixtures to hold the work in the proper position.  Machine tools and machining techniques capable of producing interchangeable parts lead to large scale factory production by the late 19th century.\n\nThe United States census of 1850 listed the occupation of \"engineer\" for the first time with a count of 2,000. There were fewer than 50 engineering graduates in the U.S. before 1865. In 1870 there were a dozen U.S. mechanical engineering graduates, with that number increasing to 43 per year in 1875.  In 1890, there were 6,000 engineers in civil, mining, mechanical and electrical.\n\nThere was no chair of applied mechanism and applied mechanics at Cambridge until 1875, and no chair of engineering at Oxford until 1907.  Germany established technical universities earlier.\n\nThe foundations of electrical engineering in the 1800s included the experiments of Alessandro Volta, Michael Faraday, Georg Ohm and others and the invention of the electric telegraph in 1816 and the electric motor in 1872. The theoretical work of James Maxwell (see: Maxwell's equations) and Heinrich Hertz in the late 19th century gave rise to the field of electronics. The later inventions of the vacuum tube and the transistor further accelerated the development of electronics to such an extent that electrical and electronics engineers currently outnumber their colleagues of any other engineering specialty.\nChemical engineering developed in the late nineteenth century. Industrial scale manufacturing demanded new materials and new processes and by 1880 the need for large scale production of chemicals was such that a new industry was created, dedicated to the development and large scale manufacturing of chemicals in new industrial plants. The role of the chemical engineer was the design of these chemical plants and processes.\n\nAeronautical engineering deals with aircraft design process design while aerospace engineering is a more modern term that expands the reach of the discipline by including spacecraft design. Its origins can be traced back to the aviation pioneers around the start of the 20th century although the work of Sir George Cayley has recently been dated as being from the last decade of the 18th century. Early knowledge of aeronautical engineering was largely empirical with some concepts and skills imported from other branches of engineering.\n\nThe first PhD in engineering (technically, applied science and engineering) awarded in the United States went to Josiah Willard Gibbs at Yale University in 1863; it was also the second PhD awarded in science in the U.S.\n\nOnly a decade after the successful flights by the Wright brothers, there was extensive development of aeronautical engineering through development of military aircraft that were used in World War I. Meanwhile, research to provide fundamental background science continued by combining theoretical physics with experiments.\n\nMain branches of engineering\n\nEngineering is a broad discipline that is often broken down into several sub-disciplines. Although an engineer will usually be trained in a specific discipline, he or she may become multi-disciplined through experience. Engineering is often characterized as having four main branches: chemical engineering, civil engineering, electrical engineering, and mechanical engineering.\n\nChemical engineering\n\nChemical engineering is the application of physics, chemistry, biology, and engineering principles in order to carry out chemical processes on a commercial scale, such as the manufacture of commodity chemicals, specialty chemicals, petroleum refining, microfabrication, fermentation, and biomolecule production.\n\nCivil engineering\n\nCivil engineering is the design and construction of public and private works, such as infrastructure (airports, roads, railways, water supply, and treatment etc.), bridges, tunnels, dams, and buildings. Civil engineering is traditionally broken into a number of sub-disciplines, including structural engineering, environmental engineering, and surveying. It is traditionally considered to be separate from military engineering.\n\nElectrical engineering\n\nElectrical engineering is the design, study, and manufacture of various electrical and electronic systems, such as broadcast engineering, electrical circuits, generators, motors, electromagnetic/electromechanical devices, electronic devices, electronic circuits, optical fibers, optoelectronic devices, computer systems, telecommunications, instrumentation, control systems, and electronics.\n\nMechanical engineering\n\nMechanical engineering is the design and manufacture of physical or mechanical systems, such as power and energy systems, aerospace/aircraft products, weapon systems, transportation products, engines, compressors, powertrains, kinematic chains, vacuum technology, vibration isolation equipment, manufacturing, robotics, turbines, audio equipments, and mechatronics.\n\nBioengineering\n\nBioengineering is the engineering of biological systems for a useful purpose. Examples of bioengineering research include bacteria engineered to produce chemicals, new medical imaging technology, portable and rapid disease diagnostic devices, prosthetics, biopharmaceuticals, and tissue-engineered organs.\n\nInterdisciplinary engineering\n\nInterdisciplinary engineering draws from more than one of the principle branches of the practice.  Historically, naval engineering and mining engineering were major branches.  Other engineering fields are manufacturing engineering, acoustical engineering, corrosion engineering, instrumentation and control, aerospace, automotive, computer, electronic, information engineering, petroleum, environmental, systems, audio, software, architectural, agricultural, biosystems, biomedical, geological, textile, industrial, materials, and nuclear engineering. These and other branches of engineering are represented in the 36 licensed member institutions of the UK Engineering Council.\n\nNew specialties sometimes combine with the traditional fields and form new branches \u2013 for example, Earth systems engineering and management involves a wide range of subject areas including engineering studies, environmental science, engineering ethics and philosophy of engineering.\n\nOther branches of engineering\n\nAerospace engineering \n\nAerospace engineering studies design, manufacture aircraft, satellites, rockets, helicopters, and so on. It closely studies the pressure difference and aerodynamics of a vehicle to ensure safety and efficiency. Since most of the studies are related to fluids, it is applied to any moving vehicle, such as cars.\n\nMarine engineering \n\nMarine engineering is associated with anything on or near the ocean. Examples are, but not limited to, ships, submarines, oil rigs, structure, watercraft propulsion, on-board design and development, plants, harbors, and so on. It requires a combined knowledge in mechanical engineering, electrical engineering, civil engineering, and some programming abilities.\n\nComputer engineering \n\nComputer engineering (CE) is a branch of engineering that integrates several fields of computer science and electronic engineering  required to develop computer hardware  and software.  Computer engineers usually have training in electronic engineering (or electrical engineering), software design, and hardware-software integration instead of only software engineering  or electronic engineering.\n\nGeological engineering \n\nGeological engineering is associated with anything constructed on or within the Earth. This discipline applies geological sciences and engineering principles to direct or support the work of other disciplines such as civil engineering, environmental engineering, and mining engineering. Geological engineers are involved with impact studies for facilities and operations that affect surface and subsurface environments, such as rock excavations (e.g. tunnels), building foundation consolidation, slope and fill stabilization, landslide risk assessment, groundwater monitoring, groundwater remediation, mining excavations, and natural resource exploration.\n\nPractice\n\nOne who practices engineering is called an engineer, and those licensed to do so may have more formal designations such as Professional Engineer, Chartered Engineer, Incorporated Engineer, Ingenieur, European Engineer, or Designated Engineering Representative.\n\nMethodology\n\nIn the engineering design process, engineers apply mathematics and sciences such as physics to find novel solutions to problems or to improve existing solutions. Engineers need proficient knowledge of relevant sciences for their design projects. As a result, many engineers continue to learn new material throughout their careers.\n\nIf multiple solutions exist, engineers weigh each design choice based on their merit and choose the solution that best matches the requirements. The task of the engineer is to identify, understand, and interpret the constraints on a design in order to yield a successful result. It is generally insufficient to build a technically successful product, rather, it must also meet further requirements.\n\nConstraints may include available resources, physical, imaginative or technical limitations, flexibility for future modifications and additions, and other factors, such as requirements for cost, safety, marketability, productivity, and serviceability. By understanding the constraints, engineers derive specifications for the limits within which a viable object or system may be produced and operated.\n\nProblem solving\n\nEngineers use their knowledge of science, mathematics, logic, economics, and appropriate experience or tacit knowledge to find suitable solutions to a particular problem. Creating an appropriate mathematical model of a problem often allows them to analyze it (sometimes definitively), and to test potential solutions.\n\nUsually, multiple reasonable solutions exist, so engineers must evaluate the different design choices on their merits and choose the solution that best meets their requirements. Genrich Altshuller, after gathering statistics on a large number of patents, suggested that compromises are at the heart of \"low-level\" engineering designs, while at a higher level the best design is one which eliminates the core contradiction causing the problem.\n\nEngineers typically attempt to predict how well their designs will perform to their specifications prior to full-scale production. They use, among other things: prototypes, scale models, simulations, destructive tests, nondestructive tests, and stress tests. Testing ensures that products will perform as expected.\n\nEngineers take on the responsibility of producing designs that will perform as well as expected and will not cause unintended harm to the public at large. Engineers typically include a factor of safety in their designs to reduce the risk of unexpected failure.\n\nThe study of failed products is known as forensic engineering and can help the product designer in evaluating his or her design in the light of real conditions. The discipline is of greatest value after disasters, such as bridge collapses, when careful analysis is needed to establish the cause or causes of the failure.\n\nComputer use\n\nAs with all modern scientific and technological endeavors, computers and software play an increasingly important role. As well as the typical business application software there are a number of computer aided applications (computer-aided technologies) specifically for engineering. Computers can be used to generate models of fundamental physical processes, which can be solved using numerical methods.\n\nOne of the most widely used design tools in the profession is computer-aided design (CAD) software.  It enables engineers to create 3D models, 2D drawings, and schematics of their designs. CAD together with digital mockup (DMU) and CAE software such as finite element method analysis or analytic element method allows engineers to create models of designs that can be analyzed without having to make expensive and time-consuming physical prototypes.\n\nThese allow products and components to be checked for flaws; assess fit and assembly; study ergonomics; and to analyze static and dynamic characteristics of systems such as stresses, temperatures, electromagnetic emissions, electrical currents and voltages, digital logic levels, fluid flows, and kinematics. Access and distribution of all this information is generally organized with the use of product data management software.\n\nThere are also many tools to support specific engineering tasks such as computer-aided manufacturing (CAM) software to generate CNC machining instructions; manufacturing process management software for production engineering; EDA for printed circuit board (PCB) and circuit schematics for electronic engineers; MRO applications for maintenance management; and Architecture, engineering and construction (AEC) software for civil engineering.\n\nIn recent years the use of computer software to aid the development of goods has collectively come to be known as product lifecycle management (PLM).\n\nSocial context\n\nThe engineering profession engages in a wide range of activities, from large collaboration at the societal level, and also smaller individual projects.  Almost all engineering projects are obligated to some sort of financing agency: a company, a set of investors, or a government.  The few types of engineering that are minimally constrained by such issues are pro bono engineering and open-design engineering.\n\nBy its very nature engineering has interconnections with society, culture and human behavior.  Every product or construction used by modern society is influenced by engineering. The results of engineering activity influence changes to the environment, society and economies, and its application brings with it a responsibility and public safety.\n\nEngineering projects can be subject to controversy. Examples from different engineering disciplines include the development of nuclear weapons, the Three Gorges Dam, the design and use of sport utility vehicles and the extraction of oil. In response, some western engineering companies have enacted serious corporate and social responsibility policies.\n\nEngineering is a key driver of innovation and human development. Sub-Saharan Africa, in particular, has a very small engineering capacity which results in many African nations being unable to develop crucial infrastructure without outside aid. The attainment of many of the Millennium Development Goals requires the achievement of sufficient engineering capacity to develop infrastructure and sustainable technological development.\n\nAll overseas development and relief NGOs make considerable use of engineers to apply solutions in disaster and development scenarios. A number of charitable organizations aim to use engineering directly for the good of mankind:\n Engineers Without Borders\n Engineers Against Poverty\n Registered Engineers for Disaster Relief\n Engineers for a Sustainable World\n Engineering for Change\n Engineering Ministries International\n\nEngineering companies in many established economies are facing significant challenges with regard to the number of professional engineers being trained, compared with the number retiring.  This problem is very prominent in the UK where engineering has a poor image and low status. There are many negative economic and political issues that this can cause, as well as ethical issues. It is widely agreed that the engineering profession faces an \"image crisis\", rather than it being fundamentally an unattractive career.  Much work is needed to avoid huge problems in the UK and other western economies. Still, the UK holds most engineering companies compared to other European countries, together with the United States.\n\nCode of ethics\n\nMany engineering societies have established codes of practice and codes of ethics to guide members and inform the public at large.  The National Society of Professional Engineers code of ethics states:\n\nIn Canada, many engineers wear the Iron Ring as a symbol and reminder of the obligations and ethics associated with their profession.\n\nRelationships with other disciplines\n\nScience\n\nThere exists an overlap between the sciences and engineering practice; in engineering, one applies science. Both areas of endeavor rely on accurate observation of materials and phenomena.  Both use mathematics and classification criteria to analyze and communicate observations.\n\nScientists may also have to complete engineering tasks, such as designing experimental apparatus or building prototypes. Conversely, in the process of developing technology, engineers sometimes find themselves exploring new phenomena, thus becoming, for the moment, scientists or more precisely \"engineering scientists\".\n\n \nIn the book What Engineers Know and How They Know It, Walter Vincenti asserts that engineering research has a character different from that of scientific research.  First, it often deals with areas in which the basic physics or chemistry are well understood, but the problems themselves are too complex to solve in an exact manner.\n\nThere is a \"real and important\" difference between engineering and physics as similar to any science field has to do with technology. Physics is an exploratory science that seeks knowledge of principles while engineering uses knowledge for practical applications of principles. The former equates an understanding into a mathematical principle while the latter measures variables involved and creates technology. For technology, physics is an auxiliary and in a way technology is considered as applied physics. Though physics and engineering are interrelated, it does not mean that a physicist is trained to do an engineer's job. A physicist would typically require additional and relevant training. Physicists and engineers engage in different lines of work. But PhD physicists who specialize in sectors of engineering physics and applied physics are titled as Technology officer, R&D Engineers and System Engineers.\n\nAn example of this is the use of numerical approximations to the Navier\u2013Stokes equations to describe aerodynamic flow over an aircraft, or the use of the Finite element method to calculate the stresses in complex components. Second, engineering research employs many semi-empirical methods that are foreign to pure scientific research, one example being the method of parameter variation.\n\nAs stated by Fung et al. in the revision to the classic engineering text Foundations of Solid Mechanics:\n\nEngineering is quite different from science. Scientists try to understand nature. Engineers try to make things that do not exist in nature. Engineers stress innovation and invention. To embody an invention the engineer must put his idea in concrete terms, and design something that people can use. That something can be a complex system, device, a gadget, a material, a method, a computing program, an innovative experiment, a new solution to a problem, or an improvement on what already exists. Since a design has to be realistic and functional, it must have its geometry, dimensions, and characteristics data defined.  In the past engineers working on new designs found that they did not have all the required information to make design decisions. Most often, they were limited by insufficient scientific knowledge. Thus they studied mathematics, physics, chemistry, biology and mechanics. Often they had to add to the sciences relevant to their profession. Thus engineering sciences were born.\n\nAlthough engineering solutions make use of scientific principles, engineers must also take into account safety, efficiency, economy, reliability, and constructability or ease of fabrication as well as the environment, ethical and legal considerations such as patent infringement or liability in the case of failure of the solution.\n\nMedicine and biology\n\nThe study of the human body, albeit from different directions and for different purposes, is an important common link between medicine and some engineering disciplines. Medicine aims to sustain, repair, enhance and even replace functions of the human body, if necessary, through the use of technology.\n\nModern medicine can replace several of the body's functions through the use of artificial organs and can significantly alter the function of the human body through artificial devices such as, for example, brain implants and pacemakers. The fields of bionics and medical bionics are dedicated to the study of synthetic implants pertaining to natural systems.\n\nConversely, some engineering disciplines view the human body as a biological machine worth studying and are dedicated to emulating many of its functions by replacing biology with technology. This has led to fields such as artificial intelligence, neural networks, fuzzy logic, and robotics.  There are also substantial interdisciplinary interactions between engineering and medicine.\n\nBoth fields provide solutions to real world problems. This often requires moving forward before phenomena are completely understood in a more rigorous scientific sense and therefore experimentation and empirical knowledge is an integral part of both.\n\nMedicine, in part, studies the function of the human body. The human body, as a biological machine, has many functions that can be modeled using engineering methods.\n\nThe heart for example functions much like a pump, the skeleton is like a linked structure with levers, the brain produces electrical signals etc. These similarities as well as the increasing importance and application of engineering principles in medicine, led to the development of the field of biomedical engineering that uses concepts developed in both disciplines.\n\nNewly emerging branches of science, such as systems biology, are adapting analytical tools traditionally used for engineering, such as systems modeling and computational analysis, to the description of biological systems.\n\nArt\n\nThere are connections between engineering and art, for example, architecture, landscape architecture and industrial design (even to the extent that these disciplines may sometimes be included in a university's Faculty of Engineering).\n\nThe Art Institute of Chicago, for instance, held an exhibition about the art of NASA's aerospace design. Robert Maillart's bridge design is perceived by some to have been deliberately artistic. At the University of South Florida, an engineering professor, through a grant with the National Science Foundation, has developed a course that connects art and engineering.\n\nAmong famous historical figures, Leonardo da Vinci is a well-known Renaissance artist and engineer, and a prime example of the nexus between art and engineering.\n\nBusiness\n\nBusiness Engineering deals with the relationship between professional engineering, IT systems, business administration and change management. Engineering management or \"Management engineering\" is a specialized field of management concerned with engineering practice or the engineering industry sector.  The demand for management-focused engineers (or from the opposite perspective, managers with an understanding of engineering), has resulted in the development of specialized engineering management degrees that develop the knowledge and skills needed for these roles. During an engineering management course, students will develop industrial engineering skills, knowledge, and expertise, alongside knowledge of business administration, management techniques, and strategic thinking.  Engineers specializing in change management must have in-depth knowledge of the application of industrial and organizational psychology principles and methods.  Professional engineers often train as certified management consultants in the very specialized field of management consulting applied to engineering practice or the engineering sector.  This work often deals with large scale complex business transformation or Business process management initiatives in aerospace and defence, automotive, oil and gas, machinery, pharmaceutical, food and beverage, electrical & electronics, power distribution & generation, utilities and transportation systems.  This combination of technical engineering practice, management consulting practice, industry sector knowledge, and change management expertise enables professional engineers who are also qualified as management consultants to lead major business transformation initiatives. These initiatives are typically sponsored by C-level executives.\n\nOther fields\nIn political science, the term engineering has been borrowed for the study of the subjects of social engineering and political engineering, which deal with forming political and social structures using engineering methodology coupled with political science principles. Marketing engineering and Financial engineering have similarly borrowed the term.\n\nSee also\n\nLists\n\n Engineering society\n List of aerospace engineering topics\n List of basic chemical engineering topics\n List of electrical engineering topics\n List of engineering topics\n List of engineers\n List of genetic engineering topics\n List of mechanical engineering topics\n List of nanoengineering topics\n List of software engineering topics\n\nGlossaries\n\n Glossary of areas of mathematics\n Glossary of biology\n Glossary of chemistry\n Glossary of engineering\n Glossary of physics\n\nRelated subjects\n\n Controversies over the term Engineer\n Design\n Earthquake engineering\n Engineer\n Engineering economics\n Engineering education\n Engineering education research\n Engineers Without Borders\n Forensic engineering\n Global Engineering Education\n Industrial design\n Infrastructure\n Mathematics\n Open-source hardware\n Planned obsolescence\n Reverse engineering\n Science\n Structural failure\n Sustainable engineering\n Technology\n Women in engineering\n\nReferences\n\nFurther reading\n\nExternal links \n\n \nEngineering occupations\nEthics\nPhilosophy of science\nMain topic articles",
  "Finance": "Finance is a term for the management, creation, and study of money and investments.\nSpecifically, it deals with the questions of how an individual, company or government acquires moneycalled capital in the context of a business and how they spend or invest that money. Finance is then often divided into the following broad categories:  personal finance, corporate finance, and public finance.\n\nAt the same time, and correspondingly, finance is about the overall \"system\" \ni.e., the financial markets that allow the flow of money, via investments and other financial instruments,  between and within these areas; this \"flow\" is facilitated by the financial services sector.\nFinance therefore refers to the study of the securities markets, including derivatives, and the institutions that serve as intermediaries to those markets, thus enabling the flow of money through the economy.\n\nA major focus within finance is thus investment managementcalled money management for individuals, and asset management for institutionsand finance then includes the associated activities of securities trading and stock broking, investment banking, financial engineering, and risk management.\nFundamental to these areas is the valuation of assets such as stocks, bonds, loans, but also, by extension, entire companies.\nAsset allocation, the mix of investments in the portfolio, is also fundamental here.\n\nAlthough they are closely related, the disciplines of economics and finance are distinct. The economy is a social institution that organizes a society's production, distribution, and consumption of goods and services, all of which must be financed.\nSimilarly, although these areas overlap the financial function of the accounting profession, financial accounting is the reporting of historical financial information, whereas finance is forward-looking.\n\nGiven its wide scope, finance is studied in several academic disciplines, and, correspondingly, there are several related degrees and professional certifications that can lead to the field.\n\nThe financial system\n\nAs above, the financial system consists of the flows of capital that take place between individuals (personal finance), governments (public finance), and businesses (corporate finance). \n\"Finance\" thus studies the process of channeling money from savers and investors to entities that need it. Savers and investors have money available which could earn interest or dividends if put to productive use. Individuals, companies and governments must obtain money from some external source, such as loans or credit, when they lack sufficient funds to operate.\n\nIn general, an entity whose income exceeds its expenditure can lend or invest the excess, intending to earn a fair return. Correspondingly, an entity where income is less than expenditure can raise capital usually in one of two ways: \n(i) by borrowing in the form of a loan (private individuals), or by selling government or corporate bonds; \n(ii) by a corporation selling equity, also called stock or shares (which may take various forms: preferred stock or common stock). \nThe owners of both bonds and stock may be institutional investors financial institutions such as investment banks and pension funds \u2013 or private individuals, called private investors or retail investors.\n\nThe lending is often indirect, through a financial intermediary such as a bank, or via the purchase of notes or bonds (corporate bonds, government bonds, or mutual bonds) in the bond market. \nThe lender receives interest, the borrower pays a higher interest than the lender receives, and the financial intermediary earns the difference for arranging the loan.\nA bank aggregates the activities of many borrowers and lenders. A bank accepts deposits from lenders, on which it pays interest. The bank then lends these deposits to borrowers. Banks allow borrowers and lenders, of different sizes, to coordinate their activity.\n\nInvesting typically entails the purchase of stock, either individual securities, or via a mutual fund for example.\nStocks are usually sold by corporations to investors so as to raise required capital in the form of \"equity financing\", as distinct from the debt financing described above.\nThe financial intermediaries here are the investment banks. The investment banks find the initial investors and facilitate the listing of the securities, typically shares and bonds. \nAdditionally, they facilitate the securities exchanges, which allow their trade thereafter, as well as the various service providers which manage the performance or risk of these investments. \nThese latter include mutual funds, pension funds, wealth managers, and stock brokers, typically servicing retail investors (private individuals).\n\nInter-institutional trade and investment, and fund-management at this scale, is referred to as \"wholesale finance\". \nInstitutions here extend the products offered, with related trading, to include bespoke options, swaps, and structured products, as well as specialized financing; this \"financial engineering\" is inherently mathematical, and these institutions are then the major employers of \"quants\" (see below). \nIn these institutions, risk management, regulatory capital, and compliance play major roles.\n\nAreas of finance\nAs above, finance comprises, broadly, the three areas of personal finance, corporate finance, and public finance.\nAlthough they are numerous, other areas, such as investments, risk management, quantitative finance / financial engineering,  and development finance typically overlap these; likewise, specific arrangements such as  public\u2013private partnerships.\n\nPersonal finance\n\nPersonal finance is defined as \"the mindful planning of monetary spending and saving, while also considering the possibility of future risk\". Personal finance may involve paying for education, financing durable goods such as real estate and cars, buying insurance, investing, and saving for retirement.\nPersonal finance may also involve paying for a loan or other debt obligations. \nThe main areas of personal finance are considered to be income, spending, saving, investing, and protection. \nThe following steps, as outlined by the Financial Planning Standards Board, suggest that an individual will understand a potentially secure personal finance plan after:\n Purchasing insurance to ensure protection against unforeseen personal events;\n Understanding the effects of tax policies, subsidies, or penalties on the management of personal finances;\n Understanding the effects of credit on individual financial standing;\n Developing a savings plan or financing for large purchases (auto, education, home);\n Planning a secure financial future in an environment of economic instability;\n Pursuing a checking and/or a savings account;\n Preparing for retirement or other long term expenses.\n\nCorporate finance\n\nCorporate finance deals with the actions that managers take to increase the value of the firm to the shareholders, the sources of funding and the capital structure of corporations, and the tools and analysis used to allocate financial resources.  \nWhile corporate finance is in principle different from managerial finance, which studies the financial management of all firms rather than corporations alone, the concepts are applicable to the financial problems of all firms, \nand this area is then often referred to as \u201cbusiness finance\u201d.\n\nTypically \"corporate finance\" relates to the long term objective of maximizing the value of the entity's assets, its stock, and its return to shareholders, while also balancing risk and profitability.  This entails  three primary areas: \nCapital budgeting: selecting which projects to invest in  - here, accurately determining value is crucial, as judgements about asset values can be \"make or break\" \nDividend policy: the use of \"excess\" funds - are these to be reinvested in the business or returned to shareholders\nCapital structure: deciding on the mix of funding to be used - here attempting to find the optimal capital mix re debt-commitments vs cost of capital\nThe latter creates the link with investment banking and securities trading, as above, in that the capital raised will generically comprise debt, i.e. corporate bonds, and equity, often listed shares.\nRe risk management within corporates, see  below.\n\nFinancial managers - i.e. as opposed to corporate financiers -  focus more on the short term elements of profitability, cash flow,  and  \"working capital management\" (inventory, credit and debtors), \nensuring that the firm can safely and profitably carry out its financial and operational  objectives; i.e. that it: \n(1) can service both maturing short-term debt repayments, and scheduled long-term debt payments , \nand (2) has sufficient cash flow for ongoing and upcoming operational expenses.\nSee  and .\n\nPublic finance\n\nPublic finance describes finance as related to sovereign states, sub-national entities, and related public entities or agencies. It generally encompasses a long-term strategic perspective regarding investment decisions that affect public entities.  These long-term strategic periods typically encompass five or more years.  Public finance is primarily concerned with:\n Identification of required expenditures of a public sector entity;\n Source(s) of that entity's revenue;\n The budgeting process;\n Debt issuance, or municipal bonds, for public works projects.\n\nCentral banks, such as the Federal Reserve System banks in the United States and the Bank of England in the United Kingdom, are strong players in public finance. They act as lenders of last resort as well as strong influences on monetary and credit conditions in the economy.\n\nInvestment management\n\nInvestment management  is the professional asset management of various securities - typically shares and bonds, but also other assets, such as real estate and commodities - in order to meet specified investment goals for the benefit of investors.\n\nAs above, investors may be institutions, such as insurance companies, pension funds, corporations, charities, educational establishments, or private investors, either directly via investment contracts or, more commonly, via collective investment schemes like mutual funds, exchange-traded funds, or REITs.\n\nAt the heart of investment management is asset allocation - diversifying the exposure among these asset classes, and among individual securities within each asset class - as appropriate to the client's investment policy, in turn, a function of risk profile, investment goals, and investment horizon (see Investor profile).  Here:\nPortfolio optimization is the process of selecting the best portfolio given the client's objectives and constraints. \nFundamental analysis is the approach typically applied in valuing and evaluating the individual securities.\n\nOverlaid is the portfolio manager's investment style  - broadly, active vs passive , value vs growth, and small cap vs. large cap - and  investment strategy.\nIn a well-diversified portfolio, achieved investment performance will, in general, largely be a function of the asset mix selected, while the individual securities are less impactful. The specific approach or philosophy will also be significant, depending on the extent to which it is complementary with the market cycle.\n\nA quantitative fund is managed  using \ncomputer-based techniques (increasingly, machine learning) instead of human judgment. The actual trading also, is typically automated via sophisticated algorithms.\n\nRisk management\n\nRisk management, in general, is the study of how to control risks and balance the possibility of gains; it is the process of measuring risk and then developing and implementing strategies to manage that risk. \nFinancial risk management\n is the practice of protecting corporate value by using financial instruments to manage exposure to risk, here called \"hedging\"; the focus is particularly on credit and market risk, and in banks includes operational risk.\nCredit risk is risk of default on a debt that may arise from a borrower failing to make required payments; \nMarket risk relates to losses arising from movements in market variables such as prices and exchange rates;\nOperational risk relates to failures in internal processes, people, and systems, or to external events.\n\nFinancial risk management is related to corporate finance in two ways. \nFirstly, firm exposure to market risk is a direct result of previous capital investments and funding decisions; \nwhile credit risk arises from the business' credit policy and is often addressed through credit insurance.\nSecondly, both disciplines share the goal of enhancing or at least preserving, the firm's economic value.  \nSee also \"ALM\" and treasury management.\n(Enterprise risk management, the domain of strategic management, addresses risks to the firm's overall objectives.)\n\nFor banks and other wholesale institutions, risk management focuses on hedging the various positions held by the institution - trading positions and long term exposures - and on calculating and monitoring the resultant regulatory- and economic capital under Basel IV. \nThe calculations here are mathematically sophisticated, and within the domain of quantitative finance as below.\nCredit risk is inherent in the business of banking, but additionally, these institutions are exposed to counterparty credit risk.\n\nInvestment managers will apply various risk management techniques to their portfolios:\nthese may relate to the portfolio as a whole or to individual stocks; bond portfolios are typically managed via  cash flow matching or immunization.\nRe derivative portfolios (and positions), \"the Greeks\" is a vital risk management tool - it measures sensitivity to a small change in a given underlying parameter so that the portfolio can be rebalanced accordingly by including additional derivatives with offsetting characteristics.\n\nQuantitative finance\n\nQuantitative finance - also referred to as \"mathematical finance\" - includes those finance activities where a sophisticated mathematical model is required, and thus overlaps several of the above. \nAs a specialized practice area, quantitative finance comprises primarily three sub-disciplines; the underlying theory and techniques are discussed in the next section:\nQuantitative finance is often synonymous with financial engineering. This area generally underpins a bank's customer-driven derivatives business \u2014 delivering bespoke OTC-contracts and \"exotics\", and designing the various structured products mentioned  \u2014 and encompasses modeling and  programming in support of the initial trade, and its subsequent hedging and management.\nQuantitative finance also significantly overlaps financial risk management in banking, as mentioned, both as regards this hedging, and as regards compliance with regulations and the Basel capital / liquidity requirements. \n\"Quants\" are also responsible for building and deploying the investment strategies at the quantitative funds mentioned; they are also involved in quantitative investing more generally, in areas such as trading strategy formulation, and in automated trading, high-frequency trading, algorithmic trading, and program trading.\n\nFinancial theory\n\nFinancial theory is studied and developed within the disciplines of management, (financial) economics, accountancy and applied mathematics.\nAbstractly, finance is concerned with the investment and deployment of assets and liabilities over \"space and time\"; \ni.e., it is about performing valuation and asset allocation today, based on the risk and uncertainty of future outcomes while appropriately incorporating the time value of money. \nDetermining the present value of these future values, \"discounting\", must be at the risk-appropriate discount rate, in turn, a major focus of finance-theory.\n\nSince the debate as to whether finance is an art or a science is still open, there have been recent efforts to organize a list of unsolved problems in finance.\n\nManagerial finance\n\nManagerial finance is the branch of management that concerns itself with the managerial application of finance techniques and theory, emphasizing the financial aspects of managerial decisions;\nthe assessment is per the managerial perspectives of planning, directing, and controlling.\nThe techniques addressed are drawn in the main from managerial accounting and corporate finance: \nthe former allow management to better understand, and hence act on, financial information relating to profitability and performance; the latter, as above, are about optimizing the overall financial structure, including its impact on working capital.\nThe implementation of these techniques - i.e. financial management - is described above.\nAcademics working in this area are typically based in business school finance departments, in accounting, or in management science.\n\nFinancial economics\n\nFinancial economics  is the branch of economics that studies the interrelation of financial variables, such as prices, interest rates and shares, as opposed to real economic variables, i.e. goods and services. \nIt thus centers on pricing, decision making, and risk management in the financial markets,   and produces many of the commonly employed financial models. (Financial econometrics is the branch of financial economics that uses econometric techniques to parameterize the relationships suggested.)\n\nThe discipline has two main areas of focus: \n\nasset pricing and (theoretical) corporate finance; the first being the perspective of providers of capital, i.e. investors, and the second of users of capital. Respectively:\n Asset pricing theory develops the models used in determining the risk-appropriate discount rate, and in pricing derivatives. The analysis essentially explores how rational investors would apply risk and return to the problem of investment under uncertainty.  The twin assumptions of rationality and market efficiency lead to modern portfolio theory (the CAPM), and to the Black\u2013Scholes theory for option valuation. At more advanced levels -  and often in response to  financial crises - the study then extends these \"Neoclassical\" models to incorporate phenomena where their assumptions do not hold, or to more general settings. Asset pricing theory also includes the portfolio- and investment theory applied in portfolio management.\n Much of corporate finance theory, by contrast, considers investment under \"certainty\" (Fisher separation theorem, \"theory of investment value\", Modigliani\u2013Miller theorem). Here theory and methods are developed for the decisioning about funding, dividends, and capital structure discussed above. A recent development is to incorporate uncertainty and contingency - and thus various elements of asset pricing - into these decisions, employing for example real options analysis.\n\nFinancial mathematics\n\nFinancial mathematics  is a field of applied mathematics concerned with financial markets. \nAs above, in terms of practice, the field is referred to as quantitative finance and / or mathematical finance, and comprises primarily the three areas discussed.\n\nRe theory, the field is largely focused on the modeling of derivatives (with much focus on interest rate- and credit risk modeling), although other important subfields include insurance mathematics and  quantitative portfolio management.\nRelatedly, the techniques developed are applied to pricing and hedging a wide range of asset-backed, government, and corporate-securities.\nThe main mathematical tools and techniques are:\nfor derivatives, It\u00f4's stochastic calculus, simulation, and partial differential equations\nfor risk management, value at risk, stress testing, \"sensitivities\" analysis (applying the \"greeks\"), and xVA\nin both of these areas, and particularly for portfolio problems, quants employ sophisticated optimization techniques\n\nMathematically, these separate into two analytic branches:\nderivatives pricing uses risk-neutral probability (or arbitrage-pricing probability), denoted by \"Q\";\nwhile risk and portfolio management generally use actual (or actuarial or physical) probability, denoted by \"P\".\n\nThe subject has a close relationship with the discipline of financial economics, which is concerned with much of the underlying theory that is involved in financial mathematics:  generally, financial mathematics will derive and extend the mathematical models suggested. \nComputational finance is the branch of (applied) computer science that deals with problems of practical interest in finance, and especially  emphasizes the numerical methods applied here.\n\nExperimental finance\n\nExperimental finance \n\naims to establish different market settings and environments to experimentally observe and provide a lens through which science can analyze agents' behavior and the resulting characteristics of trading flows, information diffusion, and aggregation, price setting mechanisms, and returns processes. Researchers in experimental finance can study to what extent existing financial economics theory makes valid predictions and therefore prove them, as well as attempt to discover new principles on which such theory can be extended and be applied to future financial decisions. Research may proceed by conducting trading simulations or by establishing and studying the behavior of people in artificial, competitive, market-like settings.\n\nBehavioral finance\n\nBehavioral finance studies how the psychology of investors or managers affects financial decisions and markets \n \nand is relevant when making a decision that can impact either negatively or positively on one of their areas. \nBehavioral finance has grown over the last few decades to become an integral aspect of finance.\n\nBehavioral finance includes such topics as:\n Empirical studies that demonstrate significant deviations from classical theories;\n Models of how psychology affects and impacts trading and prices;\n Forecasting based on these methods;\n Studies of experimental asset markets and the use of models to forecast experiments.\n\nA strand of behavioral finance has been dubbed quantitative behavioral finance, which uses mathematical and statistical methodology to understand behavioral biases in conjunction with valuation.\n\nHistory of finance \n\nThe origin of finance can be traced to the start of civilization. The earliest historical evidence of finance is dated to around 3000 BC. Banking originated in the Babylonian empire, where temples and palaces were used as safe places for the storage of valuables. Initially, the only valuable that could be deposited was grain, but cattle and precious materials were eventually included. During the same period, the Sumerian city of Uruk in Mesopotamia supported trade by lending as well as the use of interest. In Sumerian, \u201cinterest\u201d was mas, which translates to \"calf\". In Greece and Egypt, the words used for interest, tokos and ms respectively, meant \u201cto give birth\u201d. In these cultures, interest indicated a valuable increase, and seemed to consider it from the lender's point of view. The Code of Hammurabi (1792-1750 BC) included laws governing banking operations. The Babylonians were accustomed to charging interest at the rate of 20 percent per annum.\n\nJews were not allowed to take interest from other Jews, but they were allowed to take interest from Gentiles, who had at that time no law forbidding them from practicing usury. As Gentiles took interest from Jews, the Torah considered it equitable that Jews should take interest from Gentiles. In Hebrew, interest is neshek.\n\nBy 1200 BC, cowrie shells were used as a form of money in China. By 640 BC, the Lydians had started to use coin money. Lydia was the first place where permanent retail shops opened. (Herodotus mentions the use of crude coins in Lydia in an earlier date, around 687 BC.)\n\nThe use of coins as a means of representing money began in the years between 600 and 570 BCE. Cities under the Greek empire, such as Aegina (595 BCE), Athens (575 BCE), and Corinth (570 BCE), started to mint their own coins. In the Roman Republic, interest was outlawed altogether by the Lex Genucia reforms. Under Julius Caesar, a ceiling on interest rates of 12% was set, and later under Justinian it was lowered even further to between 4% and 8%.\n\nImage gallery\n\nSee also\nOutline of finance\nFinancial crisis of 2007\u20132010\n\nNotes\n\nReferences\n\nFurther reading \n  \n \nRich Dad Poor Dad: What the Rich Teach Their Kids About Money That the Poor and Middle Class Do Not!, by Robert Kiyosaki and Sharon Lechter. Warner Business Books, 2000.\n\nExternal links\n\n Wharton Finance Knowledge Project\n Hypertextual Finance Glossary (Campbell Harvey)\n  Corporate finance resources (Aswath Damodaran)\n Financial management resources (James Van Horne)\n Financial mathematics, derivatives, and risk management resources (Don Chance)\n Personal finance resources (Financial Literacy and Education Commission, mymoney.gov)\n Public Finance resources (Governance and Social Development Resource Centre, gsdrc.org)",
  "Geology": "Geology (from the Ancient Greek \u03b3\u1fc6, g\u0113 (\"earth\") and -\u03bbo\u03b3\u03af\u03b1, -logia, (\"study of\", \"discourse\")) is a branch of Earth science concerned with both the liquid and solid Earth, the rocks of which it is composed, and the processes by which they change over time. Geology can also include the study of the solid features of any terrestrial planet or natural satellite such as Mars or the Moon. Modern geology significantly overlaps all other Earth sciences, including hydrology and the atmospheric sciences, and so is treated as one major aspect of integrated Earth system science and planetary science.\n\nGeology describes the structure of the Earth on and beneath its surface, and the processes that have shaped that structure. It also provides tools to determine the relative and absolute ages of rocks found in a given location, and also to describe the histories of those rocks. By combining these tools, geologists are able to chronicle the geological history of the Earth as a whole, and also to demonstrate the age of the Earth. Geology provides the primary evidence for plate tectonics, the evolutionary history of life, and the Earth's past climates.\n\nGeologists use a wide variety of methods to understand the Earth's structure and evolution, including field work, rock description, geophysical techniques, chemical analysis, physical experiments, and numerical modelling. In practical terms, geology is important for mineral and hydrocarbon exploration and exploitation, evaluating water resources, understanding of natural hazards, the remediation of environmental problems, and providing insights into past climate change. Geology is a major academic discipline, and it is central to geological engineering and plays an important role in geotechnical engineering.\n\nGeological materials\nThe majority of geological data comes from research on solid Earth materials. Meteorites and other extra-terrestrial natural materials are also studied by geological methods.\n\nMinerals\n\nMinerals are natural occurring elements and compounds with a definite homogeneous chemical composition and ordered atomic composition.\n\nEach mineral has distinct physical properties, and there are many tests to determine each of them. The specimens can be tested for:\n Luster: Quality of light reflected from the surface of a mineral. Examples are metallic, pearly, waxy, dull. \n Color: Minerals are grouped by their color. Mostly diagnostic but impurities can change a mineral's color.\n Streak: Performed by scratching the sample on a porcelain plate. The color of the streak can help name the mineral.\n Hardness: The resistance of a mineral to scratching.\n Breakage pattern: A mineral can either show fracture or cleavage, the former being breakage of uneven surfaces, and the latter a breakage along closely spaced parallel planes.\n Specific gravity: the weight of a specific volume of a mineral.\n Effervescence: Involves dripping hydrochloric acid on the mineral to test for fizzing.\n Magnetism: Involves using a magnet to test for magnetism.\n Taste: Minerals can have a distinctive taste, such as halite (which tastes like table salt).\n\nRocks\n\nA rock is any naturally occurring solid mass or aggregate of minerals or mineraloids. Most research in geology is associated with the study of rocks, as they provide the primary record of the majority of the geological history of the Earth. There are three major types of rock: igneous, sedimentary, and metamorphic. The rock cycle \nillustrates the relationships among them (see diagram).\n\nWhen a rock solidifies or crystallizes from melt (magma or lava), it is an igneous rock. This rock can be weathered and eroded, then redeposited and lithified into a sedimentary rock. It can then be turned into a metamorphic rock by heat and pressure that change its mineral content, resulting in a characteristic fabric. All three types may melt again, and when this happens, new magma is formed, from which an igneous rock may once more solidify.\nOrganic matter, such as coal, bitumen, oil and natural gas, is linked mainly to organic-rich sedimentary rocks.\n\nTo study all three types of rock, geologists evaluate the minerals of which they are composed and their other physical properties, such as texture and fabric.\n\nUnlithified material\nGeologists also study unlithified materials (referred to as superficial deposits) that lie above the bedrock. This study is often known as Quaternary geology, after the Quaternary period of geologic history, which is the most recent period of geologic time.\n\nMagma\n\nMagma is the original unlithified source of all igneous rocks. The active flow of molten rock is closely studied in volcanology, and igneous petrology aims to determine the history of igneous rocks from their original molten source to their final crystallization.\n\nWhole-Earth structure\n\nPlate tectonics\n\nIn the 1960s, it was discovered that the Earth's lithosphere, which includes the crust and rigid uppermost portion of the upper mantle, is separated into tectonic plates that move across the plastically deforming, solid, upper mantle, which is called the asthenosphere. This theory is supported by several types of observations, including seafloor spreading and the global distribution of mountain terrain and seismicity.\n\nThere is an intimate coupling between the movement of the plates on the surface and the convection of the mantle (that is, the heat transfer caused by the slow movement of ductile mantle rock). Thus, oceanic plates and the adjoining mantle convection currents always move in the same direction \u2013 because the oceanic lithosphere is actually the rigid upper thermal boundary layer of the convecting mantle. This coupling between rigid plates moving on the surface of the Earth and the convecting mantle is called plate tectonics.\n\nThe development of plate tectonics has provided a physical basis for many observations of the solid Earth. Long linear regions of geological features are explained as plate boundaries. \n\nFor example:\n Mid-ocean ridges, high regions on the seafloor where hydrothermal vents and volcanoes exist, are seen as divergent boundaries, where two plates move apart.\n Arcs of volcanoes and earthquakes are theorized as convergent boundaries, where one plate subducts, or moves, under another.\n\nTransform boundaries, such as the San Andreas Fault system, resulted in widespread powerful earthquakes. Plate tectonics also has provided a mechanism for Alfred Wegener's theory of continental drift, in which the continents move across the surface of the Earth over geological time. They also provided a driving force for crustal deformation, and a new setting for the observations of structural geology. The power of the theory of plate tectonics lies in its ability to combine all of these observations into a single theory of how the lithosphere moves over the convecting mantle.\n\nEarth structure\n\nAdvances in seismology, computer modeling, and mineralogy and crystallography at high temperatures and pressures give insights into the internal composition and structure of the Earth.\n\nSeismologists can use the arrival times of seismic waves to image the interior of the Earth. Early advances in this field showed the existence of a liquid outer core (where shear waves were not able to propagate) and a dense solid inner core. These advances led to the development of a layered model of the Earth, with a crust and lithosphere on top, the mantle below (separated within itself by seismic discontinuities at 410 and 660 kilometers), and the outer core and inner core below that. More recently, seismologists have been able to create detailed images of wave speeds inside the earth in the same way a doctor images a body in a CT scan. These images have led to a much more detailed view of the interior of the Earth, and have replaced the simplified layered model with a much more dynamic model.\n\nMineralogists have been able to use the pressure and temperature data from the seismic and modeling studies alongside knowledge of the elemental composition of the Earth to reproduce these conditions in experimental settings and measure changes in crystal structure. These studies explain the chemical changes associated with the major seismic discontinuities in the mantle and show the crystallographic structures expected in the inner core of the Earth.\n\nGeological time\n\nThe geological time scale encompasses the history of the Earth. It is bracketed at the earliest by the dates of the first Solar System material at 4.567 Ga (or 4.567 billion years ago) and the formation of the Earth at\n4.54 Ga\n(4.54 billion years), which is the beginning of the informally recognized Hadean eona division of geological time. At the later end of the scale, it is marked by the present day (in the Holocene epoch).\n\nTimescale of the Earth\n\nImportant milestones on Earth\n\n 4.567 Ga (gigaannum: billion years ago):  Solar system formation\n 4.54 Ga: Accretion, or formation, of Earth\n c. 4 Ga: End of Late Heavy Bombardment, the first life\n c. 3.5 Ga: Start of photosynthesis\n c. 2.3 Ga: Oxygenated atmosphere, first snowball Earth\n 730\u2013635 Ma (megaannum: million years ago): second snowball Earth\n 541 \u00b1 0.3 Ma: Cambrian explosion \u2013 vast multiplication of hard-bodied life; first abundant fossils; start of the Paleozoic\n c. 380 Ma: First vertebrate land animals\n 250 Ma: Permian-Triassic extinction \u2013 90% of all land animals die; end of Paleozoic and beginning of Mesozoic\n 66 Ma: Cretaceous\u2013Paleogene extinction \u2013 Dinosaurs die; end of Mesozoic and beginning of Cenozoic\n c. 7 Ma: First hominins appear\n 3.9 Ma: First Australopithecus, direct ancestor to modern Homo sapiens, appear\n 200 ka (kiloannum: thousand years ago): First modern Homo sapiens appear in East Africa\n\nTimescale of the Moon\n\nTimescale of Mars\n\nDating methods\n\nRelative dating\n\nMethods for relative dating were developed when geology first emerged as a natural science. Geologists still use the following principles today as a means to provide information about geological history and the timing of geological events.\n\nThe principle of uniformitarianism states that the geological processes observed in operation that modify the Earth's crust at present have worked in much the same way over geological time. A fundamental principle of geology advanced by the 18th-century Scottish physician and geologist James Hutton is that \"the present is the key to the past.\" In Hutton's words: \"the past history of our globe must be explained by what can be seen to be happening now.\"\n\nThe principle of intrusive relationships concerns crosscutting intrusions. In geology, when an igneous intrusion cuts across a formation of sedimentary rock, it can be determined that the igneous intrusion is younger than the sedimentary rock. Different types of intrusions include stocks, laccoliths, batholiths, sills and dikes.\n\nThe principle of cross-cutting relationships pertains to the formation of faults and the age of the sequences through which they cut. Faults are younger than the rocks they cut; accordingly, if a fault is found that penetrates some formations but not those on top of it, then the formations that were cut are older than the fault, and the ones that are not cut must be younger than the fault. Finding the key bed in these situations may help determine whether the fault is a normal fault or a thrust fault.\n\nThe principle of inclusions and components states that, with sedimentary rocks, if inclusions (or clasts) are found in a formation, then the inclusions must be older than the formation that contains them. For example, in sedimentary rocks, it is common for gravel from an older formation to be ripped up and included in a newer layer. A similar situation with igneous rocks occurs when xenoliths are found. These foreign bodies are picked up as magma or lava flows, and are incorporated, later to cool in the matrix. As a result, xenoliths are older than the rock that contains them.\n\nThe principle of original horizontality states that the deposition of sediments occurs as essentially horizontal beds. Observation of modern marine and non-marine sediments in a wide variety of environments supports this generalization (although cross-bedding is inclined, the overall orientation of cross-bedded units is horizontal).\n\nThe principle of superposition states that a sedimentary rock layer in a tectonically undisturbed sequence is younger than the one beneath it and older than the one above it. Logically a younger layer cannot slip beneath a layer previously deposited. This principle allows sedimentary layers to be viewed as a form of the vertical timeline, a partial or complete record of the time elapsed from deposition of the lowest layer to deposition of the highest bed.\n\nThe principle of faunal succession is based on the appearance of fossils in sedimentary rocks. As organisms exist during the same period throughout the world, their presence or (sometimes) absence provides a relative age of the formations where they appear. Based on principles that William Smith laid out almost a hundred years before the publication of Charles Darwin's theory of evolution, the principles of succession developed independently of evolutionary thought. The principle becomes quite complex, however, given the uncertainties of fossilization, localization of fossil types due to lateral changes in habitat (facies change in sedimentary strata), and that not all fossils formed globally at the same time.\n\nAbsolute dating\n\nGeologists also use methods to determine the absolute age of rock samples and geological events. These dates are useful on their own and may also be used in conjunction with relative dating methods or to calibrate relative methods.\n\nAt the beginning of the 20th century, advancement in geological science was facilitated by the ability to obtain accurate absolute dates to geological events using radioactive isotopes and other methods. This changed the understanding of geological time. Previously, geologists could only use fossils and stratigraphic correlation to date sections of rock relative to one another. With isotopic dates, it became possible to assign absolute ages to rock units, and these absolute dates could be applied to fossil sequences in which there was datable material, converting the old relative ages into new absolute ages.\n\nFor many geological applications, isotope ratios of radioactive elements are measured in minerals that give the amount of time that has passed since a rock passed through its particular closure temperature, the point at which different radiometric isotopes stop diffusing into and out of the crystal lattice. These are used in geochronologic and thermochronologic studies. Common methods include uranium\u2013lead dating, potassium\u2013argon dating, argon\u2013argon dating and uranium\u2013thorium dating. These methods are used for a variety of applications. Dating of lava and volcanic ash layers found within a stratigraphic sequence can provide absolute age data for sedimentary rock units that do not contain radioactive isotopes and calibrate relative dating techniques. These methods can also be used to determine ages of pluton emplacement.\nThermochemical techniques can be used to determine temperature profiles within the crust, the uplift of mountain ranges, and paleo-topography.\n\nFractionation of the lanthanide series elements is used to compute ages since rocks were removed from the mantle.\n\nOther methods are used for more recent events. Optically stimulated luminescence and cosmogenic radionuclide dating are used to date surfaces and/or erosion rates. Dendrochronology can also be used for the dating of landscapes. Radiocarbon dating is used for geologically young materials containing organic carbon.\n\nGeological development of an area\n\nThe geology of an area changes through time as rock units are deposited and inserted, and deformational processes change their shapes and locations.\n\nRock units are first emplaced either by deposition onto the surface or intrusion into the overlying rock. Deposition can occur when sediments settle onto the surface of the Earth and later lithify into sedimentary rock, or when as volcanic material such as volcanic ash or lava flows blanket the surface. Igneous intrusions such as batholiths, laccoliths, dikes, and sills, push upwards into the overlying rock, and crystallize as they intrude.\n\nAfter the initial sequence of rocks has been deposited, the rock units can be deformed and/or metamorphosed. Deformation typically occurs as a result of horizontal shortening, horizontal extension, or side-to-side (strike-slip) motion. These structural regimes broadly relate to convergent boundaries, divergent boundaries, and transform boundaries, respectively, between tectonic plates.\n\nWhen rock units are placed under horizontal compression, they shorten and become thicker. Because rock units, other than muds, do not significantly change in volume, this is accomplished in two primary ways: through faulting and folding. In the shallow crust, where brittle deformation can occur, thrust faults form, which causes the deeper rock to move on top of the shallower rock. Because deeper rock is often older, as noted by the principle of superposition, this can result in older rocks moving on top of younger ones. Movement along faults can result in folding, either because the faults are not planar or because rock layers are dragged along, forming drag folds as slip occurs along the fault. Deeper in the Earth, rocks behave plastically and fold instead of faulting. These folds can either be those where the material in the center of the fold buckles upwards, creating \"antiforms\", or where it buckles downwards, creating \"synforms\". If the tops of the rock units within the folds remain pointing upwards, they are called anticlines and synclines, respectively. If some of the units in the fold are facing downward, the structure is called an overturned anticline or syncline, and if all of the rock units are overturned or the correct up-direction is unknown, they are simply called by the most general terms, antiforms, and synforms.\n\nEven higher pressures and temperatures during horizontal shortening can cause both folding and metamorphism of the rocks. This metamorphism causes changes in the mineral composition of the rocks; creates a foliation, or planar surface, that is related to mineral growth under stress.  This can remove signs of the original textures of the rocks, such as bedding in sedimentary rocks, flow features of lavas, and crystal patterns in crystalline rocks.\n\nExtension causes the rock units as a whole to become longer and thinner. This is primarily accomplished through normal faulting and through the ductile stretching and thinning. Normal faults drop rock units that are higher below those that are lower. This typically results in younger units ending up below older units. Stretching of units can result in their thinning. In fact, at one location within the Maria Fold and Thrust Belt, the entire sedimentary sequence of the Grand Canyon appears over a length of less than a meter. Rocks at the depth to be ductilely stretched are often also metamorphosed. These stretched rocks can also pinch into lenses, known as boudins, after the French word for \"sausage\" because of their visual similarity.\n\nWhere rock units slide past one another, strike-slip faults develop in shallow regions, and become shear zones at deeper depths where the rocks deform ductilely.\n\nThe addition of new rock units, both depositionally and intrusively, often occurs during deformation. Faulting and other deformational processes result in the creation of topographic gradients, causing material on the rock unit that is increasing in elevation to be eroded by hillslopes and channels. These sediments are deposited on the rock unit that is going down. Continual motion along the fault maintains the topographic gradient in spite of the movement of sediment and continues to create accommodation space for the material to deposit. Deformational events are often also associated with volcanism and igneous activity. Volcanic ashes and lavas accumulate on the surface, and igneous intrusions enter from below. Dikes, long, planar igneous intrusions, enter along cracks, and therefore often form in large numbers in areas that are being actively deformed. This can result in the emplacement of dike swarms, such as those that are observable across the Canadian shield, or rings of dikes around the lava tube of a volcano.\n\nAll of these processes do not necessarily occur in a single environment and do not necessarily occur in a single order. The Hawaiian Islands, for example, consist almost entirely of layered basaltic lava flows. The sedimentary sequences of the mid-continental United States and the Grand Canyon in the southwestern United States contain almost-undeformed stacks of sedimentary rocks that have remained in place since Cambrian time. Other areas are much more geologically complex. In the southwestern United States, sedimentary, volcanic, and intrusive rocks have been metamorphosed, faulted, foliated, and folded. Even older rocks, such as the Acasta gneiss of the Slave craton in northwestern Canada, the oldest known rock in the world have been metamorphosed to the point where their origin is indiscernible without laboratory analysis. In addition, these processes can occur in stages. In many places, the Grand Canyon in the southwestern United States being a very visible example, the lower rock units were metamorphosed and deformed, and then deformation ended and the upper, undeformed units were deposited. Although any amount of rock emplacement and rock deformation can occur, and they can occur any number of times, these concepts provide a guide to understanding the geological history of an area.\n\nMethods of geology\n\nGeologists use a number of fields, laboratory, and numerical modeling methods to decipher Earth history and to understand the processes that occur on and inside the Earth. In typical geological investigations, geologists use primary information related to petrology (the study of rocks), stratigraphy (the study of sedimentary layers), and structural geology (the study of positions of rock units and their deformation). In many cases, geologists also study modern soils, rivers, landscapes, and glaciers; investigate past and current life and biogeochemical pathways, and use geophysical methods to investigate the subsurface. Sub-specialities of geology may distinguish endogenous and exogenous geology.\n\nField methods\n\nGeological field work varies depending on the task at hand. Typical fieldwork could consist of:\n Geological mapping\n Structural mapping: identifying the locations of major rock units and the faults and folds that led to their placement there.\n Stratigraphic mapping: pinpointing the locations of sedimentary facies (lithofacies and biofacies) or the mapping of isopachs of equal thickness of sedimentary rock\n Surficial mapping: recording the locations of soils and surficial deposits\n Surveying of topographic features\n compilation of topographic maps\n Work to understand change across landscapes, including:\n Patterns of erosion and deposition\n River-channel change through migration and avulsion\n Hillslope processes\n Subsurface mapping through geophysical methods\n These methods include:\n Shallow seismic surveys\n Ground-penetrating radar\n Aeromagnetic surveys\n Electrical resistivity tomography\n They aid in:\n Hydrocarbon exploration\n Finding groundwater\n Locating buried archaeological artifacts\n High-resolution stratigraphy\n Measuring and describing stratigraphic sections on the surface\n Well drilling and logging\n Biogeochemistry and geomicrobiology\n Collecting samples to:\n determine biochemical pathways\n identify new species of organisms\n identify new chemical compounds\n and to use these discoveries to:\n understand early life on Earth and how it functioned and metabolized\n find important compounds for use in pharmaceuticals\n Paleontology: excavation of fossil material\n For research into past life and evolution\n For museums and education\n Collection of samples for geochronology and thermochronology\n Glaciology: measurement of characteristics of glaciers and their motion\n\nPetrology\n\nIn addition to identifying rocks in the field (lithology), petrologists identify rock samples in the laboratory. Two of the primary methods for identifying rocks in the laboratory are through optical microscopy and by using an electron microprobe. In an optical mineralogy analysis, petrologists analyze thin sections of rock samples using a petrographic microscope, where the minerals can be identified through their different properties in plane-polarized and cross-polarized light, including their birefringence, pleochroism, twinning, and interference properties with a conoscopic lens. In the electron microprobe, individual locations are analyzed for their exact chemical compositions and variation in composition within individual crystals. Stable and radioactive isotope studies provide insight into the geochemical evolution of rock units.\n\nPetrologists can also use fluid inclusion data and perform high temperature and pressure physical experiments to understand the temperatures and pressures at which different mineral phases appear, and how they change through igneous and metamorphic processes. This research can be extrapolated to the field to understand metamorphic processes and the conditions of crystallization of igneous rocks. This work can also help to explain processes that occur within the Earth, such as subduction and magma chamber evolution.\n\nStructural geology\n\nStructural geologists use microscopic analysis of oriented thin sections of geological samples to observe the fabric within the rocks, which gives information about strain within the crystalline structure of the rocks. They also plot and combine measurements of geological structures to better understand the orientations of faults and folds to reconstruct the history of rock deformation in the area. In addition, they perform analog and numerical experiments of rock deformation in large and small settings.\n\nThe analysis of structures is often accomplished by plotting the orientations of various features onto stereonets. A stereonet is a stereographic projection of a sphere onto a plane, in which planes are projected as lines and lines are projected as points. These can be used to find the locations of fold axes, relationships between faults, and relationships between other geological structures.\n\nAmong the most well-known experiments in structural geology are those involving orogenic wedges, which are zones in which mountains are built along convergent tectonic plate boundaries. In the analog versions of these experiments, horizontal layers of sand are pulled along a lower surface into a back stop, which results in realistic-looking patterns of faulting and the growth of a critically tapered (all angles remain the same) orogenic wedge. Numerical models work in the same way as these analog models, though they are often more sophisticated and can include patterns of erosion and uplift in the mountain belt. This helps to show the relationship between erosion and the shape of a mountain range. These studies can also give useful information about pathways for metamorphism through pressure, temperature, space, and time.\n\nStratigraphy\n\nIn the laboratory, stratigraphers analyze samples of stratigraphic sections that can be returned from the field, such as those from drill cores. Stratigraphers also analyze data from geophysical surveys that show the locations of stratigraphic units in the subsurface. Geophysical data and well logs can be combined to produce a better view of the subsurface, and stratigraphers often use computer programs to do this in three dimensions. Stratigraphers can then use these data to reconstruct ancient processes occurring on the surface of the Earth, interpret past environments, and locate areas for water, coal, and hydrocarbon extraction.\n\nIn the laboratory, biostratigraphers analyze rock samples from outcrop and drill cores for the fossils found in them. These fossils help scientists to date the core and to understand the depositional environment in which the rock units formed. Geochronologists precisely date rocks within the stratigraphic section to provide better absolute bounds on the timing and rates of deposition.\nMagnetic stratigraphers look for signs of magnetic reversals in igneous rock units within the drill cores. Other scientists perform stable-isotope studies on the rocks to gain information about past climate.\n\nPlanetary geology\n\nWith the advent of space exploration in the twentieth century, geologists have begun to look at other planetary bodies in the same ways that have been developed to study the Earth. This new field of study is called planetary geology (sometimes known as astrogeology) and relies on known geological principles to study other bodies of the solar system.\n\nAlthough the Greek-language-origin prefix geo refers to Earth, \"geology\" is often used in conjunction with the names of other planetary bodies when describing their composition and internal processes: examples are \"the geology of Mars\" and \"Lunar geology\". Specialized terms such as selenology (studies of the Moon), areology (of Mars), etc., are also in use.\n\nAlthough planetary geologists are interested in studying all aspects of other planets, a significant focus is to search for evidence of past or present life on other worlds. This has led to many missions whose primary or ancillary purpose is to examine planetary bodies for evidence of life. One of these is the Phoenix lander, which analyzed Martian polar soil for water, chemical, and mineralogical constituents related to biological processes.\n\nApplied geology\n\nEconomic geology\n\nEconomic geology is a branch of geology that deals with aspects of economic minerals that humankind uses to fulfill various needs. Economic minerals are those extracted profitably for various practical uses. Economic geologists help locate and manage the Earth's natural resources, such as petroleum and coal, as well as mineral resources, which include metals such as iron, copper, and uranium.\n\nMining geology\n\nMining geology consists of the extractions of mineral resources from the Earth. Some resources of economic interests include gemstones, metals such as gold and copper, and many minerals such as asbestos, perlite, mica, phosphates, zeolites, clay, pumice, quartz, and silica, as well as elements such as sulfur, chlorine, and helium.\n\nPetroleum geology\n\nPetroleum geologists study the locations of the subsurface of the Earth that can contain extractable hydrocarbons, especially petroleum and natural gas. Because many of these reservoirs are found in sedimentary basins, they study the formation of these basins, as well as their sedimentary and tectonic evolution and the present-day positions of the rock units.\n\nEngineering geology\n\nEngineering geology is the application of geological principles to engineering practice for the purpose of assuring that the geological factors affecting the location, design, construction, operation, and maintenance of engineering works are properly addressed. Engineering geology is distinct from geological engineering, particularly in North America.\n\nIn the field of civil engineering, geological principles and analyses are used in order to ascertain the mechanical principles of the material on which structures are built. This allows tunnels to be built without collapsing, bridges and skyscrapers to be built with sturdy foundations, and buildings to be built that will not settle in clay and mud.\n\nHydrology\n\nGeology and geological principles can be applied to various environmental problems such as stream restoration, the restoration of brownfields, and the understanding of the interaction between natural habitat and the geological environment. Groundwater hydrology, or hydrogeology, is used to locate groundwater, which can often provide a ready supply of uncontaminated water and is especially important in arid regions, and to monitor the spread of contaminants in groundwater wells.\n\nPaleoclimatology\n\nGeologists also obtain data through stratigraphy, boreholes, core samples, and ice cores. Ice cores and sediment cores are used for paleoclimate reconstructions, which tell geologists about past and present temperature, precipitation, and sea level across the globe. These datasets are our primary source of information on global climate change outside of instrumental data.\n\nNatural hazards\n\nGeologists and geophysicists study natural hazards in order to enact safe building codes and warning systems that are used to prevent loss of property and life. Examples of important natural hazards that are pertinent to geology (as opposed those that are mainly or only pertinent to meteorology) are:\n\nHistory\n\nThe study of the physical material of the Earth dates back at least to ancient Greece when Theophrastus (372\u2013287 BCE) wrote the work Peri Lithon (On Stones). During the Roman period, Pliny the Elder wrote in detail of the many minerals and metals, then in practical use \u2013 even correctly noting the origin of amber. Additionally, in the 4th century BCE Aristotle made critical observations of the slow rate of geological change. He observed the composition of the land and formulated a theory where the Earth changes at a slow rate and that these changes cannot be observed during one person's lifetime. Aristotle developed one of the first evidence-based concepts connected to the geological realm regarding the rate at which the Earth physically changes.\n\nAbu al-Rayhan al-Biruni (973\u20131048 CE) was one of the earliest Persian geologists, whose works included the earliest writings on the geology of India, hypothesizing that the Indian subcontinent was once a sea. Drawing from Greek and Indian scientific literature that were not destroyed by the Muslim conquests, the Persian scholar Ibn Sina (Avicenna, 981\u20131037) proposed detailed explanations for the formation of mountains, the origin of earthquakes, and other topics central to modern geology, which provided an essential foundation for the later development of the science. In China, the polymath Shen Kuo (1031\u20131095) formulated a hypothesis for the process of land formation: based on his observation of fossil animal shells in a geological stratum in a mountain hundreds of miles from the ocean, he inferred that the land was formed by the erosion of the mountains and by deposition of silt.\n\nNicolas Steno (1638\u20131686) is credited with the law of superposition, the principle of original horizontality, and the principle of lateral continuity: three defining principles of stratigraphy.\n\nThe word geology was first used by Ulisse Aldrovandi in 1603, then by Jean-Andr\u00e9 Deluc in 1778 and introduced as a fixed term by Horace-B\u00e9n\u00e9dict de Saussure in 1779. The word is derived from the Greek \u03b3\u1fc6, g\u00ea, meaning \"earth\" and \u03bb\u03cc\u03b3\u03bf\u03c2, logos, meaning \"speech\". But according to another source, the word \"geology\" comes from a Norwegian, Mikkel Peders\u00f8n Escholt (1600\u20131699), who was a priest and scholar. Escholt first used the definition in his book titled, Geologia Norvegica (1657).\n\nWilliam Smith (1769\u20131839) drew some of the first geological maps and began the process of ordering rock strata (layers) by examining the fossils contained in them.\n\nIn 1763, Mikhail Lomonosov published his treatise On the Strata of Earth. His work was the first narrative of modern geology, based on the unity of processes in time and explanation of the Earth's past from the present.\n\nJames Hutton (1726-1797) is often viewed as the first modern geologist. In 1785 he presented a paper entitled Theory of the Earth to the Royal Society of Edinburgh. In his paper, he explained his theory that the Earth must be much older than had previously been supposed to allow enough time for mountains to be eroded and for sediments to form new rocks at the bottom of the sea, which in turn were raised up to become dry land. Hutton published a two-volume version of his ideas in 1795.\n\nFollowers of Hutton were known as Plutonists because they believed that some rocks were formed by vulcanism, which is the deposition of lava from volcanoes, as opposed to the Neptunists, led by Abraham Werner, who believed that all rocks had settled out of a large ocean whose level gradually dropped over time.\n\nThe first geological map of the U.S. was produced in 1809 by William Maclure. In 1807, Maclure commenced the self-imposed task of making a geological survey of the United States. Almost every state in the Union was traversed and mapped by him, the Allegheny Mountains being crossed and recrossed some 50 times. The results of his unaided labours were submitted to the American Philosophical Society in a memoir entitled Observations on the Geology of the United States explanatory of a Geological Map, and published in the Society's Transactions, together with the nation's first geological map. This antedates William Smith's geological map of England by six years, although it was constructed using a different classification of rocks.\n\nSir Charles Lyell (1797-1875) first published his famous book, Principles of Geology, in 1830. This book, which influenced the thought of Charles Darwin, successfully promoted the doctrine of uniformitarianism. This theory states that slow geological processes have occurred throughout the Earth's history and are still occurring today. In contrast, catastrophism is the theory that Earth's features formed in single, catastrophic events and remained unchanged thereafter. Though Hutton believed in uniformitarianism, the idea was not widely accepted at the time.\n\nMuch of 19th-century geology revolved around the question of the Earth's exact age. Estimates varied from a few hundred thousand to billions of years. By the early 20th century, radiometric dating allowed the Earth's age to be estimated at two billion years. The awareness of this vast amount of time opened the door to new theories about the processes that shaped the planet.\n\nSome of the most significant advances in 20th-century geology have been the development of the theory of plate tectonics in the 1960s and the refinement of estimates of the planet's age. Plate tectonics theory arose from two separate geological observations: seafloor spreading and continental drift. The theory revolutionized the Earth sciences. Today the Earth is known to be approximately 4.5 billion years old.\n\nFields or related disciplines\n\n Earth system science\n Economic geology\n Mining geology\n Petroleum geology\n Engineering geology\n Environmental geology\n Environmental science\n Geoarchaeology\n Geochemistry\n Biogeochemistry\n Isotope geochemistry\n Geochronology\n Geodetics\n Geography\n Geological engineering\n Geological modelling\n Geometallurgy\n Geomicrobiology\n Geomorphology\n Geomythology\n Geophysics\n Glaciology\n Historical geology\n Hydrogeology\n Meteorology\n Mineralogy\n Oceanography\n Marine geology\n Paleoclimatology\n Paleontology\n Micropaleontology\n Palynology\n Petrology\n Petrophysics\n Physical geography\n Plate tectonics\n Regional geology\n Sedimentology\n Seismology\n Soil science\n Pedology (soil study)\n Speleology\n Stratigraphy\n Biostratigraphy\n Chronostratigraphy\n Lithostratigraphy\n Structural geology\n Systems geology\n Tectonics\n Volcanology\n\nSee also\n\n Glossary of geology\n Geoprofessions\n Geotourism\n Glossary of geology terms\n Index of geology articles\n International Union of Geological Sciences (IUGS)\n Outline of geology\n Timeline of geology\n\nReferences\n\nExternal links\n\n One Geology: This interactive geological map of the world is an international initiative of the geological surveys around the globe. This groundbreaking project was launched in 2007 and contributed to the 'International Year of Planet Earth', becoming one of their flagship projects. \n Earth Science News, Maps, Dictionary, Articles, Jobs\n American Geophysical Union\n American Geosciences Institute\n European Geosciences Union\n Geological Society of America\n Geological Society of London\n Geology Buzz\n Video-interviews with famous geologists\n Geology OpenTextbook\n Chronostratigraphy benchmarks",
  "Government": "A government is the system or group of people governing an organized community, generally a state.\n\nIn the case of its broad associative definition, government normally consists of legislature, executive, and judiciary. Government is a means by which organizational policies are enforced, as well as a mechanism for determining policy. In many countries, the government has a kind of constitution, a statement of its governing principles and philosophy.\n\nWhile all types of organizations have governance, the term government is often used more specifically to refer to the approximately 200 independent national governments and subsidiary organizations.\n\nHistorically prevalent forms of government include monarchy, aristocracy, timocracy, oligarchy, democracy, theocracy and tyranny. The main aspect of any philosophy of government is how political power is obtained, with the two main forms being electoral contest and hereditary succession.\n\nDefinitions and etymology\n\nA government is the system to govern a state or community.\n\nThe word government derives, ultimately, from the Greek verb \u03ba\u03c5\u03b2\u03b5\u03c1\u03bd\u03ac\u03c9 [kubern\u00e1o] (meaning to steer with gubernaculum (rudder), the metaphorical sense being attested in Plato's Ship of State).\n\nThe Columbia Encyclopedia defines government as \"a system of social control under which the right to make laws, and the right to enforce them, is vested in a particular group in society\".\n\nWhile all types of organizations have governance, the word government is often used more specifically to refer to the approximately 200 independent national governments on Earth, as well as their subsidiary organizations.\n\nIn British English, \"government\" is often used to refer to what's known in American English as an \"administration\", i.e., the policies implemented by, and government officials appointed by, a particular executive or governing coalition.\n\nFinally, government is also sometimes used in English as a synonym for governance.\n\nHistory\n\nThe moment and place that the phenomenon of human government developed is lost in time; however, history does record the formations of early governments. About 5,000 years ago, the first small city-states appeared. By the third to second millenniums BC, some of these had developed into larger governed areas: Sumer, Ancient Egypt, the Indus Valley Civilization, and the Yellow River Civilization.\n\nThe development of agriculture and water control projects were a catalyst for the development of governments. On occasion a chief of a tribe was elected by various rituals or tests of strength to govern his tribe, sometimes with a group of elder tribesmen as a council. The human ability to precisely communicate abstract, learned information allowed humans to become ever more effective at agriculture, and that allowed for ever increasing population densities. David Christian explains how this resulted in states with laws and governments.\n\nStarting at the end of the 17th century, the prevalence of republican forms of government grew. The Glorious Revolution in England, the American Revolution, and the French Revolution contributed to the growth of representative forms of government. The Soviet Union was the first large country to have a Communist government. Since the fall of the Berlin Wall, liberal democracy has become an even more prevalent form of government.\n\nIn the nineteenth and twentieth century, there was a significant increase in the size and scale of government at the national level. This included the regulation of corporations and the development of the welfare state.\n\nPolitical science\n\nClassification \nIn political science, it has long been a goal to create a typology or taxonomy of polities, as typologies of political systems are not obvious. It is especially important in the political science fields of comparative politics and international relations. Like all categories discerned within forms of government, the boundaries of government classifications are either fluid or ill-defined.\n\nSuperficially, all governments have an official or ideal form. The United States is a constitutional republic, while the former Soviet Union was a socialist republic. However self-identification is not objective, and as Kopstein and Lichbach argue, defining regimes can be tricky. For example, Voltaire argued that \"the Holy Roman Empire is neither Holy, nor Roman, nor an Empire\".\n\nIdentifying a form of government is also difficult because many political systems originate as socio-economic movements and are then carried into governments by parties naming themselves after those movements; all with competing political-ideologies. Experience with those movements in power, and the strong ties they may have to particular forms of government, can cause them to be considered as forms of government in themselves.\n\nOther complications include general non-consensus or deliberate \"distortion or bias\" of reasonable technical definitions to political ideologies and associated forms of governing, due to the nature of politics in the modern era. For example: The meaning of \"conservatism\" in the United States has little in common with the way the word's definition is used elsewhere. As Ribuffo notes, \"what Americans now call conservatism much of the world calls liberalism or neoliberalism\"; a \"conservative\" in Finland would be labeled a \"socialist\" in the United States. Since the 1950s conservatism in the United States has been chiefly associated with the Republican Party. However, during the era of segregation many Southern Democrats were conservatives, and they played a key role in the Conservative Coalition that controlled Congress from 1937 to 1963.\n\nSocial-political ambiguity\nOpinions vary by individuals concerning the types and properties of governments that exist. \"Shades of gray\" are commonplace in any government and its corresponding classification. Even the most liberal democracies limit rival political activity to one extent or another while the most tyrannical dictatorships must organize a broad base of support thereby creating difficulties for \"pigeonholing\" governments into narrow categories. Examples include the claims of the United States as being a plutocracy rather than a democracy since some American voters believe elections are being manipulated by wealthy Super PACs.\n\nDialectical forms \n\nThe Classical Greek philosopher Plato discusses five types of regimes: aristocracy, timocracy, oligarchy, democracy and tyranny. Plato also assigns a man to each of these regimes to illustrate what they stand for. The tyrannical man would represent tyranny for example. These five regimes progressively degenerate starting with aristocracy at the top and tyranny at the bottom.\n\nForms\n\nOne method of classifying governments is through which people have the authority to rule.  This can either be one person (an autocracy, such as monarchy), a select group of people (an aristocracy), or the people as a whole (a democracy, such as a republic).\n\nThomas Hobbes stated on their classification:\n\nAutocracy\n\nAn autocracy is a system of government in which supreme power is concentrated in the hands of one person, whose decisions are subject to neither external legal restraints nor regularized mechanisms of popular control (except perhaps for the implicit threat of a coup d'\u00e9tat or mass insurrection).\n\nAristocracy\n\nAristocracy (Greek \u1f00\u03c1\u03b9\u03c3\u03c4\u03bf\u03ba\u03c1\u03b1\u03c4\u03af\u03b1 aristokrat\u00eda, from  \u1f04\u03c1\u03b9\u03c3\u03c4\u03bf\u03c2 aristos \"excellent\", and \u03ba\u03c1\u03ac\u03c4\u03bf\u03c2 kratos \"power\") is a form of government that places power in the hands of a small, privileged ruling class.\n\nMany monarchies were aristocracies, although in modern constitutional monarchies the monarch himself or herself has little real power. The term aristocracy could also refer to the non-peasant, non-servant, and non-city classes in the feudal system.\n\nDemocracy\n\nDemocracy is a system of government where the citizens exercise power by voting. In a direct democracy, the citizens as a whole form a governing body and vote directly on each issue. In a representative democracy the citizens elect representatives from among themselves. These representatives meet to form a governing body, such as a legislature. In a constitutional democracy the powers of the majority are exercised within the framework of a representative democracy, but the constitution limits the majority and protects the minority, usually through the enjoyment by all of certain individual rights, e.g. freedom of speech, or freedom of association.\n\nRepublics \n\nA republic is a form of government in which the country is considered a \"public matter\" (Latin: res publica), not the private concern or property of the rulers, and where offices of states are subsequently directly or indirectly elected or appointed rather than inherited.  The people, or some significant portion of them, have supreme control over the government and where offices of state are elected or chosen by elected people. A common simplified definition of a republic is a government where the head of state is not a monarch. Montesquieu included both democracies, where all the people have a share in rule, and aristocracies or oligarchies, where only some of the people rule, as republican forms of government.\n\nOther terms used to describe different republics include democratic republic, parliamentary republic, semi-presidential republic, presidential republic, federal republic, and Islamic republic.\n\nFederalism \n\nFederalism is a political concept in which a group of members are bound together by covenant with a governing representative head. The term \"federalism\" is also used to describe a system of government in which sovereignty is constitutionally divided between a central governing authority and constituent political units, variously called states, provinces or otherwise. Federalism is a system based upon democratic principles and institutions in which the power to govern is shared between national and provincial/state governments, creating what is often called a federation. Proponents are often called federalists.\n\nEconomic systems \n\nHistorically, most political systems originated as socioeconomic ideologies. Experience with those movements in power and the strong ties they may have to particular forms of government can cause them to be considered as forms of government in themselves.\n\nMaps\n\nSee also\n\n List of forms of government\n Central government\n Civics\n Comparative government\n Constitutional economics\n Deep state\n Digital democracy\n E-Government\n Government effectiveness index\n History of politics\n Legal rights\n List of countries by system of government\n List of European Union member states by political system\n Ministry\n Political economy\n Political history\n Politics\n Prime ministerial government\n State (polity)\n Voting system\n World government\n\nPrinciples\nCertain major characteristics are defining of certain types; others are historically associated with certain types of government.\n Rule according to higher law (unwritten ethical principles) vs. written constitutionalism\n Separation of church and state or free church vs. state religion\n Civilian control of the military vs. stratocracy\n Totalitarianism or authoritarianism vs. libertarianism\n Majority rule or parliamentary sovereignty vs. constitution or bill of rights with separation of powers and supermajority rules to prevent tyranny of the majority and protect minority rights\n Androcracy (patriarchy) or gynarchy (matriarchy) vs. gender quotas, gender equality provision, or silence on the matter\n\nAutonomy\nThis list focuses on differing approaches that political systems take to the distribution of sovereignty, and the autonomy of regions within the state.\n\n Sovereignty located exclusively at the centre of political jurisdiction.\n Empire\n Unitary state\n Sovereignty located at the centre and in peripheral areas.\n Hegemony\n Federation and federal republic\n Confederation\n Federal monarchy\n Diverging degrees of sovereignty.\n Alliance\n Asymmetrical federalism\n Federacy\n Associated state\n Corpus separatum\n Colony\n Crown colony\n Chartered company\n Dependent territory\n Occupied territory\n Occupied zone\n Mandate\n Exclusive mandate\n Military Frontier\n Neutral zone\n Colonial dependency\n Protectorate\n Vassal state\n Satellite state\n Puppet state\n Thalassocracy\n Unrecognized state\n States with limited recognition\n Separatist movement\n Government in exile\n Micronation\n Provisional government\n Territorial disputes\n Non-self-governing territories\n League of Nations\n League\n Commonwealth\n Decentralisation and devolution (powers redistributed from central to regional or local governments)\n\nNotes\n\nReferences\n\nExternal links \n\n The Phrontistery Word List: Types of Government and Leadership\n Types of Governments from Historical Atlas of the 20th Century\n Other classifications examples from Historical Atlas of the 20th Century\n World Affairs: Types of Government\n CBBC Newsround: types of government\n Bill Moyers: Plutocracy Rising\n Phobiocracy by Chris Claypoole\n\n \nPolitical terminology\nMain topic articles",
  "Heraldry": "Heraldry () is a discipline relating to the design, display and study of armorial bearings (known as armory), as well as related disciplines, such as vexillology, together with the study of ceremony, rank and pedigree. Armory, the best-known branch of heraldry, concerns the design and transmission of the heraldic achievement. The achievement, or armorial bearings usually includes a coat of arms on a shield, helmet and crest, together with any accompanying devices, such as supporters, badges, heraldic banners and mottoes.\n\nAlthough the use of various devices to signify individuals and groups goes back to antiquity, both the form and use of such devices varied widely, as the concept of regular, hereditary designs, constituting the distinguishing feature of heraldry, did not develop until the High Middle Ages. It is often claimed that the use of helmets with face guards during this period made it difficult to recognize one's commanders in the field when large armies gathered together for extended periods, necessitating the development of heraldry as a symbolic language, but there is little support for this view.\n\nThe perceived beauty and pageantry of heraldic designs allowed them to survive the gradual abandonment of armour on the battlefield during the seventeenth century.  Heraldry has been described poetically as \"the handmaid of history\", \"the shorthand of history\", and \"the floral border in the garden of history\".  In modern times, individuals, public and private organizations, corporations, cities, towns, regions, and other entities use heraldry and its conventions to symbolize their heritage, achievements, and aspirations.\n\nHistory\n\nPrecursors\nVarious symbols have been used to represent individuals or groups for thousands of years.  The earliest representations of distinct persons and regions in Egyptian art show the use of standards topped with the images or symbols of various gods, and the names of kings appear upon emblems known as serekhs, representing the king's palace, and usually topped with a falcon representing the god Horus, of whom the king was regarded as the earthly incarnation.  Similar emblems and devices are found in ancient Mesopotamian art of the same period, and the precursors of heraldic beasts such as the griffin can also be found.  In the Bible, the Book of Numbers refers to the standards and ensigns of the children of Israel, who were commanded to gather beneath these emblems and declare their pedigrees.  The Greek and Latin writers frequently describe the shields and symbols of various heroes, and units of the Roman army were sometimes identified by distinctive markings on their shields.\n\nUntil the nineteenth century, it was common for heraldic writers to cite examples such as these, and metaphorical symbols such as the \"Lion of Judah\" or \"Eagle of the Caesars\" as evidence of the antiquity of heraldry itself; and to infer therefrom that the great figures of ancient history bore arms representing their noble status and descent.  The Book of Saint Albans, compiled in 1486, declares that Christ himself was a gentleman of coat armour.  These claims are now regarded as the fantasy of medieval heralds, as there is no evidence of a distinctive symbolic language akin to that of heraldry during this early period; nor do many of the shields described in antiquity bear a close resemblance to those of medieval heraldry; nor is there any evidence that specific symbols or designs were passed down from one generation to the next, representing a particular person or line of descent.\n\nThe medieval heralds also devised arms for various knights and lords from history and literature.  Notable examples include the toads attributed to Pharamond, the cross and martlets of Edward the Confessor, and the various arms attributed to the Nine Worthies and the Knights of the Round Table.  These too are readily dismissed as fanciful inventions, rather than evidence of the antiquity of heraldry.\n\nOrigins of modern heraldry\n\nThe development of the modern heraldic language cannot be attributed to a single individual, time, or place.  Although certain designs that are now considered heraldic were evidently in use during the eleventh century, most accounts and depictions of shields up to the beginning of the twelfth century contain little or no evidence of their heraldic character.  For example, the Bayeux Tapestry, illustrating the Norman invasion of England in 1066, and probably commissioned about 1077, when the cathedral of Bayeux was rebuilt, depicts a number of shields of various shapes and designs, many of which are plain, while others are decorated with dragons, crosses, or other typically heraldic figures.  Yet no individual is depicted twice bearing the same arms, nor are any of the descendants of the various persons depicted known to have borne devices resembling those in the tapestry.\n\nSimilarly, an account of the French knights at the court of the Byzantine emperor Alexius I at the beginning of the twelfth century describes their shields of polished metal, devoid of heraldic design.  A Spanish manuscript from 1109 describes both plain and decorated shields, none of which appears to have been heraldic.  The Abbey of St. Denis contained a window commemorating the knights who embarked on the Second Crusade in 1147, and was probably made soon after the event; but Montfaucon's illustration of the window before it was destroyed shows no heraldic design on any of the shields.\n\nIn England, from the time of the Norman conquest, official documents had to be sealed.  Beginning in the twelfth century, seals assumed a distinctly heraldic character; a number of seals dating from between 1135 and 1155 appear to show the adoption of heraldic devices in England, France, Germany, Spain, and Italy.  A notable example of an early armorial seal is attached to a charter granted by Philip I, Count of Flanders, in 1164.  Seals from the latter part of the eleventh and early twelfth centuries show no evidence of heraldic symbolism, but by the end of the twelfth century, seals are uniformly heraldic in nature.\n\nOne of the earliest known examples of armory as it subsequently came to be practiced can be seen on the tomb of Geoffrey Plantagenet, Count of Anjou, who died in 1151.  An enamel, probably commissioned by Geoffrey's widow between 1155 and 1160, depicts him carrying a blue shield decorated with six golden lions rampant.  He wears a blue helmet adorned with another lion, and his cloak is lined in vair.  A medieval chronicle states that Geoffrey was given a shield of this description when he was knighted by his father-in-law, Henry I, in 1128; but this account probably dates to about 1175.\n\nThe earlier heraldic writers attributed the lions of England to William the Conqueror, but the earliest evidence of the association of lions with the English crown is a seal bearing two lions passant, used by the future King John during the lifetime of his father, Henry II, who died in 1189.  Since Henry was the son of Geoffrey Plantagenet, it seems reasonable to suppose that the adoption of lions as an heraldic emblem by Henry or his sons might have been inspired by Geoffrey's shield.  John's elder brother, Richard the Lionheart, who succeeded his father on the throne, is believed to have been the first to have borne the arms of three lions passant-guardant, still the arms of England, having earlier used two lions rampant combatant, which arms may also have belonged to his father.  Richard is also credited with having originated the English crest of a lion statant (now statant-guardant).\n\nThe origins of heraldry are sometimes associated with the Crusades, a series of military campaigns undertaken by Christian armies from 1096 to 1487, with the goal of reconquering Jerusalem and other former Byzantine territories captured by Muslim forces during the seventh century.  While there is no evidence that heraldic art originated in the course of the Crusades, there is no reason to doubt that the gathering of large armies, drawn from across Europe for a united cause, would have encouraged the adoption of armorial bearings as a means of identifying one's commanders in the field, or that it helped disseminate the principles of armory across Europe.  At least two distinctive features of heraldry are generally accepted as products of the crusaders: the surcoat, an outer garment worn over the armor to protect the wearer from the heat of the sun, was often decorated with the same devices that appeared on a knight's shield.  It is from this garment that the phrase \"coat of arms\" is derived.  Also the lambrequin, or mantling, that depends from the helmet and frames the shield in modern heraldry, began as a practical covering for the helmet and the back of the neck during the Crusades, serving much the same function as the surcoat. Its slashed or scalloped edge, today rendered as billowing flourishes, is thought to have originated from hard wearing in the field, or as a means of deadening a sword blow and perhaps entangling the attacker's weapon.\n\nHeralds and heraldic authorities\nThe spread of armorial bearings across Europe gave rise to a new occupation: the herald, originally a type of messenger employed by noblemen, assumed the responsibility of learning and knowing the rank, pedigree, and heraldic devices of various knights and lords, as well as the rules governing the design and description, or blazoning of arms, and the precedence of their bearers.  As early as the late thirteenth century, certain heralds in the employ of monarchs were given the title \"King of Heralds\", which eventually became \"King of Arms.\"\n\nIn the earliest period, arms were assumed by their bearers without any need for heraldic authority.  However, by the middle of the fourteenth century, the principle that only a single individual was entitled to bear a particular coat of arms was generally accepted, and disputes over the ownership of arms seems to have led to gradual establishment of heraldic authorities to regulate their use.  The earliest known work of heraldic jurisprudence, De Insigniis et Armis, was written about 1350 by Bartolus de Saxoferrato, a professor of law at the University of Padua.  The most celebrated armorial dispute in English heraldry is that of Scrope v Grosvenor (1390), in which two different men claimed the right to bear azure, a bend or.  The continued proliferation of arms, and the number of disputes arising from different men assuming the same arms, led Henry V to issue a proclamation in 1419, forbidding all those who had not borne arms at the Battle of Agincourt from assuming arms, except by inheritance or a grant from the crown.\n\nBeginning in the reign of Henry VIII of England, the English Kings of Arms were commanded to make visitations, in which they traveled about the country, recording arms borne under proper authority, and requiring those who bore arms without authority either to obtain authority for them, or cease their use.  Arms borne improperly were to be taken down and defaced.  The first such visitation began in 1530, and the last was carried out in 1700, although no new commissions to carry out visitations were made after the accession of William III in 1689. There is little evidence that Scottish heralds ever went on visitations.\n\nIn 1484, during the reign of Richard III, the various heralds employed by the crown were incorporated into England's College of Arms, through which all new grants of arms would eventually be issued.  The college currently consists of three Kings of Arms, assisted by six Heralds, and four Pursuivants, or junior officers of arms, all under the authority of the Earl Marshal; but all of the arms granted by the college are granted by the authority of the crown.  In Scotland Court of the Lord Lyon King of Arms oversees the heraldry, and holds court sessions which are an official part of Scotland's court system.\nSimilar bodies regulate the granting of arms in other monarchies and several members of the Commonwealth of Nations, but in most other countries there is no heraldic authority, and no law preventing anyone from assuming whatever arms they please, provided that they do not infringe upon the arms of another.\n\nLater uses and developments\nAlthough heraldry originated from military necessity, it soon found itself at home in the pageantry of the medieval tournament.  The opportunity for knights and lords to display their heraldic bearings in a competitive medium led to further refinements, such as the development of elaborate tournament helms, and further popularized the art of heraldry throughout Europe.  Prominent burghers and corporations, including many cities and towns, assumed or obtained grants of arms, with only nominal military associations.  Heraldic devices were depicted in various contexts, such as religious and funerary art, and in using a wide variety of media, including stonework, carved wood, enamel, stained glass, and embroidery.\n\nAs the rise of firearms rendered the mounted knight increasingly irrelevant during the sixteenth and seventeenth centuries, and the tournament faded into history, the military character of heraldry gave way to its use as a decorative art.  Freed from the limitations of actual shields and the need for arms to be easily distinguished in combat, heraldic artists designed increasingly elaborate achievements, culminating in the development of \"landscape heraldry\", incorporating realistic depictions of landscapes, during the latter part of the eighteenth and early part of the nineteenth century.  These fell out of fashion during the mid-nineteenth century, when a renewed interest in the history of armory led to the re-evaluation of earlier designs, and a new appreciation for the medieval origins of the art.  Since the late nineteenth century, heraldry has focused on the use of varied lines of partition and little-used ordinaries to produce new and unique designs.\n\nHeraldic achievement\n\nElements of an achievement\n\nA heraldic achievement consists of a shield of arms, the coat of arms, or simply coat, together with all of its accompanying elements, such as a crest, supporters, and other heraldic embellishments.  The term \"coat of arms\" technically refers to the shield of arms itself, but the phrase is commonly used to refer to the entire achievement.  The one indispensable element of a coat of arms is the shield; many ancient coats of arms consist of nothing else, but no achievement or armorial bearings exists without a coat of arms.\n\nFrom a very early date, illustrations of arms were frequently embellished with helmets placed above the shields.  These in turn came to be decorated with fan-shaped or sculptural crests, often incorporating elements from the shield of arms; as well as a wreath or torse, or sometimes a coronet, from which depended the lambrequin or mantling.  To these elements, modern heraldry often adds a motto displayed on a ribbon, typically below the shield.  The helmet is borne of right, and forms no part of a grant of arms; it may be assumed without authority by anyone entitled to bear arms, together with mantling and whatever motto the armiger may desire.  The crest, however, together with the torse or coronet from which it arises, must be granted or confirmed by the relevant heraldic authority.\n\nIf the bearer is entitled to the ribbon, collar, or badge of a knightly order, it may encircle or depend from the shield.  Some arms, particularly those of the nobility, are further embellished with supporters, heraldic figures standing alongside or behind the shield; often these stand on a compartment, typically a mound of earth and grass, on which other badges, symbols, or heraldic banners may be displayed.  The most elaborate achievements sometimes display the entire coat of arms beneath a pavilion, an embellished tent or canopy of the type associated with the medieval tournament., though this is only very rarely found in English or Scots achievements.\n\nShield\n\nThe primary element of a heraldic achievement is the shield, or escutcheon, upon which the coat of arms is depicted.  All of the other elements of an achievement are designed to decorate and complement these arms, but only the shield of arms is required.  The shape of the shield, like many other details, is normally left to the discretion of the heraldic artist, and many different shapes have prevailed during different periods of heraldic design, and in different parts of Europe.\n\nOne shape alone is normally reserved for a specific purpose: the lozenge, a diamond-shaped escutcheon, was traditionally used to display the arms of women, on the grounds that shields, as implements of war, were inappropriate for this purpose.  This distinction was not always strictly adhered to, and a general exception was usually made for sovereigns, whose arms represented an entire nation.  Sometimes an oval shield, or cartouche, was substituted for the lozenge; this shape was also widely used for the arms of clerics in French, Spanish, and Italian heraldry, although it was never reserved for their use.  In recent years, the use of the cartouche for women's arms has become general in Scottish heraldry, while both Scottish and Irish authorities have permitted a traditional shield under certain circumstances, and in Canadian heraldry the shield is now regularly granted.\n\nThe whole surface of the escutcheon is termed the field, which may be plain, consisting of a single tincture, or divided into multiple sections of differing tinctures by various lines of partition; and any part of the field may be sem\u00e9, or powdered with small charges.  The edges and adjacent parts of the escutcheon are used to identify the placement of various heraldic charges; the upper edge, and the corresponding upper third of the shield, are referred to as the chief; the lower part is the base.  The sides of the shield are known as the dexter and sinister flanks, although it is important to note that these terms are based on the point of view of the bearer of the shield, who would be standing behind it; to the observer, and in all heraldic illustration, the dexter is on the left side, and the sinister on the right.\n\nThe placement of various charges may also refer to a number of specific points, nine in number according to some authorities, but eleven according to others.  The three most important are fess point, located in the visual center of the shield; the honour point, located midway between fess point and the chief; and the nombril point, located midway between fess point and the base.  The other points include dexter chief, center chief, and sinister chief, running along the upper part of the shield from left to right, above the honour point; dexter flank and sinister flank, on the sides approximately level with fess point; and dexter base, middle base, and sinister base along the lower part of the shield, below the nombril point.\n\nTinctures\n\nOne of the most distinctive qualities of heraldry is the use of a limited palette of colours and patterns, usually referred to as tinctures.  These are divided into three categories, known as metals, colours, and furs.\n\nThe metals are or and argent, representing gold and silver, respectively, although in practice they are usually depicted as yellow and white.  Five colours are universally recognized: gules, or red; sable, or black; azure, or blue; vert, or green; and purpure, or purple; and most heraldic authorities also admit two additional colours, known as sanguine or murrey, a dark red or mulberry colour between gules and purpure, and tenn\u00e9, an orange or dark yellow to brown colour.  These last two are quite rare, and are often referred to as stains, from the belief that they were used to represent some dishonourable act, although in fact there is no evidence that this use existed outside of fanciful heraldic writers.  Perhaps owing to the realization that there is really no such thing as a stain in genuine heraldry, as well as the desire to create new and unique designs, the use of these colours for general purposes has become accepted in the twentieth and twenty-first centuries.  Occasionally one meets with other colours, particularly in continental heraldry, although they are not generally regarded among the standard heraldic colours.  Among these are cendr\u00e9e, or ash-colour; brun\u00e2tre, or brown; bleu-c\u00e9leste or bleu de ciel, sky blue; amaranth or columbine, a bright violet-red or pink colour; and carnation, commonly used to represent flesh in French heraldry.  A more recent addition is the use of copper as a metal in one or two Canadian coats of arms.\n\nThere are two basic types of heraldic fur, known as ermine and vair, but over the course of centuries each has developed a number of variations.  Ermine represents the fur of the stoat, a type of weasel, in its white winter coat, when it is called an ermine.  It consists of a white, or occasionally silver field, powdered with black figures known as ermine spots, representing the black tip of the animal's tail.  Ermine was traditionally used to line the cloaks and caps of the nobility.  The shape of the heraldic ermine spot has varied considerably over time, and nowadays is typically drawn as an arrowhead surmounted by three small dots, but older forms may be employed at the artist's discretion.  When the field is sable and the ermine spots argent, the same pattern is termed ermines; when the field is or rather than argent, the fur is termed erminois; and when the field is sable and the ermine spots or, it is termed pean.\n\nVair represents the winter coat of the red squirrel, which is blue-grey on top and white underneath.  To form the linings of cloaks, the pelts were sewn together, forming an undulating, bell-shaped pattern, with interlocking light and dark rows.  The heraldic fur is depicted with interlocking rows of argent and azure, although the shape of the pelts, usually referred to as \"vair bells\", is usually left to the artist's discretion.  In the modern form, the bells are depicted with straight lines and sharp angles, and meet only at points; in the older, undulating pattern, now known as vair ond\u00e9 or vair ancien, the bells of each tincture are curved and joined at the base.  There is no fixed rule as to whether the argent bells should be at the top or the bottom of each row.  At one time vair commonly came in three sizes, and this distinction is sometimes encountered in continental heraldry; if the field contains fewer than four rows, the fur is termed gros vair or beffroi; if of six or more, it is menu-vair, or miniver.\n\nA common variation is counter-vair, in which alternating rows are reversed, so that the bases of the vair bells of each tincture are joined to those of the same tincture in the row above or below.  When the rows are arranged so that the bells of each tincture form vertical columns, it is termed vair in pale; in continental heraldry one may encounter vair in bend, which is similar to vair in pale, but diagonal.  When alternating rows are reversed as in counter-vair, and then displaced by half the width of one bell, it is termed vair in point, or wave-vair.  A form peculiar to German heraldry is alternate vair, in which each vair bell is divided in half vertically, with half argent and half azure.  All of these variations can also be depicted in the form known as potent, in which the shape of the vair bell is replaced by a T-shaped figure, known as a potent from its resemblance to a crutch.  Although it is really just a variation of vair, it is frequently treated as a separate fur.\n\nWhen the same patterns are composed of tinctures other than argent and azure, they are termed vair\u00e9 or vairy of those tinctures, rather than vair; potent\u00e9 of other colours may also be found.  Usually vair\u00e9 will consist of one metal and one colour, but ermine or one of its variations may also be used, and vair\u00e9 of four tinctures, usually two metals and two colours, is sometimes found.\n\nThree additional furs are sometimes encountered in continental heraldry; in French and Italian heraldry one meets with plumet\u00e9 or plumetty, in which the field appears to be covered with feathers, and papelonn\u00e9, in which it is decorated with scales.  In German heraldry one may encounter kursch, or vair bellies, depicted as brown and furry; all of these probably originated as variations of vair.\n\nConsiderable latitude is given to the heraldic artist in depicting the heraldic tinctures; there is no fixed shade or hue to any of them.\n\nWhenever an object is depicted as it appears in nature, rather than in one or more of the heraldic tinctures, it is termed proper, or the colour of nature.  This does not seem to have been done in the earliest heraldry, but examples are known from at least the seventeenth century.  While there can be no objection to the occasional depiction of objects in this manner, the overuse of charges in their natural colours is often cited as indicative of bad heraldic practice.  The practice of landscape heraldry, which flourished in the latter part of the eighteenth and early part of the nineteenth century, made extensive use of non-heraldic colours.\n\nOne of the most important conventions of heraldry is the so-called \"rule of tincture\".  To provide for contrast and visibility, metals should never be placed on metals, and colours should never be placed on colours.  This rule does not apply to charges which cross a division of the field, which is partly metal and partly colour; nor, strictly speaking, does it prevent a field from consisting of two metals or two colours, although this is unusual.  Furs are considered amphibious, and neither metal nor colour; but in practice ermine and erminois are usually treated as metals, while ermines and pean are treated as colours.  This rule is strictly adhered to in British armory, with only rare exceptions; although generally observed in continental heraldry, it is not adhered to quite as strictly.  Arms which violate this rule are sometimes known as \"puzzle arms\", of which the most famous example is the arms of the Kingdom of Jerusalem, consisting of gold crosses on a silver field.\n\nVariations of the field\n\nThe field of a shield, or less often a charge or crest, is sometimes made up of a pattern of colours, or variation. A pattern of horizontal (barwise) stripes, for example, is called barry, while a pattern of vertical (palewise) stripes is called paly. A pattern of diagonal stripes may be called bendy or bendy sinister, depending on the direction of the stripes. Other variations include chevrony, gyronny and chequy. Wave shaped stripes are termed undy. For further variations, these are sometimes combined to produce patterns of barry-bendy, paly-bendy, lozengy and fusilly. Sem\u00e9s, or patterns of repeated charges, are also considered variations of the field. The Rule of tincture applies to all sem\u00e9s and variations of the field.\n\nDivisions of the field\n\nThe field of a shield in heraldry can be divided into more than one tincture, as can the various heraldic charges. Many coats of arms consist simply of a division of the field into two contrasting tinctures. These are considered divisions of a shield, so the rule of tincture can be ignored. For example, a shield divided azure and gules would be perfectly acceptable. A line of partition may be straight or it may be varied. The variations of partition lines can be wavy, indented, embattled, engrailed, nebuly, or made into myriad other forms; see Line (heraldry).\n\nOrdinaries\n\nIn the early days of heraldry, very simple bold rectilinear shapes were painted on shields. These could be easily recognized at a long distance and could be easily remembered. They therefore served the main purpose of heraldry: identification. As more complicated shields came into use, these bold shapes were set apart in a separate class as the \"honorable ordinaries\". They act as charges and are always written first in blazon. Unless otherwise specified they extend to the edges of the field. Though ordinaries are not easily defined, they are generally described as including the cross, the fess, the pale, the bend, the chevron, the saltire, and the pall.\n\nThere is a separate class of charges called sub-ordinaries which are of a geometrical shape subordinate to the ordinary. According to Friar, they are distinguished by their order in blazon. The sub-ordinaries include the inescutcheon, the orle, the tressure, the double tressure, the bordure, the chief, the canton, the label, and flaunches.\n\nOrdinaries may appear in parallel series, in which case blazons in English give them different names such as pallets, bars, bendlets, and chevronels. French blazon makes no such distinction between these diminutives and the ordinaries when borne singly. Unless otherwise specified an ordinary is drawn with straight lines, but each may be indented, embattled, wavy, engrailed, or otherwise have their lines varied.\n\nCharges\n\nA charge is any object or figure placed on a heraldic shield or on any other object of an armorial composition. Any object found in nature or technology may appear as a heraldic charge in armory. Charges can be animals, objects, or geometric shapes. Apart from the ordinaries, the most frequent charges are the cross \u2013 with its hundreds of variations \u2013 and the lion and eagle. Other common animals are stags, wild boars, martlets, and fish. Dragons, bats, unicorns, griffins, and other monsters appear as charges and as supporters.\n\nAnimals are found in various stereotyped positions or attitudes. Quadrupeds can often be found rampant (standing on the left hind foot). Another frequent position is passant, or walking, like the lions of the coat of arms of England. Eagles are almost always shown with their wings spread, or displayed. A pair of wings conjoined is called a vol.\n\nIn English heraldry the crescent, mullet, martlet, annulet, fleur-de-lis, and rose may be added to a shield to distinguish cadet branches of a family from the senior line. These cadency marks are usually shown smaller than normal charges, but it still does not follow that a shield containing such a charge belongs to a cadet branch. All of these charges occur frequently in basic undifferenced coats of arms.\n\nMarshalling\n\nTo marshal two or more coats of arms is to combine them in one shield, to express inheritance, claims to property, or the occupation of an office. This can be done in a number of ways, of which the simplest is impalement: dividing the field per pale and putting one whole coat in each half. Impalement replaced the earlier dimidiation \u2013 combining the dexter half of one coat with the sinister half of another \u2013 because dimidiation can create ambiguity between, for example, a bend and a chevron. \"Dexter\" (from Latin, \"right\") means to the right from the viewpoint of the bearer of the arms and \"sinister\" (from Latin sinistra, \"left\") means to the bearer's left. The dexter side is considered the side of greatest honour (see also dexter and sinister).\n\nA more versatile method is quartering, division of the field by both vertical and horizontal lines. This practice originated in Spain (Castile and Le\u00f3n) after the 13th century. The usual number of divisions is four, but the principle has been extended to very large numbers of \"quarters\".\n\nQuarters are numbered from the dexter chief (the corner nearest to the right shoulder of a man standing behind the shield), proceeding across the top row, and then across the next row and so on. When three coats are quartered, the first is repeated as the fourth; when only two coats are quartered, the second is also repeated as the third. The quarters of a personal coat of arms correspond to the ancestors from whom the bearer has inherited arms, normally in the same sequence as if the pedigree were laid out with the father's father's ... father (to as many generations as necessary) on the extreme left and the mother's mother's...mother on the extreme right.  A few lineages have accumulated hundreds of quarters, though such a number is usually displayed only in documentary contexts. The Scottish and Spanish traditions resist allowing more than four quarters, preferring to subdivide one or more \"grand quarters\" into sub-quarters as needed.\n\nThe third common mode of marshalling is with an inescutcheon, a small shield placed in front of the main shield. In Britain this is most often an \"escutcheon of pretence\" indicating, in the arms of a married couple, that the wife is an heraldic heiress (i.e., she inherits a coat of arms because she has no brothers). In continental Europe an inescutcheon (sometimes called a \"heart shield\") usually carries the ancestral arms of a monarch or noble whose domains are represented by the quarters of the main shield.\n\nIn German heraldry, animate charges in combined coats usually turn to face the centre of the composition.\n\nHelm and crest\n\nIn English the word \"crest\" is commonly (but erroneously) used to refer to an entire heraldic achievement of armorial bearings. The technical use of the heraldic term crest refers to just one component of a complete achievement. The crest rests on top of a helmet which itself rests on the most important part of the achievement: the shield.\n\nThe modern crest has grown out of the three-dimensional figure placed on the top of the mounted knights' helms as a further means of identification. In most heraldic traditions, a woman does not display a crest, though this tradition is being relaxed in some heraldic jurisdictions, and the stall plate of Lady Marion Fraser in the Thistle Chapel in St Giles, Edinburgh, shows her coat on a lozenge but with helmet, crest, and motto.\n\nThe crest is usually found on a wreath of twisted cloth and sometimes within a coronet. Crest-coronets are generally simpler than coronets of rank, but several specialized forms exist; for example, in Canada, descendants of the United Empire Loyalists are entitled to use a Loyalist military coronet (for descendants of members of Loyalist regiments) or Loyalist civil coronet (for others).\n\nWhen the helm and crest are shown, they are usually accompanied by a mantling. This was originally a cloth worn over the back of the helmet as partial protection against heating by sunlight. Today it takes the form of a stylized cloak hanging from the helmet. Typically in British heraldry, the outer surface of the mantling is of the principal colour in the shield and the inner surface is of the principal metal, though peers in the United Kingdom use standard colourings (Gules doubled Argent - Red/White) regardless of rank or the colourings of their arms. The mantling is sometimes conventionally depicted with a ragged edge, as if damaged in combat, though the edges of most are simply decorated at the emblazoner's discretion.\n\nClergy often refrain from displaying a helm or crest in their heraldic achievements. Members of the clergy may display appropriate headwear. This often takes the form of a small crowned, wide brimmed hat called a galero with the colours and tassels denoting rank; or, in the case of Papal coats of arms until the inauguration of Pope Benedict XVI in 2005, an elaborate triple crown known as a tiara. Benedict broke with tradition to substitute a mitre in his arms. Orthodox and Presbyterian clergy do sometimes adopt other forms of head gear to ensign their shields. In the Anglican tradition, clergy members may pass crests on to their offspring, but rarely display them on their own shields.\n\nMottoes\nAn armorial motto is a phrase or collection of words intended to describe the motivation or intention of the armigerous person or corporation. This can form a pun on the family name as in Thomas Nevile's motto Ne vile velis. Mottoes are generally changed at will and do not make up an integral part of the armorial achievement. Mottoes can typically be found on a scroll under the shield. In Scottish heraldry, where the motto is granted as part of the blazon, it is usually shown on a scroll above the crest, and may not be changed at will. A motto may be in any language.\n\nSupporters and other insignia\n\nSupporters are human or animal figures or, very rarely, inanimate objects, usually placed on either side of a coat of arms as though supporting it. In many traditions, these have acquired strict guidelines for use by certain social classes. On the European continent, there are often fewer restrictions on the use of supporters. In the United Kingdom, only peers of the realm, a few baronets, senior members of orders of knighthood, and some corporate bodies are granted supporters. Often, these can have local significance or a historical link to the armiger.\n\nIf the armiger has the title of baron, hereditary knight, or higher, he may display a coronet of rank above the shield. In the United Kingdom, this is shown between the shield and helmet, though it is often above the crest in Continental heraldry.\n\nAnother addition that can be made to a coat of arms is the insignia of a baronet or of an order of knighthood. This is usually represented by a collar or similar band surrounding the shield. When the arms of a knight and his wife are shown in one achievement, the insignia of knighthood surround the husband's arms only, and the wife's arms are customarily surrounded by an ornamental garland of leaves for visual balance.\n\nDifferencing and cadency\n\nSince arms pass from parents to offspring, and there is frequently more than one child per couple, it is necessary to distinguish the arms of siblings and extended family members from the original arms as passed on from eldest son to eldest son. Over time several schemes have been used.\n\nBlazon\n\nTo \"blazon\" arms means to describe them using the formal language of heraldry. This language has its own vocabulary and syntax, or rules governing word order, which becomes essential for comprehension when blazoning a complex coat of arms. The verb comes from the Middle English blasoun, itself a derivative of the French blason meaning \"shield\". The system of blazoning arms used in English-speaking countries today was developed by heraldic officers in the Middle Ages. The blazon includes a description of the arms contained within the escutcheon or shield, the crest, supporters where present, motto and other insignia. Complex rules, such as the rule of tincture, apply to the physical and artistic form of newly created arms, and a thorough understanding of these rules is essential to the art of heraldry. Though heraldic forms initially were broadly similar across Europe, several national styles had developed by the end of the Middle Ages, and artistic and blazoning styles today range from the very simple to extraordinarily complex.\n\nNational styles\nThe emergence of heraldry occurred across western Europe almost simultaneously in the various countries. Originally, heraldic style was very similar from country to country. Over time, heraldic tradition diverged into four broad styles: German-Nordic, Gallo-British, Latin, and Eastern. In addition, it can be argued that newer national heraldic traditions, such as South African and Canadian heraldry, have emerged in the 20th century.\n\nGerman-Nordic heraldry\n\nCoats of arms in Germany, the Nordic countries, Estonia, Latvia, the Czech lands and northern Switzerland generally change very little over time. Marks of difference are very rare in this tradition, as are heraldic furs. One of the most striking characteristics of German-Nordic heraldry is the treatment of the crest. Often, the same design is repeated in the shield and the crest. The use of multiple crests is also common. The crest is rarely used separately as in British heraldry, but can sometimes serve as a mark of difference between different branches of a family. Torse is optional. Heraldic courtoisie is observed: that is, charges in a composite shield (or two shields displayed together) usually turn to face the centre.\n\nCoats consisting only of a divided field are somewhat more frequent in Germany than elsewhere.\n\nDutch heraldry\n\nThe Low Countries were great centres of heraldry in medieval times. One of the famous armorials is the Gelre Armorial or Wapenboek, written between 1370 and 1414. Coats of arms in the Netherlands were not controlled by an official heraldic system like the two in the United Kingdom, nor were they used solely by noble families. Any person could develop and use a coat of arms if they wished to do so, provided they did not usurp someone else's arms, and historically, this right was enshrined in Roman Dutch law. As a result, many merchant families had coats of arms even though they were not members of the nobility. These are sometimes referred to as burgher arms, and it is thought that most arms of this type were adopted while the Netherlands was a republic (1581\u20131806). This heraldic tradition was also exported to the erstwhile Dutch colonies. Dutch heraldry is characterised by its simple and rather sober style, and in this sense, is closer to its medieval origins than the elaborate styles which developed in other heraldic traditions.\n\nGallo-British heraldry\n\nThe use of cadency marks to difference arms within the same family and the use of semy fields are distinctive features of Gallo-British heraldry (in Scotland the most significant mark of cadency being the bordure, the small brisures playing a very minor role). It is common to see heraldic furs used. In the United Kingdom, the style is notably still controlled by royal officers of arms. French heraldry experienced a period of strict rules of construction under Napoleon. English and Scots heraldries make greater use of supporters than other European countries.\n\nFurs, chevrons and five-pointed stars are more frequent in France and Britain than elsewhere.\n\nLatin heraldry\n\nThe heraldry of southern France, Andorra, Spain, and Italy is characterized by a lack of crests, and uniquely shaped shields. Portuguese heraldry, however, does use crests. Portuguese and Spanish heraldry, which together form a larger Iberian tradition of heraldry, occasionally introduce words to the shield of arms, a practice usually avoided in British heraldry. Latin heraldry is known for extensive use of quartering, because of armorial inheritance via the male and the female lines. Moreover, Italian heraldry is dominated by the Roman Catholic Church, featuring many shields and achievements, most bearing some reference to the Church.\n\nTrees are frequent charges in Latin arms. Charged bordures, including bordures inscribed with words, are seen often in Spain.\n\nEastern European heraldry\n\nEastern European heraldry is in the traditions developed in Albania, Belarus, Bulgaria, Croatia, Hungary, Lithuania, Poland, Romania, Russia, Serbia, Slovakia and Ukraine. Eastern coats of arms are characterized by a pronounced, territorial, clan system \u2013 often, entire villages or military groups were granted the same coat of arms irrespective of family relationships. In Poland, nearly six hundred unrelated families are known to bear the same Jastrz\u0119biec coat of arms. Marks of cadency are almost unknown, and shields are generally very simple, with only one charge. Many heraldic shields derive from ancient house marks. At least fifteen per cent of all Hungarian personal arms bear a severed Turk's head, referring to their wars against the Ottoman Empire.\n\nQuasi-heraldic emblems\nTrue heraldry, as now generally understood, has its roots in medieval Europe. However, there have been other historical cultures which have used symbols and emblems to represent families or individuals, and in some cases these symbols have been adopted into Western heraldry. For example, the coat of arms of the Ottoman Empire incorporated the royal tughra as part of its crest, along with such traditional Western heraldic elements as the escutcheon and the compartment.\n\nGreek symbols\nAncient Greeks were among the first civilizations to use symbols consistently in order to identify a warrior, clan or a state. The first record of a shield blazon is illustrated in Aeschylus' tragedy Seven Against Thebes.\n\nMon\n\n, also , , and , are Japanese emblems used to decorate and identify an individual or family. While mon is an encompassing term that may refer to any such device, kamon and mondokoro refer specifically to emblems used to identify a family. An authoritative mon reference compiles Japan's 241 general categories of mon based on structural resemblance (a single mon may belong to multiple categories), with 5116 distinct individual mon (it is however well acknowledged that there exist lost or obscure mon that are not in this compilation).\n\nThe devices are similar to the badges and coats of arms in European heraldic tradition, which likewise are used to identify individuals and families.  Mon are often referred to as crests in Western literature, another European heraldic device similar to the mon in function. \n\nJapanese helmets (kabuto) also incorporated elements similar to crests, called datemono, which helped identify the wearer while they were concealed by armour. These devices sometimes incorporated mon, and some figures, like Date Masamune, were well-known for their helmet designs.\n\nSocialist emblems\n\nCommunist states often followed a unique style characterized by communist symbolism. Although commonly called coats of arms, most such devices are not actually coats of arms in the traditional heraldic sense and should therefore, in a strict sense, not be called arms at all. Many communist governments purposely diverged from the traditional forms of European heraldry in order to distance themselves from the monarchies that they usually replaced, with actual coats of arms being seen as symbols of the monarchs.\n\nThe Soviet Union was the first state to use this type of emblem, beginning at its creation in 1922. The style became more widespread after World War II, when many other communist states were established. Even a few non-socialist states have adopted the style, for various reasons\u2014usually because communists had helped them to gain independence\u2014but also when no apparent connection to a Communist nation exists, such as the emblem of Italy. After the fall of the Soviet Union and the other communist states in Eastern Europe in 1989\u20131991, this style of heraldry was often abandoned for the old heraldic practices, with many (but not all) of the new governments reinstating the traditional heraldry that was previously cast aside.\n\nTamgas\n\nA tamga or tamgha \"stamp, seal\" (, Turkic: tamga) is an abstract seal or stamp used by Eurasian nomadic peoples and by cultures influenced by them. The tamga was normally the emblem of a particular tribe, clan or family. They were common among the Eurasian nomads throughout Classical Antiquity and the Middle Ages (including Alans, Mongols, Sarmatians, Scythians and Turkic peoples). Similar \"tamga-like\" symbols were sometimes also adopted by sedentary peoples adjacent to the Pontic-Caspian steppe both in Eastern Europe and Central Asia, such as the East Slavs, whose ancient royal symbols are sometimes referred to as \"tamgas\" and have similar appearance.\n\nUnlike European coats of arms, tamgas were not always inherited, and could stand for families or clans (for example, when denoting territory, livestock, or religious items) as well as for specific individuals (such as when used for weapons, or for royal seals). One could also adopt the tamga of one's master or ruler, therefore signifying said master's patronage. Outside of denoting ownership, tamgas also possessed religious significance, and were used as talismans to protect one from curses (it was believed that, as symbols of family, tamgas embodied the power of one's heritage). Tamgas depicted geometric shapes, images of animals, items, or glyphs. As they were usually inscribed using heavy and unwieldy instruments, such as knives or brands, and on different surfaces (meaning that their appearance could vary somewhat), tamgas were always simple and stylised, and needed to be laconic and easily recognisable.\n\nTughras\n\nEvery sultan of the Ottoman Empire had his own monogram, called the tughra, which served as a royal symbol. A coat of arms in the European heraldic sense was created in the late 19th century. Hampton Court requested from Ottoman Empire the coat of arms to be included in their collection. As the coat of arms had not been previously used in Ottoman Empire, it was designed after this request and the final design was adopted by Sultan Abdul Hamid II on April 17, 1882. It included two flags: the flag of the Ottoman Dynasty, which had a crescent and a star on red base, and the flag of the Islamic Caliph, which had three crescents on a green base.\n\nModern heraldry\n\nHeraldry flourishes in the modern world; institutions, companies, and private persons continue using coats of arms as their pictorial identification. In the United Kingdom and Ireland, the English Kings of Arms, Scotland's Lord Lyon King of Arms, and the Chief Herald of Ireland continue making grants of arms. There are heraldic authorities in Canada, South Africa, Spain, and Sweden that grant or register coats of arms. In South Africa, the right to armorial bearings is also determined by Roman Dutch law, due to its origins as a 17th-century colony of the Netherlands.\n\nHeraldic societies abound in Africa, Asia, Australasia, the Americas and Europe. Heraldry aficionados participate in the Society for Creative Anachronism, medieval revivals, micronations and other related projects. Modern armigers use heraldry to express ancestral and personal heritage as well as professional, academic, civic, and national pride. Little is left of class identification in modern heraldry, where the emphasis is more than ever on expression of identity.\n\nHeraldry continues to build on its rich tradition in academia, government, guilds and professional associations, religious institutions, and the military. Nations and their subdivisions \u2013 provinces, states, counties, cities, etc. \u2013 continue to build on the traditions of civic heraldry. The Roman Catholic Church, Anglican churches, and other religious institutions maintain the traditions of ecclesiastical heraldry for clergy, religious orders, and schools.\n\nMany of these institutions have begun to employ blazons representing modern objects. For example, some heraldic symbols issued by the United States Army Institute of Heraldry incorporate symbols such as guns, airplanes, or locomotives. Some scientific institutions incorporate symbols of modern science such as the atom or particular scientific instruments. The arms of the United Kingdom Atomic Energy Authority uses traditional heraldic symbols to depict the harnessing of atomic power. Locations with strong associations to particular industries may incorporate associated symbols. The coat of arms of Stenungsund Municipality in Sweden incorporates a hydrocarbon molecule, alluding to the historical significance of the petrochemical industry in the region.\n\nHeraldry in countries with heraldic authorities continues to be regulated generally by laws granting rights to arms and recognizing possession of arms as well as protecting against their misuse. Countries without heraldic authorities usually treat coats of arms as creative property in the manner of logos, offering protection under copyright laws. This is the case in Nigeria, where most of the components of its heraldic system are otherwise unregulated.\n\nSee also\n\n Heraldic societies, an extended list including non-official heraldic authorities and societies\n Mon, for the Japanese emblems likened to heraldry\n Socialist heraldry\n Vexillology, the study of flag design\n Totem pole, a somewhat similar concept in North America\n\nFootnotes\n\nReferences\n\nCitations\n\nSources \n Books and Articles\n\n \n \n \n \n \n \n \n \n \n \n Hart, Vaughan. 'London\u2019s Standard: Christopher Wren and the Heraldry of the Monument\u2019, in RES: Journal of Anthropology and Aesthetics, vol.73/74, Autumn 2020, pp. 325-39\n\nExternal links \n\n EuropeanHeraldry.org catalogues a large number of European noble titles and heraldry.\n Heraldry of Greatlitvan Nobility\n Heraldry of the World (civic heraldry), an overview of thousands of coats of arms of towns and countries\n \n International heraldry Introduction and examples\n Heraldisk Selskab The Scandinavian Heraldry Society (one of the oldest and largest societies dedicated to heraldic research)\n Heraldry for Kids Introducing Heraldry for Kids with free heraldry activity sheets\n Heraldica The history of heraldry, knighthood and chivalry, glossary of the blazon, themes, coats of arms, etc.\n Heraldic Arts Founded in 1987, the Society of Heraldic Arts was the first organisation of its kind in the world.",
  "Language": "A language is a structured system of communication used by humans. Languages can be based on speech and gesture (spoken language), sign, or writing. The structure of language is its grammar and the free components are its vocabulary. Many languages, including the most widely-spoken ones, have writing systems that enable sounds or signs to be recorded for later reactivation. Human language is unique among the known systems of animal communication in that it is not dependent on a single mode of transmission (sight, sound, etc.), is highly variable between cultures and across time, and affords a much wider range of expression than other systems.  \n\nHuman languages have the properties of productivity and displacement, and rely on social convention and learning. \n\nEstimates of the number of human languages in the world vary between 5,000 and 7,000. Precise estimates depend on an arbitrary distinction (dichotomy) being established between languages and dialects. Natural languages are spoken, signed, or both; however, any language can be encoded into secondary media using auditory, visual, or tactile stimuli\u00a0\u2013 for example, writing, whistling, signing, or braille. In other words, human language is modality-independent, but written or signed language is the way to inscribe or encode the natural human speech or gestures. \n\nDepending on philosophical perspectives regarding the definition of language and meaning, when used as a general concept, \"language\" may refer to the cognitive ability to learn and use systems of complex communication, or to describe the set of rules that makes up these systems, or the set of utterances that can be produced from those rules. All languages rely on the process of semiosis to relate signs to particular meanings. Oral, manual and tactile languages contain a phonological system that governs how symbols are used to form sequences known as words or morphemes, and a syntactic system that governs how words and morphemes are combined to form phrases and utterances.\n\nThe scientific study of language is called linguistics. Critical examinations of languages, such as philosophy of language, the relationships between language and thought, etc., such as how words represent experience, have been debated at least since Gorgias and Plato in ancient Greek civilization. Thinkers such as Rousseau (1712 \u2013 1778) have debated that language originated from emotions, while others like Kant (1724 \u20131804), have held that languages originated from rational and logical thought. Twentieth century philosophers such as Wittgenstein (1889 \u2013 1951) argued that philosophy is really the study of language itself. Major figures in contemporary linguistics of these times include Ferdinand de Saussure and Noam Chomsky.\n\nLanguage is thought to have gradually diverged from earlier primate communication systems when early hominins acquired the ability to form a theory of mind and shared intentionality. This development is sometimes thought to have coincided with an increase in brain volume, and many linguists see the structures of language as having evolved to serve specific communicative and social functions. Language is processed in many different locations in the human brain, but especially in Broca's and Wernicke's areas. Humans acquire language through social interaction in early childhood, and children generally speak fluently by approximately three years old. Language and culture are codependent. Therefore, in addition to its strictly communicative uses, language has social uses such as signifying group identity, social stratification, as well as use for social grooming and entertainment.\n\nLanguages evolve and diversify over time, and the history of their evolution can be reconstructed by comparing modern languages to determine which traits their ancestral languages must have had in order for the later developmental stages to occur. A group of languages that descend from a common ancestor is known as a language family; in contrast, a language that has been demonstrated to not have any living or non-living relationship with another language is called a language isolate. There are also many unclassified languages whose relationships have not been established, and spurious languages may have not existed at all. Academic consensus holds that between 50% and 90% of languages spoken at the beginning of the 21st century will probably have become extinct by the year 2100.\n\nDefinitions \n\nThe English word language derives ultimately from Proto-Indo-European  \"tongue, speech, language\" through Latin , \"language; tongue\", and Old French . The word is sometimes used to refer to codes, ciphers, and other kinds of artificially constructed communication systems such as formally defined computer languages used for computer programming. Unlike conventional human languages, a formal language in this sense is a system of signs for encoding and decoding information. This article specifically concerns the properties of natural human language as it is studied in the discipline of linguistics.\n\nAs an object of linguistic study, \"language\" has two primary meanings: an abstract concept, and a specific linguistic system, e.g. \"French\". The Swiss linguist Ferdinand de Saussure, who defined the modern discipline of linguistics, first explicitly formulated the distinction using the French word  for language as a concept,  as a specific instance of a language system, and  for the concrete usage of speech in a particular language.\n\nWhen speaking of language as a general concept, definitions can be used which stress different aspects of the phenomenon. These definitions also entail different approaches and understandings of language, and they also inform different and often incompatible schools of linguistic theory. Debates about the nature and origin of language go back to the ancient world. Greek philosophers such as Gorgias and Plato debated the relation between words, concepts and reality. Gorgias argued that language could represent neither the objective experience nor human experience, and that communication and truth were therefore impossible. Plato maintained that communication is possible because language represents ideas and concepts that exist independently of, and prior to, language.\n\nDuring the Enlightenment and its debates about human origins, it became fashionable to speculate about the origin of language. Thinkers such as Rousseau and Herder argued that language had originated in the instinctive expression of emotions, and that it was originally closer to music and poetry than to the logical expression of rational thought. Rationalist philosophers such as Kant and Descartes held the opposite view. Around the turn of the 20th century, thinkers began to wonder about the role of language in shaping our experiences of the world\u00a0\u2013 asking whether language simply reflects the objective structure of the world, or whether it creates concepts that it in turn impose on our experience of the objective world. This led to the question of whether philosophical problems are really firstly linguistic problems. The resurgence of the view that language plays a significant role in the creation and circulation of concepts, and that the study of philosophy is essentially the study of language, is associated with what has been called the linguistic turn and philosophers such as Wittgenstein in 20th-century philosophy. These debates about language in relation to meaning and reference, cognition and consciousness remain active today.\n\nMental faculty, organ or instinct\nOne definition sees language primarily as the mental faculty that allows humans to undertake linguistic behaviour: to learn languages and to produce and understand utterances. This definition stresses the universality of language to all humans, and it emphasizes the biological basis for the human capacity for language as a unique development of the human brain. Proponents of the view that the drive to language acquisition is innate in humans argue that this is supported by the fact that all cognitively normal children raised in an environment where language is accessible will acquire language without formal instruction. Languages may even develop spontaneously in environments where people live or grow up together without a common language; for example, creole languages and spontaneously developed sign languages such as Nicaraguan Sign Language. This view, which can be traced back to the philosophers Kant and Descartes, understands language to be largely innate, for example, in Chomsky's theory of Universal Grammar, or American philosopher Jerry Fodor's extreme innatist theory. These kinds of definitions are often applied in studies of language within a cognitive science framework and in neurolinguistics.\n\nFormal symbolic system\nAnother definition sees language as a formal system of signs governed by grammatical rules of combination to communicate meaning. This definition stresses that human languages can be described as closed structural systems consisting of rules that relate particular signs to particular meanings. This structuralist view of language was first introduced by Ferdinand de Saussure, and his structuralism remains foundational for many approaches to language.\n\nSome proponents of Saussure's view of language have advocated a formal approach which studies language structure by identifying its basic elements and then by presenting a formal account of the rules according to which the elements combine in order to form words and sentences. The main proponent of such a theory is Noam Chomsky, the originator of the generative theory of grammar, who has defined language as the construction of sentences that can be generated using transformational grammars. Chomsky considers these rules to be an innate feature of the human mind and to constitute the rudiments of what language is. By way of contrast, such transformational grammars are also commonly used in formal logic, in formal linguistics, and in applied computational linguistics. In the philosophy of language, the view of linguistic meaning as residing in the logical relations between propositions and reality was developed by philosophers such as Alfred Tarski, Bertrand Russell, and other formal logicians.\n\nTool for communication\n\nYet another definition sees language as a system of communication that enables humans to exchange verbal or symbolic utterances. This definition stresses the social functions of language and the fact that humans use it to express themselves and to manipulate objects in their environment. Functional theories of grammar explain grammatical structures by their communicative functions, and understand the grammatical structures of language to be the result of an adaptive process by which grammar was \"tailored\" to serve the communicative needs of its users.\n\nThis view of language is associated with the study of language in pragmatic, cognitive, and interactive frameworks, as well as in sociolinguistics and linguistic anthropology. Functionalist theories tend to study grammar as dynamic phenomena, as structures that are always in the process of changing as they are employed by their speakers. This view places importance on the study of linguistic typology, or the classification of languages according to structural features, as it can be shown that processes of grammaticalization tend to follow trajectories that are partly dependent on typology. In the philosophy of language, the view of pragmatics as being central to language and meaning is often associated with Wittgenstein's later works and with ordinary language philosophers such as J.L. Austin, Paul Grice, John Searle, and W.O. Quine.\n\nDistinctive features of human language\n\nA number of features, many of which were described by Charles Hockett and called design features set human language apart from communication used by non-human animals.\n\nCommunication systems used by other animals such as bees or apes are closed systems that consist of a finite, usually very limited, number of possible ideas that can be expressed. In contrast, human language is open-ended and productive, meaning that it allows humans to produce a vast range of utterances from a finite set of elements, and to create new words and sentences. This is possible because human language is based on a dual code, in which a finite number of elements which are meaningless in themselves (e.g. sounds, letters or gestures) can be combined to form an infinite number of larger units of meaning (words and sentences). However, one study has demonstrated that an Australian bird, the chestnut-crowned babbler, is capable of using the same acoustic elements in different arrangements to create two functionally distinct vocalizations. Additionally, pied babblers have demonstrated the ability to generate two functionally distinct vocalisations composed of the same sound type, which can only be distinguished by the number of repeated elements.\n\nSeveral species of animals have proved to be able to acquire forms of communication through social learning: for instance a bonobo named Kanzi learned to express itself using a set of symbolic lexigrams. Similarly, many species of birds and whales learn their songs by imitating other members of their species. However, while some animals may acquire large numbers of words and symbols, none have been able to learn as many different signs as are generally known by an average 4 year old human, nor have any acquired anything resembling the complex grammar of human language.\n\nHuman languages differ from animal communication systems in that they employ grammatical and semantic categories, such as noun and verb, present and past, which may be used to express exceedingly complex meanings. It is distinguished by the property of recursivity: for example, a noun phrase can contain another noun phrase (as in \"[[the chimpanzee]'s lips]\") or a clause can contain another clause (as in \"[I see [the dog is running]]\"). Human language is the only known natural communication system whose adaptability may be referred to as modality independent. This means that it can be used not only for communication through one channel or medium, but through several. For example, spoken language uses the auditive modality, whereas sign languages and writing use the visual modality, and braille writing uses the tactile modality.\n\nHuman language is unusual in being able to refer to abstract concepts and to imagined or hypothetical events as well as events that took place in the past or may happen in the future. This ability to refer to events that are not at the same time or place as the speech event is called displacement, and while some animal communication systems can use displacement (such as the communication of bees that can communicate the location of sources of nectar that are out of sight), the degree to which it is used in human language is also considered unique.\n\nOrigin\n\nTheories about the origin of language differ in regard to their basic assumptions about what language is. Some theories are based on the idea that language is so complex that one cannot imagine it simply appearing from nothing in its final form, but that it must have evolved from earlier pre-linguistic systems among our pre-human ancestors. These theories can be called continuity-based theories. The opposite viewpoint is that language is such a unique human trait that it cannot be compared to anything found among non-humans and that it must therefore have appeared suddenly in the transition from pre-hominids to early man. These theories can be defined as discontinuity-based. Similarly, theories based on the generative view of language pioneered by Noam Chomsky see language mostly as an innate faculty that is largely genetically encoded, whereas functionalist theories see it as a system that is largely cultural, learned through social interaction.\n\nContinuity-based theories are held by a majority of scholars, but they vary in how they envision this development. Those who see language as being mostly innate, such as psychologist Steven Pinker, hold the precedents to be animal cognition, whereas those who see language as a socially learned tool of communication, such as psychologist Michael Tomasello, see it as having developed from animal communication in primates: either gestural or vocal communication to assist in cooperation. Other continuity-based models see language as having developed from music, a view already espoused by Rousseau, Herder, Humboldt, and Charles Darwin. A prominent proponent of this view is archaeologist Steven Mithen. Stephen Anderson states that the age of spoken languages is estimated at 60,000 to 100,000 years and that: Researchers on the evolutionary origin of language generally find it plausible to suggest that language was invented only once, and that all modern spoken languages are thus in some way related, even if that relation can no longer be recovered\u00a0... because of limitations on the methods available for reconstruction.\n\nBecause language emerged in the early prehistory of man, before the existence of any written records, its early development has left no historical traces, and it is believed that no comparable processes can be observed today. Theories that stress continuity often look at animals to see if, for example, primates display any traits that can be seen as analogous to what pre-human language must have been like. Early human fossils can be inspected for traces of physical adaptation to language use or pre-linguistic forms of symbolic behaviour. Among the signs in human fossils that may suggest linguistic abilities are: the size of the brain relative to body mass, the presence of a larynx capable of advanced sound production and the nature of tools and other manufactured artifacts.\n\nIt was mostly undisputed that pre-human australopithecines did not have communication systems significantly different from those found in great apes in general. However, a 2017 study on Ardipithecus ramidus challenges this belief. Scholarly opinions vary as to the developments since the appearance of the genus Homo some 2.5 million years ago. Some scholars assume the development of primitive language-like systems (proto-language) as early as Homo habilis (2.3 million years ago) while others place the development of primitive symbolic communication only with Homo erectus (1.8 million years ago) or Homo heidelbergensis (0.6 million years ago), and the development of language proper with anatomically modern Homo sapiens with the Upper Paleolithic revolution less than 100,000 years ago.\n\nChomsky is one prominent proponent of a discontinuity-based theory of human language origins. He suggests that for scholars interested in the nature of language, \"talk about the evolution of the language capacity is beside the point.\" Chomsky proposes that perhaps \"some random mutation took place [...] and it reorganized the brain, implanting a language organ in an otherwise primate brain.\" Though cautioning against taking this story literally, Chomsky insists that \"it may be closer to reality than many other fairy tales that are told about evolutionary processes, including language.\"\n\nStudy\n\nThe study of language, linguistics, has been developing into a science since the first grammatical descriptions of particular languages in India more than 2000 years ago, after the development of the Brahmi script. Modern linguistics is a science that concerns itself with all aspects of language, examining it from all of the theoretical viewpoints described above.\n\nSubdisciplines\nThe academic study of language is conducted within many different disciplinary areas and from different theoretical angles, all of which inform modern approaches to linguistics. For example, descriptive linguistics examines the grammar of single languages, theoretical linguistics develops theories on how best to conceptualize and define the nature of language based on data from the various extant human languages, sociolinguistics studies how languages are used for social purposes informing in turn the study of the social functions of language and grammatical description, neurolinguistics studies how language is processed in the human brain and allows the experimental testing of theories, computational linguistics builds on theoretical and descriptive linguistics to construct computational models of language often aimed at processing natural language or at testing linguistic hypotheses, and historical linguistics relies on grammatical and lexical descriptions of languages to trace their individual histories and reconstruct trees of language families by using the comparative method.\n\nEarly history\n\nThe formal study of language is often considered to have started in India with P\u0101\u1e47ini, the 5th century BC grammarian who formulated 3,959 rules of Sanskrit morphology. However, Sumerian scribes already studied the differences between Sumerian and Akkadian grammar around 1900 BC. Subsequent grammatical traditions developed in all of the ancient cultures that adopted writing.\n\nIn the 17th century AD, the French Port-Royal Grammarians developed the idea that the grammars of all languages were a reflection of the universal basics of thought, and therefore that grammar was universal. In the 18th century, the first use of the comparative method by British philologist and expert on ancient India William Jones sparked the rise of comparative linguistics. The scientific study of language was broadened from Indo-European to language in general by Wilhelm von Humboldt. Early in the 20th century, Ferdinand de Saussure introduced the idea of language as a static system of interconnected units, defined through the oppositions between them.\n\nBy introducing a distinction between diachronic and synchronic analyses of language, he laid the foundation of the modern discipline of linguistics. Saussure also introduced several basic dimensions of linguistic analysis that are still fundamental in many contemporary linguistic theories, such as the distinctions between syntagm and paradigm, and the Langue-parole distinction, distinguishing language as an abstract system (langue), from language as a concrete manifestation of this system (parole).\n\nModern linguistics \n\nIn the 1960s, Noam Chomsky formulated the generative theory of language. According to this theory, the most basic form of language is a set of syntactic rules that is universal for all humans and which underlies the grammars of all human languages. This set of rules is called Universal Grammar; for Chomsky, describing it is the primary objective of the discipline of linguistics. Thus, he considered that the grammars of individual languages are only of importance to linguistics insofar as they allow us to deduce the universal underlying rules from which the observable linguistic variability is generated.\n\nIn opposition to the formal theories of the generative school, functional theories of language propose that since language is fundamentally a tool, its structures are best analyzed and understood by reference to their functions. Formal theories of grammar seek to define the different elements of language and describe the way they relate to each other as systems of formal rules or operations, while functional theories seek to define the functions performed by language and then relate them to the linguistic elements that carry them out. The framework of cognitive linguistics interprets language in terms of the concepts (which are sometimes universal, and sometimes specific to a particular language) which underlie its forms. Cognitive linguistics is primarily concerned with how the mind creates meaning through language.\n\nPhysiological and neural architecture of language and speech\nSpeaking is the default modality for language in all cultures. The production of spoken language depends on sophisticated capacities for controlling the lips, tongue and other components of the vocal apparatus, the ability to acoustically decode speech sounds, and the neurological apparatus required for acquiring and producing language. The study of the genetic bases for human language is at an early stage: the only gene that has definitely been implicated in language production is FOXP2, which may cause a kind of congenital language disorder if affected by mutations.\n\nThe brain\n\n The brain is the coordinating center of all linguistic activity; it controls both the production of linguistic cognition and of meaning and the mechanics of speech production. Nonetheless, our knowledge of the neurological bases for language is quite limited, though it has advanced considerably with the use of modern imaging techniques. The discipline of linguistics dedicated to studying the neurological aspects of language is called neurolinguistics.\n\nEarly work in neurolinguistics involved the study of language in people with brain lesions, to see how lesions in specific areas affect language and speech. In this way, neuroscientists in the 19th century discovered that two areas in the brain are crucially implicated in language processing. The first area is Wernicke's area, which is in the posterior section of the superior temporal gyrus in the dominant cerebral hemisphere. People with a lesion in this area of the brain develop receptive aphasia, a condition in which there is a major impairment of language comprehension, while speech retains a natural-sounding rhythm and a relatively normal sentence structure. The second area is Broca's area, in the posterior inferior frontal gyrus of the dominant hemisphere. People with a lesion to this area develop expressive aphasia, meaning that they know what they want to say, they just cannot get it out. They are typically able to understand what is being said to them, but unable to speak fluently. Other symptoms that may be present in expressive aphasia include problems with word repetition. The condition affects both spoken and written language. Those with this aphasia also exhibit ungrammatical speech and show inability to use syntactic information to determine the meaning of sentences. Both expressive and receptive aphasia also affect the use of sign language, in analogous ways to how they affect speech, with expressive aphasia causing signers to sign slowly and with incorrect grammar, whereas a signer with receptive aphasia will sign fluently, but make little sense to others and have difficulties comprehending others' signs. This shows that the impairment is specific to the ability to use language, not to the physiology used for speech production.\n\nWith technological advances in the late 20th century, neurolinguists have also incorporated non-invasive techniques such as functional magnetic resonance imaging (fMRI) and electrophysiology to study language processing in individuals without impairments.\n\nAnatomy of speech\n\nSpoken language relies on human physical ability to produce sound, which is a longitudinal wave propagated through the air at a frequency capable of vibrating the ear drum. This ability depends on the physiology of the human speech organs. These organs consist of the lungs, the voice box (larynx), and the upper vocal tract\u00a0\u2013 the throat, the mouth, and the nose. By controlling the different parts of the speech apparatus, the airstream can be manipulated to produce different speech sounds.\n\nThe sound of speech can be analyzed into a combination of segmental and suprasegmental elements. The segmental elements are those that follow each other in sequences, which are usually represented by distinct letters in alphabetic scripts, such as the Roman script. In free flowing speech, there are no clear boundaries between one segment and the next, nor usually are there any audible pauses between them. Segments therefore are distinguished by their distinct sounds which are a result of their different articulations, and can be either vowels or consonants. Suprasegmental phenomena encompass such elements as stress, phonation type, voice timbre, and prosody or intonation, all of which may have effects across multiple segments.\n\nConsonants and vowel segments combine to form syllables, which in turn combine to form utterances; these can be distinguished phonetically as the space between two inhalations. Acoustically, these different segments are characterized by different formant structures, that are visible in a spectrogram of the recorded sound wave. Formants are the amplitude peaks in the frequency spectrum of a specific sound.\n\nVowels are those sounds that have no audible friction caused by the narrowing or obstruction of some part of the upper vocal tract. They vary in quality according to the degree of lip aperture and the placement of the tongue within the oral cavity. Vowels are called close when the lips are relatively closed, as in the pronunciation of the vowel  (English \"ee\"), or open when the lips are relatively open, as in the vowel  (English \"ah\"). If the tongue is located towards the back of the mouth, the quality changes, creating vowels such as  (English \"oo\"). The quality also changes depending on whether the lips are rounded as opposed to unrounded, creating distinctions such as that between  (unrounded front vowel such as English \"ee\") and  (rounded front vowel such as German \"\u00fc\").\n\nConsonants are those sounds that have audible friction or closure at some point within the upper vocal tract. Consonant sounds vary by place of articulation, i.e. the place in the vocal tract where the airflow is obstructed, commonly at the lips, teeth, alveolar ridge, palate, velum, uvula, or glottis. Each place of articulation produces a different set of consonant sounds, which are further distinguished by manner of articulation, or the kind of friction, whether full closure, in which case the consonant is called occlusive or stop, or different degrees of aperture creating fricatives and approximants. Consonants can also be either voiced or unvoiced, depending on whether the vocal cords are set in vibration by airflow during the production of the sound. Voicing is what separates English  in bus (unvoiced sibilant) from  in buzz (voiced sibilant).\n\nSome speech sounds, both vowels and consonants, involve release of air flow through the nasal cavity, and these are called nasals or nasalized sounds. Other sounds are defined by the way the tongue moves within the mouth such as the l-sounds (called laterals, because the air flows along both sides of the tongue), and the r-sounds (called rhotics).\n\nBy using these speech organs, humans can produce hundreds of distinct sounds: some appear very often in the world's languages, whereas others are much more common in certain language families, language areas, or even specific to a single language.\n\nModality\nHuman languages display considerable plasticity  in their deployment of two fundamental modes: oral (speech and mouthing) and manual (sign and gesture). For example it is common for oral language to be accompanied by gesture, and for sign language to be accompanied by mouthing. In addition, some language communities use both modes to convey lexical or grammatical meaning, each mode complementing the other. Such bimodal use of language is especially common in genres such as story-telling (with Plains Indian Sign Language and Australian Aboriginal sign languages used alongside oral language, for example), but also occurs in mundane conversation. For instance, many Australian languages have a rich set of case suffixes that provide details about the instrument used to perform an action. Others lack such grammatical precision in the oral mode, but supplement it with gesture to convey that information in the sign mode. In Iwaidja, for example, 'he went out for fish using a torch' is spoken as simply \"he-hunted fish torch\", but the word for 'torch' is accompanied by a gesture indicating that it was held. In another example, the ritual language Damin had a heavily reduced oral vocabulary of only a few hundred words, each of which was very general in meaning, but which were supplemented by gesture for greater precision (e.g., the single word for fish, l*i, was accompanied by a gesture to indicate the kind of fish).\n\nSecondary modes of language, by which a fundamental mode is conveyed in a different medium, include writing (including braille), sign (in manually coded language), whistling and drumming. Tertiary modes \u2013 such as semaphore, Morse code and spelling alphabets \u2013 convey the secondary mode of writing in a different medium. For some extinct languages that are maintained for ritual or liturgical purposes, writing may be the primary mode, with speech secondary.\n\nStructure\nWhen described as a system of symbolic communication, language is traditionally seen as consisting of three parts: signs, meanings, and a code connecting signs with their meanings. The study of the process of semiosis, how signs and meanings are combined, used, and interpreted is called semiotics. Signs can be composed of sounds, gestures, letters, or symbols, depending on whether the language is spoken, signed, or written, and they can be combined into complex signs, such as words and phrases. When used in communication, a sign is encoded and transmitted by a sender through a channel to a receiver who decodes it.\n\nSome of the properties that define human language as opposed to other communication systems are: the arbitrariness of the linguistic sign, meaning that there is no predictable connection between a linguistic sign and its meaning; the duality of the linguistic system, meaning that linguistic structures are built by combining elements into larger structures that can be seen as layered, e.g. how sounds build words and words build phrases; the discreteness of the elements of language, meaning that the elements out of which linguistic signs are constructed are discrete units, e.g. sounds and words, that can be distinguished from each other and rearranged in different patterns; and the productivity of the linguistic system, meaning that the finite number of linguistic elements can be combined into a theoretically infinite number of combinations.\n\nThe rules by which signs can be combined to form words and phrases are called syntax or grammar. The meaning that is connected to individual signs, morphemes, words, phrases, and texts is called semantics. The division of language into separate but connected systems of sign and meaning goes back to the first linguistic studies of de Saussure and is now used in almost all branches of linguistics.\n\nSemantics\n\nLanguages express meaning by relating a sign form to a meaning, or its content. Sign forms must be something that can be perceived, for example, in sounds, images, or gestures, and then related to a specific meaning by social convention. Because the basic relation of meaning for most linguistic signs is based on social convention, linguistic signs can be considered arbitrary, in the sense that the convention is established socially and historically, rather than by means of a natural relation between a specific sign form and its meaning.\n\nThus, languages must have a vocabulary of signs related to specific meaning. The English sign \"dog\" denotes, for example, a member of the species Canis familiaris. In a language, the array of arbitrary signs connected to specific meanings is called the lexicon, and a single sign connected to a meaning is called a lexeme. Not all meanings in a language are represented by single words. Often, semantic concepts are embedded in the morphology or syntax of the language in the form of grammatical categories.\n\nAll languages contain the semantic structure of predication: a structure that predicates a property, state, or action. Traditionally, semantics has been understood to be the study of how speakers and interpreters assign truth values to statements, so that meaning is understood to be the process by which a predicate can be said to be true or false about an entity, e.g. \"[x [is y]]\" or \"[x [does y]]\". Recently, this model of semantics has been complemented with more dynamic models of meaning that incorporate shared knowledge about the context in which a sign is interpreted into the production of meaning. Such models of meaning are explored in the field of pragmatics.\n\nSounds and symbols\n\nDepending on modality, language structure can be based on systems of sounds (speech), gestures (sign languages), or graphic or tactile symbols (writing). The ways in which languages use sounds or signs to construct meaning are studied in phonology.\n\nSounds as part of a linguistic system are called phonemes. Phonemes are abstract units of sound, defined as the smallest units in a language that can serve to distinguish between the meaning of a pair of minimally different words, a so-called minimal pair. In English, for example, the words bat  and pat  form a minimal pair, in which the distinction between  and  differentiates the two words, which have different meanings. However, each language contrasts sounds in different ways. For example, in a language that does not distinguish between voiced and unvoiced consonants, the sounds  and  (if they both occur) could be considered a single phoneme, and consequently, the two pronunciations would have the same meaning. Similarly, the English language does not distinguish phonemically between aspirated and non-aspirated pronunciations of consonants, as many other languages like Korean and Hindi do: the unaspirated  in spin  and the aspirated  in pin  are considered to be merely different ways of pronouncing the same phoneme (such variants of a single phoneme are called allophones), whereas in Mandarin Chinese, the same difference in pronunciation distinguishes between the words  'crouch' and  'eight' (the accent above the \u00e1 means that the vowel is pronounced with a high tone).\n\nAll spoken languages have phonemes of at least two different categories, vowels and consonants, that can be combined to form syllables. As well as segments such as consonants and vowels, some languages also use sound in other ways to convey meaning. Many languages, for example, use stress, pitch, duration, and tone to distinguish meaning. Because these phenomena operate outside of the level of single segments, they are called suprasegmental. Some languages have only a few phonemes, for example, Rotokas and Pirah\u00e3 language with 11 and 10 phonemes respectively, whereas languages like Taa may have as many as 141 phonemes. In sign languages, the equivalent to phonemes (formerly called cheremes) are defined by the basic elements of gestures, such as hand shape, orientation, location, and motion, which correspond to manners of articulation in spoken language.\n\nWriting systems represent language using visual symbols, which may or may not correspond to the sounds of spoken language. The Latin alphabet (and those on which it is based or that have been derived from it) was originally based on the representation of single sounds, so that words were constructed from letters that generally denote a single consonant or vowel in the structure of the word. In syllabic scripts, such as the Inuktitut syllabary, each sign represents a whole syllable. In logographic scripts, each sign represents an entire word, and will generally bear no relation to the sound of that word in spoken language.\n\nBecause all languages have a very large number of words, no purely logographic scripts are known to exist. Written language represents the way spoken sounds and words follow one after another by arranging symbols according to a pattern that follows a certain direction. The direction used in a writing system is entirely arbitrary and established by convention. Some writing systems use the horizontal axis (left to right as the Latin script or right to left as the Arabic script), while others such as traditional Chinese writing use the vertical dimension (from top to bottom). A few writing systems use opposite directions for alternating lines, and others, such as the ancient Maya script, can be written in either direction and rely on graphic cues to show the reader the direction of reading.\n\nIn order to represent the sounds of the world's languages in writing, linguists have developed the International Phonetic Alphabet, designed to represent all of the discrete sounds that are known to contribute to meaning in human languages.\n\nGrammar\n\nGrammar is the study of how meaningful elements called morphemes within a language can be combined into utterances. Morphemes can either be free or bound. If they are free to be moved around within an utterance, they are usually called words, and if they are bound to other words or morphemes, they are called affixes. The way in which meaningful elements can be combined within a language is governed by rules. The study of the rules for the internal structure of words are called morphology. The rules of the internal structure of phrases and sentences are called syntax.\n\nGrammatical categories\n\nGrammar can be described as a system of categories and a set of rules that determine how categories combine to form different aspects of meaning. Languages differ widely in whether they are encoded through the use of categories or lexical units. However, several categories are so common as to be nearly universal. Such universal categories include the encoding of the grammatical relations of participants and predicates by grammatically distinguishing between their relations to a predicate, the encoding of temporal and spatial relations on predicates, and a system of grammatical person governing reference to and distinction between speakers and addressees and those about whom they are speaking.\n\nWord classes\nLanguages organize their parts of speech into classes according to their functions and positions relative to other parts. All languages, for instance, make a basic distinction between a group of words that prototypically denotes things and concepts and a group of words that prototypically denotes actions and events. The first group, which includes English words such as \"dog\" and \"song\", are usually called nouns. The second, which includes \"think\" and \"sing\", are called verbs. Another common category is the adjective: words that describe properties or qualities of nouns, such as \"red\" or \"big\". Word classes can be \"open\" if new words can continuously be added to the class, or relatively \"closed\" if there is a fixed number of words in a class. In English, the class of pronouns is closed, whereas the class of adjectives is open, since an infinite number of adjectives can be constructed from verbs (e.g. \"saddened\") or nouns (e.g. with the -like suffix, as in \"noun-like\"). In other languages such as Korean, the situation is the opposite, and new pronouns can be constructed, whereas the number of adjectives is fixed.\n\nWord classes also carry out differing functions in grammar. Prototypically, verbs are used to construct predicates, while nouns are used as arguments of predicates. In a sentence such as \"Sally runs\", the predicate is \"runs\", because it is the word that predicates a specific state about its argument \"Sally\". Some verbs such as \"curse\" can take two arguments, e.g. \"Sally cursed John\". A predicate that can only take a single argument is called intransitive, while a predicate that can take two arguments is called transitive.\n\nMany other word classes exist in different languages, such as conjunctions like \"and\" that serve to join two sentences, articles that introduce a noun, interjections such as \"wow!\", or ideophones like \"splash\" that mimic the sound of some event. Some languages have positionals that describe the spatial position of an event or entity. Many languages have classifiers that identify countable nouns as belonging to a particular type or having a particular shape. For instance, in Japanese, the general noun classifier for humans is nin (\u4eba), and it is used for counting humans, whatever they are called:\n\nsan-nin no gakusei (\u4e09\u4eba\u306e\u5b66\u751f) lit. \"3 human-classifier of student\"\u00a0\u2014 three students\nFor trees, it would be:\nsan-bon no ki (\u4e09\u672c\u306e\u6728) lit. \"3 classifier-for-long-objects of tree\"\u00a0\u2014 three trees\n\nMorphology\nIn linguistics, the study of the internal structure of complex words and the processes by which words are formed is called morphology. In most languages, it is possible to construct complex words that are built of several morphemes. For instance, the English word \"unexpected\" can be analyzed as being composed of the three morphemes \"un-\", \"expect\" and \"-ed\".\n\nMorphemes can be classified according to whether they are independent morphemes, so-called roots, or whether they can only co-occur attached to other morphemes. These bound morphemes or affixes can be classified according to their position in relation to the root: prefixes precede the root, suffixes follow the root, and infixes are inserted in the middle of a root. Affixes serve to modify or elaborate the meaning of the root. Some languages change the meaning of words by changing the phonological structure of a word, for example, the English word \"run\", which in the past tense is \"ran\". This process is called ablaut. Furthermore, morphology distinguishes between the process of inflection, which modifies or elaborates on a word, and the process of derivation, which creates a new word from an existing one. In English, the verb \"sing\" has the inflectional forms \"singing\" and \"sung\", which are both verbs, and the derivational form \"singer\", which is a noun derived from the verb with the agentive suffix \"-er\".\n\nLanguages differ widely in how much they rely on morphological processes of word formation. In some languages, for example, Chinese, there are no morphological processes, and all grammatical information is encoded syntactically by forming strings of single words. This type of morpho-syntax is often called isolating, or analytic, because there is almost a full correspondence between a single word and a single aspect of meaning. Most languages have words consisting of several morphemes, but they vary in the degree to which morphemes are discrete units. In many languages, notably in most Indo-European languages, single morphemes may have several distinct meanings that cannot be analyzed into smaller segments. For example, in Latin, the word bonus, or \"good\", consists of the root bon-, meaning \"good\", and the suffix -us, which indicates masculine gender, singular number, and nominative case. These languages are called fusional languages, because several meanings may be fused into a single morpheme. The opposite of fusional languages are agglutinative languages which construct words by stringing morphemes together in chains, but with each morpheme as a discrete semantic unit. An example of such a language is Turkish, where for example, the word evlerinizden, or \"from your houses\", consists of the morphemes, ev-ler-iniz-den with the meanings house-plural-your-from. The languages that rely on morphology to the greatest extent are traditionally called polysynthetic languages. They may express the equivalent of an entire English sentence in a single word. For example, in Persian the single word nafahmidamesh means I didn't understand it consisting of morphemes na-fahm-id-am-esh with the meanings, \"negation.understand.past.I.it\". As another example with more complexity, in the Yupik word tuntussuqatarniksatengqiggtuq, which means \"He had not yet said again that he was going to hunt reindeer\", the word consists of the morphemes tuntu-ssur-qatar-ni-ksaite-ngqiggte-uq with the meanings, \"reindeer-hunt-future-say-negation-again-third.person.singular.indicative\", and except for the morpheme tuntu (\"reindeer\") none of the other morphemes can appear in isolation.\n\nMany languages use morphology to cross-reference words within a sentence. This is sometimes called agreement. For example, in many Indo-European languages, adjectives must cross-reference the noun they modify in terms of number, case, and gender, so that the Latin adjective bonus, or \"good\", is inflected to agree with a noun that is masculine gender, singular number, and nominative case. In many polysynthetic languages, verbs cross-reference their subjects and objects. In these types of languages, a single verb may include information that would require an entire sentence in English. For example, in the Basque phrase ikusi nauzu, or \"you saw me\", the past tense auxiliary verb n-au-zu (similar to English \"do\") agrees with both the subject (you) expressed by the n- prefix, and with the object (me) expressed by the \u2013 zu suffix. The sentence could be directly transliterated as \"see you-did-me\"\n\nSyntax\n\nAnother way in which languages convey meaning is through the order of words within a sentence. The grammatical rules for how to produce new sentences from words that are already known is called syntax. The syntactical rules of a language determine why a sentence in English such as \"I love you\" is meaningful, but \"*love you I\" is not. Syntactical rules determine how word order and sentence structure is constrained, and how those constraints contribute to meaning. For example, in English, the two sentences \"the slaves were cursing the master\" and \"the master was cursing the slaves\" mean different things, because the role of the grammatical subject is encoded by the noun being in front of the verb, and the role of object is encoded by the noun appearing after the verb. Conversely, in Latin, both Dominus servos vituperabat and Servos vituperabat dominus mean \"the master was reprimanding the slaves\", because servos, or \"slaves\", is in the accusative case, showing that they are the grammatical object of the sentence, and dominus, or \"master\", is in the nominative case, showing that he is the subject.\n\nLatin uses morphology to express the distinction between subject and object, whereas English uses word order. Another example of how syntactic rules contribute to meaning is the rule of inverse word order in questions, which exists in many languages. This rule explains why when in English, the phrase \"John is talking to Lucy\" is turned into a question, it becomes \"Who is John talking to?\", and not \"John is talking to who?\". The latter example may be used as a way of placing special emphasis on \"who\", thereby slightly altering the meaning of the question. Syntax also includes the rules for how complex sentences are structured by grouping words together in units, called phrases, that can occupy different places in a larger syntactic structure. Sentences can be described as consisting of phrases connected in a tree structure, connecting the phrases to each other at different levels. To the right is a graphic representation of the syntactic analysis of the English sentence \"the cat sat on the mat\". The sentence is analyzed as being constituted by a noun phrase, a verb, and a prepositional phrase; the prepositional phrase is further divided into a preposition and a noun phrase, and the noun phrases consist of an article and a noun.\n\nThe reason sentences can be seen as being composed of phrases is because each phrase would be moved around as a single element if syntactic operations were carried out. For example, \"the cat\" is one phrase, and \"on the mat\" is another, because they would be treated as single units if a decision was made to emphasize the location by moving forward the prepositional phrase: \"[And] on the mat, the cat sat\". There are many different formalist and functionalist frameworks that propose theories for describing syntactic structures, based on different assumptions about what language is and how it should be described. Each of them would analyze a sentence such as this in a different manner.\n\nTypology and universals\n\nLanguages can be classified in relation to their grammatical types. Languages that belong to different families nonetheless often have features in common, and these shared features tend to correlate. For example, languages can be classified on the basis of their basic word order, the relative order of the verb, and its constituents in a normal indicative sentence. In English, the basic order is SVO (subject\u2013verb\u2013object): \"The snake(S) bit(V) the man(O)\", whereas for example, the corresponding sentence in the Australian language Gamilaraay would be d\u032auyugu n\u032aama d\u032aayn yi\u02d0y (snake man bit), SOV. Word order type is relevant as a typological parameter, because basic word order type corresponds with other syntactic parameters, such as the relative order of nouns and adjectives, or of the use of prepositions or postpositions. Such correlations are called implicational universals. For example, most (but not all) languages that are of the SOV type have postpositions rather than prepositions, and have adjectives before nouns.\n\nAll languages structure sentences into Subject, Verb, and Object, but languages differ in the way they classify the relations between actors and actions. English uses the nominative-accusative word typology: in English transitive clauses, the subjects of both intransitive sentences (\"I run\") and transitive sentences (\"I love you\") are treated in the same way, shown here by the nominative pronoun I. Some languages, called ergative, Gamilaraay among them, distinguish instead between Agents and Patients. In ergative languages, the single participant in an intransitive sentence, such as \"I run\", is treated the same as the patient in a transitive sentence, giving the equivalent of \"me run\". Only in transitive sentences would the equivalent of the pronoun \"I\" be used. In this way the semantic roles can map onto the grammatical relations in different ways, grouping an intransitive subject either with Agents (accusative type) or Patients (ergative type) or even making each of the three roles differently, which is called the tripartite type.\n\nThe shared features of languages which belong to the same typological class type may have arisen completely independently. Their co-occurrence might be due to universal laws governing the structure of natural languages, \"language universals\", or they might be the result of languages evolving convergent solutions to the recurring communicative problems that humans use language to solve.\n\nSocial contexts of use and transmission\n\nWhile humans have the ability to learn any language, they only do so if they grow up in an environment in which language exists and is used by others. Language is therefore dependent on communities of speakers in which children learn language from their elders and peers and themselves transmit language to their own children. Languages are used by those who speak them to communicate and to solve a plethora of social tasks. Many aspects of language use can be seen to be adapted specifically to these purposes. Owing to the way in which language is transmitted between generations and within communities, language perpetually changes, diversifying into new languages or converging due to language contact. The process is similar to the process of evolution, where the process of descent with modification leads to the formation of a phylogenetic tree.\n\nHowever, languages differ from biological organisms in that they readily incorporate elements from other languages through the process of diffusion, as speakers of different languages come into contact. Humans also frequently speak more than one language, acquiring their first language or languages as children, or learning new languages as they grow up. Because of the increased language contact in the globalizing world, many small languages are becoming endangered as their speakers shift to other languages that afford the possibility to participate in larger and more influential speech communities.\n\nUsage and meaning\n\nWhen studying the way in which words and signs are used, it is often the case that words have different meanings, depending on the social context of use. An important example of this is the process called deixis, which describes the way in which certain words refer to entities through their relation between a specific point in time and space when the word is uttered. Such words are, for example, the word, \"I\" (which designates the person speaking), \"now\" (which designates the moment of speaking), and \"here\" (which designates the position of speaking). Signs also change their meanings over time, as the conventions governing their usage gradually change. The study of how the meaning of linguistic expressions changes depending on context is called pragmatics. Deixis is an important part of the way that we use language to point out entities in the world. Pragmatics is concerned with the ways in which language use is patterned and how these patterns contribute to meaning. For example, in all languages, linguistic expressions can be used not just to transmit information, but to perform actions. Certain actions are made only through language, but nonetheless have tangible effects, e.g. the act of \"naming\", which creates a new name for some entity, or the act of \"pronouncing someone man and wife\", which creates a social contract of marriage. These types of acts are called speech acts, although they can also be carried out through writing or hand signing.\n\nThe form of linguistic expression often does not correspond to the meaning that it actually has in a social context. For example, if at a dinner table a person asks, \"Can you reach the salt?\", that is, in fact, not a question about the length of the arms of the one being addressed, but a request to pass the salt across the table. This meaning is implied by the context in which it is spoken; these kinds of effects of meaning are called conversational implicatures. These social rules for which ways of using language are considered appropriate in certain situations and how utterances are to be understood in relation to their context vary between communities, and learning them is a large part of acquiring communicative competence in a language.\n\nAcquisition\n\nAll healthy, normally developing human beings learn to use language. Children acquire the language or languages used around them: whichever languages they receive sufficient exposure to during childhood. The development is essentially the same for children acquiring sign or oral languages. This learning process is referred to as first-language acquisition, since unlike many other kinds of learning, it requires no direct teaching or specialized study. In The Descent of Man, naturalist Charles Darwin called this process \"an instinctive tendency to acquire an art\".\n\nFirst language acquisition proceeds in a fairly regular sequence, though there is a wide degree of variation in the timing of particular stages among normally developing infants. Studies published in 2013 have indicated that unborn fetuses are capable of language acquisition to some degree. From birth, newborns respond more readily to human speech than to other sounds. Around one month of age, babies appear to be able to distinguish between different speech sounds. Around six months of age, a child will begin babbling, producing the speech sounds or handshapes of the languages used around them. Words appear around the age of 12 to 18 months; the average vocabulary of an eighteen-month-old child is around 50 words. A child's first utterances are holophrases (literally \"whole-sentences\"), utterances that use just one word to communicate some idea. Several months after a child begins producing words, he or she will produce two-word utterances, and within a few more months will begin to produce telegraphic speech, or short sentences that are less grammatically complex than adult speech, but that do show regular syntactic structure. From roughly the age of three to five years, a child's ability to speak or sign is refined to the point that it resembles adult language.\n\nAcquisition of second and additional languages can come at any age, through exposure in daily life or courses. Children learning a second language are more likely to achieve native-like fluency than adults, but in general, it is very rare for someone speaking a second language to pass completely for a native speaker. An important difference between first language acquisition and additional language acquisition is that the process of additional language acquisition is influenced by languages that the learner already knows.\n\nCulture\n\nLanguages, understood as the particular set of speech norms of a particular community, are also a part of the larger culture of the community that speaks them. Languages differ not only in pronunciation, vocabulary, and grammar, but also through having different \"cultures of speaking.\" Humans use language as a way of signalling identity with one cultural group as well as difference from others. Even among speakers of one language, several different ways of using the language exist, and each is used to signal affiliation with particular subgroups within a larger culture. Linguists and anthropologists, particularly sociolinguists, ethnolinguists, and linguistic anthropologists have specialized in studying how ways of speaking vary between speech communities.\n\nLinguists use the term \"varieties\" to refer to the different ways of speaking a language. This term includes geographically or socioculturally defined dialects as well as the jargons or styles of subcultures. Linguistic anthropologists and sociologists of language define communicative style as the ways that language is used and understood within a particular culture.\n\nBecause norms for language use are shared by members of a specific group, communicative style also becomes a way of displaying and constructing group identity. Linguistic differences may become salient markers of divisions between social groups, for example, speaking a language with a particular accent may imply membership of an ethnic minority or social class, one's area of origin, or status as a second language speaker. These kinds of differences are not part of the linguistic system, but are an important part of how people use language as a social tool for constructing groups.\n\nHowever, many languages also have grammatical conventions that signal the social position of the speaker in relation to others through the use of registers that are related to social hierarchies or divisions. In many languages, there are stylistic or even grammatical differences between the ways men and women speak, between age groups, or between social classes, just as some languages employ different words depending on who is listening. For example, in the Australian language Dyirbal, a married man must use a special set of words to refer to everyday items when speaking in the presence of his mother-in-law. Some cultures, for example, have elaborate systems of \"social deixis\", or systems of signalling social distance through linguistic means. In English, social deixis is shown mostly through distinguishing between addressing some people by first name and others by surname, and in titles such as \"Mrs.\", \"boy\", \"Doctor\", or \"Your Honor\", but in other languages, such systems may be highly complex and codified in the entire grammar and vocabulary of the language. For instance, in languages of east Asia such as Thai, Burmese, and Javanese, different words are used according to whether a speaker is addressing someone of higher or lower rank than oneself in a ranking system with animals and children ranking the lowest and gods and members of royalty as the highest.\n\nWriting, literacy and technology\n\nThroughout history a number of different ways of representing language in graphic media have been invented. These are called writing systems.\n\nThe use of writing has made language even more useful to humans. It makes it possible to store large amounts of information outside of the human body and retrieve it again, and it allows communication across physical distances and timespans that would otherwise be impossible. Many languages conventionally employ different genres, styles, and registers in written and spoken language, and in some communities, writing traditionally takes place in an entirely different language than the one spoken. There is some evidence that the use of writing also has effects on the cognitive development of humans, perhaps because acquiring literacy generally requires explicit and formal education.\n\nThe invention of the first writing systems is roughly contemporary with the beginning of the Bronze Age in the late 4th millennium BC. The Sumerian archaic cuneiform script and the Egyptian hieroglyphs are generally considered to be the earliest writing systems, both emerging out of their ancestral proto-literate symbol systems from 3400 to 3200 BC with the earliest coherent texts from about 2600 BC. It is generally agreed that Sumerian writing was an independent invention; however, it is debated whether Egyptian writing was developed completely independently of Sumerian, or was a case of cultural diffusion. A similar debate exists for the Chinese script, which developed around 1200 BC. The pre-Columbian Mesoamerican writing systems (including among others Olmec and Maya scripts) are generally believed to have had independent origins.\n\nChange\n\nAll languages change as speakers adopt or invent new ways of speaking and pass them on to other members of their speech community. Language change happens at all levels from the phonological level to the levels of vocabulary, morphology, syntax, and discourse. Even though language change is often initially evaluated negatively by speakers of the language who often consider changes to be \"decay\" or a sign of slipping norms of language usage, it is natural and inevitable.\n\nChanges may affect specific sounds or the entire phonological system. Sound change can consist of the replacement of one speech sound or phonetic feature by another, the complete loss of the affected sound, or even the introduction of a new sound in a place where there had been none. Sound changes can be conditioned in which case a sound is changed only if it occurs in the vicinity of certain other sounds. Sound change is usually assumed to be regular, which means that it is expected to apply mechanically whenever its structural conditions are met, irrespective of any non-phonological factors. On the other hand, sound changes can sometimes be sporadic, affecting only one particular word or a few words, without any seeming regularity. Sometimes a simple change triggers a chain shift in which the entire phonological system is affected. This happened in the Germanic languages when the sound change known as Grimm's law affected all the stop consonants in the system. The original consonant * became /b/ in the Germanic languages, the previous * in turn became /p/, and the previous * became /f/. The same process applied to all stop consonants and explains why Italic languages such as Latin have p in words like pater and pisces, whereas Germanic languages, like English, have father and fish.\n\nAnother example is the Great Vowel Shift in English, which is the reason that the spelling of English vowels do not correspond well to their current pronunciation. This is because the vowel shift brought the already established orthography out of synchronization with pronunciation. Another source of sound change is the erosion of words as pronunciation gradually becomes increasingly indistinct and shortens words, leaving out syllables or sounds. This kind of change caused Latin mea domina to eventually become the French madame and American English ma'am.\n\nChange also happens in the grammar of languages as discourse patterns such as idioms or particular constructions become grammaticalized. This frequently happens when words or morphemes erode and the grammatical system is unconsciously rearranged to compensate for the lost element. For example, in some varieties of Caribbean Spanish the final /s/ has eroded away. Since Standard Spanish uses final /s/ in the morpheme marking the second person subject \"you\" in verbs, the Caribbean varieties now have to express the second person using the pronoun t\u00fa. This means that the sentence \"what's your name\" is \u00bfcomo te llamas?  in Standard Spanish, but  in Caribbean Spanish. The simple sound change has affected both morphology and syntax. Another common cause of grammatical change is the gradual petrification of idioms into new grammatical forms, for example, the way the English \"going to\" construction lost its aspect of movement and in some varieties of English has almost become a full-fledged future tense (e.g. I'm gonna).\n\nLanguage change may be motivated by \"language internal\" factors, such as changes in pronunciation motivated by certain sounds being difficult to distinguish aurally or to produce, or through patterns of change that cause some rare types of constructions to drift towards more common types. Other causes of language change are social, such as when certain pronunciations become emblematic of membership in certain groups, such as social classes, or with ideologies, and therefore are adopted by those who wish to identify with those groups or ideas. In this way, issues of identity and politics can have profound effects on language structure.\n\nContact\n\nOne important source of language change is contact and resulting diffusion of linguistic traits between languages. Language contact occurs when speakers of two or more languages or varieties interact on a regular basis. Multilingualism is likely to have been the norm throughout human history and most people in the modern world are multilingual. Before the rise of the concept of the ethno-national state, monolingualism was characteristic mainly of populations inhabiting small islands. But with the ideology that made one people, one state, and one language the most desirable political arrangement, monolingualism started to spread throughout the world. Nonetheless, there are only 250 countries in the world corresponding to some 6000 languages, which means that most countries are multilingual and most languages therefore exist in close contact with other languages.\n\nWhen speakers of different languages interact closely, it is typical for their languages to influence each other. Through sustained language contact over long periods, linguistic traits diffuse between languages, and languages belonging to different families may converge to become more similar. In areas where many languages are in close contact, this may lead to the formation of language areas in which unrelated languages share a number of linguistic features. A number of such language areas have been documented, among them, the Balkan language area, the Mesoamerican language area, and the Ethiopian language area. Also, larger areas such as South Asia, Europe, and Southeast Asia have sometimes been considered language areas, because of widespread diffusion of specific areal features.\n\nLanguage contact may also lead to a variety of other linguistic phenomena, including language convergence, borrowing, and relexification (replacement of much of the native vocabulary with that of another language). In situations of extreme and sustained language contact, it may lead to the formation of new mixed languages that cannot be considered to belong to a single language family. One type of mixed language called pidgins occurs when adult speakers of two different languages interact on a regular basis, but in a situation where neither group learns to speak the language of the other group fluently. In such a case, they will often construct a communication form that has traits of both languages, but which has a simplified grammatical and phonological structure. The language comes to contain mostly the grammatical and phonological categories that exist in both languages. Pidgin languages are defined by not having any native speakers, but only being spoken by people who have another language as their first language. But if a Pidgin language becomes the main language of a speech community, then eventually children will grow up learning the pidgin as their first language. As the generation of child learners grow up, the pidgin will often be seen to change its structure and acquire a greater degree of complexity. This type of language is generally called a creole language. An example of such mixed languages is Tok Pisin, the official language of Papua New-Guinea, which originally arose as a Pidgin based on English and Austronesian languages; others are Krey\u00f2l ayisyen, the French-based creole language spoken in Haiti, and Michif, a mixed language of Canada, based on the Native American language Cree and French.\n\nLinguistic diversity\n\nSIL Ethnologue defines a \"living language\" as \"one that has at least one speaker for whom it is their first language\". The exact number of known living languages varies from 6,000 to 7,000, depending on the precision of one's definition of \"language\", and in particular, on how one defines the distinction between a \"language\" and a \"dialect\". As of 2016, Ethnologue cataloged 7,097 living human languages. The Ethnologue establishes linguistic groups based on studies of mutual intelligibility, and therefore often includes more categories than more conservative classifications. For example, the Danish language that most scholars consider a single language with several dialects is classified as two distinct languages (Danish and Jutish) by the Ethnologue.\n\nAccording to the Ethnologue, 389 languages (nearly 6%) have more than a million speakers. These languages together account for 94% of the world's population, whereas 94% of the world's languages account for the remaining 6% of the global population.\n\nLanguages and dialects\n\nThere is no clear distinction between a language and a dialect, notwithstanding a famous aphorism attributed to linguist Max Weinreich that \"a language is a dialect with an army and navy\". For example, national boundaries frequently override linguistic difference in determining whether two linguistic varieties are languages or dialects. Hakka, Cantonese and Mandarin are, for example, often classified as \"dialects\" of Chinese, even though they are more different from each other than Swedish is from Norwegian. Before the Yugoslav civil war, Serbo-Croatian was generally considered a single language with two normative variants, but due to sociopolitical reasons, Croatian and Serbian are now often treated as separate languages and employ different writing systems. In other words, the distinction may hinge on political considerations as much as on cultural differences, distinctive writing systems, or degree of mutual intelligibility.\n\nLanguage families of the world\n\nThe world's languages can be grouped into language families consisting of languages that can be shown to have common ancestry. Linguists recognize many hundreds of language families, although some of them can possibly be grouped into larger units as more evidence becomes available and in-depth studies are carried out. At present, there are also dozens of language isolates: languages that cannot be shown to be related to any other languages in the world. Among them are Basque, spoken in Europe, Zuni of New Mexico, Pur\u00e9pecha of Mexico, Ainu of Japan, Burushaski of Pakistan, and many others.\n\nThe language family of the world that has the most speakers is the Indo-European languages, spoken by 46% of the world's population. This family includes major world languages like English, Spanish, French, German, Russian, and Hindustani (Hindi/Urdu). The Indo-European family achieved prevalence first during the Eurasian Migration Period (c. 400\u2013800 AD), and subsequently through the European colonial expansion, which brought the Indo-European languages to a politically and often numerically dominant position in the Americas and much of Africa. The Sino-Tibetan languages are spoken by 20% of the world's population and include many of the languages of East Asia, including Hakka, Mandarin Chinese, Cantonese, and hundreds of smaller languages.\n\nAfrica is home to a large number of language families, the largest of which is the Niger-Congo language family, which includes such languages as Swahili, Shona, and Yoruba. Speakers of the Niger-Congo languages account for 6.9% of the world's population. A similar number of people speak the Afroasiatic languages, which include the populous Semitic languages such as Arabic, Hebrew language, and the languages of the Sahara region, such as the Berber languages and Hausa.\n\nThe Austronesian languages are spoken by 5.5% of the world's population and stretch from Madagascar to maritime Southeast Asia all the way to Oceania. It includes such languages as Malagasy, M\u0101ori, Samoan, and many of the indigenous languages of Indonesia and Taiwan. The Austronesian languages are considered to have originated in Taiwan around 3000 BC and spread through the Oceanic region through island-hopping, based on an advanced nautical technology. Other populous language families are the Dravidian languages of South Asia (among them Kannada, Tamil, and Telugu), the Turkic languages of Central Asia (such as Turkish), the Austroasiatic (among them Khmer), and Tai\u2013Kadai languages of Southeast Asia (including Thai).\n\nThe areas of the world in which there is the greatest linguistic diversity, such as the Americas, Papua New Guinea, West Africa, and South-Asia, contain hundreds of small language families. These areas together account for the majority of the world's languages, though not the majority of speakers. In the Americas, some of the largest language families include the Quechumaran, Arawak, and Tupi-Guarani families of South America, the Uto-Aztecan, Oto-Manguean, and Mayan of Mesoamerica, and the Na-Dene, Iroquoian, and Algonquian language families of North America. In Australia, most indigenous languages belong to the Pama-Nyungan family, whereas New Guinea is home to a large number of small families and isolates, as well as a number of Austronesian languages.\n\nLanguage endangerment\n\nLanguage endangerment occurs when a language is at risk of falling out of use as its speakers die out or shift to speaking another language. Language loss occurs when the language has no more native speakers, and becomes a dead language. If eventually no one speaks the language at all, it becomes an extinct language. While languages have always gone extinct throughout human history, they have been disappearing at an accelerated rate in the 20th and 21st centuries due to the processes of globalization and neo-colonialism, where the economically powerful languages dominate other languages.\n\nThe more commonly spoken languages dominate the less commonly spoken languages, so the less commonly spoken languages eventually disappear from populations. Of the between 6,000 and 7,000 languages spoken as of 2010, between 50 and 90% of those are expected to have become extinct by the year 2100. The top 20 languages, those spoken by more than 50 million speakers each, are spoken by 50% of the world's population, whereas many of the other languages are spoken by small communities, most of them with less than 10,000 speakers.\n\nThe United Nations Educational, Scientific and Cultural Organization (UNESCO) operates with five levels of language endangerment: \"safe\", \"vulnerable\" (not spoken by children outside the home), \"definitely endangered\" (not spoken by children), \"severely endangered\" (only spoken by the oldest generations), and \"critically endangered\" (spoken by few members of the oldest generation, often semi-speakers). Notwithstanding claims that the world would be better off if most adopted a single common lingua franca, such as English or Esperanto, there is a consensus that the loss of languages harms the cultural diversity of the world. It is a common belief, going back to the biblical narrative of the tower of Babel in the Old Testament, that linguistic diversity causes political conflict, but this is contradicted by the fact that many of the world's major episodes of violence have taken place in situations with low linguistic diversity, such as the Yugoslav and American Civil War, or the genocide of Rwanda, whereas many of the most stable political units have been highly multilingual.\n\nMany projects aim to prevent or slow this loss by revitalizing endangered languages and promoting education and literacy in minority languages. Across the world, many countries have enacted specific legislation to protect and stabilize the language of indigenous speech communities. A minority of linguists have argued that language loss is a natural process that should not be counteracted, and that documenting endangered languages for posterity is sufficient.\n\nThe University of Waikato are using the Welsh language as a model for their M\u0101ori language revitalisation programme as they deem Welsh to be the world's leading example for the survival of languages. In 2019 a Hawaiian TV company Oiwi visited a Welsh language centre in Nant Gwrtheyrn, North Wales to help find ways of preserving their \u014clelo Hawai\u02bbi language.\n\nSee also\n\n Lists of languages\n Human communication\n Listening\n Speaking\n Reading\n Attitude \n Body language (approachable) \n Humor\n Social skills \n International auxiliary language\n List of language regulators\n List of official languages\n Outline of linguistics\n Problem of religious language\n Psycholinguistics\n Speech\u2013language pathology\n Father Tongue hypothesis\n\nNotes\n\nCommentary notes\n\nCitations\n\nWorks cited\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  (pbk)\n\nFurther reading\n\nExternal links\n\n World Atlas of Language Structures: a large database of structural (phonological, grammatical, lexical) properties of languages\n Ethnologue: Languages of the World is a comprehensive catalog of all of the world's known living languages\n\n \nHuman communication\nLinguistics\nWikipedia articles with ASCII art\nArticles containing video clips\nMain topic articles",
  "Medicine": "Medicine is the science and practice of caring for a patient, managing the diagnosis, prognosis, prevention, treatment,  palliation of their injury or disease, and promoting their health. Medicine encompasses a variety of health care practices evolved to maintain and restore health by the prevention and treatment of illness. Contemporary medicine applies biomedical sciences, biomedical research, genetics, and medical technology to diagnose, treat, and prevent injury and disease, typically through pharmaceuticals or surgery, but also through therapies as diverse as psychotherapy, external splints and traction, medical devices, biologics, and ionizing radiation, amongst others.\n\nMedicine has been practiced since prehistoric times, during most of which it was an art (an area of skill and knowledge) frequently having connections to the religious and philosophical beliefs of local culture. For example, a medicine man would apply herbs and say prayers for healing, or an ancient philosopher and physician would apply bloodletting according to the theories of humorism. In recent centuries, since the advent of modern science, most medicine has become a combination of art and science (both basic and applied, under the umbrella of medical science). While stitching technique for sutures is an art learned through practice, the knowledge of what happens at the cellular and molecular level in the tissues being stitched arises through science.\n\nPrescientific forms of medicine are now known as traditional medicine or folk medicine, which remains commonly used in the absence of scientific medicine, and are thus called alternative medicine. Alternative treatments outside of scientific medicine having safety and efficacy concerns are termed quackery.\n\nEtymology\n\nMedicine (, ) is the science and practice of the diagnosis, prognosis, treatment, and prevention of disease. The word \"medicine\" is derived from Latin medicus, meaning \"a physician\".\n\nClinical practice\n\nMedical availability and clinical practice varies across the world due to regional differences in culture and technology. Modern scientific medicine is highly developed in the Western world, while in developing countries such as parts of Africa or Asia, the population may rely more heavily on traditional medicine with limited evidence and efficacy and no required formal training for practitioners. \n\nIn the developed world, evidence-based medicine is not universally used in clinical practice; for example, a 2007 survey of literature reviews found that about 49% of the interventions lacked sufficient evidence to support either benefit or harm.\n\nIn modern clinical practice, physicians and physician assistants personally assess patients in order to diagnose, prognose, treat, and prevent disease using clinical judgment. The doctor-patient relationship typically begins an interaction with an examination of the patient's medical history and medical record, followed by a medical interview and a physical examination. Basic diagnostic medical devices (e.g. stethoscope, tongue depressor) are typically used. After examination for signs and interviewing for symptoms, the doctor may order medical tests (e.g. blood tests), take a biopsy, or prescribe pharmaceutical drugs or other therapies. Differential diagnosis methods help to rule out conditions based on the information provided. During the encounter, properly informing the patient of all relevant facts is an important part of the relationship and the development of trust. The medical encounter is then documented in the medical record, which is a legal document in many jurisdictions. Follow-ups may be shorter but follow the same general procedure, and specialists follow a similar process. The diagnosis and treatment may take only a few minutes or a few weeks depending upon the complexity of the issue.\n\nThe components of the medical interview and encounter are:\n Chief complaint (CC): the reason for the current medical visit. These are the 'symptoms.' They are in the patient's own words and are recorded along with the duration of each one. Also called 'chief concern' or 'presenting complaint'.\n History of present illness (HPI): the chronological order of events of symptoms and further clarification of each symptom. Distinguishable from history of previous illness, often called past medical history (PMH). Medical history comprises HPI and PMH.\n Current activity: occupation, hobbies, what the patient actually does.\n Medications (Rx): what drugs the patient takes including prescribed, over-the-counter, and home remedies, as well as alternative and herbal medicines or  remedies. Allergies are also recorded.\n Past medical history (PMH/PMHx): concurrent medical problems, past hospitalizations and operations, injuries, past infectious diseases or vaccinations, history of known allergies.\n Social history (SH): birthplace, residences, marital history, social and economic status, habits (including diet, medications, tobacco, alcohol).\n Family history (FH): listing of diseases in the family that may impact the patient. A family tree is sometimes used.\n Review of systems (ROS) or systems inquiry: a set of additional questions to ask, which may be missed on HPI: a general enquiry (have you noticed any weight loss, change in sleep quality, fevers, lumps and bumps? etc.), followed by questions on the body's main organ systems (heart, lungs, digestive tract, urinary tract, etc.).\n\nThe physical examination is the examination of the patient for medical signs of disease, which are objective and observable, in contrast to symptoms that are volunteered by the patient and not necessarily objectively observable. The healthcare provider uses sight, hearing, touch, and sometimes smell (e.g., in infection, uremia, diabetic ketoacidosis). Four actions are the basis of physical examination: inspection, palpation (feel), percussion (tap to determine resonance characteristics), and auscultation (listen), generally in that order although auscultation occurs prior to percussion and palpation for abdominal assessments.\n\nThe clinical examination involves the study of:\n Vital signs including height, weight, body temperature, blood pressure, pulse, respiration rate, and hemoglobin oxygen saturation\n General appearance of the patient and specific indicators of disease (nutritional status, presence of jaundice, pallor or clubbing)\n Skin\n Head, eye, ear, nose, and throat (HEENT)\n Cardiovascular (heart and blood vessels)\n Respiratory (large airways and lungs)\n Abdomen and rectum\n Genitalia (and pregnancy if the patient is or could be pregnant)\n Musculoskeletal (including spine and extremities)\n Neurological (consciousness, awareness, brain, vision, cranial nerves, spinal cord and peripheral nerves)\n Psychiatric (orientation, mental state, mood, evidence of abnormal perception or thought).\n\nIt is to likely focus on areas of interest highlighted in the medical history and may not include everything listed above.\n\nThe treatment plan may include ordering additional medical laboratory tests and medical imaging studies, starting therapy, referral to a specialist, or watchful observation. Follow-up may be advised. Depending upon the health insurance plan and the managed care system, various forms of \"utilization review\", such as prior authorization of tests, may place barriers on accessing expensive services.\n\nThe medical decision-making (MDM) process involves analysis and synthesis of all the above data to come up with a list of possible diagnoses (the differential diagnoses), along with an idea of what needs to be done to obtain a definitive diagnosis that would explain the patient's problem.\n\nOn subsequent visits, the process may be repeated in an abbreviated manner to obtain any new history, symptoms, physical findings, and lab or imaging results or specialist consultations.\n\nInstitutions\n\nContemporary medicine is in general conducted within health care systems. Legal, credentialing and financing frameworks are established by individual governments, augmented on occasion by international organizations, such as churches. The characteristics of any given health care system have significant impact on the way medical care is provided.\n\nFrom ancient times, Christian emphasis on practical charity gave rise to the development of systematic nursing and hospitals and the Catholic Church today remains the largest non-government provider of medical services in the world. Advanced industrial countries (with the exception of the United States) and many developing countries provide medical services through a system of universal health care that aims to guarantee care for all through a single-payer health care system, or compulsory private or co-operative health insurance. This is intended to ensure that the entire population has access to medical care on the basis of need rather than ability to pay. Delivery may be via private medical practices or by state-owned hospitals and clinics, or by charities, most commonly by a combination of all three.\n\nMost tribal societies provide no guarantee of healthcare for the population as a whole. In such societies, healthcare is available to those that can afford to pay for it or have self-insured it (either directly or as part of an employment contract) or who may be covered by care financed by the government or tribe directly.\n\nTransparency of information is another factor defining a delivery system. Access to information on conditions, treatments, quality, and pricing greatly affects the choice by patients/consumers and, therefore, the incentives of medical professionals. While the US healthcare system has come under fire for lack of openness, new legislation may encourage greater openness. There is a perceived tension between the need for transparency on the one hand and such issues as patient confidentiality and the possible exploitation of information for commercial gain on the other.\n\nThe health professionals who provide care in medicine comprise multiple professions such as medics, nurses, physio therapists, and psychologists. These professions will have their own ethical standards, professional education, and bodies. The medical profession have been conceptualized from a sociological perspective.\n\nDelivery\n\nProvision of medical care is classified into primary, secondary, and tertiary care categories.\n\nPrimary care medical services are provided by physicians, physician assistants, nurse practitioners, or other health professionals who have first contact with a patient seeking medical treatment or care. These occur in physician offices, clinics, nursing homes, schools, home visits, and other places close to patients. About 90% of medical visits can be treated by the primary care provider. These include treatment of acute and chronic illnesses, preventive care and health education for all ages and both sexes.\n\nSecondary care medical services are provided by medical specialists in their offices or clinics or at local community hospitals for a patient referred by a primary care provider who first diagnosed or treated the patient. Referrals are made for those patients who required the expertise or procedures performed by specialists. These include both ambulatory care and inpatient services, Emergency departments, intensive care medicine, surgery services, physical therapy, labor and delivery, endoscopy units, diagnostic laboratory and medical imaging services, hospice centers, etc. Some primary care providers may also take care of hospitalized patients and deliver babies in a secondary care setting.\n\nTertiary care medical services are provided by specialist hospitals or regional centers equipped with diagnostic and treatment facilities not generally available at local hospitals. These include trauma centers, burn treatment centers, advanced neonatology unit services, organ transplants, high-risk pregnancy, radiation oncology, etc.\n\nModern medical care also depends on information \u2013 still delivered in many health care settings on paper records, but increasingly nowadays by electronic means.\n\nIn low-income countries, modern healthcare is often too expensive for the average person. International healthcare policy researchers have advocated that \"user fees\" be removed in these areas to ensure access, although even after removal, significant costs and barriers remain.\n\nSeparation of prescribing and dispensing is a practice in medicine and pharmacy in which the physician who provides a medical prescription is independent from the  pharmacist who provides the prescription drug. In the Western world there are centuries of tradition for separating pharmacists from physicians. In Asian countries, it is traditional for physicians to also provide drugs.\n\nBranches\n\nWorking together as an interdisciplinary team, many highly trained health professionals besides medical practitioners are involved in the delivery of modern health care. Examples include: nurses, emergency medical technicians and paramedics, laboratory scientists, pharmacists, podiatrists, physiotherapists, respiratory therapists, speech therapists, occupational therapists, radiographers, dietitians, and bioengineers, medical physics, surgeons, surgeon's assistant, surgical technologist.\n\nThe scope and sciences underpinning human medicine overlap many other fields. Dentistry, while considered by some a separate discipline from medicine, is a medical field.\n\nA patient admitted to the hospital is usually under the care of a specific team based on their main presenting problem, e.g., the cardiology team, who then may interact with other specialties, e.g., surgical, radiology, to help diagnose or treat the main problem or any subsequent complications/developments.\n\nPhysicians have many specializations and subspecializations into certain branches of medicine, which are listed below. There are variations from country to country regarding which specialties certain subspecialties are in.\n\nThe main branches of medicine are:\n Basic sciences of medicine; this is what every physician is educated in, and some return to in biomedical research\n Medical specialties\n Interdisciplinary fields, where different medical specialties are mixed to function in certain occasions.\n\nBasic sciences\n Anatomy is the study of the physical structure of organisms. In contrast to macroscopic or gross anatomy, cytology and histology are concerned with microscopic structures.\n Biochemistry is the study of the chemistry taking place in living organisms, especially the structure and function of their chemical components.\n Biomechanics is the study of the structure and function of biological systems by means of the methods of Mechanics.\n Biostatistics is the application of statistics to biological fields in the broadest sense. A knowledge of biostatistics is essential in the planning, evaluation, and interpretation of medical research. It is also fundamental to epidemiology and evidence-based medicine.\n Biophysics is an interdisciplinary science that uses the methods of physics and physical chemistry to study biological systems.\n Cytology is the microscopic study of individual cells.\n\n Embryology is the study of the early development of organisms.\n Endocrinology is the study of hormones and their effect throughout the body of animals.\n Epidemiology is the study of the demographics of disease processes, and includes, but is not limited to, the study of epidemics.\n Genetics is the study of genes, and their role in biological inheritance.\n Histology is the study of the structures of biological tissues by light microscopy, electron microscopy and immunohistochemistry.\n Immunology is the study of the immune system, which includes the innate and adaptive immune system in humans, for example.\n Lifestyle medicine is the study of the chronic conditions, and how to prevent, treat and reverse them.\n Medical physics is the study of the applications of physics principles in medicine.\n Microbiology is the study of microorganisms, including protozoa, bacteria, fungi, and viruses.\n Molecular biology is the study of molecular underpinnings of the process of replication, transcription and translation of the genetic material.\n Neuroscience includes those disciplines of science that are related to the study of the nervous system. A main focus of neuroscience is the biology and physiology of the human brain and spinal cord. Some related clinical specialties include neurology, neurosurgery and psychiatry.\n Nutrition science (theoretical focus) and dietetics (practical focus) is the study of the relationship of food and drink to health and disease, especially in determining an optimal diet. Medical nutrition therapy is done by dietitians and is prescribed for diabetes, cardiovascular diseases, weight and eating disorders, allergies, malnutrition, and neoplastic diseases.\n Pathology as a science is the study of disease\u2014the causes, course, progression and resolution thereof.\n Pharmacology is the study of drugs and their actions.\n Gynecology is the study of female reproductive system.\n Photobiology is the study of the interactions between non-ionizing radiation and living organisms.\n Physiology is the study of the normal functioning of the body and the underlying regulatory mechanisms.\n Radiobiology is the study of the interactions between ionizing radiation and living organisms.\n Toxicology is the study of hazardous effects of drugs and poisons.\n\nSpecialties\n\nIn the broadest meaning of \"medicine\", there are many different specialties. In the UK, most specialities have their own body or college, which has its own entrance examination. These are collectively known as the Royal Colleges, although not all currently use the term \"Royal\". The development of a speciality is often driven by new technology (such as the development of effective anaesthetics) or ways of working (such as emergency departments); the new specialty leads to the formation of a unifying body of doctors and the prestige of administering their own examination.\n\nWithin medical circles, specialities usually fit into one of two broad categories: \"Medicine\" and \"Surgery\". \"Medicine\" refers to the practice of non-operative medicine, and most of its subspecialties require preliminary training in Internal Medicine. In the UK, this was traditionally evidenced by passing the examination for the Membership of the Royal College of Physicians (MRCP) or the equivalent college in Scotland or Ireland. \"Surgery\" refers to the practice of operative medicine, and most subspecialties in this area require preliminary training in General Surgery, which in the UK leads to membership of the Royal College of Surgeons of England (MRCS). At present, some specialties of medicine do not fit easily into either of these categories, such as radiology, pathology, or anesthesia. Most of these have branched from one or other of the two camps above; for example anaesthesia developed first as a faculty of the Royal College of Surgeons (for which MRCS/FRCS would have been required) before becoming the Royal College of Anaesthetists and membership of the college is attained by sitting for the examination of the Fellowship of the Royal College of Anesthetists (FRCA).\n\nSurgical specialty\n\nSurgery is an ancient medical specialty that uses operative manual and instrumental techniques on a patient to investigate or treat a pathological condition such as disease or injury, to help improve bodily function or appearance or to repair unwanted ruptured areas (for example, a perforated ear drum). Surgeons must also manage pre-operative, post-operative, and potential surgical candidates on the hospital wards. Surgery has many sub-specialties, including general surgery, ophthalmic surgery, cardiovascular surgery, colorectal surgery, neurosurgery, oral and maxillofacial surgery, oncologic surgery, orthopedic surgery, otolaryngology, plastic surgery, podiatric surgery, transplant surgery, trauma surgery, urology, vascular surgery, and pediatric surgery. In some centers, anesthesiology is part of the division of surgery (for historical and logistical reasons), although it is not a surgical discipline. Other medical specialties may employ surgical procedures, such as ophthalmology and dermatology, but are not considered surgical sub-specialties per se.\n\nSurgical training in the U.S. requires a minimum of five years of residency after medical school. Sub-specialties of surgery often require seven or more years. In addition, fellowships can last an additional one to three years. Because post-residency fellowships can be competitive, many trainees devote two additional years to research. Thus in some cases surgical training will not finish until more than a decade after medical school. Furthermore, surgical training can be very difficult and time-consuming.\n\nInternal medicine specialty\n\nInternal medicine is the medical specialty dealing with the prevention, diagnosis, and treatment of adult diseases. According to some sources, an emphasis on internal structures is implied. In North America, specialists in internal medicine are commonly called \"internists\". Elsewhere, especially in Commonwealth nations, such specialists are often called physicians. These terms, internist or physician (in the narrow sense, common outside North America), generally exclude practitioners of gynecology and obstetrics, pathology, psychiatry, and especially surgery and its subspecialities.\n\nBecause their patients are often seriously ill or require complex investigations, internists do much of their work in hospitals. Formerly, many internists were not subspecialized; such general physicians would see any complex nonsurgical problem; this style of practice has become much less common. In modern urban practice, most internists are subspecialists: that is, they generally limit their medical practice to problems of one organ system or to one particular area of medical knowledge. For example, gastroenterologists and nephrologists specialize respectively in diseases of the gut and the kidneys.\n\nIn the Commonwealth of Nations and some other countries, specialist pediatricians and geriatricians are also described as specialist physicians (or internists) who have subspecialized by age of patient rather than by organ system. Elsewhere, especially in North America, general pediatrics is often a form of primary care.\n\nThere are many subspecialities (or subdisciplines) of internal medicine:\n\nAngiology/Vascular Medicine\nBariatrics\nCardiology\nCritical care medicine\nEndocrinology\nGastroenterology\nGeriatrics\nHematology\nHepatology\nInfectious disease\nNephrology\nNeurology\nOncology\nPediatrics\nPulmonology/Pneumology/Respirology/chest medicine\nRheumatology\nSports Medicine\n\nTraining in internal medicine (as opposed to surgical training), varies considerably across the world: see the articles on medical education and physician for more details. In North America, it requires at least three years of residency training after medical school, which can then be followed by a one- to three-year fellowship in the subspecialties listed above. In general, resident work hours in medicine are less than those in surgery, averaging about 60 hours per week in the US. This difference does not apply in the UK where all doctors are now required by law to work less than 48 hours per week on average.\n\nDiagnostic specialties\n Clinical laboratory sciences are the clinical diagnostic services that apply laboratory techniques to diagnosis and management of patients. In the United States, these services are supervised by a pathologist. The personnel that work in these medical laboratory departments are technically trained staff who do not hold medical degrees, but who usually hold an undergraduate medical technology degree, who actually perform the tests, assays, and procedures needed for providing the specific services. Subspecialties include transfusion medicine, cellular pathology, clinical chemistry, hematology, clinical microbiology and clinical immunology.\n Pathology as a medical specialty is the branch of medicine that deals with the study of diseases and the morphologic, physiologic changes produced by them. As a diagnostic specialty, pathology can be considered the basis of modern scientific medical knowledge and plays a large role in evidence-based medicine. Many modern molecular tests such as flow cytometry, polymerase chain reaction (PCR), immunohistochemistry, cytogenetics, gene rearrangements studies and fluorescent in situ hybridization (FISH) fall within the territory of pathology.\n Diagnostic radiology is concerned with imaging of the body, e.g. by x-rays, x-ray computed tomography, ultrasonography, and nuclear magnetic resonance tomography. Interventional radiologists can access areas in the body under imaging for an intervention or diagnostic sampling.\n Nuclear medicine is concerned with studying human organ systems by administering radiolabelled substances (radiopharmaceuticals) to the body, which can then be imaged outside the body by a gamma camera or a PET scanner. Each radiopharmaceutical consists of two parts: a tracer that is specific for the function under study (e.g., neurotransmitter pathway, metabolic pathway, blood flow, or other), and a radionuclide (usually either a gamma-emitter or a positron emitter). There is a degree of overlap between nuclear medicine and radiology, as evidenced by the emergence of combined devices such as the PET/CT scanner.\n Clinical neurophysiology is concerned with testing the physiology or function of the central and peripheral aspects of the nervous system. These kinds of tests can be divided into recordings of: (1) spontaneous or continuously running electrical activity, or (2) stimulus evoked responses. Subspecialties include electroencephalography, electromyography, evoked potential, nerve conduction study and polysomnography. Sometimes these tests are performed by techs without a medical degree, but the interpretation of these tests is done by a medical professional.\n\nOther major specialties\nThe following are some major medical specialties that do not directly fit into any of the above-mentioned groups:\n Anesthesiology (also known as anaesthetics): concerned with the perioperative management of the surgical patient. The anesthesiologist's role during surgery is to prevent derangement in the vital organs' (i.e. brain, heart, kidneys) functions and postoperative pain. Outside of the operating room, the anesthesiology physician also serves the same function in the labor and delivery ward, and some are specialized in critical medicine.\n Dermatology is concerned with the skin and its diseases. In the UK, dermatology is a subspecialty of general medicine.\n Emergency medicine is concerned with the diagnosis and treatment of acute or life-threatening conditions, including trauma, surgical, medical, pediatric, and psychiatric emergencies.\n Family medicine, family practice, general practice or primary care is, in many countries, the first port-of-call for patients with non-emergency medical problems. Family physicians often provide services across a broad range of settings including office based practices, emergency department coverage, inpatient care, and nursing home care.\n\n Obstetrics and gynecology (often abbreviated as OB/GYN (American English) or Obs & Gynae (British English)) are concerned respectively with childbirth and the female reproductive and associated organs. Reproductive medicine and fertility medicine are generally practiced by gynecological specialists.\n Medical genetics is concerned with the diagnosis and management of hereditary disorders.\n Neurology is concerned with diseases of the nervous system. In the UK, neurology is a subspecialty of general medicine.\n Ophthalmology is exclusively concerned with the eye and ocular adnexa, combining conservative and surgical therapy.\n Pediatrics (AE) or paediatrics (BE) is devoted to the care of infants, children, and adolescents. Like internal medicine, there are many pediatric subspecialties for specific age ranges, organ systems, disease classes, and sites of care delivery.\n Pharmaceutical medicine is the medical scientific discipline concerned with the discovery, development, evaluation, registration, monitoring and medical aspects of marketing of medicines for the benefit of patients and public health.\n Physical medicine and rehabilitation (or physiatry) is concerned with functional improvement after injury, illness, or congenital disorders.\n Podiatric medicine is the study of, diagnosis, and medical & surgical treatment of disorders of the foot, ankle, lower limb, hip and lower back.\n Psychiatry is the branch of medicine concerned with the bio-psycho-social study of the etiology, diagnosis, treatment and prevention of cognitive, perceptual, emotional and behavioral disorders. Related fields include psychotherapy and clinical psychology.\n Preventive medicine is the branch of medicine concerned with preventing disease.\n Community health or public health is an aspect of health services concerned with threats to the overall health of a community based on population health analysis.\n\nInterdisciplinary fields \nSome interdisciplinary sub-specialties of medicine include:\n Aerospace medicine deals with medical problems related to flying and space travel.\n Addiction medicine deals with the treatment of addiction.\n Medical ethics deals with ethical and moral principles that apply values and judgments to the practice of medicine.\n Biomedical Engineering is a field dealing with the application of engineering principles to medical practice.\n Clinical pharmacology is concerned with how systems of therapeutics interact with patients.\n Conservation medicine studies the relationship between human and animal health, and environmental conditions. Also known as ecological medicine, environmental medicine, or medical geology.\n Disaster medicine deals with medical aspects of emergency preparedness, disaster mitigation and management.\n Diving medicine (or hyperbaric medicine) is the prevention and treatment of diving-related problems.\n Evolutionary medicine is a perspective on medicine derived through applying evolutionary theory.\n Forensic medicine deals with medical questions in legal context, such as determination of the time and cause of death, type of weapon used to inflict trauma, reconstruction of the facial features using remains of deceased (skull) thus aiding identification.\n Gender-based medicine studies the biological and physiological differences between the human sexes and how that affects differences in disease.\n Hospice and Palliative Medicine is a relatively modern branch of clinical medicine that deals with pain and symptom relief and emotional support in patients with terminal illnesses including cancer and heart failure.\n Hospital medicine is the general medical care of hospitalized patients. Physicians whose primary professional focus is hospital medicine are called hospitalists in the United States and Canada. The term Most Responsible Physician (MRP) or attending physician is also used interchangeably to describe this role.\n Laser medicine involves the use of lasers in the diagnostics or treatment of various conditions.\n Medical humanities includes the humanities (literature, philosophy, ethics, history and religion), social science (anthropology, cultural studies, psychology, sociology), and the arts (literature, theater, film, and visual arts) and their application to medical education and practice.\n Health informatics is a relatively recent field that deal with the application of computers and information technology to medicine.\n Nosology is the classification of diseases for various purposes.\n Nosokinetics is the science/subject of measuring and modelling the process of care in health and social care systems.\n Occupational medicine is the provision of health advice to organizations and individuals to ensure that the highest standards of health and safety at work can be achieved and maintained.\n Pain management (also called pain medicine, or algiatry) is the medical discipline concerned with the relief of pain.\n Pharmacogenomics is a form of individualized medicine.\n Podiatric medicine is the study of, diagnosis, and medical treatment of disorders of the foot, ankle, lower limb, hip and lower back.\n Sexual medicine is concerned with diagnosing, assessing and treating all disorders related to sexuality.\n Sports medicine deals with the treatment and prevention and rehabilitation of sports/exercise injuries such as muscle spasms, muscle tears, injuries to ligaments (ligament tears or ruptures) and their repair in athletes, amateur and professional.\n Therapeutics is the field, more commonly referenced in earlier periods of history, of the various remedies that can be used to treat disease and promote health.\n Travel medicine or emporiatrics deals with health problems of international travelers or travelers across highly different environments.\n Tropical medicine deals with the prevention and treatment of tropical diseases. It is studied separately in temperate climates where those diseases are quite unfamiliar to medical practitioners and their local clinical needs.\n Urgent care focuses on delivery of unscheduled, walk-in care outside of the hospital emergency department for injuries and illnesses that are not severe enough to require care in an emergency department. In some jurisdictions this function is combined with the emergency department.\n Veterinary medicine; veterinarians apply similar techniques as physicians to the care of animals.\n Wilderness medicine entails the practice of medicine in the wild, where conventional medical facilities may not be available.\n Many other health science fields, e.g. dietetics\n\nEducation and legal controls\n\nMedical education and training varies around the world. It typically involves entry level education at a university medical school, followed by a period of supervised practice or internship, or residency. This can be followed by postgraduate vocational training. A variety of teaching methods have been employed in medical education, still itself a focus of active research. In Canada and the United States of America, a Doctor of Medicine degree, often abbreviated M.D., or a Doctor of Osteopathic Medicine degree, often abbreviated as D.O. and unique to the United States, must be completed in and delivered from a recognized university.\n\nSince knowledge, techniques, and medical technology continue to evolve at a rapid rate, many regulatory authorities require continuing medical education. Medical practitioners upgrade their knowledge in various ways, including medical journals, seminars, conferences, and online programs.  A database of objectives covering medical knowledge, as suggested by national societies across the United States, can be searched at http://data.medobjectives.marian.edu/.\n\nIn most countries, it is a legal requirement for a medical doctor to be licensed or registered. In general, this entails a medical degree from a university and accreditation by a medical board or an equivalent national organization, which may ask the applicant to pass exams. This restricts the considerable legal authority of the medical profession to physicians that are trained and qualified by national standards. It is also intended as an assurance to patients and as a safeguard against charlatans that practice inadequate medicine for personal gain. While the laws generally require medical doctors to be trained in \"evidence based\", Western, or Hippocratic Medicine, they are not intended to discourage different paradigms of health.\n\nIn the European Union, the profession of doctor of medicine is regulated. A profession is said to be regulated when access and exercise is subject to the possession of a specific professional qualification.\nThe regulated professions database contains a list of regulated professions for doctor of medicine in the EU member states, EEA countries and Switzerland. This list is covered by the Directive 2005/36/EC.\n\nDoctors who are negligent or intentionally harmful in their care of patients can face charges of medical malpractice and be subject to civil, criminal, or professional sanctions.\n\nMedical ethics\n\nMedical ethics is a system of moral principles that apply values and judgments to the practice of medicine. As a scholarly discipline, medical ethics encompasses its practical application in clinical settings as well as work on its history, philosophy, theology, and sociology. Six of the values that commonly apply to medical ethics discussions are:\n autonomy \u2013 the patient has the right to refuse or choose their treatment. (Voluntas aegroti suprema lex.)\n beneficence \u2013 a practitioner should act in the best interest of the patient. (Salus aegroti suprema lex.)\n justice \u2013 concerns the distribution of scarce health resources, and the decision of who gets what treatment (fairness and equality).\n non-maleficence \u2013 \"first, do no harm\" (primum non-nocere).\n respect for persons \u2013 the patient (and the person treating the patient) have the right to be treated with dignity.\n truthfulness and honesty \u2013 the concept of informed consent has increased in importance since the historical events of the Doctors' Trial of the Nuremberg trials, Tuskegee syphilis experiment, and others.\n\nValues such as these do not give answers as to how to handle a particular situation, but provide a useful framework for understanding conflicts. When moral values are in conflict, the result may be an ethical dilemma or crisis. Sometimes, no good solution to a dilemma in medical ethics exists, and occasionally, the values of the medical community (i.e., the hospital and its staff) conflict with the values of the individual patient, family, or larger non-medical community. Conflicts can also arise between health care providers, or among family members. For example, some argue that the principles of autonomy and beneficence clash when patients refuse blood transfusions, considering them life-saving; and truth-telling was not emphasized to a large extent before the HIV era.\n\nHistory\n\nAncient world\nPrehistoric medicine incorporated plants (herbalism), animal parts, and minerals. In many cases these materials were used ritually as magical substances by priests, shamans, or medicine men. Well-known spiritual systems include animism (the notion of inanimate objects having spirits), spiritualism (an appeal to gods or communion with ancestor spirits); shamanism (the vesting of an individual with mystic powers); and divination (magically obtaining the truth). The field of medical anthropology examines the ways in which culture and society are organized around or impacted by issues of health, health care and related issues.\n\nEarly records on medicine have been discovered from ancient Egyptian medicine, Babylonian Medicine, Ayurvedic medicine (in the Indian subcontinent), classical Chinese medicine (predecessor to the modern traditional Chinese medicine), and ancient Greek medicine and Roman medicine.\n\nIn Egypt, Imhotep (3rd millennium BCE) is the first physician in history known by name. The oldest Egyptian medical text is the Kahun Gynaecological Papyrus from around 2000 BCE, which describes gynaecological diseases. The Edwin Smith Papyrus dating back to 1600 BCE is an early work on surgery, while the Ebers Papyrus dating back to 1500 BCE is akin to a textbook on medicine.\n\nIn China, archaeological evidence of medicine in Chinese dates back to the Bronze Age Shang Dynasty, based on seeds for herbalism and tools presumed to have been used for surgery. The Huangdi Neijing, the progenitor of Chinese medicine, is a medical text written beginning in the 2nd century BCE and compiled in the 3rd century.\n\nIn India, the surgeon Sushruta described numerous surgical operations, including the earliest forms of plastic surgery. Earliest records of dedicated hospitals come from Mihintale in Sri Lanka where evidence of dedicated medicinal treatment facilities for patients are found.\n\nIn Greece, the Greek physician Hippocrates, the \"father of modern medicine\", laid the foundation for a rational approach to medicine. Hippocrates introduced the Hippocratic Oath for physicians, which is still relevant and in use today, and was the first to categorize illnesses as acute, chronic, endemic and epidemic, and use terms such as, \"exacerbation, relapse, resolution, crisis, paroxysm, peak, and convalescence\". The Greek physician Galen was also one of the greatest surgeons of the ancient world and performed many audacious operations, including brain and eye surgeries. After the fall of the Western Roman Empire and the onset of the Early Middle Ages, the Greek tradition of medicine went into decline in Western Europe, although it continued uninterrupted in the Eastern Roman (Byzantine) Empire.\n\nMost of our knowledge of ancient Hebrew medicine during the 1st\u00a0millennium\u00a0BC comes from the Torah, i.e.\u00a0the Five Books of Moses, which contain various health related laws and rituals. The Hebrew contribution to the development of modern medicine started in the Byzantine Era, with the physician Asaph the Jew.\n\nMiddle Ages\n\nThe concept of hospital as institution to offer medical care and possibility of a cure for the patients due to the ideals of Christian charity, rather than just merely a place to die, appeared in the Byzantine Empire.\n\nAlthough the concept of uroscopy was known to Galen, he did not see the importance of using it to localize the disease. It was under the Byzantines with physicians such of Theophilus Protospatharius that they realized the potential in uroscopy to determine disease in a time when no microscope or stethoscope existed. That practice eventually spread to the rest of Europe.\n\nAfter 750 CE, the Muslim world had the works of Hippocrates, Galen and Sushruta translated into Arabic, and Islamic physicians engaged in some significant medical research. Notable Islamic medical pioneers include the Persian polymath, Avicenna, who, along with Imhotep and Hippocrates, has also been called the \"father of medicine\". He wrote The Canon of Medicine which became a standard medical text at many medieval European universities, considered one of the most famous books in the history of medicine. Others include Abulcasis, Avenzoar, Ibn al-Nafis, and Averroes. Persian  physician Rhazes was one of the first to question the Greek theory of humorism, which nevertheless remained influential in both medieval Western and medieval Islamic medicine. Some volumes of Rhazes's work Al-Mansuri, namely \"On Surgery\" and \"A General Book on Therapy\", became part of the medical curriculum in European universities. Additionally, he has been described as a doctor's doctor, the father of pediatrics, and a pioneer of ophthalmology. For example, he was the first to recognize the reaction of the eye's pupil to light. The Persian Bimaristan hospitals were an early example of public hospitals.\n\nIn Europe, Charlemagne decreed that a hospital should be attached to each cathedral and monastery and the historian Geoffrey Blainey likened the activities of the Catholic Church in health care during the Middle Ages to an early version of a welfare state: \"It conducted hospitals for the old and orphanages for the young; hospices for the sick of all ages; places for the lepers; and hostels or inns where pilgrims could buy a cheap bed and meal\". It supplied food to the population during famine and distributed food to the poor. This welfare system the church funded through collecting taxes on a large scale and possessing large farmlands and estates. The Benedictine order was noted for setting up hospitals and infirmaries in their monasteries, growing medical herbs and becoming the chief medical care givers of their districts, as at the great Abbey of Cluny. The Church also established a network of cathedral schools and universities where medicine was studied. The Schola Medica Salernitana in Salerno, looking to the learning of Greek and Arab physicians, grew to be the finest medical school in Medieval Europe.\n\nHowever, the fourteenth and fifteenth century Black Death devastated both the Middle East and Europe, and it has even been argued that Western Europe was generally more effective in recovering from the pandemic than the Middle East. In the early modern period, important early figures in medicine and anatomy emerged in Europe, including Gabriele Falloppio and William Harvey.\n\nThe major shift in medical thinking was the gradual rejection, especially during the Black Death in the 14th and 15th centuries, of what may be called the 'traditional authority' approach to science and medicine. This was the notion that because some prominent person in the past said something must be so, then that was the way it was, and anything one observed to the contrary was an anomaly (which was paralleled by a similar shift in European society in general \u2013 see Copernicus's rejection of Ptolemy's theories on astronomy). Physicians like Vesalius improved upon or disproved some of the theories from the past. The main tomes used both by medicine students and expert physicians were Materia Medica and Pharmacopoeia.\n\nAndreas Vesalius was the author of De humani corporis fabrica, an important book on human anatomy. Bacteria and microorganisms were first observed with a microscope by Antonie van Leeuwenhoek in 1676, initiating the scientific field microbiology. Independently from Ibn al-Nafis, Michael Servetus rediscovered the pulmonary circulation, but this discovery did not reach the public because it was written down for the first time in the \"Manuscript of Paris\" in 1546, and later published in the theological work for which he paid with his life in 1553. Later this was described by Renaldus Columbus and Andrea Cesalpino. Herman Boerhaave is sometimes referred to as a \"father of physiology\" due to his exemplary teaching in Leiden and textbook 'Institutiones medicae' (1708). Pierre Fauchard has been called \"the father of modern dentistry\".\n\nModern\n\nVeterinary medicine was, for the first time, truly separated from human medicine in 1761, when the French veterinarian Claude Bourgelat founded the world's first veterinary school in Lyon, France. Before this, medical doctors treated both humans and other animals.\n\nModern scientific biomedical research (where results are testable and reproducible) began to replace early Western traditions based on herbalism, the Greek \"four humours\" and other such pre-modern notions. The modern era really began with Edward Jenner's discovery of the smallpox vaccine at the end of the 18th century (inspired by the method of inoculation earlier practiced in Asia), Robert Koch's discoveries around 1880 of the transmission of disease by bacteria, and then the discovery of antibiotics around 1900.\n\nThe post-18th century modernity period brought more groundbreaking researchers from Europe. From Germany and Austria, doctors Rudolf Virchow, Wilhelm Conrad R\u00f6ntgen, Karl Landsteiner and Otto Loewi made notable contributions. In the United Kingdom, Alexander Fleming, Joseph Lister, Francis Crick and Florence Nightingale are considered important. Spanish doctor Santiago Ram\u00f3n y Cajal is considered the father of modern neuroscience.\n\nFrom New Zealand and Australia came Maurice Wilkins, Howard Florey, and Frank Macfarlane Burnet.\n\nOthers that did significant work include William Williams Keen, William Coley, James D. Watson (United States); Salvador Luria (Italy); Alexandre Yersin (Switzerland); Kitasato Shibasabur\u014d (Japan); Jean-Martin Charcot, Claude Bernard, Paul Broca (France); Adolfo Lutz (Brazil); Nikolai Korotkov (Russia); Sir William Osler (Canada); and Harvey Cushing (United States).\n\nAs science and technology developed, medicine became more reliant upon medications. Throughout history and in Europe right until the late 18th century, not only animal and plant products were used as medicine, but also human body parts and fluids. Pharmacology developed in part from herbalism and some drugs are still derived from plants (atropine, ephedrine, warfarin, aspirin, digoxin, vinca alkaloids, taxol, hyoscine, etc.). Vaccines were discovered by Edward Jenner and Louis Pasteur.\n\nThe first antibiotic was arsphenamine (Salvarsan) discovered by Paul Ehrlich in 1908 after he observed that bacteria took up toxic dyes that human cells did not. The first major class of antibiotics was the sulfa drugs, derived by German chemists originally from azo dyes.\n\nPharmacology has become increasingly sophisticated; modern biotechnology allows drugs targeted towards specific physiological processes to be developed, sometimes designed for compatibility with the body to reduce side-effects. Genomics and knowledge of human genetics and human evolution is having increasingly significant influence on medicine, as the causative genes of most monogenic genetic disorders have now been identified, and the development of techniques in molecular biology, evolution, and genetics are influencing medical technology, practice and decision-making.\n\nEvidence-based medicine is a contemporary movement to establish the most effective algorithms of practice (ways of doing things) through the use of systematic reviews and meta-analysis. The movement is facilitated by modern global information science, which allows as much of the available evidence as possible to be collected and analyzed according to standard protocols that are then disseminated to healthcare providers. The Cochrane Collaboration leads this movement. A 2001 review of 160 Cochrane systematic reviews revealed that, according to two readers, 21.3% of the reviews concluded insufficient evidence, 20% concluded evidence of no effect, and 22.5% concluded positive effect.\n\nQuality, efficiency, and access \nEvidence-based medicine, prevention of medical error (and other \"iatrogenesis\"), and avoidance of unnecessary health care are a priority in modern medical systems. These topics generate significant political and public policy attention, particularly in the United States where healthcare is regarded as excessively costly but population health metrics lag similar nations.\n\nGlobally, many developing countries lack access to care and access to medicines. As of 2015, most wealthy developed countries provide health care to all citizens, with a few exceptions such as the United States where lack of health insurance coverage may limit access.\n\nSee also\n\nReferences \n\n \n\nnew:\u091a\u093f\u0915\u093f\u0924\u094d\u0938\u093e",
  "Opera": "Opera  is a form of theatre in which music is a fundamental component and dramatic roles are taken by singers. Such a \"work\" (the literal translation of the Italian word \"opera\") is typically a collaboration between a composer and a librettist and incorporates a number of the performing arts, such as acting, scenery, costume, and sometimes dance or ballet. The performance is typically given in an opera house, accompanied by an orchestra or smaller musical ensemble, which since the early 19th century has been led by a conductor. Although musical theatre is closely related to opera, the two are considered to be distinct from one another.\n\nOpera is a key part of the Western classical music tradition. Originally understood as an entirely sung piece, in contrast to a play with songs, opera has come to include numerous genres, including some that include spoken dialogue such as musical theatre, Singspiel and Op\u00e9ra comique. In traditional number opera, singers employ two styles of singing: recitative, a speech-inflected style, and self-contained arias. The 19th century saw the rise of the continuous music drama.\n\nOpera originated in Italy at the end of the 16th century (with Jacopo Peri's mostly lost Dafne, produced in Florence in 1598) especially from works by Claudio Monteverdi, notably L'Orfeo, and soon spread through the rest of Europe: Heinrich Sch\u00fctz in Germany, Jean-Baptiste Lully in France, and Henry Purcell in England all helped to establish their national traditions in the 17th century. In the 18th century, Italian opera continued to dominate most of Europe (except France), attracting foreign composers such as George Frideric Handel. Opera seria was the most prestigious form of Italian opera, until Christoph Willibald Gluck reacted against its artificiality with his \"reform\" operas in the 1760s. The most renowned figure of late 18th-century opera is Wolfgang Amadeus Mozart, who began with opera seria but is most famous for his Italian comic operas, especially The Marriage of Figaro (Le nozze di Figaro), Don Giovanni, and Cos\u00ec fan tutte, as well as Die Entf\u00fchrung aus dem Serail (The Abduction from the Seraglio), and The Magic Flute (Die Zauberfl\u00f6te), landmarks in the German tradition.\n\nThe first third of the 19th century saw the high point of the bel canto style, with Gioachino Rossini, Gaetano Donizetti and Vincenzo Bellini all creating signature works of that style. It also saw the advent of grand opera typified by the works of Daniel Auber and Giacomo Meyerbeer as well as Carl Maria von Weber's introduction of German Romantische Oper (German Romantic Opera). The mid-to-late 19th century was a golden age of opera, led and dominated by Giuseppe Verdi in Italy and Richard Wagner in Germany. The popularity of opera continued through the verismo era in Italy and contemporary French opera through to Giacomo Puccini and Richard Strauss in the early 20th century. During the 19th century, parallel operatic traditions emerged in central and eastern Europe, particularly in Russia and Bohemia. The 20th century saw many experiments with modern styles, such as atonality and serialism (Arnold Schoenberg and Alban Berg), neoclassicism (Igor Stravinsky), and minimalism (Philip Glass and John Adams). With the rise of recording technology, singers such as Enrico Caruso and Maria Callas became known to much wider audiences that went beyond the circle of opera fans. Since the invention of radio and television, operas were also performed on (and written for) these media. Beginning in 2006, a number of major opera houses began to present live high-definition video transmissions of their performances in cinemas all over the world. Since 2009, complete performances can be downloaded and are live streamed.\n\nOperatic terminology\nThe words of an opera are known as the libretto (literally \"small book\"). Some composers, notably Wagner, have written their own libretti; others have worked in close collaboration with their librettists, e.g. Mozart with Lorenzo Da Ponte. Traditional opera, often referred to as \"number opera\", consists of two modes of singing: recitative, the plot-driving passages sung in a style designed to imitate and emphasize the inflections of speech, and aria (an \"air\" or formal song) in which the characters express their emotions in a more structured melodic style. Vocal duets, trios and other ensembles often occur, and choruses are used to comment on the action. In some forms of opera, such as singspiel, op\u00e9ra comique, operetta, and semi-opera, the recitative is mostly replaced by spoken dialogue. Melodic or semi-melodic passages occurring in the midst of, or instead of, recitative, are also referred to as arioso. The terminology of the various kinds of operatic voices is described in detail below. During both the Baroque and Classical periods, recitative could appear in two basic forms, each of which was accompanied by a different instrumental ensemble: secco (dry) recitative, sung with a free rhythm dictated by the accent of the words, accompanied only by basso continuo, which was usually a harpsichord and a cello; or accompagnato (also known as strumentato) in which the orchestra provided accompaniment. Over the 18th century, arias were increasingly accompanied by the orchestra. By the 19th century, accompagnato had gained the upper hand, the orchestra played a much bigger role, and Wagner revolutionized opera by abolishing almost all distinction between aria and recitative in his quest for what Wagner termed \"endless melody\". Subsequent composers have tended to follow Wagner's example, though some, such as Stravinsky in his The Rake's Progress have bucked the trend. The changing role of the orchestra in opera is described in more detail below.\n\nHistory\n\nOrigins\n\nThe Italian word opera means \"work\", both in the sense of the labour done and the result produced. The Italian word derives from the Latin word opera, a singular noun meaning \"work\" and also the plural of the noun opus. According to the Oxford English Dictionary, the Italian word was first used in the sense \"composition in which poetry, dance, and music are combined\" in 1639; the first recorded English usage in this sense dates to 1648.\n\nDafne by Jacopo Peri was the earliest composition considered opera, as understood today. It was written around 1597, largely under the inspiration of an elite circle of literate Florentine humanists who gathered as the \"Camerata de' Bardi\". Significantly, Dafne was an attempt to revive the classical Greek drama, part of the wider revival of antiquity characteristic of the Renaissance. The members of the Camerata considered that the \"chorus\" parts of Greek dramas were originally sung, and possibly even the entire text of all roles; opera was thus conceived as a way of \"restoring\" this situation. Dafne, however, is lost. A later work by Peri, Euridice, dating from 1600, is the first opera score to have survived until the present day. However, the honour of being the first opera still to be regularly performed goes to Claudio Monteverdi's L'Orfeo, composed for the court of Mantua in 1607. The Mantua court of the Gonzagas, employers of Monteverdi, played a significant role in the origin of opera employing not only court singers of the concerto delle donne (till 1598), but also one of the first actual \"opera singers\", Madama Europa.\n\nItalian opera\n\nBaroque era\n\nOpera did not remain confined to court audiences for long. In 1637, the idea of a \"season\" (often during the carnival) of publicly attended operas supported by ticket sales emerged in Venice. Monteverdi had moved to the city from Mantua and composed his last operas, Il ritorno d'Ulisse in patria and L'incoronazione di Poppea, for the Venetian theatre in the 1640s. His most important follower Francesco Cavalli helped spread opera throughout Italy. In these early Baroque operas, broad comedy was blended with tragic elements in a mix that jarred some educated sensibilities, sparking the first of opera's many reform movements, sponsored by the Arcadian Academy, which came to be associated with the poet Metastasio, whose libretti helped crystallize the genre of opera seria, which became the leading form of Italian opera until the end of the 18th century. Once the Metastasian ideal had been firmly established, comedy in Baroque-era opera was reserved for what came to be called opera buffa. Before such elements were forced out of opera seria, many libretti had featured a separately unfolding comic plot as sort of an \"opera-within-an-opera\". One reason for this was an attempt to attract members of the growing merchant class, newly wealthy, but still not as cultured as the nobility, to the public opera houses. These separate plots were almost immediately resurrected in a separately developing tradition that partly derived from the commedia dell'arte, a long-flourishing improvisatory stage tradition of Italy. Just as intermedi had once been performed in between the acts of stage plays, operas in the new comic genre of intermezzi, which developed largely in Naples in the 1710s and 1720s, were initially staged during the intermissions of opera seria. They became so popular, however, that they were soon being offered as separate productions.\n\nOpera seria was elevated in tone and highly stylised in form, usually consisting of secco recitative interspersed with long da capo arias. These afforded great opportunity for virtuosic singing and during the golden age of opera seria the singer really became the star. The role of the hero was usually written for the high-pitched male castrato voice, which was produced by castration of the singer before puberty, which prevented a boy's larynx from being transformed at puberty. Castrati such as Farinelli and Senesino, as well as female sopranos such as Faustina Bordoni, became in great demand throughout Europe as opera seria ruled the stage in every country except France. Farinelli was one of the most famous singers of the 18th century. Italian opera set the Baroque standard. Italian libretti were the norm, even when a German composer like Handel found himself composing the likes of Rinaldo and Giulio Cesare for London audiences. Italian libretti remained dominant in the classical period as well, for example in the operas of Mozart, who wrote in Vienna near the century's close. Leading Italian-born composers of opera seria include Alessandro Scarlatti, Antonio Vivaldi and Nicola Porpora.\n\nGluck's reforms and Mozart\n\nOpera seria had its weaknesses and critics. The taste for embellishment on behalf of the superbly trained singers, and the use of spectacle as a replacement for dramatic purity and unity drew attacks. Francesco Algarotti's Essay on the Opera (1755) proved to be an inspiration for Christoph Willibald Gluck's reforms. He advocated that opera seria had to return to basics and that all the various elements\u2014music (both instrumental and vocal), ballet, and staging\u2014must be subservient to the overriding drama. In 1765 Melchior Grimm published \"\", an influential article for the Encyclop\u00e9die on lyric and opera librettos. Several composers of the period, including Niccol\u00f2 Jommelli and Tommaso Traetta, attempted to put these ideals into practice. The first to succeed however, was Gluck. Gluck strove to achieve a \"beautiful simplicity\". This is evident in his first reform opera, Orfeo ed Euridice, where his non-virtuosic vocal melodies are supported by simple harmonies and a richer orchestra presence throughout.\n\nGluck's reforms have had resonance throughout operatic history. Weber, Mozart, and Wagner, in particular, were influenced by his ideals. Mozart, in many ways Gluck's successor, combined a superb sense of drama, harmony, melody, and counterpoint to write a series of comic operas with libretti by Lorenzo Da Ponte, notably Le nozze di Figaro, Don Giovanni, and Cos\u00ec fan tutte, which remain among the most-loved, popular and well-known operas. But Mozart's contribution to opera seria was more mixed; by his time it was dying away, and in spite of such fine works as Idomeneo and La clemenza di Tito, he would not succeed in bringing the art form back to life again.\n\nBel canto, Verdi and verismo\n\nThe bel canto opera movement flourished in the early 19th century and is exemplified by the operas of Rossini, Bellini, Donizetti, Pacini, Mercadante and many others. Literally \"beautiful singing\", bel canto opera derives from the Italian stylistic singing school of the same name. Bel canto lines are typically florid and intricate, requiring supreme agility and pitch control. Examples of famous operas in the bel canto style include Rossini's Il barbiere di Siviglia and La Cenerentola, as well as Bellini's Norma, La sonnambula and I puritani and Donizetti's Lucia di Lammermoor, L'elisir d'amore and Don Pasquale.\n\nFollowing the bel canto era, a more direct, forceful style was rapidly popularized by Giuseppe Verdi, beginning with his biblical opera Nabucco. This opera, and the ones that would follow in Verdi's career, revolutionized Italian opera, changing it from merely a display of vocal fireworks, with Rossini's and Donizetti's works, to dramatic story-telling. Verdi's operas resonated with the growing spirit of Italian nationalism in the post-Napoleonic era, and he quickly became an icon of the patriotic movement for a unified Italy. In the early 1850s, Verdi produced his three most popular operas: Rigoletto, Il trovatore and La traviata. The first of these, Rigoletto, proved the most daring and revolutionary. In it, Verdi blurs the distinction between the aria and recitative as it never before was, leading the opera to be \"an unending string of duets\". La traviata was also novel. It tells the story of courtesan, and is often cited as one of the first \"realistic\" operas, because rather than featuring great kings and figures from literature, it focuses on the tragedies of ordinary life and society. After these, he continued to develop his style, composing perhaps the greatest French grand opera, Don Carlos, and ending his career with two Shakespeare-inspired works, Otello and Falstaff, which reveal how far Italian opera had grown in sophistication since the early 19th century. These final two works showed Verdi at his most masterfully orchestrated, and are both incredibly influential, and modern. In Falstaff, Verdi sets the preeminent standard for the form and style that would dominate opera throughout the twentieth century. Rather than long, suspended melodies, Falstaff contains many little motifs and mottos, that, rather than being expanded upon, are introduced and subsequently dropped, only to be brought up again later. These motifs never are expanded upon, and just as the audience expects a character to launch into a long melody, a new character speaks, introducing a new phrase. This fashion of opera directed opera from Verdi, onward, exercising tremendous influence on his successors Giacomo Puccini, Richard Strauss, and Benjamin Britten.\n\nAfter Verdi, the sentimental \"realistic\" melodrama of verismo appeared in Italy. This was a style introduced by Pietro Mascagni's Cavalleria rusticana and Ruggero Leoncavallo's Pagliacci that came to dominate the world's opera stages with such popular works as Giacomo Puccini's La boh\u00e8me, Tosca, and Madama Butterfly. Later Italian composers, such as Berio and Nono, have experimented with modernism.\n\nGerman-language opera\n\nThe first German opera was Dafne, composed by Heinrich Sch\u00fctz in 1627, but the music score has not survived. Italian opera held a great sway over German-speaking countries until the late 18th century. Nevertheless, native forms would develop in spite of this influence. In 1644, Sigmund Staden produced the first Singspiel, Seelewig, a popular form of German-language opera in which singing alternates with spoken dialogue. In the late 17th century and early 18th century, the Theater am G\u00e4nsemarkt in Hamburg presented German operas by Keiser, Telemann and Handel. Yet most of the major German composers of the time, including Handel himself, as well as Graun, Hasse and later Gluck, chose to write most of their operas in foreign languages, especially Italian. In contrast to Italian opera, which was generally composed for the aristocratic class, German opera was generally composed for the masses and tended to feature simple folk-like melodies, and it was not until the arrival of Mozart that German opera was able to match its Italian counterpart in musical sophistication. The theatre company of Abel Seyler pioneered serious German-language opera in the 1770s, marking a break with the previous simpler musical entertainment.\n\nMozart's Singspiele, Die Entf\u00fchrung aus dem Serail (1782) and Die Zauberfl\u00f6te (1791) were an important breakthrough in achieving international recognition for German opera. The tradition was developed in the 19th century by Beethoven with his Fidelio (1805), inspired by the climate of the French Revolution. Carl Maria von Weber established German Romantic opera in opposition to the dominance of Italian bel canto. His Der Freisch\u00fctz (1821) shows his genius for creating a supernatural atmosphere. Other opera composers of the time include Marschner, Schubert and Lortzing, but the most significant figure was undoubtedly Wagner.\n\nWagner was one of the most revolutionary and controversial composers in musical history. Starting under the influence of Weber and Meyerbeer, he gradually evolved a new concept of opera as a Gesamtkunstwerk (a \"complete work of art\"), a fusion of music, poetry and painting. He greatly increased the role and power of the orchestra, creating scores with a complex web of leitmotifs, recurring themes often associated with the characters and concepts of the drama, of which prototypes can be heard in his earlier operas such as Der fliegende Holl\u00e4nder, Tannh\u00e4user and Lohengrin; and he was prepared to violate accepted musical conventions, such as tonality, in his quest for greater expressivity. In his mature music dramas, Tristan und Isolde, Die Meistersinger von N\u00fcrnberg, Der Ring des Nibelungen and Parsifal, he abolished the distinction between aria and recitative in favour of a seamless flow of \"endless melody\". Wagner also brought a new philosophical dimension to opera in his works, which were usually based on stories from Germanic or Arthurian legend. Finally, Wagner built his own opera house at Bayreuth with part of the patronage from Ludwig II of Bavaria, exclusively dedicated to performing his own works in the style he wanted.\n\nOpera would never be the same after Wagner and for many composers his legacy proved a heavy burden. On the other hand, Richard Strauss accepted Wagnerian ideas but took them in wholly new directions, along with incorporating the new form introduced by Verdi. He first won fame with the scandalous Salome and the dark tragedy Elektra, in which tonality was pushed to the limits. Then Strauss changed tack in his greatest success, Der Rosenkavalier, where Mozart and Viennese waltzes became as important an influence as Wagner. Strauss continued to produce a highly varied body of operatic works, often with libretti by the poet Hugo von Hofmannsthal. Other composers who made individual contributions to German opera in the early 20th century include Alexander von Zemlinsky, Erich Korngold, Franz Schreker, Paul Hindemith, Kurt Weill and the Italian-born Ferruccio Busoni. The operatic innovations of Arnold Schoenberg and his successors are discussed in the section on modernism.\n\nDuring the late 19th century, the Austrian composer Johann Strauss II, an admirer of the French-language operettas composed by Jacques Offenbach, composed several German-language operettas, the most famous of which was Die Fledermaus. Nevertheless, rather than copying the style of Offenbach, the operettas of Strauss II had distinctly Viennese flavor to them.\n\nFrench opera\n\nIn rivalry with imported Italian opera productions, a separate French tradition was founded by the Italian Jean-Baptiste Lully at the court of King Louis XIV. Despite his foreign origin, Lully established an Academy of Music and monopolised French opera from 1672. Starting with Cadmus et Hermione, Lully and his librettist Quinault created trag\u00e9die en musique, a form in which dance music and choral writing were particularly prominent. Lully's operas also show a concern for expressive recitative which matched the contours of the French language. In the 18th century, Lully's most important successor was Jean-Philippe Rameau, who composed five trag\u00e9dies en musique as well as numerous works in other genres such as op\u00e9ra-ballet, all notable for their rich orchestration and harmonic daring. Despite the popularity of Italian opera seria throughout much of Europe during the Baroque period, Italian opera never gained much of a foothold in France, where its own national operatic tradition was more popular instead. After Rameau's death, the German Gluck was persuaded to produce six operas for the Parisian stage in the 1770s. They show the influence of Rameau, but simplified and with greater focus on the drama. At the same time, by the middle of the 18th century another genre was gaining popularity in France: op\u00e9ra comique. This was the equivalent of the German singspiel, where arias alternated with spoken dialogue. Notable examples in this style were produced by Monsigny, Philidor and, above all, Gr\u00e9try. During the Revolutionary and Napoleonic period, composers such as \u00c9tienne M\u00e9hul, Luigi Cherubini and Gaspare Spontini, who were followers of Gluck, brought a new seriousness to the genre, which had never been wholly \"comic\" in any case. Another phenomenon of this period was the 'propaganda opera' celebrating revolutionary successes, e.g. Gossec's Le triomphe de la R\u00e9publique (1793).\n\nBy the 1820s, Gluckian influence in France had given way to a taste for Italian bel canto, especially after the arrival of Rossini in Paris. Rossini's Guillaume Tell helped found the new genre of grand opera, a form whose most famous exponent was another foreigner, Giacomo Meyerbeer. Meyerbeer's works, such as Les Huguenots, emphasised virtuoso singing and extraordinary stage effects. Lighter op\u00e9ra comique also enjoyed tremendous success in the hands of Bo\u00efeldieu, Auber, H\u00e9rold and Adam. In this climate, the operas of the French-born composer Hector Berlioz struggled to gain a hearing. Berlioz's epic masterpiece Les Troyens, the culmination of the Gluckian tradition, was not given a full performance for almost a hundred years.\n\nIn the second half of the 19th century, Jacques Offenbach created operetta with witty and cynical works such as Orph\u00e9e aux enfers, as well as the opera Les Contes d'Hoffmann; Charles Gounod scored a massive success with Faust; and Georges Bizet composed Carmen, which, once audiences learned to accept its blend of Romanticism and realism, became the most popular of all op\u00e9ra comiques. Jules Massenet, Camille Saint-Sa\u00ebns and L\u00e9o Delibes all composed works which are still part of the standard repertory, examples being Massenet's Manon, Saint-Sa\u00ebns' Samson et Dalila and Delibes' Lakm\u00e9. Their operas formed another genre, the Opera Lyrique, combined opera comique and grand opera. It is less grandiose than grand opera, but without the spoken dialogue of opera comique.  At the same time, the influence of Richard Wagner was felt as a challenge to the French tradition. Many French critics angrily rejected Wagner's music dramas while many French composers closely imitated them with variable success. Perhaps the most interesting response came from Claude Debussy. As in Wagner's works, the orchestra plays a leading role in Debussy's unique opera Pell\u00e9as et M\u00e9lisande (1902) and there are no real arias, only recitative. But the drama is understated, enigmatic and completely un-Wagnerian.\n\nOther notable 20th-century names include Ravel, Dukas, Roussel, Honegger and Milhaud. Francis Poulenc is one of the very few post-war composers of any nationality whose operas (which include Dialogues des Carm\u00e9lites) have gained a foothold in the international repertory. Olivier Messiaen's lengthy sacred drama Saint Fran\u00e7ois d'Assise (1983) has also attracted widespread attention.\n\nEnglish-language opera\n\nIn England, opera's antecedent was the 17th-century jig. This was an afterpiece that came at the end of a play. It was frequently libellous and scandalous and consisted in the main of dialogue set to music arranged from popular tunes. In this respect, jigs anticipate the ballad operas of the 18th century. At the same time, the French masque was gaining a firm hold at the English Court, with even more lavish splendour and highly realistic scenery than had been seen before. Inigo Jones became the quintessential designer of these productions, and this style was to dominate the English stage for three centuries. These masques contained songs and dances. In Ben Jonson's Lovers Made Men (1617), \"the whole masque was sung after the Italian manner, stilo recitativo\". The approach of the English Commonwealth closed theatres and halted any developments that may have led to the establishment of English opera. However, in 1656, the dramatist Sir William Davenant produced The Siege of Rhodes. Since his theatre was not licensed to produce drama, he asked several of the leading composers (Lawes, Cooke, Locke, Coleman and Hudson) to set sections of it to music. This success was followed by The Cruelty of the Spaniards in Peru (1658) and The History of Sir Francis Drake (1659). These pieces were encouraged by Oliver Cromwell because they were critical of Spain. With the English Restoration, foreign (especially French) musicians were welcomed back. In 1673, Thomas Shadwell's Psyche, patterned on the 1671 'com\u00e9die-ballet' of the same name produced by Moli\u00e8re and Jean-Baptiste Lully. William Davenant produced The Tempest in the same year, which was the first musical adaption of a Shakespeare play (composed by Locke and Johnson). About 1683, John Blow composed Venus and Adonis, often thought of as the first true English-language opera.\n\nBlow's immediate successor was the better known Henry Purcell. Despite the success of his masterwork Dido and Aeneas (1689), in which the action is furthered by the use of Italian-style recitative, much of Purcell's best work was not involved in the composing of typical opera, but instead, he usually worked within the constraints of the semi-opera format, where isolated scenes and masques are contained within the structure of a spoken play, such as Shakespeare in Purcell's The Fairy-Queen (1692) and Beaumont and Fletcher in The Prophetess (1690) and Bonduca (1696). The main characters of the play tend not to be involved in the musical scenes, which means that Purcell was rarely able to develop his characters through song. Despite these hindrances, his aim (and that of his collaborator John Dryden) was to establish serious opera in England, but these hopes ended with Purcell's early death at the age of 36.\n\nFollowing Purcell, the popularity of opera in England dwindled for several decades. A revived interest in opera occurred in the 1730s which is largely attributed to Thomas Arne, both for his own compositions and for alerting Handel to the commercial possibilities of large-scale works in English. Arne was the first English composer to experiment with Italian-style all-sung comic opera, with his greatest success being Thomas and Sally in 1760. His opera Artaxerxes (1762) was the first attempt to set a full-blown opera seria in English and was a huge success, holding the stage until the 1830s. Although Arne imitated many elements of Italian opera, he was perhaps the only English composer at that time who was able to move beyond the Italian influences and create his own unique and distinctly English voice. His modernized ballad opera, Love in a Village (1762), began a vogue for pastiche opera that lasted well into the 19th century. Charles Burney wrote that Arne introduced \"a light, airy, original, and pleasing melody, wholly different from that of Purcell or Handel, whom all English composers had either pillaged or imitated\".\n\nBesides Arne, the other dominating force in English opera at this time was George Frideric Handel, whose opera serias filled the London operatic stages for decades and influenced most home-grown composers, like John Frederick Lampe, who wrote using Italian models. This situation continued throughout the 18th and 19th centuries, including in the work of Michael William Balfe, and the operas of the great Italian composers, as well as those of Mozart, Beethoven, and Meyerbeer, continued to dominate the musical stage in England.\n\nThe only exceptions were ballad operas, such as John Gay's The Beggar's Opera (1728), musical burlesques, European operettas, and late Victorian era light operas, notably the Savoy Operas of W. S. Gilbert and Arthur Sullivan, all of which types of musical entertainments frequently spoofed operatic conventions. Sullivan wrote only one grand opera, Ivanhoe (following the efforts of a number of young English composers beginning about 1876), but he claimed that even his light operas constituted part of a school of \"English\" opera, intended to supplant the French operettas (usually performed in bad translations) that had dominated the London stage from the mid-19th century into the 1870s. London's Daily Telegraph agreed, describing The Yeomen of the Guard as \"a genuine English opera, forerunner of many others, let us hope, and possibly significant of an advance towards a national lyric stage\". Sullivan produced a few light operas in the 1890s that were of a more serious nature than those in the G&S series, including Haddon Hall and The Beauty Stone, but Ivanhoe (which ran for 155 consecutive performances, using alternating casts\u2014a record until Broadway's La boh\u00e8me) survives as his only grand opera.\n\nIn the 20th century, English opera began to assert more independence, with works of Ralph Vaughan Williams and in particular Benjamin Britten, who in a series of works that remain in standard repertory today, revealed an excellent flair for the dramatic and superb musicality. More recently Sir Harrison Birtwistle has emerged as one of Britain's most significant contemporary composers from his first opera Punch and Judy to his most recent critical success in The Minotaur. In the first decade of the 21st century, the librettist of an early Birtwistle opera, Michael Nyman, has been focusing on composing operas, including Facing Goya, Man and Boy: Dada, and Love Counts. Today composers such as Thomas Ad\u00e8s continue to export English opera abroad.\n\nAlso in the 20th century, American composers like George Gershwin (Porgy and Bess), Scott Joplin (Treemonisha), Leonard Bernstein (Candide), Gian Carlo Menotti, Douglas Moore, and Carlisle Floyd began to contribute English-language operas infused with touches of popular musical styles. They were followed by composers such as Philip Glass (Einstein on the Beach), Mark Adamo, John Corigliano (The Ghosts of Versailles), Robert Moran, John Adams (Nixon in China), Andr\u00e9 Previn and Jake Heggie. Many contemporary 21st century opera composers have emerged such as Missy Mazzoli, Kevin Puts, Tom Cipullo, Huang Ruo, David T. Little, Terence Blanchard, Jennifer Higdon, Tobias Picker, Michael Ching, and Ricky Ian Gordon.\n\nRussian opera\n\nOpera was brought to Russia in the 1730s by the Italian operatic troupes and soon it became an important part of entertainment for the Russian Imperial Court and aristocracy. Many foreign composers such as Baldassare Galuppi, Giovanni Paisiello, Giuseppe Sarti, and Domenico Cimarosa (as well as various others) were invited to Russia to compose new operas, mostly in the Italian language. Simultaneously some domestic musicians like Maksym Berezovsky and Dmitry Bortniansky were sent abroad to learn to write operas. The first opera written in Russian was Tsefal i Prokris by the Italian composer Francesco Araja (1755). The development of Russian-language opera was supported by the Russian composers Vasily Pashkevich, Yevstigney Fomin and Alexey Verstovsky.\n\nHowever, the real birth of Russian opera came with Mikhail Glinka and his two great operas A Life for the Tsar (1836) and Ruslan and Lyudmila (1842). After him, during the 19th century in Russia, there were written such operatic masterpieces as Rusalka and The Stone Guest by Alexander Dargomyzhsky, Boris Godunov and Khovanshchina by Modest Mussorgsky, Prince Igor by Alexander Borodin, Eugene Onegin and The Queen of Spades by Pyotr Tchaikovsky, and The Snow Maiden and Sadko by Nikolai Rimsky-Korsakov. These developments mirrored the growth of Russian nationalism across the artistic spectrum, as part of the more general Slavophilism movement.\n\nIn the 20th century, the traditions of Russian opera were developed by many composers including Sergei Rachmaninoff in his works The Miserly Knight and Francesca da Rimini, Igor Stravinsky in Le Rossignol, Mavra, Oedipus rex, and The Rake's Progress, Sergei Prokofiev in The Gambler, The Love for Three Oranges, The Fiery Angel, Betrothal in a Monastery, and War and Peace; as well as Dmitri Shostakovich in The Nose and Lady Macbeth of the Mtsensk District, Edison Denisov in L'\u00e9cume des jours, and Alfred Schnittke in Life with an Idiot and Historia von D. Johann Fausten.\n\nCzech opera \nCzech composers also developed a thriving national opera movement of their own in the 19th century, starting with Bed\u0159ich Smetana, who wrote eight operas including the internationally popular The Bartered Bride. Smetana's eight operas created the bedrock of the Czech opera repertory, but of these only The Bartered Bride is performed regularly outside the composer's homeland. After reaching Vienna in 1892 and London in 1895 it rapidly became part of the repertory of every major opera company worldwide.\n\nAnton\u00edn Dvo\u0159\u00e1k's nine operas, except his first, have librettos in Czech and were intended to convey the Czech national spirit, as were some of his choral works. By far the most successful of the operas is Rusalka which contains the well-known aria \"M\u011bs\u00ed\u010dku na nebi hlubok\u00e9m\" (\"Song to the Moon\"); it is played on contemporary opera stages frequently outside the Czech Republic. This is attributable to their uneven invention and libretti, and perhaps also their staging requirements \u2013 The Jacobin, Armida, Vanda and Dimitrij need stages large enough to portray invading armies.\n\nLeo\u0161 Jan\u00e1\u010dek gained international recognition in the 20th century for his innovative works. His later, mature works incorporate his earlier studies of national folk music in a modern, highly original synthesis, first evident in the opera Jen\u016ffa, which was premiered in 1904 in Brno. The success of Jen\u016ffa (often called the \"Moravian national opera\") at Prague in 1916 gave Jan\u00e1\u010dek access to the world's great opera stages. Jan\u00e1\u010dek's later works are his most celebrated. They include operas such as K\u00e1\u0165a Kabanov\u00e1 and The Cunning Little Vixen, the Sinfonietta and the Glagolitic Mass.\n\nOther national operas\nSpain also produced its own distinctive form of opera, known as zarzuela, which had two separate flowerings: one from the mid-17th century through the mid-18th century, and another beginning around 1850. During the late 18th century up until the mid-19th century, Italian opera was immensely popular in Spain, supplanting the native form.\n\nIn Russian Eastern Europe, several national operas began to emerge. Ukrainian opera was developed by Semen Hulak-Artemovsky (1813\u20131873) whose most famous work Zaporozhets za Dunayem (A Cossack Beyond the Danube) is regularly performed around the world. Other Ukrainian opera composers include Mykola Lysenko (Taras Bulba and Natalka Poltavka), Heorhiy Maiboroda, and Yuliy Meitus. At the turn of the century, a distinct national opera movement also began to emerge in Georgia under the leadership Zacharia Paliashvili, who fused local folk songs and stories with 19th-century Romantic classical themes.\n\nThe key figure of Hungarian national opera in the 19th century was Ferenc Erkel, whose works mostly dealt with historical themes. Among his most often performed operas are Hunyadi L\u00e1szl\u00f3 and B\u00e1nk b\u00e1n. The most famous modern Hungarian opera is B\u00e9la Bart\u00f3k's Duke Bluebeard's Castle.\n\nStanis\u0142aw Moniuszko's opera Straszny Dw\u00f3r (in English The Haunted Manor) (1861\u201364) represents a nineteenth-century peak of Polish national opera. In the 20th century, other operas created by Polish composers included King Roger by Karol Szymanowski and Ubu Rex by Krzysztof Penderecki.\n\nThe first known opera from Turkey (the Ottoman Empire) was Arshak II, which was an Armenian opera composed by an ethnic Armenian composer Tigran Chukhajian in 1868 and partially performed in 1873. It was fully staged in 1945 in Armenia.\n\nThe first years of the Soviet Union saw the emergence of new national operas, such as the Koro\u011flu (1937) by the Azerbaijani composer Uzeyir Hajibeyov. The first Kyrgyz opera, Ai-Churek, premiered in Moscow at the Bolshoi Theatre on 26 May 1939, during Kyrgyz Art Decade. It was composed by Vladimir Vlasov, Abdylas Maldybaev and Vladimir Fere. The libretto was written by Joomart Bokonbaev, Jusup Turusbekov, and Kybanychbek Malikov. The opera is based on the Kyrgyz heroic epic Manas.\n\nIn Iran, opera gained more attention after the introduction of Western classical music in the late 19th century. However, it took until mid 20th century for Iranian composers to start experiencing with the field, especially as the construction of the Roudaki Hall in 1967, made possible staging of a large variety of works for stage. Perhaps, the most famous Iranian opera is Rostam and Sohrab by Loris Tjeknavorian premiered not until the early 2000s.\n\nChinese contemporary classical opera, a Chinese language form of Western style opera that is distinct from traditional Chinese opera, has had operas dating back to The White Haired Girl in 1945.\n\nIn Latin America, opera started as a result of European colonisation. The first opera ever written in the Americas was La p\u00farpura de la rosa, by Tom\u00e1s de Torrej\u00f3n y Velasco, although Partenope, by the Mexican Manuel de Zumaya, was the first opera written from a composer born in Latin America (music now lost). The first Brazilian opera for a libretto in Portuguese was A Noite de S\u00e3o Jo\u00e3o, by Elias \u00c1lvares Lobo. However, Ant\u00f4nio Carlos Gomes is generally regarded as the most outstanding Brazilian composer, having a relative success in Italy with its Brazilian-themed operas with Italian librettos, such as Il Guarany. Opera in Argentina developed in the 20th century after the inauguration of Teatro Col\u00f3n in Buenos Aires\u2014with the opera Aurora, by Ettore Panizza, being heavily influenced by the Italian tradition, due to immigration. Other important composers from Argentina include Felipe Boero and Alberto Ginastera.\n\nContemporary, recent, and modernist trends\n\nModernism\nPerhaps the most obvious stylistic manifestation of modernism in opera is the development of atonality. The move away from traditional tonality in opera had begun with Richard Wagner, and in particular the Tristan chord. Composers such as Richard Strauss, Claude Debussy, Giacomo Puccini, Paul Hindemith, Benjamin Britten and Hans Pfitzner pushed Wagnerian harmony further with a more extreme use of chromaticism and greater use of dissonance. Another aspect of modernist opera is the shift away from long, suspended melodies, to short quick mottos, as first illustrated by Giuseppe Verdi in his Falstaff. Composers such as Strauss, Britten, Shostakovich and Stravinsky adopted and expanded upon this style.\n\nOperatic modernism truly began in the operas of two Viennese composers, Arnold Schoenberg and his student Alban Berg, both composers and advocates of atonality and its later development (as worked out by Schoenberg), dodecaphony. Schoenberg's early musico-dramatic works, Erwartung (1909, premiered in 1924) and Die gl\u00fcckliche Hand display heavy use of chromatic harmony and dissonance in general. Schoenberg also occasionally used Sprechstimme.\n\nThe two operas of Schoenberg's pupil Alban Berg, Wozzeck (1925) and Lulu (incomplete at his death in 1935) share many of the same characteristics as described above, though Berg combined his highly personal interpretation of Schoenberg's twelve-tone technique with melodic passages of a more traditionally tonal nature (quite Mahlerian in character) which perhaps partially explains why his operas have remained in standard repertory, despite their controversial music and plots. Schoenberg's theories have influenced (either directly or indirectly) significant numbers of opera composers ever since, even if they themselves did not compose using his techniques.\n\nComposers thus influenced include the Englishman Benjamin Britten, the German Hans Werner Henze, and the Russian Dmitri Shostakovich. (Philip Glass also makes use of atonality, though his style is generally described as minimalist, usually thought of as another 20th-century development.)\n\nHowever, operatic modernism's use of atonality also sparked a backlash in the form of neoclassicism. An early leader of this movement was Ferruccio Busoni, who in 1913 wrote the libretto for his neoclassical number opera Arlecchino (first performed in 1917). Also among the vanguard was the Russian Igor Stravinsky. After composing music for the Diaghilev-produced ballets Petrushka (1911) and The Rite of Spring (1913), Stravinsky turned to neoclassicism, a development culminating in his opera-oratorio Oedipus Rex (1927).  Stravinsky had already turned away from the modernist trends of his early ballets to produce small-scale works that do not fully qualify as opera, yet certainly contain many operatic elements, including Renard (1916: \"a burlesque in song and dance\") and The Soldier's Tale (1918: \"to be read, played, and danced\"; in both cases the descriptions and instructions are those of the composer). In the latter, the actors declaim portions of speech to a specified rhythm over instrumental accompaniment, peculiarly similar to the older German genre of Melodrama.  Well after his Rimsky-Korsakov-inspired works The Nightingale (1914), and Mavra (1922), Stravinsky continued to ignore serialist technique and eventually wrote a full-fledged 18th-century-style diatonic number opera The Rake's Progress (1951). His resistance to serialism (an attitude he reversed following Schoenberg's death) proved to be an inspiration for many other composers.\n\nOther trends\nA common trend throughout the 20th century, in both opera and general orchestral repertoire, is the use of smaller orchestras as a cost-cutting measure; the grand Romantic-era orchestras with huge string sections, multiple harps, extra horns, and exotic percussion instruments were no longer feasible. As government and private patronage of the arts decreased throughout the 20th century, new works were often commissioned and performed with smaller budgets, very often resulting in chamber-sized works, and short, one-act operas. Many of Benjamin Britten's operas are scored for as few as 13 instrumentalists; Mark Adamo's two-act realization of Little Women is scored for 18 instrumentalists.\n\nAnother feature of late 20th-century opera is the emergence of contemporary historical operas, in contrast to the tradition of basing operas on more distant history, the re-telling of contemporary fictional stories or plays, or on myth or legend. The Death of Klinghoffer, Nixon in China, and Doctor Atomic by John Adams, Dead Man Walking by Jake Heggie, and Anna Nicole by Mark-Anthony Turnage exemplify the dramatisation onstage of events in recent living memory, where characters portrayed in the opera were alive at the time of the premiere performance.\n\nThe Metropolitan Opera in the US (often known as the Met) reported in 2011 that the average age of its audience was 60. Many opera companies  attempted to attract a younger audience to halt the larger trend of greying audiences for classical music since the last decades of the 20th century. Efforts resulted in lowering the average age of the Met's audience to 58 in 2018, the average age at Berlin State Opera was reported as 54, and Paris Opera reported an average age of 48.\n\nSmaller companies in the US have a more fragile existence, and they usually depend on a \"patchwork quilt\" of support from state and local governments, local businesses, and fundraisers. Nevertheless, some smaller companies have found ways of drawing new audiences. In addition to radio and television broadcasts of opera performances, which have had some success in gaining new audiences, broadcasts of live performances to movie theatres have shown the potential to reach new audiences.\n\nFrom musicals back towards opera\nBy the late 1930s, some musicals began to be written with a more operatic structure. These works include complex polyphonic ensembles and reflect musical developments of their times. Porgy and Bess (1935), influenced by jazz styles, and Candide (1956), with its sweeping, lyrical passages and farcical parodies of opera, both opened on Broadway but became accepted as part of the opera repertory. Popular musicals such as Show Boat, West Side Story, Brigadoon, Sweeney Todd, Passion, Evita, The Light in the Piazza, The Phantom of the Opera and others tell dramatic stories through complex music and in the 2010s they are sometimes seen in opera houses. The Most Happy Fella (1952) is quasi-operatic and has been revived by the New York City Opera. Other rock-influenced musicals, such as Tommy (1969) and Jesus Christ Superstar (1971), Les Mis\u00e9rables (1980), Rent (1996), Spring Awakening (2006), and Natasha, Pierre & The Great Comet of 1812 (2012) employ various operatic conventions, such as through composition, recitative instead of dialogue, and leitmotifs.\n\nAcoustic enhancement in opera\nA subtle type of sound electronic reinforcement called acoustic enhancement is used in some modern concert halls and theatres where operas are performed. Although none of the major opera houses \"...use traditional, Broadway-style sound reinforcement, in which most if not all singers are equipped with radio microphones mixed to a series of unsightly loudspeakers scattered throughout the theatre\", many use a sound reinforcement system for acoustic enhancement and for subtle boosting of offstage voices, child singers, onstage dialogue, and sound effects (e.g., church bells in Tosca or thunder effects in Wagnerian operas).\n\nOperatic voices\nOperatic vocal technique evolved, in a time before electronic amplification, to allow singers to produce enough volume to be heard over an orchestra, without the instrumentalists having to substantially compromise their volume.\n\nVocal classifications\nSingers and the roles they play are classified by voice type, based on the tessitura, agility, power and timbre of their voices. Male singers can be classified by vocal range as bass, bass-baritone, baritone, baritenor, tenor and countertenor, and female singers as contralto, mezzo-soprano and soprano. (Men sometimes sing in the \"female\" vocal ranges, in which case they are termed sopranist or countertenor. The countertenor is commonly encountered in opera, sometimes singing parts written for castrati\u2014men neutered at a young age specifically to give them a higher singing range.) Singers are then further classified by size\u2014for instance, a soprano can be described as a lyric soprano, coloratura, soubrette, spinto, or dramatic soprano. These terms, although not fully describing a singing voice, associate the singer's voice with the roles most suitable to the singer's vocal characteristics.\n\nYet another sub-classification can be made according to acting skills or requirements, for example the basso buffo who often must be a specialist in patter as well as a comic actor. This is carried out in detail in the Fach system of German speaking countries, where historically opera and spoken drama were often put on by the same repertory company.\n\nA particular singer's voice may change drastically over his or her lifetime, rarely reaching vocal maturity until the third decade, and sometimes not until middle age. Two French voice types, premiere dugazon and deuxieme dugazon, were named after successive stages in the career of Louise-Rosalie Lefebvre (Mme. Dugazon). Other terms originating in the star casting system of the Parisian theatres are baryton-martin and soprano falcon.\n\nHistorical use of voice parts\nThe following is only intended as a brief overview. For the main articles, see soprano, mezzo-soprano, contralto, tenor, baritone, bass, countertenor and castrato.\n\nThe soprano voice has typically been used as the voice of choice for the female protagonist of the opera since the latter half of the 18th century. Earlier, it was common for that part to be sung by any female voice, or even a castrato. The current emphasis on a wide vocal range was primarily an invention of the Classical period. Before that, the vocal virtuosity, not range, was the priority, with soprano parts rarely extending above a high A (Handel, for example, only wrote one role extending to a high C), though the castrato Farinelli was alleged to possess a top D (his lower range was also extraordinary, extending to tenor C). The mezzo-soprano, a term of comparatively recent origin, also has a large repertoire, ranging from the female lead in Purcell's Dido and Aeneas to such heavyweight roles as Brang\u00e4ne in Wagner's Tristan und Isolde (these are both roles sometimes sung by sopranos; there is quite a lot of movement between these two voice-types). For the true contralto, the range of parts is more limited, which has given rise to the insider joke that contraltos only sing \"witches, bitches, and britches\" roles. In recent years many of the \"trouser roles\" from the Baroque era, originally written for women, and those originally sung by castrati, have been reassigned to countertenors.\n\nThe tenor voice, from the Classical era onwards, has traditionally been assigned the role of male protagonist. Many of the most challenging tenor roles in the repertory were written during the bel canto era, such as Donizetti's sequence of 9 Cs above middle C during La fille du r\u00e9giment. With Wagner came an emphasis on vocal heft for his protagonist roles, with this vocal category described as Heldentenor; this heroic voice had its more Italianate counterpart in such roles as Calaf in Puccini's Turandot. Basses have a long history in opera, having been used in opera seria in supporting roles, and sometimes for comic relief (as well as providing a contrast to the preponderance of high voices in this genre). The bass repertoire is wide and varied, stretching from the comedy of Leporello in Don Giovanni to the nobility of Wotan in Wagner's Ring Cycle, to the conflicted King Phillip of Verdi's Don Carlos. In between the bass and the tenor is the baritone, which also varies in weight from say, Guglielmo in Mozart's Cos\u00ec fan tutte to Posa in Verdi's Don Carlos; the actual designation \"baritone\" was not standard until the mid-19th century.\n\nFamous singers\n\nEarly performances of opera were too infrequent for singers to make a living exclusively from the style, but with the birth of commercial opera in the mid-17th century, professional performers began to emerge. The role of the male hero was usually entrusted to a castrato, and by the 18th century, when Italian opera was performed throughout Europe, leading castrati who possessed extraordinary vocal virtuosity, such as Senesino and Farinelli, became international stars. The career of the first major female star (or prima donna), Anna Renzi, dates to the mid-17th century. In the 18th century, a number of Italian sopranos gained international renown and often engaged in fierce rivalry, as was the case with Faustina Bordoni and Francesca Cuzzoni, who started a fistfight with one another during a performance of a Handel opera. The French disliked castrati, preferring their male heroes to be sung by an haute-contre (a high tenor), of which Joseph Legros (1739\u20131793) was a leading example.\n\nThough opera patronage has decreased in the last century in favor of other arts and media (such as musicals, cinema, radio, television and recordings), mass media and the advent of recording have supported the popularity of many famous singers including Maria Callas, Enrico Caruso, Amelita Galli-Curci, Kirsten Flagstad, Juan Arvizu, Nestor Mesta Chayres,Mario Del Monaco, Renata Tebaldi, Ris\u00eb Stevens, Alfredo Kraus, Franco Corelli, Montserrat Caball\u00e9, Joan Sutherland, Birgit Nilsson, Nellie Melba, Rosa Ponselle, Beniamino Gigli, Jussi Bj\u00f6rling, Feodor Chaliapin, Cecilia Bartoli, Ren\u00e9e Fleming, Marilyn Horne, Bryn Terfel, Dmitri Hvorostovsky and The Three Tenors (Luciano Pavarotti, Pl\u00e1cido Domingo, Jos\u00e9 Carreras).\n\nChanging role of the orchestra\nBefore the 1700s, Italian operas used a small string orchestra, but it rarely played to accompany the singers. Opera solos during this period were accompanied by the basso continuo group, which consisted of the harpsichord, \"plucked instruments\" such as lute and a bass instrument. The string orchestra typically only played when the singer was not singing, such as during a singer's \"...entrances and exits, between vocal numbers, [or] for [accompanying] dancing\". Another role for the orchestra during this period was playing an orchestral ritornello to mark the end of a singer's solo. During the early 1700s, some composers began to use the string orchestra to mark certain aria or recitatives \"...as special\"; by 1720, most arias were accompanied by an orchestra. Opera composers such as Domenico Sarro, Leonardo Vinci, Giambattista Pergolesi, Leonardo Leo, and Johann Adolf Hasse added new instruments to the opera orchestra and gave the instruments new roles. They added wind instruments to the strings and used orchestral instruments to play instrumental solos, as a way to mark certain arias as special.\n\nThe orchestra has also provided an instrumental overture before the singers come onstage since the 1600s. Peri's Euridice opens with a brief instrumental ritornello, and Monteverdi's L'Orfeo (1607) opens with a toccata, in this case a fanfare for muted trumpets. The French overture as found in Jean-Baptiste Lully's operas consist of a slow introduction in a marked \"dotted rhythm\", followed by a lively movement in fugato style. The overture was frequently followed by a series of dance tunes before the curtain rose. This overture style was also used in English opera, most notably in Henry Purcell's Dido and Aeneas. Handel also uses the French overture form in some of his Italian operas such as Giulio Cesare.\n\nIn Italy, a distinct form called \"overture\" arose in the 1680s, and became established particularly through the operas of Alessandro Scarlatti, and spread throughout Europe, supplanting the French form as the standard operatic overture by the mid-18th century. It uses three generally homophonic movements: fast\u2013slow\u2013fast. The opening movement was normally in duple metre and in a major key; the slow movement in earlier examples was short, and could be in a contrasting key; the concluding movement was dance-like, most often with rhythms of the gigue or minuet, and returned to the key of the opening section. As the form evolved, the first movement may incorporate fanfare-like elements and took on the pattern of so-called \"sonatina form\" (sonata form without a development section), and the slow section became more extended and lyrical.\n\nIn Italian opera after about 1800, the \"overture\" became known as the sinfonia. Fisher also notes the term Sinfonia avanti l'opera (literally, the \"symphony before the opera\") was \"an early term for a sinfonia used to begin an opera, that is, as an overture as opposed to one serving to begin a later section of the work\". In 19th-century opera, in some operas, the overture, Vorspiel, Einleitung, Introduction, or whatever else it may be called, was the portion of the music which takes place before the curtain rises; a specific, rigid form was no longer required for the overture.\n\nThe role of the orchestra in accompanying the singers changed over the 19th century, as the Classical style transitioned to the Romantic era. In general, orchestras got bigger, new instruments were added, such as additional percussion instruments (e.g., bass drum, cymbals, snare drum, etc.). The orchestration of orchestra parts also developed over the 19th century. In Wagnerian operas, the forefronting of the orchestra went beyond the overture. In Wagnerian operas such as the Ring Cycle, the orchestra often played the recurrent musical themes or leitmotifs, a role which gave a prominence to the orchestra which \"...elevated its status to that of a prima donna\". Wagner's operas were scored with unprecedented scope and complexity, adding more brass instruments and huge ensemble sizes: indeed, his score to Das Rheingold calls for six harps. In Wagner and the work of subsequent composers, such as Benjamin Britten, the orchestra \"often communicates facts about the story that exceed the levels of awareness of the characters therein.\" As a result, critics began to regard the orchestra as performing a role analogous to that of a literary narrator.\"\n\nAs the role of the orchestra and other instrumental ensembles changed over the history of opera, so did the role of leading the musicians. In the Baroque era, the musicians were usually directed by the harpsichord player, although the French composer Lully is known to have conducted with a long staff. In the 1800s, during the Classical period, the first violinist, also known as the concertmaster, would lead the orchestra while sitting. Over time, some directors began to stand up and use hand and arm gestures to lead the performers. Eventually this role of music director became termed the conductor, and a podium was used to make it easier for all the musicians to see him or her. By the time Wagnerian operas were introduced, the complexity of the works and the huge orchestras used to play them gave the conductor an increasingly important role. Modern opera conductors have a challenging role: they have to direct both the orchestra in the orchestra pit and the singers on stage.\n\nLanguage and translation issues\nSince the days of Handel and Mozart, many composers have favored Italian as the language for the libretto of their operas. From the Bel Canto era to Verdi, composers would sometimes supervise versions of their operas in both Italian and French. Because of this, operas such as Lucia di Lammermoor or Don Carlos are today deemed canonical in both their French and Italian versions.\n\nUntil the mid-1950s, it was acceptable to produce operas in translations even if these had not been authorized by the composer or the original librettists. For example, opera houses in Italy routinely staged Wagner in Italian. After World War II, opera scholarship improved, artists refocused on the original versions, and translations fell out of favor. Knowledge of European languages, especially Italian, French, and German, is today an important part of the training for professional singers. \"The biggest chunk of operatic training is in linguistics and musicianship\", explains mezzo-soprano Dolora Zajick. \"[I have to understand] not only what I'm singing, but what everyone else is singing. I sing Italian, Czech, Russian, French, German, English.\"\n\nIn the 1980s, supertitles (sometimes called surtitles) began to appear. Although supertitles were first almost universally condemned as a distraction, today many opera houses provide either supertitles, generally projected above the theatre's proscenium arch, or individual seat screens where spectators can choose from more than one language. TV broadcasts typically include subtitles even if intended for an audience who knows well the language (for example, a RAI broadcast of an Italian opera). These subtitles target not only the hard of hearing but the audience generally, since a sung discourse is much harder to understand than a spoken one\u2014even in the ears of native speakers. Subtitles in one or more languages have become standard in opera broadcasts, simulcasts, and DVD editions.\n\nToday, operas are only rarely performed in translation. Exceptions include the English National Opera, the Opera Theatre of Saint Louis, Opera Theater of Pittsburgh, and Opera South East, which favor English translations. Another exception are opera productions intended for a young audience, such as Humperdinck's Hansel and Gretel and some productions of Mozart's The Magic Flute.\n\nFunding\n\nOutside the US, and especially in Europe, most opera houses receive public subsidies from taxpayers. In Milan, Italy, 60% of La Scala's annual budget of \u20ac115\u00a0million is from ticket sales and private donations, with the remaining 40% coming from public funds. In 2005, La Scala received 25% of Italy's total state subsidy of \u20ac464\u00a0million for the performing arts. In the UK, Arts Council England provides funds to Opera North, the Royal Opera House, Welsh National Opera, and English National Opera. Between 2012 and 2015, these four opera companies along with the English National Ballet, Birmingham Royal Ballet and Northern Ballet accounted for 22% of the funds in the Arts Council's national portfolio. During that period, the Council undertook an analysis of its funding for large-scale opera and ballet companies, setting recommendations and targets for the companies to meet prior to the 2015\u20132018 funding decisions. In February 2015, concerns over English National Opera's business plan led to the Arts Council placing it \"under special funding arrangements\" in what The Independent termed \"the unprecedented step\" of threatening to withdraw public funding if the council's concerns were not met by 2017. European public funding to opera has led to a disparity between the number of year-round opera houses in Europe and the United States. For example, \"Germany has about 80 year-round opera houses [as of 2004], while the U.S., with more than three times the population, does not have any. Even the Met only has a seven-month season.\"\n\nTelevision, cinema and the Internet\n\nA milestone for opera broadcasting in the U.S. was achieved on 24 December 1951, with the live broadcast of Amahl and the Night Visitors, an opera in one act by Gian Carlo Menotti. It was the first opera specifically composed for television in America. Another milestone occurred in Italy in 1992 when Tosca was broadcast live from its original Roman settings and times of the day: the first act came from the 16th-century Church of Sant'Andrea della Valle at noon on Saturday; the 16th-century Palazzo Farnese was the setting for the second at 8:15 pm; and on Sunday at 6 am, the third act was broadcast from Castel Sant'Angelo. The production was transmitted via satellite to 105 countries.\n\nMajor opera companies have begun presenting their performances in local cinemas throughout the United States and many other countries. The Metropolitan Opera began a series of live high-definition video transmissions to cinemas around the world in 2006. In 2007, Met performances were shown in over 424 theaters in 350 U.S. cities. La boh\u00e8me went out to 671 screens worldwide. San Francisco Opera began prerecorded video transmissions in March 2008. As of June 2008, approximately 125 theaters in 117 U.S. cities carry the showings. The HD video opera transmissions are presented via the same HD digital cinema projectors used for major Hollywood films. European opera houses and festivals including the Royal Opera in London, La Scala in Milan, the Salzburg Festival, La Fenice in Venice, and the Maggio Musicale in Florence have also transmitted their productions to theaters in cities around the world since 2006, including 90 cities in the U.S.\n\nThe emergence of the Internet has also affected the way in which audiences consume opera. In 2009 the British Glyndebourne Festival Opera offered for the first time an online digital video download of its complete 2007 production of Tristan und Isolde. In the 2013 season, the festival streamed all six of its productions online. In July 2012, the first online community opera was premiered at the Savonlinna Opera Festival. Titled Free Will, it was created by members of the Internet group Opera By You. Its 400 members from 43 countries wrote the libretto, composed the music, and designed the sets and costumes using the Wreckamovie web platform. Savonlinna Opera Festival provided professional soloists, an 80-member choir, a symphony orchestra, and the stage machinery. It was performed live at the festival and streamed live on the internet.\n\nSee also\n\n Lists of operas, including a general list as well as by theme, by country, by medium, and by venue\n List of fictional literature featuring opera\n Opera management\n Opera length\n\nReferences\n\nNotes\n\nSources\n \n  See also Google Books partial preview.\n\nFurther reading\n The New Grove Dictionary of Opera, edited by Stanley Sadie (1992), 5,448 pages, is the best, and by far the largest, general reference in the English language. \n The Viking Opera Guide, edited by Amanda Holden (1994), 1,328 pages, \n The Oxford Illustrated History of Opera, ed. Roger Parker (1994)\n The Oxford Dictionary of Opera, by John Warrack and Ewan West (1992), 782 pages, \n Opera, the Rough Guide, by Matthew Boyden et al. (1997), 672 pages, \n Opera: A Concise History, by Leslie Orrey and Rodney Milnes, World of Art, Thames & Hudson\n \n DiGaetani, John Louis: An Invitation to the Opera, Anchor Books, 1986/91. .\n Dorschel, Andreas, 'The Paradox of Opera', The Cambridge Quarterly 30 (2001), no. 4, pp.\u00a0283\u2013306.  (print).  (electronic). Discusses the aesthetics of opera.\n Silke Leopold, \"The Idea of National Opera, c. 1800\", United and Diversity in European Culture c. 1800, ed. Tim Blanning and Hagen Schulze (New York: Oxford University Press, 2006), 19\u201334.\n MacMurray, Jessica M. and Allison Brewster Franzetti: The Book of 101 Opera Librettos: Complete Original Language Texts with English Translations, Black Dog & Leventhal Publishers, 1996. \n Howard Mayer Brown, \"Opera\", The New Grove Dictionary of Music and Musicians. 2001. Oxford University Press\n Rous, Samuel Holland (1919). The Victrola Book of the Opera. Stories of The Operas with Illustrations.... Camden, New Jersey: Victor Talking Machine Company. View at Internet Archive.\n Simon, Henry W.: A Treasury of Grand Opera, Simon and Schuster, New York, 1946.\n \"Opera\", Herbert Weinstock and Barbara Russano Hanning, Encyclop\u00e6dia Britannica\n\nExternal links\n\nComprehensive opera performances database, Operabase\n StageAgent \u2013 synopses and character descriptions for most major operas\n What's it about? \u2013 Opera plot summaries\n Vocabulaire de l'Op\u00e9ra \n OperaGlass, a resource at Stanford University\n HistoricOpera \u2013 historic operatic images\n \"America's Opera Boom\" By Jonathan Leaf, The American, July/August 2007 Issue\n Opera~Opera article archives\n \n\n \n \nMusical forms\nItalian inventions\nDrama\nTheatre\nVocal music\nSinging",
  "Physics": "Physics is the natural science that studies matter, its fundamental constituents, its motion and behavior through space and time, and the related entities of energy and force. Physics is one of the most fundamental scientific disciplines, and its main goal is to understand how the universe behaves.\n\nPhysics is one of the oldest academic disciplines and, through its inclusion of astronomy, perhaps the oldest. Over much of the past two millennia, physics, chemistry, biology, and certain branches of mathematics were a part of natural philosophy, but during the Scientific Revolution in the 17th century these natural sciences emerged as unique research endeavors in their own right. Physics intersects with many interdisciplinary areas of research, such as biophysics and quantum chemistry, and the boundaries of physics are not rigidly defined. New ideas in physics often explain the fundamental mechanisms studied by other sciences and suggest new avenues of research in academic disciplines such as mathematics and philosophy.\n\nAdvances in physics often enable advances in new technologies. For example, advances in the understanding of electromagnetism, solid-state physics, and nuclear physics led directly to the development of new products that have dramatically transformed modern-day society, such as television, computers, domestic appliances, and nuclear weapons; advances in thermodynamics led to the development of industrialization; and advances in mechanics inspired the development of calculus.\n\nHistory\n\nThe word \"physics\" comes from , meaning \"knowledge of nature\".\n\nAncient astronomy \n\nAstronomy is one of the oldest natural sciences. Early civilizations dating back before 3000\u00a0BCE, such as the Sumerians, ancient Egyptians, and the Indus Valley Civilisation, had a predictive knowledge and a basic awareness of the motions of the Sun, Moon, and stars. The stars and planets, believed to represent gods, were often worshipped. While the explanations for the observed positions of the stars were often unscientific and lacking in evidence, these early observations laid the foundation for later astronomy, as the stars were found to traverse great circles across the sky, which however did not explain the positions of the planets.\n\nAccording to Asger Aaboe, the origins of Western astronomy can be found in Mesopotamia, and all Western efforts in the exact sciences are descended from late Babylonian astronomy. Egyptian astronomers left monuments showing knowledge of the constellations and the motions of the celestial bodies, while Greek poet Homer wrote of various celestial objects in his Iliad and Odyssey; later Greek astronomers provided names, which are still used today, for most constellations visible from the Northern Hemisphere.\n\nNatural philosophy \n\nNatural philosophy has its origins in Greece during the Archaic period (650 BCE \u2013 480 BCE), when pre-Socratic philosophers like Thales rejected non-naturalistic explanations for natural phenomena and proclaimed that every event had a natural cause. They proposed ideas verified by reason and observation, and many of their hypotheses proved successful in experiment; for example, atomism was found to be correct approximately 2000 years after it was proposed by Leucippus and his pupil Democritus.\n\nMedieval European and Islamic \n\nThe Western Roman Empire fell in the fifth century, and this resulted in a decline in intellectual pursuits in the western part of Europe. By contrast, the Eastern Roman Empire (also known as the Byzantine Empire) resisted the attacks from the barbarians, and continued to advance various fields of learning, including physics.\n\nIn the sixth century, Isidore of Miletus created an important compilation of Archimedes' works that are copied in the Archimedes Palimpsest.\n\nIn sixth-century Europe John Philoponus, a Byzantine scholar, questioned Aristotle's teaching of physics and noted its flaws. He introduced the theory of impetus. Aristotle's physics was not scrutinized until Philoponus appeared; unlike Aristotle, who based his physics on verbal argument, Philoponus relied on observation. On Aristotle's physics Philoponus wrote:But this is completely erroneous, and our view may be corroborated by actual observation more effectively than by any sort of verbal argument. For if you let fall from the same height two weights of which one is many times as heavy as the other, you will see that the ratio of the times required for the motion does not depend on the ratio of the weights, but that the difference in time is a very small one. And so, if the difference in the weights is not considerable, that is, of one is, let us say, double the other, there will be no difference, or else an imperceptible difference, in time, though the difference in weight is by no means negligible, with one body weighing twice as much as the otherPhiloponus' criticism of Aristotelian principles of physics served as an inspiration for Galileo Galilei ten centuries later, during the Scientific Revolution. Galileo cited Philoponus substantially in his works when arguing that Aristotelian physics was flawed. In the 1300s Jean Buridan, a teacher in the faculty of arts at the University of Paris, developed the concept of impetus. It was a step toward the modern ideas of inertia and momentum.\n\nIslamic scholarship inherited Aristotelian physics from the Greeks and during the Islamic Golden Age developed it further, especially placing emphasis on observation and a priori reasoning, developing early forms of the scientific method.\n\nThe most notable innovations were in the field of optics and vision, which came from the works of many scientists like Ibn Sahl, Al-Kindi, Ibn al-Haytham, Al-Farisi and Avicenna. The most notable work was The Book of Optics (also known as Kit\u0101b al-Man\u0101\u1e93ir), written by Ibn al-Haytham, in which he conclusively disproved the ancient Greek idea about vision, but also came up with a new theory. In the book, he presented a study of the phenomenon of the camera obscura (his thousand-year-old version of the pinhole camera) and delved further into the way the eye itself works. Using dissections and the knowledge of previous scholars, he was able to begin to explain how light enters the eye. He asserted that the light ray is focused, but the actual explanation of how light projected to the back of the eye had to wait until 1604. His Treatise on Light explained the camera obscura, hundreds of years before the modern development of photography.\n\nThe seven-volume Book of Optics (Kitab al-Manathir) hugely influenced thinking across disciplines from the theory of visual perception to the nature of perspective in medieval art, in both the East and the West, for more than 600 years. Many later European scholars and fellow polymaths, from Robert Grosseteste and Leonardo da Vinci to Ren\u00e9 Descartes, Johannes Kepler and Isaac Newton, were in his debt. Indeed, the influence of Ibn al-Haytham's Optics ranks alongside that of Newton's work of the same title, published 700 years later.\n\nThe translation of The Book of Optics had a huge impact on Europe. From it, later European scholars were able to build devices that replicated those Ibn al-Haytham had built, and understand the way light works. From this, important inventions such as eyeglasses, magnifying glasses, telescopes, and cameras were developed.\n\nClassical \n\nPhysics became a separate science when early modern Europeans used experimental and quantitative methods to discover what are now considered to be the laws of physics.\n\nMajor developments in this period include the replacement of the geocentric model of the Solar System with the heliocentric Copernican model, the laws governing the motion of planetary bodies (determined by Kepler between 1609 and 1619), Galileo's pioneering work on telescopes and observational astronomy in the 16th and 17th Centuries, and Newton's discovery and unification of the laws of motion and universal gravitation (that would come to bear his name). Newton also developed calculus, the mathematical study of change, which provided new mathematical methods for solving physical problems.\n\nThe discovery of new laws in thermodynamics, chemistry, and electromagnetics resulted from greater research efforts during the Industrial Revolution as energy needs increased. The laws comprising classical physics remain very widely used for objects on everyday scales travelling at non-relativistic speeds, since they provide a very close approximation in such situations, and theories such as quantum mechanics and the theory of relativity simplify to their classical equivalents at such scales. However, inaccuracies in classical mechanics for very small objects and very high velocities led to the development of modern physics in the 20th century.\n\nModern \n\nModern physics began in the early 20th century with the work of Max Planck in quantum theory and Albert Einstein's theory of relativity. Both of these theories came about due to inaccuracies in classical mechanics in certain situations. Classical mechanics predicted a varying speed of light, which could not be resolved with the constant speed predicted by Maxwell's equations of electromagnetism; this discrepancy was corrected by Einstein's theory of special relativity, which replaced classical mechanics for fast-moving bodies and allowed for a constant speed of light. Black-body radiation provided another problem for classical physics, which was corrected when Planck proposed that the excitation of material oscillators is possible only in discrete steps proportional to their frequency; this, along with the photoelectric effect and a complete theory predicting discrete energy levels of electron orbitals, led to the theory of quantum mechanics taking over from classical physics at very small scales.\n\nQuantum mechanics would come to be pioneered by Werner Heisenberg, Erwin Schr\u00f6dinger and Paul Dirac. From this early work, and work in related fields, the Standard Model of particle physics was derived. Following the discovery of a particle with properties consistent with the Higgs boson at CERN in 2012, all fundamental particles predicted by the standard model, and no others, appear to exist; however, physics beyond the Standard Model, with theories such as supersymmetry, is an active area of research. Areas of mathematics in general are important to this field, such as the study of probabilities and groups.\n\nPhilosophy\n\nIn many ways, physics stems from ancient Greek philosophy. From Thales' first attempt to characterize matter, to Democritus' deduction that matter ought to reduce to an invariant state, the Ptolemaic astronomy of a crystalline firmament, and Aristotle's book Physics (an early book on physics, which attempted to analyze and define motion from a philosophical point of view), various Greek philosophers advanced their own theories of nature. Physics was known as natural philosophy until the late 18th century.\n\nBy the 19th century, physics was realized as a discipline distinct from philosophy and the other sciences. Physics, as with the rest of science, relies on philosophy of science and its \"scientific method\" to advance our knowledge of the physical world. The scientific method employs a priori reasoning as well as a posteriori reasoning and the use of Bayesian inference to measure the validity of a given theory.\n\nThe development of physics has answered many questions of early philosophers, but has also raised new questions. Study of the philosophical issues surrounding physics, the philosophy of physics, involves issues such as the nature of space and time, determinism, and metaphysical outlooks such as empiricism, naturalism and realism.\n\nMany physicists have written about the philosophical implications of their work, for instance Laplace, who championed causal determinism, and Schr\u00f6dinger, who wrote on quantum mechanics. The mathematical physicist Roger Penrose had been called a Platonist by Stephen Hawking, a view Penrose discusses in his book, The Road to Reality. Hawking referred to himself as an \"unashamed reductionist\" and took issue with Penrose's views.\n\nCore theories\n\nThough physics deals with a wide variety of systems, certain theories are used by all physicists. Each of these theories was experimentally tested numerous times and found to be an adequate approximation of nature. For instance, the theory of classical mechanics accurately describes the motion of objects, provided they are much larger than atoms and moving at much less than the speed of light. These theories continue to be areas of active research today. Chaos theory, a remarkable aspect of classical mechanics, was discovered in the 20th century, three centuries after the original formulation of classical mechanics by Newton (1642\u20131727).\n\nThese central theories are important tools for research into more specialised topics, and any physicist, regardless of their specialisation, is expected to be literate in them. These include classical mechanics, quantum mechanics, thermodynamics and statistical mechanics, electromagnetism, and special relativity.\n\nClassical\n\nClassical physics includes the traditional branches and topics that were recognised and well-developed before the beginning of the 20th century\u2014classical mechanics, acoustics, optics, thermodynamics, and electromagnetism. Classical mechanics is concerned with bodies acted on by forces and bodies in motion and may be divided into statics (study of the forces on a body or bodies not subject to an acceleration), kinematics (study of motion without regard to its causes), and dynamics (study of motion and the forces that affect it); mechanics may also be divided into solid mechanics and fluid mechanics (known together as continuum mechanics), the latter include such branches as hydrostatics, hydrodynamics, aerodynamics, and pneumatics. Acoustics is the study of how sound is produced, controlled, transmitted and received.  Important modern branches of acoustics include ultrasonics, the study of sound waves of very high frequency beyond the range of human hearing; bioacoustics, the physics of animal calls and hearing, and electroacoustics, the manipulation of audible sound waves using electronics.\n\nOptics, the study of light, is concerned not only with visible light but also with infrared and ultraviolet radiation, which exhibit all of the phenomena of visible light except visibility, e.g., reflection, refraction, interference, diffraction, dispersion, and polarization of light. Heat is a form of energy, the internal energy possessed by the particles of which a substance is composed; thermodynamics deals with the relationships between heat and other forms of energy. Electricity and magnetism have been studied as a single branch of physics since the intimate connection between them was discovered in the early 19th century; an electric current gives rise to a magnetic field, and a changing magnetic field induces an electric current. Electrostatics deals with electric charges at rest, electrodynamics with moving charges, and magnetostatics with magnetic poles at rest.\n\nModern\n\nClassical physics is generally concerned with matter and energy on the normal scale of observation, while much of modern physics is concerned with the behavior of matter and energy under extreme conditions or on a very large or very small scale. For example, atomic and nuclear physics study matter on the smallest scale at which chemical elements can be identified. The physics of elementary particles is on an even smaller scale since it is concerned with the most basic units of matter; this branch of physics is also known as high-energy physics because of the extremely high energies necessary to produce many types of particles in particle accelerators. On this scale, ordinary, commonsensical notions of space, time, matter, and energy are no longer valid.\n\nThe two chief theories of modern physics present a different picture of the concepts of space, time, and matter from that presented by classical physics. Classical mechanics approximates nature as continuous, while quantum theory is concerned with the discrete nature of many phenomena at the atomic and subatomic level and with the complementary aspects of particles and waves in the description of such phenomena. The theory of relativity is concerned with the description of phenomena that take place in a frame of reference that is in motion with respect to an observer; the special theory of relativity is concerned with motion in the absence of gravitational fields and the general theory of relativity with motion and its connection with gravitation. Both quantum theory and the theory of relativity find applications in all areas of modern physics.\n\nFundamental concepts in modern physics \n Causality\n Covariance\n Action\n Physical field\n Symmetry\n Physical interaction\n Statistical ensemble\n Quantum\n Wave\n Particle\n\nDifference\n\nWhile physics aims to discover universal laws, its theories lie in explicit domains of applicability.\n\nLoosely speaking, the laws of classical physics accurately describe systems whose important length scales are greater than the atomic scale and whose motions are much slower than the speed of light. Outside of this domain, observations do not match predictions provided by classical mechanics. Einstein contributed the framework of special relativity, which replaced notions of absolute time and space with spacetime and allowed an accurate description of systems whose components have speeds approaching the speed of light. Planck, Schr\u00f6dinger, and others introduced quantum mechanics, a probabilistic notion of particles and interactions that allowed an accurate description of atomic and subatomic scales. Later, quantum field theory unified quantum mechanics and special relativity. General relativity allowed for a dynamical, curved spacetime, with which highly massive systems and the large-scale structure of the universe can be well-described. General relativity has not yet been unified with the other fundamental descriptions; several candidate theories of quantum gravity are being developed.\n\nRelation to other fields\n\nPrerequisites\nMathematics provides a compact and exact language used to describe the order in nature. This was noted and advocated by Pythagoras, Plato, Galileo, and Newton.\n\nPhysics uses mathematics to organise and formulate experimental results. From those results, precise or estimated solutions are obtained, or quantitative results, from which new predictions can be made and experimentally confirmed or negated. The results from physics experiments are numerical data, with their units of measure and estimates of the errors in the measurements. Technologies based on mathematics, like computation have made computational physics an active area of research.\n\nOntology is a prerequisite for physics, but not for mathematics. It means physics is ultimately concerned with descriptions of the real world, while mathematics is concerned with abstract patterns, even beyond the real world. Thus physics statements are synthetic, while mathematical statements are analytic. Mathematics contains hypotheses, while physics contains theories. Mathematics statements have to be only logically true, while predictions of physics statements must match observed and experimental data.\n\nThe distinction is clear-cut, but not always obvious. For example, mathematical physics is the application of mathematics in physics. Its methods are mathematical, but its subject is physical. The problems in this field start with a \"mathematical model of a physical situation\" (system) and a \"mathematical description of a physical law\" that will be applied to that system. Every mathematical statement used for solving has a hard-to-find physical meaning. The final mathematical solution has an easier-to-find meaning, because it is what the solver is looking for.\n\nPure physics is a branch of fundamental science (also called basic science). Physics is also called \"the fundamental science\" because all branches of natural science like chemistry, astronomy, geology, and biology are constrained by laws of physics. Similarly, chemistry is often called the central science because of its role in linking the physical sciences. For example, chemistry studies properties, structures, and reactions of matter (chemistry's focus on the molecular and atomic scale distinguishes it from physics). Structures are formed because particles exert electrical forces on each other, properties include physical characteristics of given substances, and reactions are bound by laws of physics, like conservation of energy, mass, and charge. Physics is applied in industries like engineering and medicine.\n\nApplication and influence\n\nApplied physics is a general term for physics research, which is intended for a particular use. An applied physics curriculum usually contains a few classes in an applied discipline, like geology or electrical engineering. It usually differs from engineering in that an applied physicist may not be designing something in particular, but rather is using physics or conducting physics research with the aim of developing new technologies or solving a problem.\n\nThe approach is similar to that of applied mathematics. Applied physicists use physics in scientific research. For instance, people working on accelerator physics might seek to build better particle detectors for research in theoretical physics.\n\nPhysics is used heavily in engineering. For example, statics, a subfield of mechanics, is used in the building of bridges and other static structures. The understanding and use of acoustics results in sound control and better concert halls; similarly, the use of optics creates better optical devices. An understanding of physics makes for more realistic flight simulators, video games, and movies, and is often critical in forensic investigations.\n\nWith the standard consensus that the laws of physics are universal and do not change with time, physics can be used to study things that would ordinarily be mired in uncertainty. For example, in the study of the origin of the earth, one can reasonably model earth's mass, temperature, and rate of rotation, as a function of time allowing one to extrapolate forward or backward in time and so predict future or prior events. It also allows for simulations in engineering that drastically speed up the development of a new technology.\n\nBut there is also considerable interdisciplinarity, so many other important fields are influenced by physics (e.g., the fields of econophysics and sociophysics).\n\nResearch\n\nScientific method\nPhysicists use the scientific method to test the validity of a physical theory. By using a methodical approach to compare the implications of a theory with the conclusions drawn from its related experiments and observations, physicists are better able to test the validity of a theory in a logical, unbiased, and repeatable way. To that end, experiments are performed and observations are made in order to determine the validity or invalidity of the theory.\n\nA scientific law is a concise verbal or mathematical statement of a relation that expresses a fundamental principle of some theory, such as Newton's law of universal gravitation.\n\nTheory and experiment\n\nTheorists seek to develop mathematical models that both agree with existing experiments and successfully predict future experimental results, while experimentalists devise and perform experiments to test theoretical predictions and explore new phenomena. Although theory and experiment are developed separately, they strongly affect and depend upon each other. Progress in physics frequently comes about when experimental results defy explanation by existing theories, prompting intense focus on applicable modelling, and when new theories generate experimentally testable predictions, which inspire the development of new experiments (and often related equipment).\n\nPhysicists who work at the interplay of theory and experiment are called phenomenologists, who study complex phenomena observed in experiment and work to relate them to a fundamental theory.\n\nTheoretical physics has historically taken inspiration from philosophy; electromagnetism was unified this way. Beyond the known universe, the field of theoretical physics also deals with hypothetical issues, such as parallel universes, a multiverse, and higher dimensions. Theorists invoke these ideas in hopes of solving particular problems with existing theories; they then explore the consequences of these ideas and work toward making testable predictions.\n\nExperimental physics expands, and is expanded by, engineering and technology. Experimental physicists who are involved in basic research, design and perform experiments with equipment such as particle accelerators and lasers, whereas those involved in applied research often work in industry, developing technologies such as magnetic resonance imaging (MRI) and transistors. Feynman has noted that experimentalists may seek areas that have not been explored well by theorists.\n\nScope and aims\n\nPhysics covers a wide range of phenomena, from elementary particles (such as quarks, neutrinos, and electrons) to the largest superclusters of galaxies. Included in these phenomena are the most basic objects composing all other things. Therefore, physics is sometimes called the \"fundamental science\". Physics aims to describe the various phenomena that occur in nature in terms of simpler phenomena. Thus, physics aims to both connect the things observable to humans to root causes, and then connect these causes together.\n\nFor example, the ancient Chinese observed that certain rocks (lodestone and magnetite) were attracted to one another by an invisible force. This effect was later called magnetism, which was first rigorously studied in the 17th century. But even before the Chinese discovered magnetism, the ancient Greeks knew of other objects such as amber, that when rubbed with fur would cause a similar invisible attraction between the two. This was also first studied rigorously in the 17th century and came to be called electricity. Thus, physics had come to understand two observations of nature in terms of some root cause (electricity and magnetism). However, further work in the 19th century revealed that these two forces were just two different aspects of one force\u2014electromagnetism. This process of \"unifying\" forces continues today, and electromagnetism and the weak nuclear force are now considered to be two aspects of the electroweak interaction. Physics hopes to find an ultimate reason (theory of everything) for why nature is as it is (see section Current research below for more information).\n\nResearch fields\nContemporary research in physics can be broadly divided into nuclear and particle physics; condensed matter physics; atomic, molecular, and optical physics; astrophysics; and applied physics. Some physics departments also support physics education research and physics outreach.\n\nSince the 20th century, the individual fields of physics have become increasingly specialised, and today most physicists work in a single field for their entire careers. \"Universalists\" such as Einstein (1879\u20131955) and Lev Landau (1908\u20131968), who worked in multiple fields of physics, are now very rare.\n\nThe major fields of physics, along with their subfields and the theories and concepts they employ, are shown in the following table.\n\nNuclear and particle\n\nParticle physics is the study of the elementary constituents of matter and energy and the interactions between them. In addition, particle physicists design and develop the high-energy accelerators, detectors, and computer programs necessary for this research. The field is also called \"high-energy physics\" because many elementary particles do not occur naturally but are created only during high-energy collisions of other particles.\n\nCurrently, the interactions of elementary particles and fields are described by the Standard Model. The model accounts for the 12 known particles of matter (quarks and leptons) that interact via the strong, weak, and electromagnetic fundamental forces. Dynamics are described in terms of matter particles exchanging gauge bosons (gluons, W and Z bosons, and photons, respectively). The Standard Model also predicts a particle known as the Higgs boson. In July 2012 CERN, the European laboratory for particle physics, announced the detection of a particle consistent with the Higgs boson, an integral part of the Higgs mechanism.\n\nNuclear physics is the field of physics that studies the constituents and interactions of atomic nuclei. The most commonly known applications of nuclear physics are nuclear power generation and nuclear weapons technology, but the research has provided application in many fields, including those in nuclear medicine and magnetic resonance imaging, ion implantation in materials engineering, and radiocarbon dating in geology and archaeology.\n\nAtomic, molecular, and optical\n\nAtomic, molecular, and optical physics (AMO) is the study of matter\u2013matter and light\u2013matter interactions on the scale of single atoms and molecules. The three areas are grouped together because of their interrelationships, the similarity of methods used, and the commonality of their relevant energy scales. All three areas include both classical, semi-classical and quantum treatments; they can treat their subject from a microscopic view (in contrast to a macroscopic view).\n\nAtomic physics studies the electron shells of atoms. Current research focuses on activities in quantum control, cooling and trapping of atoms and ions, low-temperature collision dynamics and the effects of electron correlation on structure and dynamics. Atomic physics is influenced by the nucleus (see hyperfine splitting), but intra-nuclear phenomena such as fission and fusion are considered part of nuclear physics.\n\nMolecular physics focuses on multi-atomic structures and their internal and external interactions with matter and light. Optical physics is distinct from optics in that it tends to focus not on the control of classical light fields by macroscopic objects but on the fundamental properties of optical fields and their interactions with matter in the microscopic realm.\n\nCondensed matter\n\nCondensed matter physics is the field of physics that deals with the macroscopic physical properties of matter. In particular, it is concerned with the \"condensed\" phases that appear whenever the number of particles in a system is extremely large and the interactions between them are strong.\n\nThe most familiar examples of condensed phases are solids and liquids, which arise from the bonding by way of the electromagnetic force between atoms. More exotic condensed phases include the superfluid and the Bose\u2013Einstein condensate found in certain atomic systems at very low temperature, the superconducting phase exhibited by conduction electrons in certain materials, and the ferromagnetic and antiferromagnetic phases of spins on atomic lattices.\n\nCondensed matter physics is the largest field of contemporary physics. Historically, condensed matter physics grew out of solid-state physics, which is now considered one of its main subfields. The term condensed matter physics was apparently coined by Philip Anderson when he renamed his research group\u2014previously solid-state theory\u2014in 1967. In 1978, the Division of Solid State Physics of the American Physical Society was renamed as the Division of Condensed Matter Physics. Condensed matter physics has a large overlap with chemistry, materials science, nanotechnology and engineering.\n\nAstrophysics\n\nAstrophysics and astronomy are the application of the theories and methods of physics to the study of stellar structure, stellar evolution, the origin of the Solar System, and related problems of cosmology. Because astrophysics is a broad subject, astrophysicists typically apply many disciplines of physics, including mechanics, electromagnetism, statistical mechanics, thermodynamics, quantum mechanics, relativity, nuclear and particle physics, and atomic and molecular physics.\n\nThe discovery by Karl Jansky in 1931 that radio signals were emitted by celestial bodies initiated the science of radio astronomy. Most recently, the frontiers of astronomy have been expanded by space exploration. Perturbations and interference from the earth's atmosphere make space-based observations necessary for infrared, ultraviolet, gamma-ray, and X-ray astronomy.\n\nPhysical cosmology is the study of the formation and evolution of the universe on its largest scales. Albert Einstein's theory of relativity plays a central role in all modern cosmological theories. In the early 20th century, Hubble's discovery that the universe is expanding, as shown by the Hubble diagram, prompted rival explanations known as the steady state universe and the Big Bang.\n\nThe Big Bang was confirmed by the success of Big Bang nucleosynthesis and the discovery of the cosmic microwave background in 1964. The Big Bang model rests on two theoretical pillars: Albert Einstein's general relativity and the cosmological principle. Cosmologists have recently established the \u039bCDM model of the evolution of the universe, which includes cosmic inflation, dark energy, and dark matter.\n\nNumerous possibilities and discoveries are anticipated to emerge from new data from the Fermi Gamma-ray Space Telescope over the upcoming decade and vastly revise or clarify existing models of the universe. In particular, the potential for a tremendous discovery surrounding dark matter is possible over the next several years. Fermi will search for evidence that dark matter is composed of weakly interacting massive particles, complementing similar experiments with the Large Hadron Collider and other underground detectors.\n\nIBEX is already yielding new astrophysical discoveries: \"No one knows what is creating the ENA (energetic neutral atoms) ribbon\" along the termination shock of the solar wind, \"but everyone agrees that it means the textbook picture of the heliosphere\u2014in which the Solar System's enveloping pocket filled with the solar wind's charged particles is plowing through the onrushing 'galactic wind' of the interstellar medium in the shape of a comet\u2014is wrong.\"\n\nCurrent research\n\nResearch in physics is continually progressing on a large number of fronts.\n\nIn condensed matter physics, an important unsolved theoretical problem is that of high-temperature superconductivity. Many condensed matter experiments are aiming to fabricate workable spintronics and quantum computers.\n\nIn particle physics, the first pieces of experimental evidence for physics beyond the Standard Model have begun to appear. Foremost among these are indications that neutrinos have non-zero mass. These experimental results appear to have solved the long-standing solar neutrino problem, and the physics of massive neutrinos remains an area of active theoretical and experimental research. The Large Hadron Collider has already found the Higgs boson, but future research aims to prove or disprove the supersymmetry, which extends the Standard Model of particle physics. Research on the nature of the major mysteries of dark matter and dark energy is also currently ongoing.\n\nAlthough much progress has been made in high-energy, quantum, and astronomical physics, many everyday phenomena involving complexity, chaos, or turbulence are still poorly understood. Complex problems that seem like they could be solved by a clever application of dynamics and mechanics remain unsolved; examples include the formation of sandpiles, nodes in trickling water, the shape of water droplets, mechanisms of surface tension catastrophes, and self-sorting in shaken heterogeneous collections.\n\nThese complex phenomena have received growing attention since the 1970s for several reasons, including the availability of modern mathematical methods and computers, which enabled complex systems to be modeled in new ways. Complex physics has become part of increasingly interdisciplinary research, as exemplified by the study of turbulence in aerodynamics and the observation of pattern formation in biological systems. In the 1932 Annual Review of Fluid Mechanics, Horace Lamb said:\n\nSee also\n\nList of important publications in physics\nList of physicists\nLists of physics equations\nRelationship between mathematics and physics\nEarth science\nNeurophysics\nPsychophysics\nScience tourism\n\nNotes\n\nReferences\n\nSources\n\nExternal links\n\n PhysicsCentral \u2013 Web portal run by the American Physical Society\n Physics.org \u2013 Web portal run by the Institute of Physics\n Usenet Physics FAQ \u2013 FAQ compiled by sci.physics and other physics newsgroups\n Website of the Nobel Prize in physics \u2013 Award for outstanding contributions to the subject\n World of Physics  \u2013 Online encyclopedic dictionary of physics\n Nature Physics \u2013 Academic journal\n Physics \u2013 Online magazine by the American Physical Society\n  \u2013 Directory of physics related media\n The Vega Science Trust \u2013 Science videos, including physics\n HyperPhysics website \u2013 Physics and astronomy mind-map from Georgia State University\n PHYSICS at MIT OCW \u2013 Online course material from Massachusetts Institute of Technology",
  "Politics": "Politics (from , ) is the method of rulership over a national government, state government and local government in groups, or other forms of ruling power relations among individuals, such as the distribution of resources or status. The branch of social science that studies rulership, law making and government is referred to as political science. \n\nIt may be used positively in the context of a \"political solution\" which is compromising and nonviolent, or descriptively as \"the art or science of government\", but also often carries a negative connotation. For example, abolitionist Wendell Phillips declared that \"we do not play politics; anti-slavery is no half-jest with us.\" The concept has been defined in various ways, and different approaches have fundamentally differing views on whether it should be used extensively or limitedly, empirically or normatively, and on whether conflict or co-operation is more essential to it.\n\nA variety of methods are deployed in politics, which include promoting one's own political views among people, negotiation with other political subjects, making laws, and exercising force, including warfare against adversaries. Politics is exercised on a wide range of social levels, from clans and tribes of traditional societies, through modern local governments, companies and institutions up to sovereign states, to the international level. In modern nation states, people often form political parties to represent their ideas. Members of a party often agree to take the same position on many issues and agree to support the same changes to law and the same leaders. An election is usually a competition between different parties.\n\nA political system is a framework which defines acceptable political methods within a society. The history of political thought can be traced back to early antiquity, with seminal works such as Plato's Republic and Aristotle's Politics in the West, and Confucius's political manuscripts and Chanakya's Arthashastra in the East.\n\nEtymology \nThe English politics has its roots in the name of Aristotle's classic work, Politik\u00e1, which introduced the Greek term  (). In the mid-15th century, Aristotle's composition would be rendered in Early Modern English as , which would become Politics in Modern English.\n\nThe singular politic first attested in English in 1430, coming from Middle French \u2014itself taking from , a Latinization of the Greek  () from  () and  ().\n\nDefinitions \n\n In the view of Harold Lasswell, politics is \"who gets what, when, how.\"\n For David Easton, it is about \"the authoritative allocation of values for a society.\"\n To Vladimir Lenin, \"politics is the most concentrated expression of economics.\"\n Bernard Crick argued that \"politics is a distinctive form of rule whereby people act together through institutionalized procedures to resolve differences, to conciliate diverse interests and values and to make public policies in the pursuit of common purposes.\"\n According to Adrian Leftwich \"Politics comprises all the activities of co-operation, negotiation and conflict within and between societies, whereby people go about organizing the use, production or distribution of human, natural and other resources in the course of the production and reproduction of their biological and social life.\"\nPolitics is the sphere of activity involved in running a state. According to Max Webber the \"state can be defined as a human community that successfully claims the monopoly of the legitimate use of physical force within a given territory\".\n In the view of Manjunath Hegde, politics is \" the power, to rule the people.\"\n\nApproaches \nThere are several ways in which approaching politics has been conceptualized.\n\nExtensive and limited \nAdrian Leftwich has differentiated views of politics based on how extensive or limited their perception of what accounts as 'political' is. The extensive view sees politics as present across the sphere of human social relations, while the limited view restricts it to certain contexts. For example, in a more restrictive way, politics may be viewed as primarily about governance, while a feminist perspective could argue that sites which have been viewed traditionally as non-political, should indeed be viewed as political as well. This latter position is encapsulated in the slogan the personal is political, which disputes the distinction between private and public issues. Instead, politics may be defined by the use of power, as has been argued by Robert A. Dahl.\n\nMoralism and realism \nSome perspectives on politics view it empirically as an exercise of power, while others see it as a social function with a normative basis. This distinction has been called the difference between political moralism and political realism. For moralists, politics is closely linked to ethics, and is at its extreme in utopian thinking. For example, according to Hannah Arendt, the view of Aristotle was that \"to be political\u2026meant that everything was decided through words and persuasion and not through violence;\" while according to Bernard Crick \"[p]olitics is the way in which free societies are governed. Politics is politics and other forms of rule are something else.\" In contrast, for realists, represented by those such as Niccol\u00f2 Machiavelli, Thomas Hobbes, and Harold Lasswell, politics is based on the use of power, irrespective of the ends being pursued.\n\nConflict and co-operation \nAgonism argues that politics essentially comes down to conflict between conflicting interests. Political scientist Elmer Schattschneider argued that \"at the root of all politics is the universal language of conflict,\" while for Carl Schmitt the essence of politics is the distinction of 'friend' from foe'. This is in direct contrast to the more co-operative views of politics by Aristotle and Crick. However, a more mixed view between these extremes is provided by Irish political scientist Michael Laver, who noted that:Politics is about the characteristic blend of conflict and co-operation that can be found so often in human interactions. Pure conflict is war. Pure co-operation is true love. Politics is a mixture of both.\n\nHistory \n\nThe history of politics spans human history and is not limited to modern institutions of government.\n\nPrehistoric \nFrans de Waal argued that already chimpanzees engage in politics through \"social manipulation to secure and maintain influential positions.\" Early human forms of social organization\u2014bands and tribes\u2014lacked centralized political structures. These are sometimes referred to as stateless societies.\n\nEarly states \nIn ancient history, civilizations did not have definite boundaries as states have today, and their borders could be more accurately described as frontiers. Early dynastic Sumer, and early dynastic Egypt were the first civilizations to define their borders. Moreover, up to the 12th century, many people lived in non-state societies. These range from relatively egalitarian bands and tribes to complex and highly stratified chiefdoms.\n\nState formation \n\nThere are a number of different theories and hypotheses regarding early state formation that seek generalizations to explain why the state developed in some places but not others. Other scholars believe that generalizations are unhelpful and that each case of early state formation should be treated on its own.\n\nVoluntary theories contend that diverse groups of people came together to form states as a result of some shared rational interest. The theories largely focus on the development of agriculture, and the population and organizational pressure that followed and resulted in state formation. One of the most prominent theories of early and primary state formation is the hydraulic hypothesis, which contends that the state was a result of the need to build and maintain large-scale irrigation projects.\n\nConflict theories of state formation regard conflict and dominance of some population over another population as key to the formation of states. In contrast with voluntary theories, these arguments believe that people do not voluntarily agree to create a state to maximize benefits, but that states form due to some form of oppression by one group over others. Some theories in turn argue that warfare was critical for state formation.\n\nAncient history \nThe first states of sorts were those of early dynastic Sumer and early dynastic Egypt, which arose from the Uruk period and Predynastic Egypt respectively around approximately 3000 BCE. Early dynastic Egypt was based around the Nile River in the north-east of Africa, the kingdom's boundaries being based around the Nile and stretching to areas where oases existed. Early dynastic Sumer was located in southern Mesopotamia with its borders extending from the Persian Gulf to parts of the Euphrates and Tigris rivers.\n\nAlthough state-forms existed before the rise of the Ancient Greek empire, the Greeks were the first people known to have explicitly formulated a political philosophy of the state, and to have rationally analyzed political institutions. Prior to this, states were described and justified in terms of religious myths.\n\nSeveral important political innovations of classical antiquity came from the Greek city-states (polis) and the Roman Republic. The Greek city-states before the 4th century granted citizenship rights to their free population; in Athens these rights were combined with a directly democratic form of government that was to have a long afterlife in political thought and history.\n\nModern states \n\nThe Peace of Westphalia (1648) is considered by political scientists to be the beginning of the modern international system, in which external powers should avoid interfering in another country's domestic affairs. The principle of non-interference in other countries' domestic affairs was laid out in the mid-18th century by Swiss jurist Emer de Vattel. States became the primary institutional agents in an interstate system of relations. The Peace of Westphalia is said to have ended attempts to impose supranational authority on European states. The \"Westphalian\" doctrine of states as independent agents was bolstered by the rise in 19th century thought of nationalism, under which legitimate states were assumed to correspond to nations\u2014groups of people united by language and culture.\n\nIn Europe, during the 18th century, the classic non-national states were the multinational empires: the Austrian Empire, Kingdom of France, Kingdom of Hungary, the Russian Empire, the Spanish Empire, the Ottoman Empire, and the British Empire. Such empires also existed in Asia, Africa, and the Americas; in the Muslim world, immediately after the death of Muhammad in 632, Caliphates were established, which developed into multi-ethnic trans-national empires. The multinational empire was an absolute monarchy ruled by a king, emperor or sultan. The population belonged to many ethnic groups, and they spoke many languages. The empire was dominated by one ethnic group, and their language was usually the language of public administration. The ruling dynasty was usually, but not always, from that group. Some of the smaller European states were not so ethnically diverse, but were also dynastic states, ruled by a royal house. A few of the smaller states survived, such as the independent principalities of Liechtenstein, Andorra, Monaco, and the republic of San Marino.\n\nMost theories see the nation state as a 19th-century European phenomenon, facilitated by developments such as state-mandated education, mass literacy, and mass media. However, historians also note the early emergence of a relatively unified state and identity in Portugal and the Dutch Republic. Scholars such as Steven Weber, David Woodward, Michel Foucault, and Jeremy Black have advanced the hypothesis that the nation state did not arise out of political ingenuity or an unknown undetermined source, nor was it an accident of history or political invention. Rather, the nation state is an inadvertent byproduct of 15th-century intellectual discoveries in political economy, capitalism, mercantilism, political geography, and geography combined with cartography and advances in map-making technologies.\n\nSome nation states, such as Germany and Italy, came into existence at least partly as a result of political campaigns by nationalists, during the 19th century. In both cases, the territory was previously divided among other states, some of them very small. Liberal ideas of free trade played a role in German unification, which was preceded by a customs union, the Zollverein. National self-determination was a key aspect of United States President Woodrow Wilson's Fourteen Points, leading to the dissolution of the Austro-Hungarian Empire and the Ottoman Empire after the First World War, while the Russian Empire became the Soviet Union after the Russian Civil War. Decolonization lead to the creation of new nation states in place of multinational empires in the Third World.\n\nGlobalization \n\nPolitical globalization began in the 20th century through intergovernmental organizations and supranational unions. The League of Nations was founded after World War I, and after World War II it was replaced by the United Nations. Various international treaties have been signed through it. Regional integration has been pursued by the African Union, ASEAN, the European Union, and Mercosur. International political institutions on the international level include the International Criminal Court, the International Monetary Fund, and the World Trade Organization.\n\nPolitical science \n\nThe study of politics is called political science, or politology. It comprises numerous subfields, including comparative politics, political economy, international relations, political philosophy, public administration, public policy, gender and politics, and political methodology. Furthermore, political science is related to, and draws upon, the fields of economics, law, sociology, history, philosophy, geography, psychology/psychiatry, anthropology, and neurosciences.\n\nComparative politics is the science of comparison and teaching of different types of constitutions, political actors, legislature and associated fields, all of them from an intrastate perspective. International relations deals with the interaction between nation-states as well as intergovernmental and transnational organizations. Political philosophy is more concerned with contributions of various classical and contemporary thinkers and philosophers.\n\nPolitical science is methodologically diverse and appropriates many methods originating in psychology, social research, and cognitive neuroscience. Approaches include positivism, interpretivism, rational choice theory, behavioralism, structuralism, post-structuralism, realism, institutionalism, and pluralism. Political science, as one of the social sciences, uses methods and techniques that relate to the kinds of inquiries sought: primary sources such as historical documents and official records, secondary sources such as scholarly journal articles, survey research, statistical analysis, case studies, experimental research, and model building.\n\nPolitical system \n\nThe political system defines the process for making official government decisions. It is usually compared to the legal system, economic system, cultural system, and other social systems. According to David Easton, \"A political system can be designated as the interactions through which values are authoritatively allocated for a society.\" Each political system is embedded in a society with its own political culture, and they in turn shape their societies through public policy. The interactions between different political systems are the basis for global politics.\n\nForms of government \n\nForms of government can be classified by several ways. In terms of the structure of power, there are monarchies (including constitutional monarchies) and republics (usually presidential, semi-presidential, or parliamentary).\n\nThe separation of powers describes the degree of horizontal integration between the legislature, the executive, the judiciary, and other independent institutions.\n\nSource of power \n\nThe source of power determines the difference between democracies, oligarchies, and autocracies.\n\nIn a democracy, political legitimacy is based on popular sovereignty. Forms of democracy include representative democracy, direct democracy, and demarchy. These are separated by the way decisions are made, whether by elected representatives, referendums, or by citizen juries. Democracies can be either republics or constitutional monarchies.\n\nOligarchy is a power structure where a minority rules. These may be in the form of anocracy, aristocracy, ergatocracy, geniocracy, gerontocracy, kakistocracy, kleptocracy, meritocracy, noocracy, particracy, plutocracy, stratocracy, technocracy, theocracy, or timocracy.\n\nAutocracies are either dictatorships (including military dictatorships) or absolute monarchies.\n\nVertical integration \nIn terms of level of vertical integration, political systems can be divided into (from least to most integrated) confederations, federations, and unitary states.\n\nA federation (also known as a federal state) is a political entity characterized by a union of partially self-governing provinces, states, or other regions under a central federal government (federalism). In a federation, the self-governing status of the component states, as well as the division of power between them and the central government, is typically constitutionally entrenched and may not be altered by a unilateral decision of either party, the states or the federal political body. Federations were formed first in Switzerland, then in the United States in 1776, in Canada in 1867 and in Germany in 1871 and in 1901, Australia. Compared to a federation, a confederation has less centralized power.\n\nState \n\nAll the above forms of government are variations of the same basic polity, the sovereign state. The state has been defined by Max Weber as a political entity that has monopoly on violence within its territory, while the Montevideo Convention holds that states need to have a defined territory; a permanent population; a government; and a capacity to enter into international relations.\n\nA stateless society is a society that is not governed by a state. In stateless societies, there is little concentration of authority; most positions of authority that do exist are very limited in power and are generally not permanently held positions; and social bodies that resolve disputes through predefined rules tend to be small. Stateless societies are highly variable in economic organization and cultural practices.\n\nWhile stateless societies were the norm in human prehistory, few stateless societies exist today; almost the entire global population resides within the jurisdiction of a sovereign state. In some regions nominal state authorities may be very weak and wield little or no actual power. Over the course of history most stateless peoples have been integrated into the state-based societies around them.\n\nSome political philosophies consider the state undesirable, and thus consider the formation of a stateless society a goal to be achieved. A central tenet of anarchism is the advocacy of society without states. The type of society sought for varies significantly between anarchist schools of thought, ranging from extreme individualism to complete collectivism. In Marxism, Marx's theory of the state considers that in a post-capitalist society the state, an undesirable institution, would be unnecessary and wither away. A related concept is that of stateless communism, a phrase sometimes used to describe Marx's anticipated post-capitalist society.\n\nConstitutions \nConstitutions are written documents that specify and limit the powers of the different branches of government. Although a constitution is a written document, there is also an unwritten constitution. The unwritten constitution is continually being written by the legislative and judiciary branch of government; this is just one of those cases in which the nature of the circumstances determines the form of government that is most appropriate. England did set the fashion of written constitutions during the Civil War but after the Restoration abandoned them to be taken up later by the American Colonies after their emancipation and then France after the Revolution and the rest of Europe including the European colonies.\n\nConstitutions often set out separation of powers, dividing the government into the executive, the legislature, and the judiciary (together referred to as the trias politica), in order to achieve checks and balances within the state. Additional independent branches may also be created, including civil service commissions, election commissions, and supreme audit institutions.\n\nPolitical culture \n\nPolitical culture describes how culture impacts politics. Every political system is embedded in a particular political culture. Lucian Pye's definition is that \"Political culture is the set of attitudes, beliefs, and sentiments, which give order and meaning to a political process and which provide the underlying assumptions and rules that govern behavior in the political system\".\n\nTrust is a major factor in political culture, as its level determines the capacity of the state to function. Postmaterialism is the degree to which a political culture is concerned with issues which are not of immediate physical or material concern, such as human rights and environmentalism. Religion has also an impact on political culture.\n\nPolitical dysfunction\n\nPolitical corruption \n\nPolitical corruption is the use of powers for illegitimate private gain, conducted by government officials or their network contacts. Forms of political corruption include bribery, cronyism, nepotism, and political patronage. Forms of political patronage, in turn, includes clientelism, earmarking, pork barreling, slush funds, and spoils systems; as well as political machines, which is a political system that operates for corrupt ends.\n\nWhen corruption is embedded in political culture, this may be referred to as patrimonialism or neopatrimonialism. A form of government that is built on corruption is called a kleptocracy ('rule of thieves').\n\nLevels of politics\n\nMacropolitics \n\nMacropolitics can either describe political issues that affect an entire political system (e.g. the nation state), or refer to interactions between political systems (e.g. international relations).\n\nGlobal politics (or world politics) covers all aspects of politics that affect multiple political systems, in practice meaning any political phenomenon crossing national borders. This can include cities, nation-states, multinational corporations, non-governmental organizations, and/or international organizations. An important element is international relations: the relations between nation-states may be peaceful when they are conducted through diplomacy, or they may be violent, which is described as war. States that are able to exert strong international influence are referred to as superpowers, whereas less-powerful ones may be called regional or middle powers. The international system of power is called the world order, which is affected by the balance of power that defines the degree of polarity in the system. Emerging powers are potentially destabilizing to it, especially if they display revanchism or irredentism.\n\nPolitics inside the limits of political systems, which in contemporary context correspond to national borders, are referred to as domestic politics. This includes most forms of public policy, such as social policy, economic policy, or law enforcement, which are executed by the state bureaucracy.\n\nMesopolitics \nMesopolitics describes the politics of intermediary structures within a political system, such as national political parties or movements.\n\nA political party is a political organization that typically seeks to attain and maintain political power within government, usually by participating in political campaigns, educational outreach, or protest actions. Parties often espouse an expressed ideology or vision, bolstered by a written platform with specific goals, forming a coalition among disparate interests.\n\nPolitical parties within a particular political system together form the party system, which can be either multiparty, two-party, dominant-party, or one-party, depending on the level of pluralism. This is affected by characteristics of the political system, including its electoral system. According to Duverger's law, first-past-the-post systems are likely to lead to two-party systems, while proportional representation systems are more likely to create a multiparty system.\n\nMicropolitics \nMicropolitics describes the actions of individual actors within the political system. This is often described as political participation. Political participation may take many forms, including:\n\nActivism\nBoycott\nCivil disobedience\nDemonstration\nPetition\nPicketing\nStrike action\nTax resistance\nVoting (or its opposite, abstentionism)\n\nPolitical values\n\nDemocracy \n\nDemocracy is a system of processing conflicts in which outcomes depend on what participants do, but no single force controls what occurs and its outcomes. The uncertainty of outcomes is inherent in democracy. Democracy makes all forces struggle repeatedly to realize their interests and devolves power from groups of people to sets of rules.\n\nAmong modern political theorists, there are three contending conceptions of democracy: aggregative, deliberative, and radical.\n\nAggregative \nThe theory of aggregative democracy claims that the aim of the democratic processes is to solicit the preferences of citizens, and aggregate them together to determine what social policies the society should adopt. Therefore, proponents of this view hold that democratic participation should primarily focus on voting, where the policy with the most votes gets implemented.\n\nDifferent variants of aggregative democracy exist. Under minimalism, democracy is a system of government in which citizens have given teams of political leaders the right to rule in periodic elections. According to this minimalist conception, citizens cannot and should not \"rule\" because, for example, on most issues, most of the time, they have no clear views or their views are not well-founded. Joseph Schumpeter articulated this view most famously in his book Capitalism, Socialism, and Democracy. Contemporary proponents of minimalism include William H. Riker, Adam Przeworski, Richard Posner.\n\nAccording to the theory of direct democracy, on the other hand, citizens should vote directly, not through their representatives, on legislative proposals. Proponents of direct democracy offer varied reasons to support this view. Political activity can be valuable in itself, it socializes and educates citizens, and popular participation can check powerful elites. Most importantly, citizens do not rule themselves unless they directly decide laws and policies.\n\nGovernments will tend to produce laws and policies that are close to the views of the median voter\u2014with half to their left and the other half to their right. This is not a desirable outcome as it represents the action of self-interested and somewhat unaccountable political elites competing for votes. Anthony Downs suggests that ideological political parties are necessary to act as a mediating broker between individual and governments. Downs laid out this view in his 1957 book An Economic Theory of Democracy.\n\nRobert A. Dahl argues that the fundamental democratic principle is that, when it comes to binding collective decisions, each person in a political community is entitled to have his/her interests be given equal consideration (not necessarily that all people are equally satisfied by the collective decision). He uses the term polyarchy to refer to societies in which there exists a certain set of institutions and procedures which are perceived as leading to such democracy. First and foremost among these institutions is the regular occurrence of free and open elections which are used to select representatives who then manage all or most of the public policy of the society. However, these polyarchic procedures may not create a full democracy if, for example, poverty prevents political participation. Similarly, Ronald Dworkin argues that \"democracy is a substantive, not a merely procedural, ideal.\"\n\nDeliberative \n\nDeliberative democracy is based on the notion that democracy is government by deliberation. Unlike aggregative democracy, deliberative democracy holds that, for a democratic decision to be legitimate, it must be preceded by authentic deliberation, not merely the aggregation of preferences that occurs in voting. Authentic deliberation is deliberation among decision-makers that is free from distortions of unequal political power, such as power a decision-maker obtained through economic wealth or the support of interest groups. If the decision-makers cannot reach consensus after authentically deliberating on a proposal, then they vote on the proposal using a form of majority rule.\n\nRadical \n\nRadical democracy is based on the idea that there are hierarchical and oppressive power relations that exist in society. Democracy's role is to make visible and challenge those relations by allowing for difference, dissent and antagonisms in decision-making processes.\n\nEquality \n\nEquality is a state of affairs in which all people within a specific society or isolated group have the same social status, especially socioeconomic status, including protection of human rights and dignity, and equal access to certain social goods and social services. Furthermore, it may also include health equality, economic equality and other social securities. Social equality requires the absence of legally enforced social class or caste boundaries and the absence of discrimination motivated by an inalienable part of a person's identity. To this end there must be equal justice under law, and equal opportunity regardless of, for example, sex, gender, ethnicity, age, sexual orientation, origin, caste or class, income or property, language, religion, convictions, opinions, health or disability.\n\nLeft\u2013right spectrum \nA common way of understanding politics is through the left\u2013right political spectrum, which ranges from left-wing politics via centrism to right-wing politics. This classification is comparatively recent and dates from the French Revolution, when those members of the National Assembly who supported the republic, the common people and a secular society sat on the left and supporters of the monarchy, aristocratic privilege and the Church sat on the right.\n\nToday, the left is generally progressivist, seeking social progress in society. The more extreme elements of the left, named the far-left, tend to support revolutionary means for achieving this. This includes ideologies such as Communism and Marxism. The center-left, on the other hand, advocate for more reformist approaches, for example that of social democracy.\n\nIn contrast, the right is generally motivated by conservatism, which seeks to conserve what it sees as the important elements of society. The far-right goes beyond this, and often represents a reactionary turn against progress, seeking to undo it. Examples of such ideologies have included Fascism and Nazism. The center-right may be less clear-cut and more mixed in this regard, with neoconservatives supporting the spread of free markets and capitalism, and one-nation conservatives more open to social welfare programs.\n\nAccording to Norberto Bobbio, one of the major exponents of this distinction, the left believes in attempting to eradicate social inequality\u2014believing it to be unethical or unnatural, while the right regards most social inequality as the result of ineradicable natural inequalities, and sees attempts to enforce social equality as utopian or authoritarian.\nSome ideologies, notably Christian Democracy, claim to combine left and right-wing politics; according to Geoffrey K. Roberts and Patricia Hogwood, \"In terms of ideology, Christian Democracy has incorporated many of the views held by liberals, conservatives and socialists within a wider framework of moral and Christian principles.\" Movements which claim or formerly claimed to be above the left-right divide include Fascist Terza Posizione economic politics in Italy and Peronism in Argentina.\n\nFreedom \n\nPolitical freedom (also known as political liberty or autonomy) is a central concept in political thought and one of the most important features of democratic societies. Negative liberty has been described as freedom from oppression or coercion and unreasonable external constraints on action, often enacted through civil and political rights, while positive liberty is the absence of disabling conditions for an individual and the fulfillment of enabling conditions, e.g. economic compulsion, in a society. This capability approach to freedom requires economic, social and cultural rights in order to be realized.\n\nAuthoritarianism and libertarianism \nAuthoritarianism and libertarianism disagree the amount of individual freedom each person possesses in that society relative to the state. One author describes authoritarian political systems as those where \"individual rights and goals are subjugated to group goals, expectations and conformities,\" while libertarians generally oppose the state and hold the individual as sovereign. In their purest form, libertarians are anarchists, who argue for the total abolition of the state, of political parties and of other political entities, while the purest authoritarians are, by definition, totalitarians who support state control over all aspects of society.\n\nFor instance, classical liberalism (also known as laissez-faire liberalism) is a doctrine stressing individual freedom and limited government. This includes the importance of human rationality, individual property rights, free markets, natural rights, the protection of civil liberties, constitutional limitation of government, and individual freedom from restraint as exemplified in the writings of John Locke, Adam Smith, David Hume, David Ricardo, Voltaire, Montesquieu and others. According to the libertarian Institute for Humane Studies, \"the libertarian, or 'classical liberal,' perspective is that individual well-being, prosperity, and social harmony are fostered by 'as much liberty as possible' and 'as little government as necessary.'\" For anarchist political philosopher L. Susan Brown (1993), \"liberalism and anarchism are two political philosophies that are fundamentally concerned with individual freedom yet differ from one another in very distinct ways. Anarchism shares with liberalism a radical commitment to individual freedom while rejecting liberalism's competitive property relations.\"\n\nSee also \n\n Political history of the world\n Index of law articles\n Index of politics articles \u2013 alphabetical list of political subjects\n List of politics awards\n List of years in politics\n Outline of law\n Outline of political science \u2013 structured list of political topics, arranged by subject area\n Political lists \u2013 lists of political topics\n Politics of present-day states\n List of political ideologies\n\nReferences\n\nNotes\n\nCitations\n\nBibliography\n\nFurther reading \n Adcock, Robert. 2014. Liberalism and the Emergence of American Political Science: A Transatlantic Tale. New York: Oxford University Press. \n Adcock, Robert, Mark Bevir, and Shannon Stimson (eds.). 2007. Modern Political Science: Anglo-American Exchanges Since 1870. Princeton, NJ: Princeton University Press.\n Almond, Gabriel A. 1996. \u201cPolitical Science: The History of the Discipline,\u201d pp.\u00a050\u201396, in Robert E. Goodin and Hans-Dieter Klingemann (eds.), The New Handbook of Political Science. Oxford, UK: Oxford University Press.\n \n \n Mount, Ferdinand, \"Ruthless and Truthless\" (review of Peter Oborne, The Assault on Truth: Boris Johnson, Donald Trump and the Emergence of a New Moral Barbarism, Simon and Schuster, February 2021, , 192 pp.; and Colin Kidd and Jacqueline Rose, eds., Political Advice: Past, Present and Future, I.B. Tauris, February 2021, , 240 pp.), London Review of Books, vol. 43, no. 9 (6 May 2021), pp.\u00a03, 5\u20138. \n Munck, Gerardo L., and Richard Snyder (eds.). Passion, Craft, and Method in Comparative Politics. Johns Hopkins University Press, 2007. \n Ross, Dorothy. 1991. The Origins of American Social Science. New York: Cambridge University Press.\n \n\n \nMain topic articles",
  "Recreation": "Recreation is an activity of leisure, leisure being discretionary time. The \"need to do something for recreation\" is an essential element of human biology and psychology. Recreational activities are often done for enjoyment, amusement, or pleasure and are considered to be \"fun\".\n\nEtymology\nThe term recreation appears to have been used in English first in the late 14th century, first in the sense of \"refreshment or curing of a sick person\", and derived  turn from Latin (re: \"again\", creare: \"to create, bring forth, beget\").\n\nPrerequisites to leisure\nHumans spend their time in activities of daily living, work, sleep, social duties and leisure, the latter time being free from prior commitments to physiologic or social needs, a prerequisite of recreation. Leisure has increased with increased longevity and, for many, with decreased hours spent for physical and economic survival, yet others argue that time pressure has increased for modern people, as they are committed to too many tasks. Other factors that account for an increased role of recreation are affluence, population trends, and increased commercialization of recreational offerings. While one perception is that leisure is just \"spare time\", time not consumed by the necessities of living, another holds that leisure is a force that allows individuals to consider and reflect on the values and realities that are missed in the activities of daily life, thus being an essential element of personal development and civilization. This direction of thought has even been extended to the view that leisure is the purpose of work, and a reward in itself, and \"leisure life\" reflects the values and character of a nation. Leisure is considered a human right under the Universal Declaration of Human Rights.\n\nPlay, recreation and work\n\nRecreation is difficult to separate from the general concept of play, which is usually the term for children's recreational activity. Children may playfully imitate activities that reflect the realities of adult life. It has been proposed that play or recreational activities are outlets of or expression of excess energy, channeling it into socially acceptable activities that fulfill individual as well as societal needs, without need for compulsion, and providing satisfaction and pleasure for the participant. A traditional view holds that work is supported by  recreation, recreation being useful to \"recharge the battery\" so that work performance is improved.\n\nWork, an activity generally performed out of economic necessity and useful for society and organized within the economic framework, however can also be pleasurable and may be self-imposed thus blurring the distinction to recreation. Many activities in entertainment are work for one person and recreation for another. Over time, a recreational activity may become work, and vice versa. Thus, for a musician, playing an instrument may be at one time a profession, and at another a recreation.\n\nSimilarly, it may be difficult to separate education from recreation as in the case of recreational mathematics.\n\nHealth and recreation\nRecreation has many health benefits, and, accordingly, Therapeutic Recreation has been developed to take advantage of this effect. The National Council for Therapeutic Recreation Certification (NCTRC) is the nationally recognized credentialing organization for the profession of Therapeutic Recreation. Professionals in the field of Therapeutic Recreation who are certified by the NCTRC are called \"Certified Therapeutic Recreation Specialists\". The job title \"Recreation Therapist\" is identified in the U.S. Dept of Labor's Occupation Outlook. Such therapy is applied in rehabilitation, psychiatric facilities for youth and adults, and in the care of the elderly, the disabled, or people with chronic diseases. Recreational physical activity is important to reduce obesity, and the risk of osteoporosis and of cancer, most significantly in men that of colon and prostate, and in women that of the breast; however, not all malignancies are reduced as outdoor recreation has been linked to a higher risk of melanoma. Extreme adventure recreation naturally carries its own hazards.\n\nForms and activities\n\nRecreation is an essential part of human life and finds many different forms which are shaped naturally by individual interests but also by the surrounding social construction. Recreational activities can be communal or solitary, active or passive, outdoors or indoors, healthy or harmful, and useful for society or detrimental. Some recreational activities \u2013 such as gambling, recreational drug use, or delinquent activities \u2013 may violate societal norms and laws. A list of typical activities could be almost endless\n\nHobby\n\nA significant section of recreational activities are designated as  hobbies which are activities done for pleasure on a regular basis. A hobby is considered to be a regular activity that is done for enjoyment, typically during one's leisure time, not professionally and not for pay. Hobbies include collecting themed items and objects, engaging in creative and artistic pursuits, playing sports, or pursuing other amusements. Participation in hobbies encourages acquiring substantial skills and knowledge in that area. A list of hobbies changes with renewed interests and developing fashions, making it diverse and lengthy. Hobbies tend to follow trends in society, for example stamp collecting was popular during the nineteenth and twentieth centuries as postal systems were the main means of communication, while video games are more popular nowadays following technological advances. The advancing production and technology of the nineteenth century provided workers with more availability in leisure time to engage in hobbies. Because of this, the efforts of people investing in hobbies has increased with time.\n\nBricolage\n\nBricolage and DIY are some of the terms describing the building, modifying, or repairing things without the direct aid of experts or professionals. Academic research has described DIY as behaviors where \"individuals engage raw and semi-raw materials and parts to produce, transform, or reconstruct material possessions, including those drawn from the natural environment (e.g., landscaping)\". DIY behavior can be triggered by various motivations previously categorized as marketplace motivations (economic benefits, lack of product availability, lack of product quality, need for customization), and identity enhancement (craftsmanship, empowerment, community seeking, uniqueness). They could involve crafts that requires particular skills and knowledge of skilled work. Typical interests enjoyed by the maker culture include engineering-oriented pursuits such as home improvement, electronics, robotics, 3-D printing, and the use of Computer Numeric Control tools, as well as more traditional activities such as metalworking, woodworking, and, mainly, its predecessor, traditional arts and crafts. The subculture stresses a cut-and-paste approach to standardized hobbyist technologies, and encourages cookbook re-use of designs published on websites and maker-oriented publications. There is a strong focus on using and learning practical skills and applying them to reference designs. There is also growing work on equity and the maker culture.\n\nGames\n\nAny structured form of play could become a game. Games are played sometimes purely for recreation, sometimes for achievement or monetary rewards as well. They are played for recreation alone, in teams, or online; by amateurs. Professionals can play as part of their work for entertainment of the audience. The games could be board games, puzzles, computer or video games.\n\nOutdoor recreation\n\nRecreation engaged in out of doors, most commonly in natural settings. The activities themselves \u2014 such as fishing, hunting, backpacking, and horseback riding \u2014 characteristically dependent on the environment practiced in. While many of these activities can be classified as sports, they do not all demand that a participant be an athlete. Competition generally is less stressed than in individual or team sports organized into opposing squads in pursuit of a trophy or championship. When the activity involves exceptional excitement, physical challenge, or risk, it is sometimes referred to as \"adventure recreation\" or \"adventure training\", rather than an extreme sport.\n\nOther traditional examples of outdoor recreational activities include hiking, camping, mountaineering, cycling, canoeing, caving, kayaking, rafting, rock climbing, running, sailing, skiing, sky diving and surfing.  As new pursuits, often hybrids of prior ones, emerge, they gain their own identities, such as coasteering, canyoning, fastpacking, and plogging.\n\nPerforming arts\n\nDance\n\nParticipatory dance whether it be a folk dance, a social dance, a group dance such as a line, circle, chain or square dance, or a partner dance such as is common in western Western ballroom dancing, is undertaken primarily for a common purpose, such as entertainment, social interaction or exercise, of participants rather than onlookers. The many forms of dance provide recreation for all age groups and cultures.\n\nMusic Creation\n\nMusic is composed and performed for many purposes, ranging from recreation, religious or ceremonial purposes, or for entertainment. When music was only available through sheet music scores, such as during the Classical and Romantic eras in Europe, music lovers would buy the sheet music of their favourite pieces and songs so that they could perform them at home on their instruments.\n\nVisual arts\n\nWoodworking, photography, moviemaking, jewelry making, software projects such as Photoshopping and home music or video production, making bracelets, artistic projects such as drawing, painting, Cosplay (design, creation, and wearing a costume based on an already existing creative property), creating models out of card stock or paper \u2013 called papercraft fall under the category visual arts. many of these are practised for recreation.\n\nDrawing\n\nDrawing goes back at least 16,000 years to Paleolithic cave representations of animals such as those at Lascaux in France and Altamira in Spain. In ancient Egypt, ink drawings on papyrus, often depicting people, were used as models for painting or sculpture. Drawings on Greek vases, initially geometric, later developed to the human form with black-figure pottery during the 7th century BC.\n\nWith paper becoming common in Europe by the 15th century, drawing was adopted by masters such as Sandro Botticelli, Raphael, Michelangelo, and Leonardo da Vinci who sometimes treated drawing as an art in its own right rather than a preparatory stage for painting or sculpture.\n\nLiterature\nWriting may involve letters, journals and weblogs.\nIn the US, about half of all adults read one or more books for pleasure each year.  About 5% read more than 50 books per year.\n\nPainting\n\nLike drawing, painting has its documented origins in caves and on rock faces. The finest examples, believed by some to be 32,000 years old, are in the Chauvet and Lascaux caves in southern France. In shades of red, brown, yellow and black, the paintings on the walls and ceilings are of bison, cattle, horses and deer. Paintings of human figures can be found in the tombs of ancient Egypt. In the great temple of Ramses II, Nefertari, his queen, is depicted being led by Isis. Greek and Roman art like the Hellenistic Fayum mummy portraits and Battle of Issus at Pompeii contributed to Byzantine art in the 4th century BC, which initiated a tradition in icon painting. Models of aeroplanes, boats, cars, tanks, artillery, and even figures of soldiers and superheroes are popular subjects to build, paint and display.\n\nPhotography\n\nAn amateur photographer practices photography as a hobby/passion and not for monetary profit. The quality of some amateur work may be highly specialized or eclectic in choice of subjects. Amateur photography is often pre-eminent in photographic subjects which have little prospect of commercial use or reward. Amateur photography grew during the late 19th century due to the popularization of the Hand-held camera. Nowadays it has spread widely through social media and is carried out throughout different platforms and equipment, including the use of cell phone. Clear pictures can now be taken with a cell phone which is a key tool for making photography more accessible to everyone.\n\nOrganized recreation\n\nMany recreational activities are organized, typically by public institutions, voluntary group-work agencies, private groups supported by membership fees, and commercial enterprises. Examples of each of these are the National Park Service, the YMCA, the Kiwanis, and Walt Disney World. Public space such as parks and beaches are essential venues for many recreational activities and Tourism has recognized that many visitors are specifically attracted by recreational offerings. In particular, beach and waterfront promenades such as the beach area of Venice Beach in California, the Promenade de la Croisette in Cannes, the Promenade des Anglais in Nice or the lungomare of Barcola with Miramare Castle in Trieste are important recreational areas for the city population on the one hand and on the other also important tourist destinations with all advantages and disadvantages for the locals.\n\nIn support of recreational activities government has taken an important role in their creation, maintenance, and organization, and whole industries have developed merchandise or services. Recreation-related business is an important factor in the economy; it has been estimated that the outdoor recreation sector alone contributes $730 billion annually to the U.S. economy and generates 6.5 million jobs.\n\nRecreation center\nA recreation center is a place for recreational activities usually administered by a municipal government agency. Swimming, basketball, weightlifting, volleyball and kids' play areas are very common.\n\nRecreation as a career\nA recreation specialist would be expected to meet the recreational needs of a community or assigned interest group. Educational institutions offer courses that lead to a degree as a Bachelor of Arts in recreation management. People with such degrees often work in parks and recreation centers in towns, on community projects and activities. Networking with instructors, budgeting, and evaluation of continuing programs are common job duties.\n\nIn the United States, most states have a professional organization for continuing education and certification in recreation management. The National Recreation and Park Association administers a certification program called the CPRP (Certified Park and Recreation Professional) that is considered a national standard for professional recreation specialist practices.\n\ne-commerce \nSince the beginning of the 2000s, there are more and more online booking / ticketing platforms for recreational activities that emerged. Many of them leveraged the ever-growing prevalence of internet, mobile devices and e-payments to build comprehensive online booking solutions. The first successful batch includes tourist recreation activities platform like TripAdvisor that went public. The emergence of these platforms infers the rising needs for recreation and entertainment from the growing urban citizens worldwide.\n\nSee also\n\nReferences\n\nExternal links\n\n \nArticles containing video clips",
  "Religion": "Religion is usually defined as a social-cultural system of designated behaviors and practices, morals, beliefs, worldviews, texts, sanctified places, prophecies, ethics, or organizations, that generally relates humanity to supernatural, transcendental, and spiritual elements; however, there is no scholarly consensus over what precisely constitutes a religion.\n\nDifferent religions may or may not contain various elements ranging from the divine, sacred things, faith, a supernatural being or supernatural beings or \"some sort of ultimacy and transcendence that will provide norms and power for the rest of life\". Religious practices may include rituals, sermons, commemoration or veneration (of deities and/or saints), sacrifices, festivals, feasts, trances, initiations, funerary services, matrimonial services, meditation, prayer, music, art, dance, public service, or other aspects of human culture. Religions have sacred histories and narratives, which may be preserved in sacred scriptures, and symbols and holy places, that aim mostly to give a meaning to life. Religions may contain symbolic stories, which are sometimes said by followers to be true, that may also attempt to explain the origin of life, the universe, and other phenomena. Traditionally, faith, in addition to reason, has been considered a source of religious beliefs.\n\nThere are an estimated 10,000 distinct religions worldwide. About 84% of the world's population is affiliated with Christianity, Islam, Hinduism, Buddhism, or some form of folk religion. The religiously unaffiliated demographic includes those who do not identify with any particular religion, atheists, and agnostics. While the religiously unaffiliated have grown globally, many of the religiously unaffiliated still have various religious beliefs.\n\nThe study of religion comprises a wide variety of academic disciplines, including theology, comparative religion and social scientific studies. Theories of religion offer various explanations for the origins and workings of religion, including the ontological foundations of religious being and belief.\n\nConcept and etymology\n\nReligion comes from Old French and Anglo Norman (1200s AD) and means respect for sense of right, moral obligation, sanctity, what is sacred, reverence for the gods. It is ultimately derived from the Latin word religi\u014d. According to Cicero, religio comes from relegere: re (again) +  (read) where lego is in the sense of \"go over\", \"choose\", or \"consider carefully\". However, some modern scholars such as Tom Harpur and Joseph Campbell have argued that religio is derived from : re (again) +  (bind or connect), which was made prominent by St. Augustine, following the interpretation given by Lactantius in Divinae institutiones, IV, 28. The medieval usage alternates with order in designating bonded communities like those of monastic orders: \"we hear of the 'religion' of the Golden Fleece, of a knight 'of the religion of Avys'\".\n\n\"Religio\"\nIn classic antiquity, 'religio' broadly meant conscientiousness, sense of right, moral obligation, or duty to anything. In the ancient and medieval world, the etymological Latin root religio was understood as an individual virtue of worship in mundane contexts; never as doctrine, practice, or actual source of knowledge. In general, religio referred to broad social obligations towards anything including family, neighbors, rulers, and even towards God. Religio was most often used by the ancient Romans not in the context of a relation towards gods, but as a range of general emotions such as hesitation, caution, anxiety, fear; feelings of being bound, restricted, inhibited; which arose from heightened attention in any mundane context. The term was also closely related to other terms like scrupulus which meant \"very precisely\" and some Roman authors related the term superstitio, which meant too much fear or anxiety or shame, to religio at times. When religio came into English around the 1200s as religion, it took the meaning of \"life bound by monastic vows\" or monastic orders. The compartmentalized concept of religion, where religious things were separated from worldly things, was not used before the 1500s. The concept of religion was first used in the 1500s to distinguish the domain of the church and the domain of civil authorities.\n\nJulius Caesar used religio to mean \"obligation of an oath\" when discussing captured soldiers making an oath to their captors. The Roman naturalist Pliny the Elder used the term religio on elephants in that they venerate the sun and the moon. Cicero used religio as being related to cultum deorum (worship of the gods).\n\n\"Threskeia\"\nIn the ancient Greece, the Greek term threskeia (\u03b8\u03c1\u03b7\u03c3\u03ba\u03b5\u03af\u03b1) was loosely translated into Latin as religio in late antiquity. Threskeia was sparsely used in classical Greece but became more frequently used in the writings of Josephus in the first century CE. It was used in mundane contexts and could mean multiple things from respectful fear to excessive or harmfully distracting practices of others; to cultic practices. It was often contrasted with the Greek word deisidaimonia which meant too much fear.\n\nReligion and religions\nThe modern concept of religion, as an abstraction that entails distinct sets of beliefs or doctrines, is a recent invention in the English language. Such usage began with texts from the 17th century due to events such as the splitting of Christendom during the Protestant Reformation and globalization in the age of exploration, which involved contact with numerous foreign cultures with non-European languages.\nSome argue that regardless of its definition, it is not appropriate to apply the term religion to non-Western cultures. Others argue that using religion on non-Western cultures distorts what people do and believe.\n\nThe concept of religion was formed in the 16th and 17th centuries, despite the fact that ancient sacred texts like the Bible, the Quran, and others did not have a word or even a concept of religion in the original languages and neither did the people or the cultures in which these sacred texts were written. For example, there is no precise equivalent of religion in Hebrew, and Judaism does not distinguish clearly between religious, national, racial, or ethnic identities. One of its central concepts is halakha, meaning the walk or path sometimes translated as law, which guides religious practice and belief and many aspects of daily life. Even though the beliefs and traditions of Judaism are found in the ancient world, ancient Jews saw Jewish identity as being about an ethnic or national identity and did not entail a compulsory belief system or regulated rituals. In the 1st century CE Josephus had used the Greek term ioudaismos (Judaism) as an ethnic term and was not linked to modern abstract concepts of religion or a set of beliefs. The very concept of \"Judaism\" was invented by the Christian Church. and it was in the 19th century that Jews began to see their ancestral culture as a religion analogous to Christianity. The Greek word threskeia, which was used by Greek writers such as Herodotus and Josephus, is found in the New Testament. Threskeia is sometimes translated as \"religion\" in today's translations, however, the term was understood as generic \"worship\" well into the medieval period. In the Quran, the Arabic word din is often translated as religion in modern translations, but up to the mid-1600s translators expressed din as \"law\".\n\nThe Sanskrit word dharma, sometimes translated as religion, also means law. Throughout classical South Asia, the study of law consisted of concepts such as penance through piety and ceremonial as well as practical traditions. Medieval Japan at first had a similar union between imperial law and universal or Buddha law, but these later became independent sources of power.\n\nThough traditions, sacred texts, and practices have existed throughout time, most cultures did not align with Western conceptions of religion since they did not separate everyday life from the sacred. In the 18th and 19th centuries, the terms Buddhism, Hinduism, Taoism, Confucianism, and world religions first entered the English language. Native Americans were also thought of as not having religions and also had no word for religion in their languages either. No one self-identified as a Hindu or Buddhist or other similar terms before the 1800s. \"Hindu\" has historically been used as a geographical, cultural, and later religious identifier for people indigenous to the Indian subcontinent. Throughout its long history, Japan had no concept of religion since there was no corresponding Japanese word, nor anything close to its meaning, but when American warships appeared off the coast of Japan in 1853 and forced the Japanese government to sign treaties demanding, among other things, freedom of religion, the country had to contend with this idea.\n\nAccording to the philologist Max M\u00fcller in the 19th century, the root of the English word religion, the Latin religio, was originally used to mean only reverence for God or the gods, careful pondering of divine things, piety (which Cicero further derived to mean diligence). Max M\u00fcller characterized many other cultures around the world, including Egypt, Persia, and India, as having a similar power structure at this point in history. What is called ancient religion today, they would have only called law.\n\nDefinition\n\nScholars have failed to agree on a definition of religion. There are, however, two general definition systems: the sociological/functional and the phenomenological/philosophical.\n\nModern Western\nThe concept of religion originated in the modern era in the West. Parallel concepts are not found in many current and past cultures; there is no equivalent term for religion in many languages. Scholars have found it difficult to develop a consistent definition, with some giving up on the possibility of a definition. Others argue that regardless of its definition, it is not appropriate to apply it to non-Western cultures.\n\nAn increasing number of scholars have expressed reservations about ever defining the essence of religion. They observe that the way the concept today is used is a particularly modern construct that would not have been understood through much of history and in many cultures outside the West (or even in the West until after the Peace of Westphalia). The MacMillan Encyclopedia of Religions states:\n\nThe anthropologist Clifford Geertz defined religion as a\n\nAlluding perhaps to Tylor's \"deeper motive\", Geertz remarked that\n\nThe theologian Antoine Vergote took the term supernatural simply to mean whatever transcends the powers of nature or human agency. He also emphasized the cultural reality of religion, which he defined as\n\nPeter Mandaville and Paul James intended to get away from the modernist dualisms or dichotomous understandings of immanence/transcendence, spirituality/materialism, and sacredness/secularity. They define religion as\n\nAccording to the MacMillan Encyclopedia of Religions, there is an experiential aspect to religion which can be found in almost every culture:\n\nClassical\n\nFriedrich Schleiermacher in the late 18th century defined religion as das schlechthinnige Abh\u00e4ngigkeitsgef\u00fchl, commonly translated as \"the feeling of absolute dependence\".\n\nHis contemporary Georg Wilhelm Friedrich Hegel disagreed thoroughly, defining religion as \"the Divine Spirit becoming conscious of Himself through the finite spirit.\"\n\nEdward Burnett Tylor defined religion in 1871 as \"the belief in spiritual beings\". He argued that narrowing the definition to mean the belief in a supreme deity or judgment after death or idolatry and so on, would exclude many peoples from the category of religious, and thus \"has the fault of identifying religion rather with particular developments than with the deeper motive which underlies them\". He also argued that the belief in spiritual beings exists in all known societies.\n\nIn his book The Varieties of Religious Experience, the psychologist William James defined religion as \"the feelings, acts, and experiences of individual men in their solitude, so far as they apprehend themselves to stand in relation to whatever they may consider the divine\". By the term divine James meant \"any object that is godlike, whether it be a concrete deity or not\" to which the individual feels impelled to respond with solemnity and gravity.\n\nThe sociologist \u00c9mile Durkheim, in his seminal book The Elementary Forms of the Religious Life, defined religion as a \"unified system of beliefs and practices relative to sacred things\". By sacred things he meant things \"set apart and forbidden\u2014beliefs and practices which unite into one single moral community called a Church, all those who adhere to them\". Sacred things are not, however, limited to gods or spirits. On the contrary, a sacred thing can be \"a rock, a tree, a spring, a pebble, a piece of wood, a house, in a word, anything can be sacred\". Religious beliefs, myths, dogmas and legends are the representations that express the nature of these sacred things, and the virtues and powers which are attributed to them.\n\nEchoes of James' and Durkheim's definitions are to be found in the writings of, for example, Frederick Ferr\u00e9 who defined religion as \"one's way of valuing most comprehensively and intensively\". Similarly, for the theologian Paul Tillich, faith is \"the state of being ultimately concerned\", which \"is itself religion. Religion is the substance, the ground, and the depth of man's spiritual life.\"\n\nWhen religion is seen in terms of sacred, divine, intensive valuing, or ultimate concern, then it is possible to understand why scientific findings and philosophical criticisms (e.g., those made by Richard Dawkins) do not necessarily disturb its adherents.\n\nAspects\n\nBeliefs\n\nTraditionally, faith, in addition to reason, has been considered a source of religious beliefs. The interplay between faith and reason, and their use as perceived support for religious beliefs, have been a subject of interest to philosophers and theologians. The origin of religious belief as such is an open question, with possible explanations including awareness of individual death, a sense of community, and dreams.\n\nMythology\n\nThe word myth has several meanings.\n A traditional story of ostensibly historical events that serves to unfold part of the world view of a people or explain a practice, belief, or natural phenomenon;\n A person or thing having only an imaginary or unverifiable existence; or\n A metaphor for the spiritual potentiality in the human being.\n\nAncient polytheistic religions, such as those of Greece, Rome, and Scandinavia, are usually categorized under the heading of mythology. Religions of pre-industrial peoples, or cultures in development, are similarly called myths in the anthropology of religion. The term myth can be used pejoratively by both religious and non-religious people. By defining another person's religious stories and beliefs as mythology, one implies that they are less real or true than one's own religious stories and beliefs. Joseph Campbell remarked, \"Mythology is often thought of as other people's religions, and religion can be defined as mis-interpreted mythology.\"\n\nIn sociology, however, the term myth has a non-pejorative meaning. There, myth is defined as a story that is important for the group whether or not it is objectively or provably true. Examples include the resurrection of their real-life founder Jesus, which, to Christians, explains the means by which they are freed from sin, is symbolic of the power of life over death, and is also said to be a historical event. But from a mythological outlook, whether or not the event actually occurred is unimportant. Instead, the symbolism of the death of an old life and the start of a new life is what is most significant. Religious believers may or may not accept such symbolic interpretations.\n\nPractices\n\nThe practices of a religion may include rituals, sermons, commemoration or veneration of a deity (god or goddess), sacrifices, festivals, feasts, trances, initiations, funerary services, matrimonial services, meditation, prayer, religious music, religious art, sacred dance, public service, or other aspects of human culture.\n\nSocial organisation\nReligions have a societal basis, either as a living tradition which is carried by lay participants, or with an organized clergy, and a definition of what constitutes adherence or membership.\n\nAcademic study\n\nA number of disciplines study the phenomenon of religion: theology, comparative religion, history of religion, evolutionary origin of religions, anthropology of religion, psychology of religion (including neuroscience of religion and evolutionary psychology of religion), law and religion, and sociology of religion.\n\nDaniel L. Pals mentions eight classical theories of religion, focusing on various aspects of religion: animism and magic, by E.B. Tylor and J.G. Frazer; the psycho-analytic approach of Sigmund Freud; and further \u00c9mile Durkheim, Karl Marx, Max Weber, Mircea Eliade, E.E. Evans-Pritchard, and Clifford Geertz.\n\nMichael Stausberg gives an overview of contemporary theories of religion, including cognitive and biological approaches.\n\nTheories\n\nSociological and anthropological theories of religion generally attempt to explain the origin and function of religion. These theories define what they present as universal characteristics of religious belief and practice.\n\nOrigins and development\n\nThe origin of religion is uncertain. There are a number of theories regarding the subsequent origins of religious practices.\n\nAccording to anthropologists John Monaghan and Peter Just, \"Many of the great world religions appear to have begun as revitalization movements of some sort, as the vision of a charismatic prophet fires the imaginations of people seeking a more comprehensive answer to their problems than they feel is provided by everyday beliefs. Charismatic individuals have emerged at many times and places in the world. It seems that the key to long-term success\u2014and many movements come and go with little long-term effect\u2014has relatively little to do with the prophets, who appear with surprising regularity, but more to do with the development of a group of supporters who are able to institutionalize the movement.\"\n\nThe development of religion has taken different forms in different cultures. Some religions place an emphasis on belief, while others emphasize practice. Some religions focus on the subjective experience of the religious individual, while others consider the activities of the religious community to be most important. Some religions claim to be universal, believing their laws and cosmology to be binding for everyone, while others are intended to be practiced only by a closely defined or localized group. In many places, religion has been associated with public institutions such as education, hospitals, the family, government, and political hierarchies.\n\nAnthropologists John Monoghan and Peter Just state that, \"it seems apparent that one thing religion or belief helps us do is deal with problems of human life that are significant, persistent, and intolerable. One important way in which religious beliefs accomplish this is by providing a set of ideas about how and why the world is put together that allows people to accommodate anxieties and deal with misfortune.\"\n\nCultural system\nWhile religion is difficult to define, one standard model of religion, used in religious studies courses, was proposed by Clifford Geertz, who simply called it a \"cultural system\". A critique of Geertz's model by Talal Asad categorized religion as \"an anthropological category\". Richard Niebuhr's (1894\u20131962) five-fold classification of the relationship between Christ and culture, however, indicates that religion and culture can be seen as two separate systems, though not without some interplay.\n\nSocial constructionism\n\nOne modern academic theory of religion, social constructionism, says that religion is a modern concept that suggests all spiritual practice and worship follows a model similar to the Abrahamic religions as an orientation system that helps to interpret reality and define human beings. Among the main proponents of this theory of religion are Daniel Dubuisson, Timothy Fitzgerald, Talal Asad, and Jason \u0100nanda Josephson. The social constructionists argue that religion is a modern concept that developed from Christianity and was then applied inappropriately to non-Western cultures.\n\nCognitive science\n\nCognitive science of religion is the study of religious thought and behavior from the perspective of the cognitive and evolutionary sciences. The field employs methods and theories from a very broad range of disciplines, including: cognitive psychology, evolutionary psychology, cognitive anthropology, artificial intelligence, cognitive neuroscience, neurobiology, zoology, and ethology.  Scholars in this field seek to explain how human minds acquire, generate, and transmit religious thoughts, practices, and schemas by means of ordinary cognitive capacities.\n\nHallucinations and delusions related to religious content occurs in about 60% of people with schizophrenia. While this number varies across cultures, this had led to theories about a number of influential religious phenomenon and possible relation to psychotic disorders. A number of prophetic experiences are consistent with psychotic symptoms, although retrospective diagnoses are practically impossible. Schizophrenic episodes are also experienced by people who do not have belief in gods.\n\nReligious content is also common in temporal lobe epilepsy, and obsessive-compulsive disorder. Atheistic content is also found to be common with temporal lobe epilepsy.\n\nComparativism\n\nComparative religion is the branch of the study of religions concerned with the systematic comparison of the doctrines and practices of the world's religions. In general, the comparative study of religion yields a deeper understanding of the fundamental philosophical concerns of religion such as ethics, metaphysics, and the nature and form of salvation. Studying such material is meant to give one a richer and more sophisticated understanding of human beliefs and practices regarding the sacred, numinous, spiritual and divine.\n\nIn the field of comparative religion, a common geographical classification of the main world religions includes Middle Eastern religions (including Zoroastrianism and Iranian religions), Indian religions, East Asian religions, African religions, American religions, Oceanic religions, and classical Hellenistic religions.\n\nClassification\n\nIn the 19th and 20th centuries, the academic practice of comparative religion divided religious belief into philosophically defined categories called world religions. Some academics studying the subject have divided religions into three broad categories:\n world religions, a term which refers to transcultural, international religions;\n indigenous religions, which refers to smaller, culture-specific or nation-specific religious groups; and\n new religious movements, which refers to recently developed religions.\n\nSome recent scholarship has argued that not all types of religion are necessarily separated by mutually exclusive philosophies, and furthermore that the utility of ascribing a practice to a certain philosophy, or even calling a given practice religious, rather than cultural, political, or social in nature, is limited. The current state of psychological study about the nature of religiousness suggests that it is better to refer to religion as a largely invariant phenomenon that should be distinguished from cultural norms (i.e. religions).\n\nMorphological classification\nSome scholars classify religions as either universal religions that seek worldwide acceptance and actively look for new converts, such as Christianity, Islam, Buddhism and Jainism, while ethnic religions are identified with a particular ethnic group and do not seek converts. Others reject the distinction, pointing out that all religious practices, whatever their philosophical origin, are ethnic because they come from a particular culture.\n\nDemographical classification\n\nThe five largest religious groups by world population, estimated to account for 5.8 billion people and 84% of the population, are Christianity, Islam, Buddhism, Hinduism (with the relative numbers for Buddhism and Hinduism dependent on the extent of syncretism) and traditional folk religion.\n\nA global poll in 2012 surveyed 57 countries and reported that 59% of the world's population identified as religious, 23% as not religious, 13% as convinced atheists, and also a 9% decrease in identification as religious when compared to the 2005 average from 39 countries. A follow-up poll in 2015 found that 63% of the globe identified as religious, 22% as not religious, and 11% as convinced atheists. On average, women are more religious than men. Some people follow multiple religions or multiple religious principles at the same time, regardless of whether or not the religious principles they follow traditionally allow for syncretism. A 2017 Pew projection suggests that Islam will overtake Christianity as the plurality religion by 2075. Unaffiliated populations are projected to drop, even when taking disaffiliation rates into account, due to differences in birth rates.\n\nSpecific religions\n\nAbrahamic\n\nAbrahamic religions are monotheistic religions which believe they descend from Abraham.\n\nJudaism\n\nJudaism is the oldest Abrahamic religion, originating in the people of ancient Israel and Judea. The Torah is its foundational text, and is part of the larger text known as the Tanakh or Hebrew Bible. It is supplemented by oral tradition, set down in written form in later texts such as the Midrash and the Talmud. Judaism includes a wide corpus of texts, practices, theological positions, and forms of organization. Within Judaism there are a variety of movements, most of which emerged from Rabbinic Judaism, which holds that God revealed his laws and commandments to Moses on Mount Sinai in the form of both the Written and Oral Torah; historically, this assertion was challenged by various groups. The Jewish people were scattered after the destruction of the Temple in Jerusalem in 70 CE. Today there are about 13 million Jews, about 40 per cent living in Israel and 40 per cent in the United States. The largest Jewish religious movements are Orthodox Judaism (Haredi Judaism and Modern Orthodox Judaism), Conservative Judaism and Reform Judaism.\n\nChristianity\n\nChristianity is based on the life and teachings of Jesus of Nazareth (1st century) as presented in the New Testament. The Christian faith is essentially faith in Jesus as the Christ, the Son of God, and as Savior and Lord. Almost all Christians believe in the Trinity, which teaches the unity of Father, Son (Jesus Christ), and Holy Spirit as three persons in one Godhead. Most Christians can describe their faith with the Nicene Creed. As the religion of Byzantine Empire in the first millennium and of Western Europe during the time of colonization, Christianity has been propagated throughout the world via missionary work. It is the world's largest religion, with about 2.3 billion followers as of 2015. The main divisions of Christianity are, according to the number of adherents:\n The Catholic Church, led by the Bishop of Rome and the bishops worldwide in communion with him, is a communion of 24 Churches sui iuris, including the Latin Church and 23 Eastern Catholic churches, such as the Maronite Catholic Church.\n Eastern Christianity, which include Eastern Orthodoxy, Oriental Orthodoxy, and the Church of the East.\n Protestantism, separated from the Catholic Church in the 16th-century Protestant Reformation and is split into thousands of denominations.  Major branches of Protestantism include Anglicanism, Baptists, Calvinism, Lutheranism, and Methodism, though each of these contain many different denominations or groups.\n\nThere are also smaller groups, including:\n Restorationism, the belief that Christianity should be restored (as opposed to reformed) along the lines of what is known about the apostolic early church.\n Latter-day Saint movement, founded by Joseph Smith in the late 1820s.\n Jehovah's Witnesses, founded in the late 1870s by Charles Taze Russell.\n\nIslam \n\nIslam is a monotheistic religion based on the Quran, one of the holy books considered by Muslims to be revealed by God, and on the teachings (hadith) of the Islamic prophet Muhammad, a major political and religious figure of the 7th century CE. Islam is based on the unity of all religious philosophies and accepts all of the Abrahamic prophets of Judaism, Christianity and other Abrahamic religions before Muhammad. It is the most widely practiced religion of Southeast Asia, North Africa, Western Asia, and Central Asia, while Muslim-majority countries also exist in parts of South Asia, Sub-Saharan Africa, and Southeast Europe. There are also several Islamic republics, including Iran, Pakistan, Mauritania, and Afghanistan.\n Sunni Islam is the largest denomination within Islam and follows the Qur'an, the ahadith (ar: plural of Hadith) which record the sunnah, whilst placing emphasis on the sahabah.\n Shia Islam is the second largest denomination of Islam and its adherents believe that Ali succeeded Muhammad and further places emphasis on Muhammad's family.\n There are also Muslim revivalist movements such as Muwahhidism and Salafism.\n\nOther denominations of Islam include Nation of Islam, Ibadi, Sufism, Quranism, Mahdavia, and non-denominational Muslims. Wahhabism is the dominant Muslim schools of thought in the Kingdom of Saudi Arabia.\n\nOther\nWhilst Judaism, Christianity and Islam are commonly seen as the only three Abrahamic faiths, there are smaller and newer traditions which lay claim to the designation as well.\n\nFor example, the Bah\u00e1\u02bc\u00ed Faith is a new religious movement that has links to the major Abrahamic religions as well as other religions (e.g. of Eastern philosophy). Founded in 19th-century Iran, it teaches the unity of all religious philosophies and accepts all of the prophets of Judaism, Christianity, and Islam as well as additional prophets (Buddha, Mahavira), including its founder Bah\u00e1'u'll\u00e1h. It is an offshoot of B\u00e1bism. One of its divisions is the Orthodox Bah\u00e1\u02bc\u00ed Faith.\n\nEven smaller regional Abrahamic groups also exist, including Samaritanism (primarily in Israel and the West Bank), the Rastafari movement (primarily in Jamaica), and Druze (primarily in Syria, Lebanon, and Israel). The Druze faith originally developed out of Isma'ilism, and it has sometimes been considered an Islamic school by some Islamic authorities, but Druze themselves do not identify as Muslims. Mandaeism, also known as Sabianism, is a Gnostic, monotheistic and ethnic religion.  Its adherents, the Mandaeans, consider John the Baptist to be their chief prophet. Mandaeans are the last surviving Gnostics from antiquity.\n\nEast Asian\n\nEast Asian religions (also known as Far Eastern religions or Taoic religions) consist of several religions of East Asia which make use of the concept of Tao (in Chinese), D\u014d (in Japanese or Korean) or \u0110\u1ea1o (in Vietnamese). They include:\n\nTaoism and Confucianism\n Taoism and Confucianism, as well as Korean, Vietnamese, and Japanese religion influenced by Chinese thought.\n\nFolk religions\n Chinese folk religion: the indigenous religions of the Han Chinese, or, by metonymy, of all the populations of the Chinese cultural sphere. It includes the syncretism of Confucianism, Taoism and Buddhism, Wuism, as well as many new religious movements such as Chen Tao, Falun Gong and Yiguandao.\n Other folk and new religions of East Asia and Southeast Asia such as Korean shamanism, Chondogyo, and Jeung San Do in Korea; indigenous Philippine folk religions  in the Philippines; Shinto, Shugendo, Ryukyuan religion, and Japanese new religions in Japan; Satsana Phi in Laos; Cao \u0110\u00e0i, H\u00f2a H\u1ea3o, and Vietnamese folk religion in Vietnam.\n\nIndian religions\nIndian religions are practiced or were founded in the Indian subcontinent. They are sometimes classified as the dharmic religions, as they all feature dharma, the specific law of reality and duties expected according to the religion.\n\nHinduism\n\n \nHinduism is also called Vaidika Dharma, the dharma of the Vedas. It is a synecdoche describing the similar philosophies of Vaishnavism, Shaivism, and related groups practiced or founded in the Indian subcontinent. Concepts most of them share in common include karma, caste, reincarnation, mantras, yantras, and dar\u015bana. Hinduism is one of the most ancient of still-active religions, with origins perhaps as far back as prehistoric times. Hinduism is not a monolithic religion but a religious category containing dozens of separate philosophies amalgamated as San\u0101tana Dharma, which is the name by which Hinduism has been known throughout history by its followers.\n\nJainism\n\n Jainism, taught primarily by Rishabhanatha (the founder of ahimsa) is an ancient Indian religion that prescribes a path of non-violence, truth and anekantavada for all forms of living beings in this universe; which helps them to eliminate all the Karmas, and hence to attain freedom from the cycle of birth and death (sa\u1e43s\u0101ra), that is, achieving nirvana. Jains are found mostly in India. According to Dundas, outside of the Jain tradition, historians date the Mahavira as about contemporaneous with the Buddha in the 5th-century BCE, and accordingly the historical Parshvanatha, based on the c. 250-year gap, is placed in 8th or 7th century BCE.\n Digambara Jainism (or sky-clad) is mainly practiced in South India. Their holy books are Pravachanasara and Samayasara written by their Prophets Kundakunda and Amritchandra as their original canon is lost.\n Shwetambara Jainism (or white-clad) is mainly practiced in Western India. Their holy books are Jain Agamas, written by their Prophet Sthulibhadra.\n\nBuddhism \n\nBuddhism was founded by Siddhartha Gautama in the 5th century BCE. Buddhists generally agree that Gotama aimed to help sentient beings end their suffering (dukkha) by understanding the true nature of phenomena, thereby escaping the cycle of suffering and rebirth (sa\u1e43s\u0101ra), that is, achieving nirvana.\nTheravada Buddhism, which is practiced mainly in Sri Lanka and Southeast Asia alongside folk religion, shares some characteristics of Indian religions. It is based in a large collection of texts called the Pali Canon.\n Mahayana Buddhism (or the Great Vehicle) under which are a multitude of doctrines that became prominent in China and are still relevant in Vietnam, Korea, Japan and to a lesser extent in Europe and the United States. Mahayana Buddhism includes such disparate teachings as Zen, Pure Land, and Soka Gakkai.\n Vajrayana Buddhism first appeared in India in the 3rd century CE. It is currently most prominent in the Himalaya regions and extends across all of Asia (cf. Mikky\u014d).\n Two notable new Buddhist sects are H\u00f2a H\u1ea3o and the Navayana (Dalit Buddhist movement), which were developed separately in the 20th century.\n\nSikhism\n\n Sikhism is a panentheistic religion founded on the teachings of Guru Nanak and ten successive Sikh gurus in 15th-century Punjab. It is the fifth-largest organized religion in the world, with approximately 30 million Sikhs. Sikhs are expected to embody the qualities of a Sant-Sip\u0101h\u012b\u2014a saint-soldier, have control over one's internal vices and be able to be constantly immersed in virtues clarified in the Guru Granth Sahib. The principal beliefs of Sikhi are faith in Waheguru\u2014represented by the phrase ik \u014da\u1e45k\u0101r, meaning one God, who prevails in everything, along with a praxis in which the Sikh is enjoined to engage in social reform through the pursuit of justice for all human beings.\n\nIndigenous and folk\n\nIndigenous religions or folk religions refers to a broad category of traditional religions that can be characterised by shamanism, animism and ancestor worship, where traditional means \"indigenous, that which is aboriginal or foundational, handed down from generation to generation\u2026\". These are religions that are closely associated with a particular group of people, ethnicity or tribe; they often have no formal creeds or sacred texts. Some faiths are syncretic, fusing diverse religious beliefs and practices.\n Australian Aboriginal religions.\n Folk religions of the Americas: Native American religions\n\nFolk religions are often omitted as a category in surveys even in countries where they are widely practiced, e.g. in China.\n\nTraditional African\n\nAfrican traditional religion encompasses the traditional religious beliefs of people in Africa. In West Africa, these religions include the Akan religion, Dahomey (Fon) mythology, Efik mythology, Odinani, Serer religion (A \u01adat Roog), and Yoruba religion, while Bushongo mythology, Mbuti (Pygmy) mythology, Lugbara mythology, Dinka religion, and Lotuko mythology come from central Africa. Southern African traditions include Akamba mythology, Masai mythology, Malagasy mythology, San religion, Lozi mythology, Tumbuka mythology, and Zulu mythology. Bantu mythology is found throughout central, southeast, and southern Africa. In north Africa, these traditions include Berber and ancient Egyptian.\n\nThere are also notable African diasporic religions practiced in the Americas, such as Santeria, Candomble, Vodun, Lucumi, Umbanda, and Macumba.\n\nIranian\nIranian religions are ancient religions whose roots predate the Islamization of Greater Iran. Nowadays these religions are practiced only by minorities.\n\nZoroastrianism is based on the teachings of prophet Zoroaster in the 6th century BCE. Zoroastrians worship the creator Ahura Mazda. In Zoroastrianism, good and evil have distinct sources, with evil trying to destroy the creation of Mazda, and good trying to sustain it.\n\nKurdish religions include the traditional beliefs of the Yazidi, Alevi, and Ahl-e Haqq. Sometimes these are labeled Yazd\u00e2nism.\n\nNew religious movements\n\n The Bah\u00e1\u02bc\u00ed Faith teaches the unity of all religious philosophies.\n Cao \u0110\u00e0i is a syncretistic, monotheistic religion, established in Vietnam in 1926.\n Eckankar is a pantheistic religion with the purpose of making God an everyday reality in one's life.\n Epicureanism is a Hellenistic philosophy that is considered by many of its practitioners as a type of (sometimes non-theistic) religious identity. It has its own scriptures, a monthly \"feast of reason\" on the Twentieth, and considers friendship to be holy.\n Hindu reform movements, such as Ayyavazhi, Swaminarayan Faith and Ananda Marga, are examples of new religious movements within Indian religions.\n Japanese new religions (shinshukyo) is a general category for a wide variety of religious movements founded in Japan since the 19th century. These movements share almost nothing in common except the place of their founding. The largest religious movements centered in Japan include Soka Gakkai, Tenrikyo, and Seicho-No-Ie among hundreds of smaller groups.\n Jehovah's Witnesses, a non-trinitarian Christian Reformist movement sometimes described as millenarian.\n Neo-Druidism is a religion promoting harmony with nature, and drawing on the practices of the druids.\n There are various Neopagan movements that attempt to reconstruct or revive ancient pagan practices. These include Heathenry, Hellenism, and Kemeticism.\n Noahidism is a monotheistic ideology based on the Seven Laws of Noah, and on their traditional interpretations within Rabbinic Judaism.\n Some forms of parody religion or fiction-based religion like Jediism, Pastafarianism, Dudeism, \"Tolkien religion\", and others often develop their own writings, traditions, and cultural expressions, and end up behaving like traditional religions.\n Satanism is a broad category of religions that, for example, worship Satan as a deity (Theistic Satanism) or use Satan as a symbol of carnality and earthly values (LaVeyan Satanism and The Satanic Temple).\n Scientology is a religious movement that teaches that people are immortal beings who have forgotten their true nature. Its method of spiritual rehabilitation is a type of counseling known as auditing, in which practitioners aim to consciously re-experience and understand painful or traumatic events and decisions in their past in order to free themselves of their limiting effects. \n UFO Religions in which extraterrestrial entities are an element of belief, such as Ra\u00eblism, Aetherius Society, and Marshall Vian Summers's New Message from God\n Unitarian Universalism is a religion characterized by support for a free and responsible search for truth and meaning, and has no accepted creed or theology.\n Wicca is a neo-pagan religion first popularised in 1954 by British civil servant Gerald Gardner, involving the worship of a God and Goddess.\n\nRelated aspects\n\nLaw\n\nThe study of law and religion is a relatively new field, with several thousand scholars involved in law schools, and academic departments including political science, religion, and history since 1980. Scholars in the field are not only focused on strictly legal issues about religious freedom or non-establishment, but also study religions as they are qualified through judicial discourses or legal understanding of religious phenomena. Exponents look at canon law, natural law, and state law, often in a comparative perspective. Specialists have explored themes in Western history regarding Christianity and justice and mercy, rule and equity, and discipline and love. Common topics of interest include marriage and the family and human rights. Outside of Christianity, scholars have looked at law and religion links in the Muslim Middle East and pagan Rome.\n\nStudies have focused on secularization. In particular, the issue of wearing religious symbols in public, such as headscarves that are banned in French schools, have received scholarly attention in the context of human rights and feminism.\n\nScience\n\nScience acknowledges reason and empirical evidence; and religions include revelation, faith and sacredness whilst also acknowledging philosophical and metaphysical explanations with regard to the study of the universe. Both science and religion are not monolithic, timeless, or static because both are complex social and cultural endeavors that have changed through time across languages and cultures.\n\nThe concepts of science and religion are a recent invention: the term religion emerged in the 17th century in the midst of colonization and globalization and the Protestant Reformation. The term science emerged in the 19th century out of natural philosophy in the midst of attempts to narrowly define those who studied nature (natural science), and the phrase religion and science emerged in the 19th century due to the reification of both concepts. It was in the 19th century that the terms Buddhism, Hinduism, Taoism, and Confucianism first emerged. In the ancient and medieval world, the etymological Latin roots of both science (scientia) and religion (religio) were understood as inner qualities of the individual or virtues, never as doctrines, practices, or actual sources of knowledge.\n\nIn general the scientific method gains knowledge by testing hypotheses to develop theories through elucidation of facts or evaluation by experiments and thus only answers cosmological questions about the universe that can be observed and measured. It develops theories of the world which best fit physically observed evidence. All scientific knowledge is subject to later refinement, or even rejection, in the face of additional evidence. Scientific theories that have an overwhelming preponderance of favorable evidence are often treated as de facto verities in general parlance, such as the theories of general relativity and natural selection to explain respectively the mechanisms of gravity and evolution.\n\nReligion does not have a method per se partly because religions emerge through time from diverse cultures and it is an attempt to find meaning in the world, and to explain humanity's place in it and relationship to it and to any posited entities. In terms of Christian theology and ultimate truths, people rely on reason, experience, scripture, and tradition to test and gauge what they experience and what they should believe. Furthermore, religious models, understanding, and metaphors are also revisable, as are scientific models.\n\nRegarding religion and science, Albert Einstein states (1940): \"For science can only ascertain what is, but not what should be, and outside of its domain value judgments of all kinds remain necessary. Religion, on the other hand, deals only with evaluations of human thought and action; it cannot justifiably speak of facts and relationships between facts\u2026Now, even though the realms of religion and science in themselves are clearly marked off from each other, nevertheless there exist between the two strong reciprocal relationships and dependencies. Though religion may be that which determine the goals, it has, nevertheless, learned from science, in the broadest sense, what means will contribute to the attainment of the goals it has set up.\"\n\nMorality \n\nMany religions have value frameworks regarding personal behavior meant to guide adherents in determining between right and wrong. These include the Triple Jems of Jainism, Judaism's Halacha, Islam's Sharia, Catholicism's Canon Law, Buddhism's Eightfold Path, and Zoroastrianism's good thoughts, good words, and good deeds concept, among others.\n\nReligion and morality are not synonymous. While it is \"an almost automatic assumption.\" in Christianity, morality can have a secular basis.\n\nThe study of religion and morality can be contentious due to ethnocentric views on morality, failure to distinguish between in group and out group altruism, and inconsistent definitions of religiosity.\n\nPolitics\n\nImpact\n\nReligion has had a significant impact on the political system in many countries. Notably, most Muslim-majority countries adopt various aspects of sharia, the Islamic law. Some countries even define themselves in religious terms, such as The Islamic Republic of Iran. The sharia thus affects up to 23% of the global population, or 1.57\u00a0billion people who are Muslims. However, religion also affects political decisions in many western countries. For instance, in the United States, 51% of voters would be less likely to vote for a presidential candidate who did not believe in God, and only 6% more likely. Christians make up 92% of members of the US Congress, compared with 71% of the general public (as of 2014). At the same time, while 23% of U.S. adults are religiously unaffiliated, only one member of Congress (Kyrsten Sinema, D-Arizona), or 0.2% of that body, claims no religious affiliation. In most European countries, however, religion has a much smaller influence on politics although it used to be much more important. For instance, same-sex marriage and abortion were illegal in many European countries until recently, following Christian (usually Catholic) doctrine. Several European leaders are atheists (e.g. France's former president Francois Hollande or Greece's prime minister Alexis Tsipras). In Asia, the role of religion differs widely between countries. For instance, India is still one of the most religious countries and religion still has a strong impact on politics, given that Hindu nationalists have been targeting minorities like the Muslims and the Christians, who historically belonged to the lower castes. By contrast, countries such as China or Japan are largely secular and thus religion has a much smaller impact on politics.\n\nSecularism\n\nSecularization is the transformation of the politics of a society from close identification with a particular religion's values and institutions toward nonreligious values and secular institutions. The purpose of this is frequently modernization or protection of the populations religious diversity.\n\nEconomics\n\nOne study has found there is a negative correlation between self-defined religiosity and the wealth of nations. In other words, the richer a nation is, the less likely its inhabitants to call themselves religious, whatever this word means to them (Many people identify themselves as part of a religion (not irreligion) but do not self-identify as religious).\n\nSociologist and political economist Max Weber has argued that Protestant Christian countries are wealthier because of their Protestant work ethic. According to a study from 2015, Christians hold the largest amount of wealth (55% of the total world wealth), followed by Muslims (5.8%), Hindus (3.3%) and Jews (1.1%). According to the same study it was found that adherents under the classification Irreligion or other religions hold about 34.8% of the total global wealth (while making up only about 20% of the world population, see section on classification).\n\nHealth\n\nMayo Clinic researchers examined the association between religious involvement and spirituality, and physical health, mental health, health-related quality of life, and other health outcomes. The authors reported that: \"Most studies have shown that religious involvement and spirituality are associated with better health outcomes, including greater longevity, coping skills, and health-related quality of life (even during terminal illness) and less anxiety, depression, and suicide.\"\n\nThe authors of a subsequent study concluded that the influence of religion on health is largely beneficial, based on a review of related literature. According to academic James W. Jones, several studies have discovered \"positive correlations between religious belief and practice and mental and physical health and longevity.\"\n\nAn analysis of data from the 1998 US General Social Survey, whilst broadly confirming that religious activity was associated with better health and well-being, also suggested that the role of different dimensions of spirituality/religiosity in health is rather more complicated. The results suggested \"that it may not be appropriate to generalize findings about the relationship between spirituality/religiosity and health from one form of spirituality/religiosity to another, across denominations, or to assume effects are uniform for men and women.\n\nViolence\n\nCritics like Hector Avalos Regina Schwartz, Christopher Hitchens and Richard Dawkins have argued that religions are inherently violent and harmful to society by using violence to promote their goals, in ways that are endorsed and exploited by their leaders.\n\nAnthropologist Jack David Eller asserts that religion is not inherently violent, arguing \"religion and violence are clearly compatible, but they are not identical.\" He asserts that \"violence is neither essential to nor exclusive to religion\" and that \"virtually every form of religious violence has its nonreligious corollary.\"\n\nAnimal sacrifice \n\nDone by some (but not all) religions, animal sacrifice is the ritual killing and offering of an animal to appease or maintain favour with a deity. It has been banned in India.\n\nSuperstition \n\nGreek and Roman pagans, who saw their relations with the gods in political and social terms, scorned the man who constantly trembled with fear at the thought of the gods (deisidaimonia), as a slave might fear a cruel and capricious master. The Romans called such fear of the gods superstitio. Ancient Greek historian Polybius described superstition in ancient Rome as an instrumentum regni, an instrument of maintaining the cohesion of the Empire.\n\nSuperstition has been described as the non-rational establishment of cause and effect. Religion is more complex and is often composed of social institutions and has a moral aspect. Some religions may include superstitions or make use of magical thinking. Adherents of one religion sometimes think of other religions as superstition. Some atheists, deists, and skeptics regard religious belief as superstition.\n\nThe Roman Catholic Church considers superstition to be sinful in the sense that it denotes a lack of trust in the divine providence of God and, as such, is a violation of the first of the Ten Commandments. The Catechism of the Catholic Church states that superstition \"in some sense represents a perverse excess of religion\" (para. #2110).  \"Superstition,\" it says, \"is a deviation of religious feeling and of the practices this feeling imposes. It can even affect the worship we offer the true God, e.g., when one attributes an importance in some way magical to certain practices otherwise lawful or necessary. To attribute the efficacy of prayers or of sacramental signs to their mere external performance, apart from the interior dispositions that they demand is to fall into superstition. Cf. Matthew 23:16\u201322\" (para. #2111)\n\nAgnosticism and atheism\n\nThe terms atheist (lack of belief in any gods) and agnostic (belief in the unknowability of the existence of gods), though specifically contrary to theistic (e.g. Christian, Jewish, and Muslim) religious teachings, do not by definition mean the opposite of religious. There are religions (including Buddhism, Taoism, and Hinduism), in fact, that classify some of their followers as agnostic, atheistic, or nontheistic. The true opposite of religious is the word irreligious. Irreligion describes an absence of any religion; antireligion describes an active opposition or aversion toward religions in general.\n\nInterfaith cooperation\n\nBecause religion continues to be recognized in Western thought as a universal impulse, many religious practitioners have aimed to band together in interfaith dialogue, cooperation, and religious peacebuilding. The first major dialogue was the Parliament of the World's Religions at the 1893 Chicago World's Fair, which affirmed universal values and recognition of the diversity of practices among different cultures. The 20th century has been especially fruitful in use of interfaith dialogue as a means of solving ethnic, political, or even religious conflict, with Christian\u2013Jewish reconciliation representing a complete reverse in the attitudes of many Christian communities towards Jews.\n\nRecent interfaith initiatives include A Common Word, launched in 2007 and focused on bringing Muslim and Christian leaders together, the \"C1 World Dialogue\", the Common Ground initiative between Islam and Buddhism, and a United Nations sponsored \"World Interfaith Harmony Week\".\n\nCulture\nCulture and religion have usually been seen as closely related. Paul Tillich looked at religion as the soul of culture and culture as the form or framework of religion. In his own words:\nReligion as ultimate concern is the meaning-giving substance of culture, and culture is the totality of forms in which the basic concern of religion expresses itself. In abbreviation: religion is the substance of culture, culture is the form of religion. Such a consideration definitely prevents the establishment of a dualism of religion and culture. Every religious act, not only in organized religion, but also in the most intimate movement of the soul, is culturally formed.\nErnst Troeltsch, similarly, looked at culture as the soil of religion and thought that, therefore, transplanting a religion from its original culture to a foreign culture would actually kill it in the same manner that transplanting a plant from its natural soil to an alien soil would kill it. However, there have been many attempts in the modern pluralistic situation to distinguish culture from religion. Domenic Marbaniang has argued that elements grounded on beliefs of a metaphysical nature (religious) are distinct from elements grounded on nature and the natural (cultural). For instance, language (with its grammar) is a cultural element while sacralization of language in which a particular religious scripture is written is more often a religious practice. The same applies to music and the arts.\n\nCriticism\n\nCriticism of religion is criticism of the ideas, the truth, or the practice of religion, including its political and social implications.\n\nSee also\n\n Cosmogony\n Index of religion-related articles\n Life stance\n List of foods with religious symbolism\n List of religion-related awards\n List of religious texts\n Nontheistic religions\n Outline of religion\n Parody religions\n Ethics in religion\n Philosophy of religion\n Priest\n Religion and happiness\n Religion and peacebuilding\n Religions by country\n Religious conversion\n Religious discrimination\n Social conditioning\n Socialization\n Temple\n Theocracy\n Theology of religions\n Timeline of religion\n Why is there something rather than nothing?\n The State Museum of the History of Religion\n\nNotes\n\nReferences\n\nSources\n\nPrimary \n Saint Augustine; The Confessions of Saint Augustine (John K. Ryan translator); Image (1960), .\n Lao Tzu; Tao Te Ching (Victor H. Mair translator); Bantam (1998).\n The Holy Bible, King James Version; New American Library (1974).\n The Koran; Penguin (2000), .\n The Origin of Live & Death, African Creation Myths; Heinemann (1966).\n Poems of Heaven and Hell from Ancient Mesopotamia; Penguin (1971).\n Selected Work Marcus Tullius Cicero\n United States Constitution\n\nSecondary \n Barzilai, Gad; Law and Religion; The International Library of Essays in Law and Society; Ashgate (2007), \n \n \n Yves Coppens, Origines de l'homme \u2013 De la mati\u00e8re \u00e0 la conscience, De Vive Voix, Paris, 2010\n Yves Coppens, La preistoria dell'uomo, Jaca Book, Milano, 2011\n Descartes, Ren\u00e9; Meditations on First Philosophy; Bobbs-Merril (1960), .\n Dow, James W. (2007), A Scientific Definition of Religion \n \n Durant, Will (& Ariel (uncredited)); Our Oriental Heritage; MJF Books (1997), .\n Durant, Will (& Ariel (uncredited)); Caesar and Christ; MJF Books (1994), \n Durant, Will (& Ariel (uncredited)); The Age of Faith; Simon & Schuster (1980), .\n \n \n Marija Gimbutas 1989. The Language of the Goddess. Thames and Hudson New York\n Gonick, Larry; The Cartoon History of the Universe; Doubleday, vol. 1 (1978) , vol. II (1994) , W.W. Norton, vol. III (2002) .\n Haisch, Bernard The God Theory: Universes, Zero-point Fields, and What's Behind It All\u2014discussion of science vs. religion (Preface), Red Wheel/Weiser, 2006, \n \n Khanbaghi, A., The Fire, the Star and the Cross: Minority Religions in Medieval and Early Modern Iran  (IB Tauris; 2006) 268 pages. Social, political and cultural history of religious minorities in Iran, c. 226\u20131722 AD.\n King, Winston, Religion [First Edition]. In: Encyclopedia of Religion. Ed. Lindsay Jones. Vol. 11. 2nd ed. Detroit: Macmillan Reference US, 2005. pp.\u00a07692\u20137701.\n Korotayev, Andrey, World Religions and Social Evolution of the Old World Oikumene Civilizations: A Cross-cultural Perspective, Lewiston, NY: Edwin Mellen Press, 2004, .\n \n McKinnon, Andrew M. (2002), \"Sociological Definitions, Language Games and the 'Essence' of Religion\" . Method & theory in the study of religion, vol 14, no. 1, pp.\u00a061\u201383.\n Marx, Karl; \"Introduction to A Contribution to the Critique of Hegel's Philosophy of Right\", Deutsch-Franz\u00f6sische Jahrb\u00fccher, (1844).\n \n\n Palmer, Spencer J., et al. Religions of the World: a Latter-day Saint [Mormon] View. 2nd general ed., tev. and enl. Provo, Utah: Brigham Young University, 1997. xv, 294 p., ill. \n \n Ramsay, Michael, Abp. Beyond Religion? Cincinnati, Ohio: Forward Movement Publications, (cop. 1964).\n Saler, Benson; \"Conceptualizing Religion: Immanent Anthropologists, Transcendent Natives, and Unbounded Categories\" (1990), \n Schuon, Frithjof. The Transcendent Unity of Religions, in series, Quest Books. 2nd Quest ... rev. ed. Wheaton, Ill.: Theosophical Publishing House, 1993, cop. 1984. xxxiv, 173 p. \n \n Smith, Wilfred Cantwell (1962), The Meaning and End of Religion\n \n Wallace, Anthony F.C. 1966. Religion: An Anthropological View. New York: Random House. (pp.\u00a062\u201366)\n The World Almanac (annual), World Almanac Books, .\n The World Almanac (for numbers of adherents of various religions), 2005\n\nFurther reading\n\n \n Noss, John B.; Man's Religions, 6th ed.; Macmillan Publishing Co. (1980). N.B.: The first ed. appeared in 1949, .\n Inglehart, Ronald F., \"Giving Up on God: The Global Decline of Religion\", Foreign Affairs, vol. 99, no. 5 (September / October 2020), pp.\u00a0110\u2013118. \n Lang, Andrew; The Making of Religion, (1898)\n\nExternal links\n\n Religion Statistics from UCB Libraries GovPubs\n \n  by Adherents.com August 2005\n IACSR \u2013 International Association for the Cognitive Science of Religion\n Studying Religion \u2013 Introduction to the methods and scholars of the academic study of religion\n A Contribution to the Critique of Hegel's Philosophy of Right \u2013 Marx's original reference to religion as the opium of the people.\n The Complexity of Religion and the Definition of \"Religion\" in International Law Harvard Human Rights Journal article from the President and Fellows of Harvard College (2003)\n Sociology of Religion Resources\n Video: 5 Religions spreading across the world\n\n \nCulture\nMain topic articles",
  "Technology": "Technology (\"science of craft\", from Greek , techne, \"art, skill, cunning of hand\"; and , -logia) is the sum of any techniques, skills, methods, and processes used in the production of goods or services or in the accomplishment of objectives, such as scientific investigation. Technology can be the knowledge of techniques, processes, and the like, or it can be embedded in machines to allow for operation without detailed knowledge of their workings. Systems (e.g. machines) applying technology by taking an input, changing it according to the system's use, and then producing an outcome are referred to as technology systems or technological systems.\n\nThe simplest form of technology is the development and use of basic tools. The prehistoric invention of shaped stone tools followed by the discovery of how to control fire increased sources of food. The later Neolithic Revolution extended this, and quadrupled the sustenance available from a territory.  The invention of the wheel helped humans to travel in and control their environment.\n\nDevelopments in historic times, including the printing press, the telephone, and the Internet, have lessened physical barriers to communication and allowed humans to interact freely on a global scale.\n\nTechnology has many effects. It has helped develop more advanced economies (including today's global economy) and has allowed the rise of a leisure class. Many technological processes produce unwanted by-products known as pollution and deplete natural resources to the detriment of Earth's environment. Innovations have always influenced the values of a society and raised new questions in the ethics of technology. Examples include the rise of the notion of efficiency in terms of human productivity, and the challenges of bioethics.\n\nPhilosophical debates have arisen over the use of technology, with disagreements over whether technology improves the human condition or worsens it. Neo-Luddism, anarcho-primitivism, and similar reactionary movements criticize the pervasiveness of technology, arguing that it harms the environment and alienates people; proponents of ideologies such as transhumanism and techno-progressivism view continued technological progress as beneficial to society and the human condition.\n\nDefinition and usage \n\nThe use of the term \"technology\" has changed significantly over the last 200 years. Before the 20th century, the term was uncommon in English, and it was used either to refer to the description or study of the useful arts or to allude to technical education, as in the Massachusetts Institute of Technology (chartered in 1861).\n\nThe term \"technology\" rose to prominence in the 20th century in connection with the Second Industrial Revolution. The term's meanings changed in the early 20th century when American social scientists, beginning with Thorstein Veblen, translated ideas from the German concept of Technik into \"technology.\" In German and other European languages, a distinction exists between technik and technologie that is absent in English, which usually translates both terms as \"technology.\" By the 1930s, \"technology\" referred not only to the study of the industrial arts but to the industrial arts themselves.\n\nIn 1937, the American sociologist Read Bain wrote that \"technology includes all tools, machines, utensils, weapons, instruments, housing, clothing, communicating and transporting devices and the skills by which we produce and use them.\" Bain's definition remains common among scholars today, especially social scientists.  Scientists and engineers usually prefer to define technology as applied science, rather than as the things that people make and use. More recently, scholars have borrowed from European philosophers of \"technique\" to extend the meaning of technology to various forms of instrumental reason, as in Foucault's work on technologies of the self (techniques de soi).\n\nDictionaries and scholars have offered a variety of definitions. The Merriam-Webster Learner's Dictionary offers a definition of the term: \"the use of science in industry, engineering, etc., to invent useful things or to solve problems\" and \"a machine, piece of equipment, method, etc., that is created by technology.\" Ursula Franklin, in her 1989 \"Real World of Technology\" lecture, gave another definition of the concept; it is \"practice, the way we do things around here.\" The term is often used to imply a specific field of technology, or to refer to high technology or just consumer electronics, rather than technology as a whole. Bernard Stiegler, in Technics and Time, 1, defines technology in two ways: as \"the pursuit of life by means other than life,\" and as \"organized inorganic matter.\"\n\nTechnology can be most broadly defined as the entities, both material and immaterial, created by the application of mental and physical effort in order to achieve some value. In this usage, technology refers to tools and machines that may be used to solve real-world problems. It is a far-reaching term that may include simple tools, such as a crowbar or wooden spoon, or more complex machines, such as a space station or particle accelerator. Tools and machines need not be material; virtual technology, such as computer software and business methods, fall under this definition of technology. W. Brian Arthur defines technology in a similarly broad way as \"a means to fulfill a human purpose.\"\n\nThe word \"technology\" can also be used to refer to a collection of techniques. In this context, it is the current state of humanity's knowledge of how to combine resources to produce desired products, to solve problems, fulfill needs, or satisfy wants; it includes technical methods, skills, processes, techniques, tools and raw materials. When combined with another term, such as \"medical technology\" or \"space technology,\" it refers to the state of the respective field's knowledge and tools. \"State-of-the-art technology\" refers to the high technology available to humanity in any field.\n\nTechnology can be viewed as an activity that forms or changes culture. Additionally, technology is the application of mathematics, science, and the arts for the benefit of life as it is known. A modern example is the rise of communication technology, which has lessened barriers to human interaction and as a result has helped spawn new subcultures; the rise of cyberculture has at its basis the development of the Internet and the computer. As a cultural activity, technology predates both science and engineering, each of which formalize some aspects of technological endeavor. In this sense, it remains connected with artistic endeavors.\n\nScience, engineering, and technology\n\nThe distinction between science, engineering, and technology is not always clear. Science is systematic knowledge of the physical or material world gained through observation and experimentation. Technologies are not usually exclusively products of science, because they have to satisfy requirements such as utility, usability, and safety.\n\nEngineering is the goal-oriented process of designing and making tools and systems to exploit natural phenomena for practical human means, often (but not always) using results and techniques from science. The development of technology may draw upon many fields of knowledge, including scientific, engineering, mathematical, linguistic, and historical knowledge, to achieve some practical result.\n\nTechnology is often a consequence of science and engineering, although technology as a human activity precedes the two fields. For example, science might study the flow of electrons in electrical conductors by using already-existing tools and knowledge. This new-found knowledge may then be used by engineers to create new tools and machines such as semiconductors, computers, and other forms of advanced technology. In this sense, scientists and engineers may both be considered technologists; the three fields are often considered as one for the purposes of research and reference.\n\nThe exact relations between science and technology, in particular, have been debated by scientists, historians, and policymakers in the late 20th century, in part because the debate can inform the funding of basic and applied science. In the immediate wake of World War II, for example, it was widely considered in the United States that technology was simply \"applied science\" and that to fund basic science was to reap technological results in due time. An articulation of this philosophy could be found explicitly in Vannevar Bush's treatise on postwar science policy, Science \u2013 The Endless Frontier: \"New products, new industries, and more jobs require continuous additions to knowledge of the laws of nature\u00a0... This essential new knowledge can be obtained only through basic scientific research.\" In the late-1960s, however, this view came under direct attack, leading towards initiatives to fund science for specific tasks (initiatives resisted by the scientific community). The issue remains contentious, though most analysts resist the model that technology is a result of scientific research.\n\nHistory\n\nPaleolithic (2.5 Ma\u00a0\u2013 10 ka)\n\nThe use of tools by early humans was partly a process of discovery and of evolution. Early humans evolved from a species of foraging hominids which were already bipedal, with a brain mass approximately one third of modern humans. Tool use remained relatively unchanged for most of early human history. Approximately 50,000 years ago, the use of tools and a complex set of behaviors emerged, believed by many archaeologists to be connected to the emergence of fully modern language.\n\nStone tools\n\nHominids started using primitive stone tools millions of years ago. The earliest stone tools were little more than a fractured rock, but approximately 75,000 years ago, pressure flaking provided a way to make much finer work.\n\nFire\n\nThe discovery and use of fire, a simple energy source with many profound uses, was a turning point in the technological evolution of humankind. The exact date of its discovery is not known; evidence of burnt animal bones at the Cradle of Humankind suggests that the domestication of fire occurred before 1 Ma; scholarly consensus indicates that Homo erectus had controlled fire by between 500 and 400 ka. Fire, fueled with wood and charcoal, allowed early humans to cook their food to increase its digestibility, improving its nutrient value and broadening the number of foods that could be eaten.\n\nClothing and shelter\nOther technological advances made during the Paleolithic era were clothing and shelter; the adoption of both technologies cannot be dated exactly, but they were a key to humanity's progress. As the Paleolithic era progressed, dwellings became more sophisticated and more elaborate; as early as 380 ka, humans were constructing temporary wood huts. Clothing, adapted from the fur and hides of hunted animals, helped humanity expand into colder regions; humans began to migrate\nout of Africa by 200 ka and into other continents such as Eurasia.\n\nNeolithic through classical antiquity (10 ka\u00a0\u2013 300 CE) \n\nHuman's technological ascent began in earnest in what is known as the Neolithic Period (\"New Stone Age\"). The invention of polished stone axes was a major advance that allowed forest clearance on a large scale to create farms. This use of polished stone axes increased greatly in the Neolithic, but were originally used in the preceding Mesolithic in some areas such as Ireland. Agriculture fed larger populations, and the transition to sedentism allowed simultaneously raising more children, as infants no longer needed to be carried, as nomadic ones must. Additionally, children could contribute labor to the raising of crops more readily than they could to the hunter-gatherer economy.\n\nWith this increase in population and availability of labor came an increase in labor specialization. What triggered the progression from early Neolithic villages to the first cities, such as Uruk, and the first civilizations, such as Sumer, is not specifically known; however, the emergence of increasingly hierarchical social structures and specialized labor, of trade and war amongst adjacent cultures, and the need for collective action to overcome environmental challenges such as irrigation, are all thought to have played a role.\n\nMetal tools\nContinuing improvements led to the furnace and bellows and provided, for the first time, the ability to smelt and forge gold, copper, silver, and lead native metals found in relatively pure form in nature. The advantages of copper tools over stone, bone, and wooden tools were quickly apparent to early humans, and native copper was probably used from near the beginning of Neolithic times (about 10 ka). Native copper does not naturally occur in large amounts, but copper ores are quite common and some of them produce metal easily when burned in wood or charcoal fires. Eventually, the working of metals led to the discovery of alloys such as bronze and brass (about 4000 BCE). The first uses of iron alloys such as steel dates to around 1800 BCE.\n\nEnergy and transport\n\nMeanwhile, humans were learning to harness other forms of energy. The earliest known use of wind power is the sailing ship; the earliest record of a ship under sail is that of a Nile boat dating to the 8th-millennium BCE. From prehistoric times, Egyptians probably used the power of the annual flooding of the Nile to irrigate their lands, gradually learning to regulate much of it through purposely built irrigation channels and \"catch\" basins. The ancient Sumerians in Mesopotamia used a complex system of canals and levees to divert water from the Tigris and Euphrates rivers for irrigation.\n\nAccording to archaeologists, the wheel was invented around 4000 BCE probably independently and nearly simultaneously in Mesopotamia (in present-day Iraq), the Northern Caucasus (Maykop culture) and Central Europe. Estimates on when this may have occurred range from 5500 to 3000 BCE with most experts putting it closer to 4000 BCE. The oldest artifacts with drawings depicting wheeled carts date from about 3500 BCE; however, the wheel may have been in use for millennia before these drawings were made. More recently, the oldest-known wooden wheel in the world was found in the Ljubljana marshes of Slovenia.\n\nThe invention of the wheel revolutionized trade and war. It did not take long to discover that wheeled wagons could be used to carry heavy loads. The ancient Sumerians used the potter's wheel and may have invented it. A stone pottery wheel found in the city-state of Ur dates to around 3429 BCE, and even older fragments of wheel-thrown pottery have been found in the same area. Fast (rotary) potters' wheels enabled early mass production of pottery, but it was the use of the wheel as a transformer of energy (through water wheels, windmills, and even treadmills) that revolutionized the application of nonhuman power sources. The first two-wheeled carts were derived from travois and were first used in Mesopotamia and Iran in around 3000 BCE.\n\nThe oldest known constructed roadways are the stone-paved streets of the city-state of Ur, dating to circa 4000 BCE and timber roads leading through the swamps of Glastonbury, England, dating to around the same time period. The first long-distance road, which came into use around 3500 BCE, spanned 1,500 miles from the Persian Gulf to the Mediterranean Sea, but was not paved and was only partially maintained. In around 2000 BCE, the Minoans on the Greek island of Crete built a fifty-kilometer (thirty-mile) road leading from the palace of Gortyn on the south side of the island, through the mountains, to the palace of Knossos on the north side of the island. Unlike the earlier road, the Minoan road was completely paved.\n\nPlumbing\n\nAncient Minoan private homes had running water. A bathtub virtually identical to modern ones was unearthed at the Palace of Knossos. Several Minoan private homes also had toilets, which could be flushed by pouring water down the drain. The ancient Romans had many public flush toilets, which emptied into an extensive sewage system. The primary sewer in Rome was the Cloaca Maxima; construction began on it in the sixth century BCE and it is still in use today.\n\nThe ancient Romans also had a complex system of aqueducts, which were used to transport water across long distances. The first Roman aqueduct was built in 312 BCE. The eleventh and final ancient Roman aqueduct was built in 226 CE. Put together, the Roman aqueducts extended over 450 kilometers, but less than seventy kilometers of this was above ground and supported by arches.\n\nMedieval and modern history (300 CE\u00a0\u2013 present) \n\nInnovations continued through the Middle Ages with innovations such as silk-manufacture (introduced into Europe after centuries of development in Asia), the horse collar and horseshoes in the first few hundred years after the 5th-century fall of the Roman Empire. Medieval technology saw the use of simple machines (such as the lever, the screw, and the pulley) being combined to form more complicated tools, such as the wheelbarrow, windmills and clocks, and a system of universities developed and spread scientific ideas and practices. The Renaissance era produced many innovations, including the printing press (which facilitated the communication of knowledge), and technology became increasingly associated with science, beginning a cycle of mutual advancement. Advances in technology in this era allowed a more reliable supply of food, followed by the wider availability of consumer goods.\n\nStarting in the United Kingdom in the 18th century, the Industrial Revolution was a period of great technological discovery, particularly in the areas of agriculture, manufacturing, mining, metallurgy, and transport, driven by the discovery of steam power and the widespread application of the factory system. Technology took another step in a second industrial revolution ( to ) with the harnessing of electricity to allow such innovations as the electric motor, light bulb, and countless others. Scientific advances and the discovery of new concepts later allowed for powered flight and developments in medicine, chemistry, physics, and engineering. The rise in technology has led to skyscrapers and broad urban areas whose inhabitants rely on motors to transport them and their food supplies. Communication improved with the invention of the telegraph, telephone, radio and television. The late-19th and early-20th centuries saw a revolution in transportation with the invention of the airplane and automobile.\n\nThe 20th century brought a host of innovations. In physics, the discovery of nuclear fission has led to both nuclear weapons and nuclear power. Computers were invented and later miniaturized using transistors and integrated circuits. Information technology, particularly the optical fiber and optical amplifiers that led to the birth of the Internet, which ushered in the Information Age. Humans started to explore space with satellites (late 1950s, later used for telecommunication) and in crewed missions (1960s) going all the way to the moon. In medicine, this era brought innovations such as open-heart surgery and later stem-cell therapy along with new medications and treatments using genomics.\n\nComplex manufacturing and construction techniques and organizations are needed to make and maintain some of the newer technologies, and entire industries have arisen to support and develop succeeding generations of increasingly more complex tools. Modern technology increasingly relies on training and education\u00a0\u2013 their designers, builders, maintainers, and users often require sophisticated general and specific training. Moreover, these technologies have become so complex that entire fields have developed to support them, including engineering, medicine, and computer science; and other fields have become more complex, such as construction, transportation, and architecture.\n\nPhilosophy\n\nTechnicism\nGenerally, technicism is the belief in the utility of technology for improving human societies. Taken to an extreme, technicism \"reflects a fundamental attitude which seeks to control reality, to resolve all problems with the use of scientific\u2013technological methods and tools.\" In other words, human beings will someday be able to master all problems and possibly even control the future using technology. Some, such as Stephen V. Monsma, connect these ideas to the abdication of religion as a higher moral authority.\n\nOptimism\n\nOptimistic assumptions are made by proponents of ideologies such as transhumanism and singularitarianism, which view technological development as generally having beneficial effects for the society and the human condition. In these ideologies, technological development is morally good.\n\nTranshumanists generally believe that the point of technology is to overcome barriers, and that what we commonly refer to as the human condition is just another barrier to be surpassed.\n\nSingularitarians believe in some sort of \"accelerating change\"; that the rate of technological progress accelerates as we obtain more technology, and that this will culminate in a \"Singularity\" after artificial general intelligence is invented in which progress is nearly infinite; hence the term. Estimates for the date of this Singularity vary, but prominent futurist Ray Kurzweil estimates the Singularity will occur in 2045.\n\nKurzweil is also known for his history of the universe in six epochs: (1) the physical/chemical epoch, (2) the life epoch, (3) the human/brain epoch, (4) the technology epoch, (5) the artificial intelligence epoch, and (6) the universal colonization epoch. Going from one epoch to the next is a Singularity in its own right, and a period of speeding up precedes it. Each epoch takes a shorter time, which means the whole history of the universe is one giant Singularity event.\n\nSome critics see these ideologies as examples of scientism and techno-utopianism and fear the notion of human enhancement and technological singularity which they support. Some have described Karl Marx as a techno-optimist.\n\nSkepticism and critics\n\nOn the somewhat skeptical side are certain philosophers like Herbert Marcuse and John Zerzan, who believe that technological societies are inherently flawed. They suggest that the inevitable result of such a society is to become evermore technological at the cost of freedom and psychological health.\n\nMany, such as the Luddites and prominent philosopher Martin Heidegger, hold serious, although not entirely, deterministic reservations about technology (see \"The Question Concerning Technology\"). According to Heidegger scholars Hubert Dreyfus and Charles Spinosa, \"Heidegger does not oppose technology. He hopes to reveal the essence of technology in a way that 'in no way confines us to a stultified compulsion to push on blindly with technology or, what comes to the same thing, to rebel helplessly against it.' Indeed, he promises that 'when we once open ourselves expressly to the essence of technology, we find ourselves unexpectedly taken into a freeing claim.' What this entails is a more complex relationship to technology than either techno-optimists or techno-pessimists tend to allow.\"\n\nSome of the most poignant criticisms of technology are found in what are now considered to be dystopian literary classics such as Aldous Huxley's Brave New World, Anthony Burgess's A Clockwork Orange, and George Orwell's Nineteen Eighty-Four. In Goethe's Faust, Faust selling his soul to the devil in return for power over the physical world is also often interpreted as a metaphor for the adoption of industrial technology. More recently, modern works of science fiction such as those by Philip K. Dick and William Gibson and films such as Blade Runner and Ghost in the Shell project highly ambivalent or cautionary attitudes toward technology's impact on human society and identity.\n\nThe late cultural critic Neil Postman distinguished tool-using societies from technological societies and from what he called \"technopolies,\" societies that are dominated by the ideology of technological and scientific progress to the exclusion or harm of other cultural practices, values, and world-views.\n\nDarin Barney has written about technology's impact on practices of citizenship and democratic culture, suggesting that technology can be construed as (1) an object of political debate, (2) a means or medium of discussion, and (3) a setting for democratic deliberation and citizenship. As a setting for democratic culture, Barney suggests that technology tends to make ethical questions, including the question of what a good life consists in, nearly impossible because they already give an answer to the question: a good life is one that includes the use of more and more technology.\n\nNikolas Kompridis has also written about the dangers of new technology, such as genetic engineering, nanotechnology, synthetic biology, and robotics. He warns that these technologies introduce unprecedented new challenges to human beings, including the possibility of the permanent alteration of our biological nature. These concerns are shared by other philosophers, scientists and public intellectuals who have written about similar issues (e.g. Francis Fukuyama, J\u00fcrgen Habermas, William Joy, and Michael Sandel).\n\nAnother prominent critic of technology is Hubert Dreyfus, who has published books such as On the Internet and What Computers Still Can't Do.\n\nA more infamous anti-technological treatise is Industrial Society and Its Future, written by the Unabomber Ted Kaczynski and printed in several major newspapers (and later books) as part of an effort to end his bombing campaign of the techno-industrial infrastructure. There are also subcultures that disapprove of some or most technology, such as self-identified off-gridders.\n\nAppropriate technology\n\nThe notion of appropriate technology was developed in the 20th century by thinkers such as E.F. Schumacher and Jacques Ellul to describe situations where it was not desirable to use very new technologies or those that required access to some centralized infrastructure or parts or skills imported from elsewhere. The ecovillage movement emerged in part due to this concern.\n\nOptimism and skepticism in the 21st century\nThis section mainly focuses on American concerns even if it can reasonably be generalized to other Western countries. \n\nIn his article, Jared Bernstein, a Senior Fellow at the Center on Budget and Policy Priorities, questions the widespread idea that automation, and more broadly, technological advances, have mainly contributed to this growing labor market problem.\nHis thesis appears to be a third way between optimism and skepticism. Essentially, he stands for a neutral approach of the linkage between technology and American issues concerning unemployment and declining wages.\n\nHe uses two main arguments to defend his point.\nFirst, because of recent technological advances, an increasing number of workers are losing their jobs. Yet, scientific evidence fails to clearly demonstrate that technology has displaced so many workers that it has created more problems than it has solved. Indeed, automation threatens repetitive jobs but higher-end jobs are still necessary because they complement technology and manual jobs that \"requires flexibility judgment and common sense\" remain hard to replace with machines. Second, studies have not shown clear links between recent technology advances and the wage trends of the last decades.\n\nTherefore, according to Bernstein, instead of focusing on technology and its hypothetical influences on current American increasing unemployment and declining wages, one needs to worry more about \"bad policy that fails to offset the imbalances in demand, trade, income, and opportunity.\"\n\nComplex technological systems\n\nThomas P. Hughes stated that because technology has been considered as a key way to solve problems, we need to be aware of its complex and varied characters to use it more efficiently. What is the difference between a wheel or a compass and cooking machines such as an oven or a gas stove? Can we consider all of them, only a part of them, or none of them as technologies?\n\nTechnology is often considered too narrowly; according to Hughes, \"Technology is a creative process involving human ingenuity\". This definition's emphasis on creativity avoids unbounded definitions that may mistakenly include cooking \"technologies,\" but it also highlights the prominent role of humans and therefore their responsibilities for the use of complex technological systems.\n\nYet, because technology is everywhere and has dramatically changed landscapes and societies, Hughes argues that engineers, scientists, and managers have often believed that they can use technology to shape the world as they want. They have often supposed that technology is easily controllable and this assumption has to be thoroughly questioned. For instance, Evgeny Morozov particularly challenges two concepts: \"Internet-centrism\" and \"solutionism.\" Internet-centrism refers to the idea that our society is convinced that the Internet is one of the most stable and coherent forces. Solutionism is the ideology that every social issue can be solved thanks to technology and especially thanks to the internet. In fact, technology intrinsically contains uncertainties and limitations. According to Alexis Madrigal's review of Morozov's theory, to ignore it will lead to \"unexpected consequences that could eventually cause more damage than the problems they seek to address.\" Benjamin R. Cohen and Gwen Ottinger also discussed the multivalent effects of technology.\n\nTherefore, recognition of the limitations of technology, and more broadly, scientific knowledge, is needed\u00a0\u2013 especially in cases dealing with environmental justice and health issues. Ottinger continues this reasoning and argues that the ongoing recognition of the limitations of scientific knowledge goes hand in hand with scientists and engineers\u2019 new comprehension of their role. Such an approach of technology and science \"[require] technical professionals to conceive of their roles in the process differently. [They have to consider themselves as] collaborators in research and problem solving rather than simply providers of information and technical solutions.\"\n\nOther animal species\n\nThe use of basic technology is also a feature of other animal species apart from humans. These include primates such as chimpanzees, some dolphin communities, and crows. Considering a more generic perspective of technology as ethology of active environmental conditioning and control, we can also refer to animal examples such as beavers and their dams, or bees and their honeycombs.\n\nThe ability to make and use tools was once considered a defining characteristic of the genus Homo. However, the discovery of tool construction among chimpanzees and related primates has discarded the notion of the use of technology as unique to humans. For example, researchers have observed wild chimpanzees using tools for foraging: some of the tools used include leaf sponges, termite fishing probes, pestles and levers. West African chimpanzees also use stone hammers and anvils for cracking nuts, as do capuchin monkeys of Boa Vista, Brazil.\n\nFuture technology\n\nTheories of technology often attempt to predict the future of technology based on the high technology and science of the time. As with all predictions of the future, however, technology is uncertain.\n\nIn 2005, futurist Ray Kurzweil predicted that the future of technology would mainly consist of an overlapping \"GNR Revolution\" of genetics, nanotechnology and robotics, with robotics being the most important of the three. This future revolution has been explored in films, novels, and video games, which have predicted the creation of many inventions, as well as foreseeing future events. Such inventions and events include a government-controlled simulation that resulted from massive robotics advancements (The Matrix), a society that has rid itself of procreation due to improvements in genetic engineering (Brave New World), and a police state enforced by the government using datamining, nanobots, and drones (Watch Dogs). Humans have already made some of the first steps toward achieving the GNR revolution.\n\nRecent discoveries and ingenuity has allowed us to create robotics in the form of Artificial Intelligence, as well as in the physical form of robots. Artificial intelligence has been used for a variety of purposes, including personal assistants in a smart phone, the first of which was Siri, released in the iPhone 4S in 2011 by Apple. Some believe that the future of robotics will involve a 'greater than human non-biological intelligence.' This concept can be compared to that of a 'rogue AI,' an artificial intelligence that has gained self-awareness, and tries to eradicate humanity. Others believe that the future will involve AI servants creating an easy and effortless life for humankind, where robots have become the primary work force. This future shares many similarities with the concept of planned obsolescence, however, planned obsolescence is seen as a \"sinister business strategy.' Man-controlled robots such as drones have been developed to carry out tasks such as bomb defusal and space exploration. Universities such as Harvard are working towards the invention of autonomous robots to be used in situations that would aid humans, such as surgery robots, search and rescue robots, and physical therapy robots.\n\nGenetics have also been explored, with humans understanding genetic engineering to a certain degree. However, gene editing is widely divisive, and usually involves some degree of eugenics. Some have speculated the future of human engineering to include 'super humans,' humans who have been genetically engineered to be faster, stronger, and more survivable than current humans. Others think that genetic engineering will be used to make humans more resistant or completely immune to some diseases. Some even suggest that 'cloning,' the process of creating an exact copy of a human, may be possible through genetic engineering.\n\nSome believe that within the next 10 years, humans will discover nanobot technology, while others believe that we are centuries away from its invention. It is believed by futurists that nanobot technology will allow humans to 'manipulate matter at the molecular and atomic scale.' This discovery could pave the way for many scientific and medical advancements, such as curing new diseases, or inventing new, more efficient technology. It is also believed that nanobots could be injected or otherwise inserted inside the human body, and replace certain parts, keeping humans healthy for an incredibly long amount of time, or combating organ failure to a degree.\n\nThe 'GNR revolution,' would bring a new age of technology and advancement for humanity like none that has been seen before.\n\nSee also\n\nReferences\n\nFurther reading\n\n \n \n \n \n \n \n \n \n .\n \n\n \n \nMain topic articles",
  "War": "War is an intense armed conflict between states, governments, societies, or paramilitary groups such as mercenaries, insurgents, and militias. It is generally characterized by extreme violence, aggression, destruction, and mortality, using regular or irregular military forces. Warfare refers to the common activities and characteristics of types of war, or of wars in general. Total war is warfare that is not restricted to purely legitimate military targets, and can result in massive civilian or other non-combatant suffering and casualties.\n\nWhile some war studies scholars consider war a universal and ancestral aspect of human nature, others argue it is a result of specific socio-cultural, economic or ecological circumstances.\n\nEtymology\n\nThe English word war derives from the 11th-century Old English words wyrre and werre, from Old French werre (also guerre as in modern French), in turn from the Frankish *werra, ultimately deriving from the Proto-Germanic *werz\u014d 'mixture, confusion'. The word is related to the Old Saxon werran, Old High German werran, and the German verwirren, meaning \"to confuse\", \"to perplex\", and \"to bring into confusion\".\n\nHistory\n\nThe earliest evidence of prehistoric warfare is a Mesolithic cemetery in Jebel Sahaba, which has been determined to be approximately 14,000 years old. About forty-five percent of the skeletons there displayed signs of violent death. Since the rise of the state some 5,000 years ago, military activity has occurred over much of the globe. The advent of gunpowder and the acceleration of technological advances led to modern warfare. According to Conway W. Henderson, \"One source claims that 14,500 wars have taken place between 3500 BC and the late 20th century, costing 3.5 billion lives, leaving only 300 years of peace (Beer 1981: 20).\" An unfavorable review of this estimate mentions the following regarding one of the proponents of this estimate: \"In addition, perhaps feeling that the war casualties figure was improbably high, he changed 'approximately 3,640,000,000 human beings have been killed by war or the diseases produced by war' to 'approximately 1,240,000,000 human beings...&c.'\" The lower figure is more plausible, but could still be on the high side considering that the 100 deadliest acts of mass violence between 480 BC and 2002 AD (wars and other man-made disasters with at least 300,000 and up to 66 million victims) claimed about 455 million human lives in total. Primitive warfare is estimated to have accounted for 15.1% of deaths and claimed 400 million victims. Added to the aforementioned  figure of 1,240 million between 3500 BC and the late 20th century, this would mean a total of 1,640,000,000 people killed by war (including deaths from famine and disease caused by war) throughout the history and pre-history of mankind. For comparison, an estimated 1,680,000,000 people died from infectious diseases in the 20th century.\n\nIn War Before Civilization, Lawrence H. Keeley, a professor at the University of Illinois, says approximately 90\u201395% of known societies throughout history engaged in at least occasional warfare, and many fought constantly.\n\nKeeley describes several styles of primitive combat such as small raids, large raids, and massacres. All of these forms of warfare were used by primitive societies, a finding supported by other researchers. Keeley explains that early war raids were not well organized, as the participants did not have any formal training. Scarcity of resources meant defensive works were not a cost-effective way to protect the society against enemy raids.\n\nWilliam Rubinstein wrote \"Pre-literate societies, even those organised in a relatively advanced way, were renowned for their studied cruelty...'archaeology yields evidence of prehistoric massacres more severe than any recounted in ethnography [i.e., after the coming of the Europeans].'\"\n\nIn Western Europe, since the late 18th century, more than 150 conflicts and about 600 battles have taken place. During the 20th century, war resulted in a dramatic intensification of the pace of social changes, and was a crucial catalyst for the emergence of the political Left as a force to be reckoned with.\n\nIn 1947, in view of the rapidly increasingly destructive consequences of modern warfare, and with a particular concern for the consequences and costs of the newly developed atom bomb, Albert Einstein famously stated, \"I know not with what weapons World War III will be fought, but World War IV will be fought with sticks and stones.\"\n\nMao Zedong urged the socialist camp not to fear nuclear war with the United States since, even if \"half of mankind died, the other half would remain while imperialism would be razed to the ground and the whole world would become socialist.\"\n\nA distinctive feature of war since 1945 is the absence of wars between major powers\u2014indeed the near absence of any traditional wars between established countries. The major exceptions were the Indo-Pakistani War of 1971, the Iran\u2013Iraq War 1980\u20131988, and the Gulf War of 1990\u201391.  Instead, combat has largely been a matter of civil wars and insurgencies.\n\nThe Human Security Report 2005 documented a significant decline in the number and severity of armed conflicts since the end of the Cold War in the early 1990s. However, the evidence examined in the 2008 edition of the Center for International Development and Conflict Management's \"Peace and Conflict\" study indicated the overall decline in conflicts had stalled.\n\nTypes of warfare\n\n Asymmetric warfare is a conflict between belligerents of drastically different levels of military capability or size.\n Biological warfare, or germ warfare, is the use of weaponized biological toxins or infectious agents such as bacteria, viruses, and fungi.\n Chemical warfare involves the use of weaponized chemicals in combat. Poison gas as a chemical weapon was principally used during World War I, and resulted in over a million estimated casualties, including more than 100,000 civilians.\n Cold warfare is an intense international rivalry without direct military conflict, but with a sustained threat of it, including high levels of military preparations, expenditures, and development, and may involve active conflicts by indirect means, such as economic warfare, political warfare, covert operations, espionage, cyberwarfare, or proxy wars.\n Conventional warfare is declared war between states in which nuclear, biological, or chemical weapons are not used or see limited deployment.\n Cyberwarfare involves the actions by a nation-state or international organization to attack and attempt to damage another nation's information systems.\n Insurgency is a rebellion against authority, when those taking part in the rebellion are not recognized as belligerents (lawful combatants). An insurgency can be fought via counterinsurgency, and may also be opposed by measures to protect the population, and by political and economic actions of various kinds aimed at undermining the insurgents' claims against the incumbent regime.\n Information warfare is the application of destructive force on a large scale against information assets and systems, against the computers and networks that support the four critical infrastructures (the power grid, communications, financial, and transportation).\n Nuclear warfare is warfare in which nuclear weapons are the primary, or a major, method of achieving capitulation.\n Total war is warfare by any means possible, disregarding the laws of war, placing no limits on legitimate military targets, using weapons and tactics resulting in significant civilian casualties, or demanding a war effort requiring significant sacrifices by the friendly civilian population.\n Unconventional warfare, the opposite of conventional warfare, is an attempt to achieve military victory through acquiescence, capitulation, or clandestine support for one side of an existing conflict.\n\nAims\n\nEntities contemplating going to war and entities considering whether to end a war may formulate war aims as an evaluation/propaganda tool. War aims may stand as a proxy for national-military resolve.\n\nDefinition \nFried defines war aims as \"the desired territorial, economic, military or other benefits expected following successful conclusion of a war\".\n\nClassification \n\nTangible/intangible aims:\n Tangible war aims may involve (for example) the acquisition of territory (as in the German goal of Lebensraum in the first half of the 20th century) or the recognition of economic concessions (as in the Anglo-Dutch Wars).\n Intangible war aims \u2013 like the accumulation of credibility or reputation \u2013 may have more tangible expression (\"conquest restores prestige, annexation increases power\").\n\nExplicit/implicit aims:\n Explicit war aims may involve published policy decisions.\n Implicit war aims can take the form of minutes of discussion, memoranda and instructions.\n\nPositive/negative aims:\n \"Positive war aims\" cover tangible outcomes.\n \"Negative war aims\" forestall or prevent undesired outcomes.\n\nWar aims can change in the course of conflict and may eventually morph into \"peace conditions\" \u2013 the minimal conditions under which a state may cease to wage a particular war.\n\nEffects\n\nMilitary and civilian casualties in recent human history \n\nThroughout the course of human history, the average number of people dying from war has fluctuated relatively little, being about 1 to 10 people dying per 100,000. However, major wars over shorter periods have resulted in much higher casualty rates, with 100-200 casualties per 100,000 over a few years. While conventional wisdom holds that casualties have increased in recent times due to technological improvements in warfare, this is not generally true. For instance, the Thirty Years' War (1618\u20131648) had about the same number of casualties per capita as World War I, although it was higher during World War II (WWII). That said, overall the number of casualties from war has not significantly increased in recent times. Quite to the contrary, on a global scale the time since WWII has been unusually peaceful.\n\nLargest by death toll\n\nThe deadliest war in history, in terms of the cumulative number of deaths since its start, is World War II, from 1939 to 1945, with 60\u201385\u00a0million deaths, followed by the Mongol conquests at up to 60\u00a0million. As concerns a belligerent's losses in proportion to its prewar population, the most destructive war in modern history may have been the Paraguayan War (see Paraguayan War casualties). In 2013 war resulted in 31,000 deaths, down from 72,000 deaths in 1990. In 2003, Richard Smalley identified war as the sixth biggest problem (of ten) facing humanity for the next fifty years. War usually results in significant deterioration of infrastructure and the ecosystem, a decrease in social spending, famine, large-scale emigration from the war zone, and often the mistreatment of prisoners of war or civilians. For instance, of the nine million people who were on the territory of the Byelorussian SSR in 1941, some 1.6\u00a0million were killed by the Germans in actions away from battlefields, including about 700,000 prisoners of war, 500,000 Jews, and 320,000 people counted as partisans (the vast majority of whom were unarmed civilians). Another byproduct of some wars is the prevalence of propaganda by some or all parties in the conflict, and increased revenues by weapons manufacturers.\n\nThree of the ten most costly wars, in terms of loss of life, have been waged in the last century. These are the two World Wars, followed by the Second Sino-Japanese War (which is sometimes considered part of World War II, or as overlapping). Most of the others involved China or neighboring peoples. The death toll of World War II, being over 60\u00a0million, surpasses all other war-death-tolls.\n\nOn military personnel\nMilitary personnel subject to combat in war often suffer mental and physical injuries, including depression, posttraumatic stress disorder, disease, injury, and death.\n\nDuring World War II, research conducted by US Army Brigadier General S.L.A. Marshall found, on average, 15% to 20% of American riflemen in WWII combat fired at the enemy. In Civil War Collector's Encyclopedia, F.A. Lord notes that of the 27,574 discarded muskets found on the Gettysburg battlefield, nearly 90% were loaded, with 12,000 loaded more than once and 6,000 loaded 3 to 10 times. These studies suggest most military personnel resist firing their weapons in combat, that \u2013 as some theorists argue \u2013 human beings have an inherent resistance to killing their fellow human beings. Swank and Marchand's WWII study found that after sixty days of continuous combat, 98% of all surviving military personnel will become psychiatric casualties. Psychiatric casualties manifest themselves in fatigue cases, confusional states, conversion hysteria, anxiety, obsessional and compulsive states, and character disorders.\n\nAdditionally, it has been estimated anywhere from 18% to 54% of Vietnam war veterans suffered from posttraumatic stress disorder.\n\nBased on 1860 census figures, 8% of all white American males aged 13 to 43 died in the American Civil War, including about 6% in the North and approximately 18% in the South. The war remains the deadliest conflict in American history, resulting in the deaths of 620,000 military personnel. United States military casualties of war since 1775 have totaled over two million. Of the 60\u00a0million European military personnel who were mobilized in World War I, 8\u00a0million were killed, 7\u00a0million were permanently disabled, and 15\u00a0million were seriously injured.\n\nDuring Napoleon's retreat from Moscow, more French military personnel died of typhus than were killed by the Russians. Of the 450,000 soldiers who crossed the Neman on 25 June 1812, less than 40,000 returned. More military personnel were killed from 1500 to 1914 by typhus than from military action. In addition, if it were not for modern medical advances there would be thousands more dead from disease and infection. For instance, during the Seven Years' War, the Royal Navy reported it conscripted 184,899 sailors, of whom 133,708 (72%) died of disease or were 'missing'.\n\nIt is estimated that between 1985 and 1994, 378,000 people per year died due to war.\n\nOn civilians\n\nMost wars have resulted in significant loss of life, along with destruction of infrastructure and resources (which may lead to famine, disease, and death in the civilian population). During the Thirty Years' War in Europe, the population of the Holy Roman Empire was reduced by 15 to 40 percent. Civilians in war zones may also be subject to war atrocities such as genocide, while survivors may suffer the psychological aftereffects of witnessing the destruction of war. War also results in lower quality of life and worse health outcomes. A medium-sized conflict with about 2,500 battle deaths reduces civilian life expectancy by one year and increases infant mortality by 10% and malnutrition by 3.3%. Additionally, about 1.8% of the population loses access to drinking water.\n\nMost estimates of World War II casualties indicate around 60\u00a0million people died, 40\u00a0million of whom were civilians. Deaths in the Soviet Union were around 27 million. Since a high proportion of those killed were young men who had not yet fathered any children, population growth in the postwar Soviet Union was much lower than it otherwise would have been.\n\nEconomic\n\nOnce a war has ended, losing nations are sometimes required to pay war reparations to the victorious nations. In certain cases, land is ceded to the victorious nations. For example, the territory of Alsace-Lorraine has been traded between France and Germany on three different occasions.\n\nTypically, war becomes intertwined with the economy and many wars are partially or entirely based on economic reasons. Some economists believe war can stimulate a country's economy (high government spending for World War II is often credited with bringing the U.S. out of the Great Depression by most Keynesian economists), but in many cases, such as the wars of Louis XIV, the Franco-Prussian War, and World War I, warfare primarily results in damage to the economy of the countries involved. For example, Russia's involvement in World War I took such a toll on the Russian economy that it almost collapsed and greatly contributed to the start of the Russian Revolution of 1917.\n\nWorld War II\n\nWorld War II was the most financially costly conflict in history; its belligerents cumulatively spent about a trillion U.S. dollars on the war effort (as adjusted to 1940 prices).\nThe Great Depression of the 1930s ended as nations increased their production of war materials.\n\nBy the end of the war, 70% of European industrial infrastructure was destroyed. Property damage in the Soviet Union inflicted by the Axis invasion was estimated at a value of 679\u00a0billion rubles. The combined damage consisted of complete or partial destruction of 1,710 cities and towns, 70,000 villages/hamlets, 2,508 church buildings, 31,850 industrial establishments,  of railroad, 4100 railroad stations, 40,000 hospitals, 84,000 schools, and 43,000 public libraries.\n\nTheories of motivation\n\nThere are many theories about the motivations for war, but no consensus about which are most common. Carl von Clausewitz said, 'Every age has its own kind of war, its own limiting conditions, and its own peculiar preconceptions.'\n\nPsychoanalytic\nDutch psychoanalyst Joost Meerloo held that, \"War is often...a mass discharge of accumulated internal rage (where)...the inner fears of mankind are discharged in mass destruction.\"\n\nOther psychoanalysts such as E.F.M. Durban and John Bowlby have argued human beings are inherently violent. This aggressiveness is fueled by displacement and projection where a person transfers his or her grievances into bias and hatred against other races, religions, nations or ideologies. By this theory, the nation state preserves order in the local society while creating an outlet for aggression through warfare.\n\nThe Italian psychoanalyst Franco Fornari, a follower of Melanie Klein, thought war was the paranoid or projective \"elaboration\" of mourning. Fornari thought war and violence develop out of our \"love need\": our wish to preserve and defend the sacred object to which we are attached, namely our early mother and our fusion with her. For the adult, nations are the sacred objects that generate warfare. Fornari focused upon sacrifice as the essence of war: the astonishing willingness of human beings to die for their country, to give over their bodies to their nation.\n\nDespite Fornari's theory that man's altruistic desire for self-sacrifice for a noble cause is a contributing factor towards war, few wars have originated from a desire for war among the general populace. Far more often the general population has been reluctantly drawn into war by its rulers. One psychological theory that looks at the leaders is advanced by Maurice Walsh. He argues the general populace is more neutral towards war and wars occur when leaders with a psychologically abnormal disregard for human life are placed into power. War is caused by leaders who seek war such as Napoleon and Hitler. Such leaders most often come to power in times of crisis when the populace opts for a decisive leader, who then leads the nation to war.\n\nEvolutionary\n\nSeveral theories concern the evolutionary origins of warfare. There are two main schools: One sees organized warfare as emerging in or after the Mesolithic as a result of complex social organization and greater population density and competition over resources; the other sees human warfare as a more ancient practice derived from common animal tendencies, such as territoriality and sexual competition.\n\nThe latter school argues that since warlike behavior patterns are found in many primate species such as chimpanzees, as well as in many ant species, group conflict may be a general feature of animal social behavior. Some proponents of the idea argue that war, while innate, has been intensified greatly by developments of technology and social organization such as weaponry and states.\n\nPsychologist and linguist Steven Pinker argued that war-related behaviors may have been naturally selected in the ancestral environment due to the benefits of victory.  He also argued that in order to have credible deterrence against other groups (as well as on an individual level), it was important to have a reputation for retaliation, causing humans to develop instincts for revenge as well as for protecting a group's (or an individual's) reputation (\"honor\").\n\nCrofoot and Wrangham have argued that warfare, if defined as group interactions in which \"coalitions attempt to aggressively dominate or kill members of other groups\", is a characteristic of most human societies. Those in which it has been lacking \"tend to be societies that were politically dominated by their neighbors\".\n\nAshley Montagu strongly denied universalistic instinctual arguments, arguing that social factors and childhood socialization are important in determining the nature and presence of warfare. Thus, he argues, warfare is not a universal human occurrence and appears to have been a historical invention, associated with certain types of human societies. Montagu's argument is supported by ethnographic research conducted in societies where the concept of aggression seems to be entirely absent, e.g. the Chewong and Semai of the Malay peninsula. Bobbi S. Low has observed correlation between warfare and education, noting societies where warfare is commonplace encourage their children to be more aggressive.\n\nEconomic\n\nWar can be seen as a growth of economic competition in a competitive international system. In this view wars begin as a pursuit of markets for natural resources and for wealth. War has also been linked to economic development by economic historians and development economists studying state-building and fiscal capacity. While this theory has been applied to many conflicts, such counter arguments become less valid as the increasing mobility of capital and information level the distributions of wealth worldwide, or when considering that it is relative, not absolute, wealth differences that may fuel wars. There are those on the extreme right of the political spectrum who provide support, fascists in particular, by asserting a natural right of a strong nation to whatever the weak cannot hold by force. Some centrist, capitalist, world leaders, including Presidents of the United States and U.S. Generals, expressed support for an economic view of war.\n\nMarxist\n\nThe Marxist theory of war is quasi-economic in that it states all modern wars are caused by competition for resources and markets between great (imperialist) powers, claiming these wars are a natural result of capitalism. Marxist economists Karl Kautsky, Rosa Luxemburg, Rudolf Hilferding and Vladimir Lenin theorized that imperialism was the result of capitalist countries needing new markets. Expansion of the means of production is only possible if there is a corresponding growth in consumer demand. Since the workers in a capitalist economy would be unable to fill the demand, producers must expand into non-capitalist markets to find consumers for their goods, hence driving imperialism.\n\nDemographic\n\nDemographic theories can be grouped into two classes, Malthusian and youth bulge theories:\n\nMalthusian\n\nMalthusian theories see expanding population and scarce resources as a source of violent conflict.\n\nPope Urban II in 1095, on the eve of the First Crusade, advocating Crusade as a solution to European overpopulation, said:\n\nThis is one of the earliest expressions of what has come to be called the Malthusian theory of war, in which wars are caused by expanding populations and limited resources. Thomas Malthus (1766\u20131834) wrote that populations always increase until they are limited by war, disease, or famine.\n\nThe violent herder\u2013farmer conflicts in Nigeria, Mali, Sudan and other countries in the Sahel region have been exacerbated by land degradation and population growth.\n\nYouth bulge\n\nAccording to Heinsohn, who proposed youth bulge theory in its most generalized form, a youth bulge occurs when 30 to 40 percent of the males of a nation belong to the \"fighting age\" cohorts from 15 to 29 years of age. It will follow periods with total fertility rates as high as 4\u20138 children per woman with a 15\u201329-year delay.\n\nHeinsohn saw both past \"Christianist\" European colonialism and imperialism, as well as today's Islamist civil unrest and terrorism as results of high birth rates producing youth bulges. Among prominent historical events that have been attributed to youth bulges are the role played by the historically large youth cohorts in the rebellion and revolution waves of early modern Europe, including the French Revolution of 1789, and the effect of economic depression upon the largest German youth cohorts ever in explaining the rise of Nazism in Germany in the 1930s. The 1994 Rwandan genocide has also been analyzed as following a massive youth bulge.\n\nYouth bulge theory has been subjected to statistical analysis by the World Bank, Population Action International, and the Berlin Institute for Population and Development. Youth bulge theories have been criticized as leading to racial, gender and age discrimination.\n\nCultural\nGeoffrey Parker argues that what distinguishes the \"Western way of war\" based in Western Europe chiefly allows historians to explain its extraordinary success in conquering most of the world after 1500: The Western way of war rests upon five principal foundations: technology, discipline, a highly aggressive military tradition, a remarkable capacity to innovate and to respond rapidly to the innovation of others and\u2014from about 1500 onward\u2014a unique system of war finance. The combination of all five provided a formula for military success....The outcome of wars has been determined less by technology, then by better war plans, the achievement of surprise, greater economic strength, and above all superior discipline. \n\nParker argues that Western armies were stronger because they emphasized discipline, that is, \"the ability of a formation to stand fast in the face of the enemy, where they're attacking or being attacked, without giving way to the natural impulse of fear and panic.\"  Discipline came from drills and marching in formation, target practice, and creating small \"artificial kinship groups: such as the company and the platoon, to enhance psychological cohesion and combat efficiency.\n\nRationalist\n\nRationalism is an international relations theory or framework. Rationalism (and Neorealism (international relations)) operate under the assumption that states or international actors are rational, seek the best possible outcomes for themselves, and desire to avoid the costs of war. Under one game theory approach, rationalist theories posit all actors can bargain, would be better off if war did not occur, and likewise seek to understand why war nonetheless reoccurs. Under another rationalist game theory without bargaining, the peace war game, optimal strategies can still be found that depend upon number of iterations played. In \"Rationalist Explanations for War\", James Fearon examined three rationalist explanations for why some countries engage in war:\n Issue indivisibilities\n Incentives to misrepresent or information asymmetry\n Commitment problems\n\n\"Issue indivisibility\" occurs when the two parties cannot avoid war by bargaining, because the thing over which they are fighting cannot be shared between them, but only owned entirely by one side or the other.\n\n\"Information asymmetry with incentives to misrepresent\" occurs when two countries have secrets about their individual capabilities, and do not agree on either: who would win a war between them, or the magnitude of state's victory or loss. For instance, Geoffrey Blainey argues that war is a result of miscalculation of strength. He cites historical examples of war and demonstrates, \"war is usually the outcome of a diplomatic crisis which cannot be solved because both sides have conflicting estimates of their bargaining power.\" Thirdly, bargaining may fail due to the states' inability to make credible commitments.\n\nWithin the rationalist tradition, some theorists have suggested that individuals engaged in war suffer a normal level of cognitive bias, but are still \"as rational as you and me\". According to philosopher Iain King, \"Most instigators of conflict overrate their chances of success, while most participants underrate their chances of injury....\" King asserts that \"Most catastrophic military decisions are rooted in GroupThink\" which is faulty, but still rational.\n\nThe rationalist theory focused around bargaining is currently under debate. The Iraq War proved to be an anomaly that undercuts the validity of applying rationalist theory to some wars.\n\nPolitical science\nThe statistical analysis of war was pioneered by Lewis Fry Richardson following World War I. More recent databases of wars and armed conflict have been assembled by the Correlates of War Project, Peter Brecke and the Uppsala Conflict Data Program.\n\nThe following subsections consider causes of war from system, societal, and individual levels of analysis. This kind of division was first proposed by Kenneth Waltz in Man, the State, and War and has been often used by political scientists since then.\n\nSystem-level\n\nThere are several different international relations theory schools. Supporters of realism in international relations argue that the motivation of states is the quest for security, and conflicts can arise from the inability to distinguish defense from offense, which is called the security dilemma.\n\nWithin the realist school as represented by scholars such as Henry Kissinger and Hans Morgenthau, and the neorealist school represented by scholars such as Kenneth Waltz and John Mearsheimer, two main sub-theories are:\n Balance of power theory: States have the goal of preventing a single state from becoming a hegemon, and war is the result of the would-be hegemon's persistent attempts at power acquisition. In this view, an international system with more equal distribution of power is more stable, and \"movements toward unipolarity are destabilizing.\" However, evidence has shown power polarity is not actually a major factor in the occurrence of wars.\n Power transition theory: Hegemons impose stabilizing conditions on the world order, but they eventually decline, and war occurs when a declining hegemon is challenged by another rising power or aims to preemptively suppress them. On this view, unlike for balance-of-power theory, wars become more probable when power is more equally distributed. This \"power preponderance\" hypothesis has empirical support.\nThe two theories are not mutually exclusive and may be used to explain disparate events according to the circumstance.\n\nLiberalism as it relates to international relations emphasizes factors such as trade, and its role in disincentivizing conflict which will damage economic relations.  Realists respond that military force may sometimes be at least as effective as trade at achieving economic benefits, especially historically if not as much today. Furthermore, trade relations which result in a high level of dependency may escalate tensions and lead to conflict. Empirical data on the relationship of trade to peace are mixed, and moreover, some evidence suggests countries at war don't necessarily trade less with each other.\n\nSocietal-level\n Diversionary theory, also known as the \"scapegoat hypothesis\", suggests the politically powerful may use war to as a diversion or to rally domestic popular support. This is supported by literature showing out-group hostility enhances in-group bonding, and a significant domestic \"rally effect\" has been demonstrated when conflicts begin. However, studies examining the increased use of force as a function of need for internal political support are more mixed. U.S. war-time presidential popularity surveys taken during the presidencies of several recent U.S. leaders have supported diversionary theory.\n\nIndividual-level\n\nThese theories suggest differences in people's personalities, decision-making, emotions, belief systems, and biases are important in determining whether conflicts get out of hand. For instance, it has been proposed that conflict is modulated by bounded rationality and various cognitive biases, such as prospect theory.\n\nEthics\n\nThe morality of war has been the subject of debate for thousands of years.\n\nThe two principal aspects of ethics in war, according to the just war theory, are jus ad bellum and jus in bello.\n\nJus ad bellum (right to war), dictates which unfriendly acts and circumstances justify a proper authority in declaring war on another nation. There are six main criteria for the declaration of a just war: first, any just war must be declared by a lawful authority; second, it must be a just and righteous cause, with sufficient gravity to merit large-scale violence; third, the just belligerent must have rightful intentions \u2013 namely, that they seek to advance good and curtail evil; fourth, a just belligerent must have a reasonable chance of success; fifth, the war must be a last resort; and sixth, the ends being sought must be proportional to means being used.\n\nJus in bello (right in war), is the set of ethical rules when conducting war. The two main principles are proportionality and discrimination. Proportionality regards how much force is necessary and morally appropriate to the ends being sought and the injustice suffered. The principle of discrimination determines who are the legitimate targets in a war, and specifically makes a separation between combatants, who it is permissible to kill, and non-combatants, who it is not. Failure to follow these rules can result in the loss of legitimacy for the just-war-belligerent.\n\n The just war theory was foundational in the creation of the United Nations and in international law's regulations on legitimate war.\n\nFascism, and the ideals it encompasses, such as Pragmatism, racism, and social Darwinism, hold that violence is good. Pragmatism holds that war and violence can be good if it serves the ends of the people, without regard for universal morality. Racism holds that violence is good so that a master race can be established, or to purge an inferior race from the earth, or both. Social Darwinism asserts that violence is sometimes necessary to weed the unfit from society so civilization can flourish. These are broad archetypes for the general position that the ends justify the means. Lewis Coser, U.S. conflict theorist and sociologist, argued conflict provides a function and a process whereby a succession of new equilibriums are created. Thus, the struggle of opposing forces, rather than being disruptive, may be a means of balancing and maintaining a social structure or society.\n\nLimiting and stopping\n\nReligious groups have long formally opposed or sought to limit war as in the Second Vatican Council document Gaudiem et Spes: \"Any act of war aimed indiscriminately at the destruction of entire cities of extensive areas along with their population is a crime against God and man himself. It merits unequivocal and unhesitating condemnation.\"\n\nAnti-war movements have existed for every major war in the 20th century, including, most prominently, World War I, World War II, and the Vietnam War. In the 21st century, worldwide anti-war movements occurred in response to the United States invasion of Afghanistan and Iraq. Protests opposing the War in Afghanistan occurred in Europe, Asia, and the United States.\n\nSee also\n\n Outline of war\n Grey-zone (international relations)\n\nNotes\n\nReferences\n\nBibliography\n\n \n \n \n \n \n Butler, Smedley (1935). War is a Racket.\n Chagnon, N. (1983). The Yanomamo. Holt, Rinehart & Winston.\n Clausewitz, Carl Von (1976). On War, Princeton University Press\n Codevilla, Angelo (2005). No Victory, No Peace. Rowman and Littlefield\n \n \n \n \n Fry, Douglas (2005). The Human Potential for Peace: An Anthropological Challenge to Assumptions about War and Violence. Oxford University Press.\n Fry, Douglas (2009).  Beyond War.  Oxford University Press.\n Gat, Azar (2006). War in Human Civilization. Oxford University Press.\n \n Howell, Signe; Willis, Roy (1990). Societies at Peace: Anthropological Perspectives. London: Routledge.\n \n \n Keegan, John (1994). A History of Warfare. Pimlico.\n Keeley, Lawrence (1996). War Before Civilization, Oxford University Press.\n \n Kelly, Raymond C. (2000). Warless Societies and the Origin of War, University of Michigan Press.\n Kemp, Graham; Fry, Douglas (2004).  Keeping the Peace.  New York: Routledge.\n \n Lebow, Richard Ned (2008). A Cultural Theory of International Relations. Cambridge University Press.\n Lindemann, Thomas (2010). Causes of War. The Struggle for Recognition. Colchester, ECPR Press\n \n McIntosh, Jane (2002).  A Peaceful Realm: The Rise and Fall of the Indus Civilization.  Oxford, UK: Westview Press.\n Metz, Steven and Cuccia, Philip R. (2011). Defining War for the 21st Century, Strategic Studies Institute, U.S. Army War College. \n Montagu, Ashley (1978).  Learning Nonaggression.  New York: Oxford University Press.\n Otterbein, Keith (2004). How War Began.  College Station TX: Texas A&M University Press.\n Parker, Geoffrey, ed. (2008) The Cambridge Illustrated History of Warfare: The Triumph of the West (Cambridge University Press, 1995, revised 2008) online\n\n Pauketat, Timothy (2005). North American Archaeology. Blackwell Publishing.\n \n \n Sponsel, Leslie; Gregor, Thomas (1994). Anthropology of Peace and Nonviolence. Lynne Rienner Publishing.\n Strachan, Hew (2013). The Direction of War. Cambridge University Press.\n Turchin, P. (2005). War and Peace and War: Life Cycles of Imperial Nations. NY: Pi Press.\n Van Creveld, Martin. The Art of War: War and Military Thought London: Cassell, Wellington House\n Wade, Nicholas (2006). Before the Dawn, New York: Penguin.\n Walzer, Michael (1977). Just and Unjust Wars. Basic Books.\n\nExternal links\n\nAn Interactive map of all the battles fought around the world in the last 4,000 years\n Timeline of wars on Histropedia\n\n \n\n \nDispute resolution\nEthics\nViolence",
  "Society": "A society is a group of individuals involved in persistent social interaction, or a large social group sharing the same spatial or social territory, typically subject to the same political authority and dominant cultural expectations. Societies are characterized by patterns of relationships (social relations) between individuals who share a distinctive culture and institutions; a given society may be described as the sum total of such relationships among its constituent of members. In the social sciences, a larger society often exhibits stratification or dominance patterns in subgroups.\n\nSocieties construct patterns of behavior by deeming certain actions or concepts as acceptable or unacceptable. These patterns of behavior within a given society are known as societal norms. Societies, and their norms, undergo gradual and perpetual changes.\n\nInsofar as it is collaborative, a society can enable its members to benefit in ways that would otherwise be difficult on an individual basis; both individual and social (common) benefits can thus be distinguished, or in many cases found to overlap. A society can also consist of like-minded people governed by their own norms and values within a dominant, larger society. This is sometimes referred to as a subculture, a term used extensively within criminology, and also applied to distinctive subsections of a larger society.\n\nMore broadly, and especially within structuralist thought, a society may be illustrated as an economic, social, industrial or cultural infrastructure, made up of, yet distinct from, a varied collection of individuals. In this regard society can mean the objective relationships people have with the material world and with other people, rather than \"other people\" beyond the individual and their familiar social environment.\n\nEtymology and usage\n\nThe term \"society\" came from the 12th Century French soci\u00e9t\u00e9 (meaning 'company'). This was in turn from the Latin word societas, which in turn was derived from the noun socius (\"comrade, friend, ally\"; adjectival form socialis) used to describe a bond or interaction between parties that are friendly, or at least civil. Without an article, the term can refer to the entirety of humanity (also: \"society in general\", \"society at large\", etc.), although those who are unfriendly or uncivil to the remainder of society in this sense may be deemed to be \"antisocial\". In the 1630s it was used in reference to \"people bound by neighborhood and intercourse aware of living together in an ordered community\". However, in the 18th century the Scottish economist, Adam Smith taught that a society \"may subsist among different men, as among different merchants, from a sense of its utility without any mutual love or affection, if only they refrain from doing injury to each other.\"\n\nUsed in the sense of an association, a society is a body of individuals outlined by the bounds of functional interdependence, possibly comprising characteristics such as national or cultural identity, social solidarity, language, or hierarchical structure.\n\nConceptions\nSociety, in general, addresses the fact that an individual has rather limited means as an autonomous unit. The great apes have always been more (Bonobo, Homo, Pan) or less (Gorilla, Pongo) social animals, so Robinson Crusoe-like situations are either fictions or unusual corner cases to the ubiquity of social context for humans, who fall between presocial and eusocial in the spectrum of animal ethology.\n\nCultural relativism as a widespread approach or ethic has largely replaced notions of \"primitive\", better/worse, or \"progress\" in relation to cultures (including their material culture/technology and social organization).\n\nAccording to anthropologist Maurice Godelier, one critical novelty in society, in contrast to humanity's closest biological relatives (chimpanzees and bonobos), is the parental role assumed by the males, which supposedly would be absent in our nearest relatives for whom paternity is not generally determinable.\n\nIn political science \nSocieties may also be structured politically. In order of increasing size and complexity, there are bands, tribes, chiefdoms, and state societies. These structures may have varying degrees of political power, depending on the cultural, geographical, and historical environments that these societies must contend with. Thus, a more isolated society with the same level of technology and culture as other societies is more likely to survive than one in close proximity to others that may encroach on their resources. A society that is unable to offer an effective response to other societies it competes with will usually be subsumed into the culture of the competing society.\n\nIn sociology \n\nSociologist Peter L. Berger defines society as \"...a human product, and nothing but a human product, that yet continuously acts upon its producers.\"  According to him, society was created by humans, but this creation turns back and creates or molds humans every day.\n\nSociologist Gerhard Lenski differentiates societies based on their level of technology, communication, and economy: (1) hunters and gatherers, (2) simple agricultural, (3) advanced agricultural, (4) industrial, and (5) special (e.g. fishing societies or maritime societies). This is similar to the system earlier developed by anthropologists Morton H. Fried, a conflict theorist, and Elman Service, an integration theorist, who have produced a system of classification for societies in all human cultures based on the evolution of social inequality and the role of the state. This system of classification contains four categories:\n Hunter-gatherer bands (categorization of duties and responsibilities). Then came the agricultural society.\n Tribal societies in which there are some limited instances of social rank and prestige.\n Stratified structures led by chieftains.\n Civilizations, with complex social hierarchies and organized, institutional governments.\n\nIn addition to this there are:\n Humanity, humankind, upon which rest all the elements of society, including society's beliefs.\n Virtual society, a society based on online identity, which is evolving in the information age.\n\nOver time, some cultures have progressed toward more complex forms of organization and control. This cultural evolution has a profound effect on patterns of community. Hunter-gatherer tribes settled around seasonal food stocks to become agrarian villages. Villages grew to become towns and cities. Cities turned into city-states and nation-states.\n\nMany societies distribute largess at the behest of some individual or some larger group of people. This type of generosity can be seen in all known cultures; typically, prestige accrues to the generous individual or group. Conversely, members of a society may also shun or scapegoat any members of the society who violate its norms. Mechanisms such as gift-giving, joking relationships and scapegoating, which may be seen in various types of human groupings, tend to be institutionalized within a society. Social evolution as a phenomenon carries with it certain elements that could be detrimental to the population it serves.\n\nSome societies bestow status on an individual or group of people when that individual or group performs an admired or desired action. This type of recognition is bestowed in the form of a name, title, manner of dress, or monetary reward. In many societies, adult male or female status is subject to a ritual or process of this type. Altruistic action in the interests of the larger group is seen in virtually all societies. The phenomena of community action, shunning, scapegoating, generosity, shared risk, and reward is common to many forms of society.\n\nTypes\nSocieties are social groups that differ according to subsistence strategies, the ways that humans use technology to provide needs for themselves. Although humans have established many types of societies throughout history, anthropologists tend to classify different societies according to the degree to which different groups within a society have unequal access to advantages such as resources, prestige, or power. Virtually all societies have developed some degree of inequality among their people through the process of social stratification, the division of members of a society into levels with unequal wealth, prestige, or power. Sociologists place societies in three broad categories: pre-industrial, industrial, and postindustrial.\n\nPre-industrial\n\nIn a pre-industrial society, food production, which is carried out through the use of human and animal labor, is the main economic activity. These societies can be subdivided according to their level of technology and their method of producing food. These subdivisions are hunting and gathering, pastoral, horticultural, agricultural, and feudal.\n\nHunting and gathering \n\nThe main form of food production in such societies is the daily collection of wild plants and the hunting of wild animals. Hunter-gatherers move around constantly in search of food. As a result, they do not build permanent villages or create a wide variety of artifacts, and usually only form small groups such as bands and tribes. However, some hunting and gathering societies in areas with abundant resources (such as people of tlingit) lived in larger groups and formed complex hierarchical social structures such as chiefdom. The need for mobility also limits the size of these societies. They generally consist of fewer than 60 people and rarely exceed 100. Statuses within the tribe are relatively equal, and decisions are reached through general agreement. The ties that bind the tribe are more complex than those of the bands. Leadership is personal\u2014charismatic\u2014and used for special purposes only in tribal society. There are no political offices containing real power, and a chief is merely a person of influence, a sort of adviser; therefore, tribal consolidations for collective action are not governmental. The family forms the main social unit, with most members being related by birth or marriage. This type of organization requires the family to carry out most social functions, including production and education.\n\nPastoral \n\nPastoralism is a slightly more efficient form of subsistence. Rather than searching for food on a daily basis, members of a pastoral society rely on domesticated herd animals to meet their food needs. Pastoralists live a nomadic life, moving their herds from one pasture to another. Because their food supply is far more reliable, pastoral societies can support larger populations. Since there are food surpluses, fewer people are needed to produce food. As a result, the division of labor (the specialization by individuals or groups in the performance of specific economic activities) becomes more complex. For example, some people become craftworkers, producing tools, weapons, and jewelry, among other items of value. The production of goods encourages trade. This trade helps to create inequality, as some families acquire more goods than others do. These families often gain power through their increased wealth. The passing on of property from one generation to another helps to centralize wealth and power. Over time emerge hereditary chieftainships, the typical form of government in pastoral societies.\n\nHorticultural \n\nFruits and vegetables grown in garden plots that have been cleared from the jungle or forest provide the main source of food in a horticultural society. These societies have a level of technology and complexity similar to pastoral societies. Some horticultural groups use the slash-and-burn method to raise crops. The wild vegetation is cut and burned, and ashes are used as fertilizers. Horticulturists use human labor and simple tools to cultivate the land for one or more seasons. When the land becomes barren, horticulturists clear a new plot and leave the old plot to revert to its natural state. They may return to the original land several years later and begin the process again. By rotating their garden plots, horticulturists can stay in one area for a fairly long period of time. This allows them to build semipermanent or permanent villages. The size of a village's population depends on the amount of land available for farming; thus villages can range from as few as 30 people to as many as 2000.\n\nAs with pastoral societies, surplus food leads to a more complex division of labor. Specialized roles in horticultural societies include craftspeople, shamans (religious leaders), and traders. This role specialization allows people to create a wide variety of artifacts. As in pastoral societies, surplus food can lead to inequalities in wealth and power within horticultural political systems, developed because of the settled nature of horticultural life.\n\nAgrarian \n\nAgrarian societies use agricultural technological advances to cultivate crops over a large area. Sociologists use the phrase agricultural revolution to refer to the technological changes that occurred as long as 8,500 years ago that led to cultivating crops and raising farm animals. Increases in food supplies then led to larger populations than in earlier communities. This meant a greater surplus, which resulted in towns that became centers of trade supporting various rulers, educators, craftspeople, merchants, and religious leaders who did not have to worry about locating nourishment.\n\nGreater degrees of social stratification appeared in agrarian societies. For example, women previously had higher social status because they shared labor more equally with men. In hunting and gathering societies, women even gathered more food than men. However, as food stores improved and women took on lesser roles in providing food for the family, they increasingly became subordinate to men. As villages and towns expanded into neighboring areas, conflicts with other communities inevitably occurred. Farmers provided warriors with food in exchange for protection against invasion by enemies. A system of rulers with high social status also appeared. This nobility organized warriors to protect the society from invasion. In this way, the nobility managed to extract goods from \"lesser\" members of society.\n\nFeudal \n\nFeudalism was a form of society based on ownership of land. Unlike today's farmers, vassals under feudalism were bound to cultivating their lord's land. In exchange for military protection, the lords exploited the peasants into providing food, crops, crafts, homage, and other services to the landowner. The estates of the realm system of feudalism was often multigenerational; the families of peasants may have cultivated their lord's land for generations.\n\nIndustrial\n\nBetween the 15th and 16th centuries, a new economic system emerged that began to replace feudalism. Capitalism is marked by open competition in a free market, in which the means of production are privately owned. Europe's exploration of the Americas served as one impetus for the development of capitalism. The introduction of foreign metals, silks, and spices stimulated great commercial activity in European societies.\n\nIndustrial societies rely heavily on machines powered by fuels for the production of goods. This produced further dramatic increases in efficiency. The increased efficiency of production of the industrial revolution produced an even greater surplus than before. Now the surplus was not just agricultural goods, but also manufactured goods. This larger surplus caused all of the changes discussed earlier in the domestication revolution to become even more pronounced.\n\nOnce again, the population boomed. Increased productivity made more goods available to everyone. However, inequality became even greater than before. The breakup of agricultural-based feudal societies caused many people to leave the land and seek employment in cities. This created a great surplus of labor and gave capitalists plenty of laborers who could be hired for extremely low wages.\n\nPost-industrial\n\nPost-industrial societies are societies dominated by information, services, and high technology more than the production of goods. Advanced industrial societies are now seeing a shift toward an increase in service sectors over manufacturing and production. The United States is the first country to have over half of its workforce employed in service industries. Service industries include government, research, education, health, sales, law, and banking.\n\nContemporary usage\nThe term \"society\" is currently used to cover both a number of political and scientific connotations as well as a variety of associations.\n\nWestern\n\nThe development of the Western world has brought with it the emerging concepts of Western culture, politics, and ideas, often referred to simply as \"Western society\". Geographically, it covers at the very least the countries of Western Europe, North America, Australia, and New Zealand. It sometimes also includes Eastern Europe, South America, and Israel.\n\nThe cultures and lifestyles of all of these stem from Western Europe. They all enjoy relatively strong economies and stable governments, allow freedom of religion, have chosen democracy as a form of governance, favor capitalism and international trade, are heavily influenced by Judeo-Christian values, and have some form of political and military alliance or cooperation.\n\nInformation\n\nAlthough the concept of information society has been under discussion since the 1930s, in the modern world it is almost always applied to the manner in which information technologies have impacted society and culture. It, therefore, covers the effects of computers and telecommunications on the home, the workplace, schools, government, and various communities and organizations, as well as the emergence of new social forms in cyberspace.\n\nOne of the European Union's areas of interest is the information society. Here policies are directed towards promoting an open and competitive digital economy, research into information and communication technologies, as well as their application to improve social inclusion, public services, and quality of life.\n\nThe International Telecommunication Union's World Summit on the Information Society in Geneva and Tunis (2003 and 2005) has led to a number of policy and application areas where action is envisaged.\n\nKnowledge\n\nAs the access to electronic information resources increased at the beginning of the 21st century, special attention was extended from the information society to the knowledge society. An analysis by the Irish government stated, \"The capacity to manipulate, store and transmit large quantities of information cheaply has increased at a staggering rate over recent years. The digitisation of information and the associated pervasiveness of the Internet are facilitating a new intensity in the application of knowledge to economic activity, to the extent that it has become the predominant factor in the creation of wealth. As much as 70 to 80 percent of economic growth is now said to be due to new and better knowledge.\"\n\nOther uses\n\nPeople of many nations united by common political and cultural traditions, beliefs, or values are sometimes also said to form a society (such as Judeo-Christian, Eastern, and Western). When used in this context, the term is employed as a means of contrasting two or more \"societies\" whose members represent alternative conflicting and competing worldviews.\n\nSome academic, professional, and scientific associations describe themselves as societies (for example, the American Mathematical Society, the American Society of Civil Engineers, or the Royal Society).\n\nIn some countries, e.g. the United States, France, and Latin America, the term \"society' is used in commerce to denote a partnership between investors or the start of a business. In the United Kingdom, partnerships are not called societies, but co-operatives or mutuals are often known as societies (such as friendly societies and building societies).\n\nSee also\n\n Civil society\n Club (organization)\n Consumer society\n Community (outline)\n Culture (outline)\n Eusociality\n High society (group)\n Mass society\n Open society\n Outline of society\n Presociality\n Professional society\n Religion (outline)\n Scientific society\n Secret societies\n Sociobiology\n Social actions\n Social capital\n Social cohesion\n Societal collapse\n Social contract\n Social disintegration\n Social order\n Social solidarity\n Social structure\n Social system\n Social work\n Structure and agency\n\nNotes\n\nReferences\n\nFurther reading\n\n Effland, R. 1998. The Cultural Evolution of Civilizations Mesa Community College.\n \n \n Raymond Williams, Keywords: A Vocabulary of Culture and Society. Fontana, 1976.\n Althusser, Louis and Balibar, \u00c9tienne. Reading Capital. London: Verso, 2009.\n Bottomore, Tom (ed). A Dictionary of Marxist Thought, 2nd ed. Malden, MA: Blackwell Publishing, 1991. 45\u201348.\n Calhoun, Craig (ed), Dictionary of the Social Sciences Oxford University Press (2002)\n Hall, Stuart. \"Rethinking the Base and Superstructure Metaphor\". Papers on Class, Hegemony and Party. Bloomfield, J., ed. London: Lawrence & Wishart, 1977.\n Chris Harman. \"Base and Superstructure\". International Socialism 2:32, Summer 1986, pp.\u00a03\u201344.\n Harvey, David. A Companion to Marx's Capital. London: Verso, 2010.\n Larrain, Jorge. Marxism and Ideology. Atlantic Highlands, NJ: Humanities Press, 1983.\n Luk\u00e1cs, Georg. History and Class Consciousness. Cambridge, MA: MIT Press, 1972.\n Postone, Moishe. Time, Labour, and Social Domination: A Reinterpretation of Marx's Critical Theory. Cambridge [England]: Cambridge University Press, 1993.\n Williams, Raymond. Marxism and Literature. Oxford: Oxford University Press, 1977.\n Leonid Griffen. The society as a superorganism. The scientific heritage. No 67 Vol 5. P. 51\u201360, 2021.\n\nExternal links\n\n \nHumans\nTypes of organization\nMain topic articles",
  "Business": "Business is the activity of making one's living or making money by producing or buying and selling products (such as goods and services). Simply put, it is \"any activity or enterprise entered into for profit.\"\n\nHaving a business name does not separate the business entity from the owner, which means that the owner of the business is responsible and liable for debts incurred by the business.  If the business acquires debts, the creditors can go after the owner's personal possessions.  A business structure does not allow for corporate tax rates. The proprietor is personally taxed on all income from the business.\n\nThe term is also often used colloquially (but not by lawyers or by public officials) to refer to a company. A company, on the other hand, is a separate legal entity and provides for limited liability, as well as corporate tax rates.  A company structure is more complicated and expensive to set up, but offers more protection and benefits for the owner.\n\nForms  \n\nForms of business ownership vary by jurisdiction, but several common entities exist:\n Sole proprietorship: A sole proprietorship, also known as a sole trader, is owned by one person and operates for their benefit. The owner operates the business alone and may hire employees. A sole proprietor has unlimited liability for all obligations incurred by the business, whether from operating costs or judgments against the business. All assets of the business belong to a sole proprietor, including, for example, a computer infrastructure, any inventory, manufacturing equipment, or retail fixtures, as well as any real property owned by the sole proprietor.\n Partnership:  A partnership is a business owned by two or more people. In most forms of partnerships, each partner has unlimited liability for the debts incurred by the business. The three most prevalent types of for-profit partnerships are general partnerships, limited partnerships, and limited liability partnerships.\n Corporation:  The owners of a corporation have limited liability and the business has a separate legal personality from its owners.  Corporations can be either government-owned or privately owned, and they can organize either for profit or as nonprofit organizations. A privately owned, for-profit corporation is owned by its shareholders, who elect a board of directors to direct the corporation and hire its managerial staff.  A privately owned, for-profit corporation can be either privately held by a small group of individuals, or publicly held, with publicly traded shares listed on a stock exchange.\n Cooperative: Often referred to as a \"co-op\", a cooperative is a limited-liability business that can organize as for-profit or not-for-profit. A cooperative differs from a corporation in that it has members, not shareholders, and they share decision-making authority. Cooperatives are typically classified as either consumer cooperatives or worker cooperatives. Cooperatives are fundamental to the ideology of economic democracy.\n Limited liability companies (LLC), limited liability partnerships, and other specific types of business organization protect their owners or shareholders from business failure by doing business under a separate legal entity with certain legal protections. In contrast, unincorporated businesses or persons working on their own are usually not as protected.\n Franchises: A franchise is a system in which entrepreneurs purchase the rights to open and run a business from a larger corporation.  Franchising in the United States is widespread and is a major economic powerhouse.  One out of twelve retail businesses in the United States are franchised and 8 million people are employed in a franchised business.\n A company limited by guarantee:  Commonly used where companies are formed for non-commercial purposes, such as clubs or charities.  The members guarantee the payment of certain (usually nominal) amounts if the company goes into insolvent liquidation, but otherwise, they have no economic rights in relation to the company. This type of company is common in England. A company limited by guarantee may be with or without having share capital.\n A company limited by shares:  The most common form of the company used for business ventures. Specifically, a limited company is a \"company in which the liability of each shareholder is limited to the amount individually invested\" with corporations being \"the most common example of a limited company.\" This type of company is common in England and many English-speaking countries. A company limited by shares may be a\n publicly traded company or a\n privately held company\n A company limited by guarantee with a share capital:  A hybrid entity, usually used where the company is formed for non-commercial purposes, but the activities of the company are partly funded by investors who expect a return.  This type of company may no longer be formed in the UK, although provisions still exist in law for them to exist.\n A limited liability company: \"A company\u2014statutorily authorized in certain states\u2014that is characterized by limited liability, management by members or managers, and limitations on ownership transfer\", i.e., L.L.C. LLC structure has been called \"hybrid\" in that it \"combines the characteristics of a corporation and of a partnership or sole proprietorship\". Like a corporation, it has limited liability for members of the company, and like a partnership, it has \"flow-through taxation to the members\" and must be \"dissolved upon the death or bankruptcy of a member\".\n An unlimited company with or without a share capital: A hybrid entity, a company where the liability of members or shareholders for the debts (if any) of the company are not limited. In this case, the doctrine of a veil of incorporation does not apply.\nLess common types of companies are:\n Companies formed by letters patent:  Most corporations by letters patent are corporations sole and not companies as the term is commonly understood today.\n Charter corporations:  Before the passing of modern companies legislation, these were the only types of companies.  Now they are relatively rare, except for very old companies that still survive (of which there are still many, particularly many British banks), or modern societies that fulfill a quasi-regulatory function (for example, the Bank of England is a corporation formed by a modern charter).\n Statutory companies:  Relatively rare today, certain companies have been formed by a private statute passed in the relevant jurisdiction.\nNote that \"Ltd after the company's name signifies limited company, and PLC (public limited company) indicates that its shares are widely held.\"\n\nIn legal parlance, the owners of a company are normally referred to as the \"members\". In a company limited or unlimited by shares (formed or incorporated with a share capital), this will be the shareholders. In a company limited by guarantee, this will be the guarantors. Some offshore jurisdictions have created special forms of offshore company in a bid to attract business for their jurisdictions. Examples include \"segregated portfolio companies\" and restricted purpose companies.\n\nThere are, however, many, many sub-categories of types of company that can be formed in various jurisdictions in the world.\n\nCompanies are also sometimes distinguished into public companies and private companies for legal and regulatory purposes. Public companies are companies whose shares can be publicly traded, often (although not always) on a stock exchange which imposes listing requirements/Listing Rules as to the issued shares, the trading of shares and a future issue of shares to help bolster the reputation of the exchange or particular market of exchange. Private companies do not have publicly traded shares, and often contain restrictions on transfers of shares. In some jurisdictions, private companies have maximum numbers of shareholders.\n\nA parent company is a company that owns enough voting stock in another firm to control management and operations by influencing or electing its board of directors; the second company being deemed as a subsidiary of the parent company. The definition of a parent company differs by jurisdiction, with the definition normally being defined by way of laws dealing with companies in that jurisdiction.\n\nClassifications \n\n Agriculture, such as the domestication of fish, animals, and livestock, as well as lumber, oil and mining businesses that extract natural resources and raw materials, such as wood, petroleum, natural gas, ores, plants or minerals.\nService businesses offer intangible goods or services and typically charge for labor or other services provided to government, to consumers, or to other businesses. Interior decorators, beauticians, hair stylists, make-up artists, tanning salons, laundromats, dry cleaners, and pest controllers are service businesses.\n Financial services businesses include banks, brokerage firms, credit unions, credit cards, insurance companies, asset and investment companies such as private-equity firms, private-equity funds, real estate investment trusts, sovereign wealth funds, pension funds, mutual funds, index funds, hedge funds, stock exchanges, and other companies that generate profits through investment and management of capital.\nTransportation businesses such as railways, airlines, and shipping companies deliver goods and individuals to their destinations for a fee.\n Utilities produce public services such as water, electricity, waste management or sewage treatment. These industries are usually operated under the charge of a public government.\n Entertainment companies and mass media agencies generate profits primarily from the sale of intellectual property. They include film studios and production houses, mass media companies such as cable television networks, online digital media agencies, talent agencies, mobile media outlets, newspapers, book and magazine publishing houses.\nSports organizations are involved in producing, facilitating, promoting, or organizing any activity, experience, or business enterprise focused on sports. They make their profits by selling goods and services that are sports related.\n Industrial manufacturers produce products, either from raw materials or from component parts, then export the finished products at a profit. They include tangible goods such as cars, buses, medical devices, glass, or aircraft.\n Real estate businesses sell, invest, construct and develop properties, including land, residential homes, and other buildings.\n Retailers, wholesalers, and distributors act as middlemen and get goods produced by manufacturers to the intended consumers; they make their profits by marking up their prices. Most stores and catalog companies are distributors or retailers.\n\nActivities\n\nAccounting \n\nAccounting is the measurement, processing, and communication of financial information about economic entities such as businesses and corporations. The modern field was established by the Italian mathematician Luca Pacioli in 1494.  Accounting, which has been called the \"language of business\", measures the results of an organization's economic activities and conveys this information to a variety of users, including investors, creditors, management, and regulators.  Practitioners of accounting are known as accountants. The terms \"accounting\" and \"financial reporting\" are often used as synonyms.\n\nFinance \n\nFinance is a field that deals with the study of money and investments. It includes the dynamics of assets and liabilities over time under conditions of different degrees of uncertainty and risk. \nIn the context of business and management, finance deals with the problems of ensuring that the firm can safely and profitably carry out its operational and financial objectives; i.e. that it: (1) has sufficient cash flow for ongoing and upcoming operational expenses, and (2) can service both maturing short-term debt repayments, and scheduled long-term debt payments. \nFinance also deals with the long term objective of maximizing the value of the business, while also balancing risk and profitability; this includes the interrelated questions of (1) capital investment, which businesses and projects to invest in; (2) capital structure, deciding on the mix of funding to be used; and (3)  dividend policy, what to do with \"excess\" capital.\n\nManufacturing \n\nManufacturing is the production of merchandise for use or sale using labour and machines, tools, chemical and biological processing, or formulation. The term may refer to a range of human activity, from handicraft to high tech, but is most commonly applied to industrial production, in which raw materials are transformed into finished goods on a large scale.\n\nMarketing \n\nMarketing is defined by the American Marketing Association as \"the activity, set of institutions, and processes for creating, communicating, delivering, and exchanging offerings that have value for customers, clients, partners, and society at large.\" The term developed from the original meaning which referred literally to going to a market to buy or sell goods or services.  Marketing tactics include advertising as well as determining product pricing.\n\nWith the rise in technology, marketing is further divided into a class called digital marketing. It is marketing products and services using digital technologies.\n\nResearch and development \n\nResearch and development refer to activities in connection with corporate or government innovation. Research and development constitute the first stage of development of a potential new service or product. Research and development are very difficult to manage since the defining feature of the research is that the researchers do not know in advance exactly how to accomplish the desired result.\n\nSafety \n\nInjuries cost businesses billions of dollars annually.  Studies have shown how company acceptance and implementation of comprehensive safety and health management systems reduce incidents, insurance costs, and workers' compensation claims.  New technologies, like wearable safety devices and available online safety training, continue to be developed to encourage employers to invest in protection beyond the \"canary in the coal mine\" and reduce the cost to businesses of protecting their employees.\n\nSales \n\nSales are activity related to selling or the number of goods or services sold in a given time period. Sales are often integrated with all lines of business and are key to a companies' success.\n\nManagement \n\nThe efficient and effective operation of a business, and study of this subject, is called management. The major branches of management are financial management, marketing management, human resource management, strategic management, production management, operations management, service management, and information technology management. \n\nOwners may manage their businesses themselves, or employ managers to do so for them. Whether they are owners or employees, managers administer three primary components of the business' value: financial resources, capital (tangible resources), and human resources.  These resources are administered in at least six functional areas: legal contracting, manufacturing or service production, marketing, accounting, financing, and human resources.\n\nRestructuring state enterprises \nIn recent decades, states modeled some of their assets and enterprises after business enterprises. In 2003, for example, the People's Republic of China modeled 80% of its state-owned enterprises on a company-type management system. Many state institutions and enterprises in China and Russia have transformed into joint-stock companies, with part of their shares being listed on public stock markets.\n\nBusiness process management (BPM) is a holistic management approach focused on aligning all aspects of an organization with the wants and needs of clients. BPM attempts to improve processes continuously. It can, therefore, be described as a \"process optimization process\". It is argued that BPM enables organizations to be more efficient, effective and capable of change than a functionally focused, traditional hierarchical management approach.\n\nOrganization and regulation \n\nMost legal jurisdictions specify the forms of ownership that a business can take, creating a body of commercial law for each type.\n\nThe major factors affecting how a business is organized are usually:\n The size and scope of the business firm and its structure, management, and ownership, broadly analyzed in the theory of the firm. Generally, a smaller business is more flexible, while larger businesses, or those with wider ownership or more formal structures, will usually tend to be organized as corporations or (less often) partnerships. In addition, a business that wishes to raise money on a stock market or to be owned by a wide range of people will often be required to adopt a specific legal form to do so.\n The sector and country. Private profit-making businesses are different from government-owned bodies. In some countries, certain businesses are legally obliged to be organized in certain ways.\n Tax advantages. Different structures are treated differently in tax law and may have advantages for this reason.\n Disclosure and compliance requirements. Different business structures may be required to make less or more information public (or report it to relevant authorities) and may be bound to comply with different rules and regulations.\n Control and coordination requirements. In function of the risk and complexity of the tasks to organize, a business is organized through a set of formal and informal mechanisms. In particular, contractual and relational governance can help mitigate opportunism as well as support communication and information sharing.:\n\nMany businesses are operated through a separate entity such as a corporation or a partnership (either formed with or without limited liability). Most legal jurisdictions allow people to organize such an entity by filing certain charter documents with the relevant Secretary of State or equivalent and complying with certain other ongoing obligations. The relationships and legal rights of shareholders, limited partners, or members are governed partly by the charter documents and partly by the law of the jurisdiction where the entity is organized. Generally speaking, shareholders in a corporation, limited partners in a limited partnership, and members in a limited liability company are shielded from personal liability for the debts and obligations of the entity, which is legally treated as a separate \"person\". This means that unless there is misconduct, the owner's own possessions are strongly protected in law if the business does not succeed.\n\nWhere two or more individuals own a business together but have failed to organize a more specialized form of vehicle, they will be treated as a general partnership. The terms of a partnership are partly governed by a partnership agreement if one is created, and partly by the law of the jurisdiction where the partnership is located. No paperwork or filing is necessary to create a partnership, and without an agreement, the relationships and legal rights of the partners will be entirely governed by the law of the jurisdiction where the partnership is located. A single person who owns and runs a business is commonly known as a sole proprietor, whether that person owns it directly or through a formally organized entity. Depending on the business needs, an adviser can decide what kind is proprietorship will be most suitable.\n\nA few relevant factors to consider in deciding how to operate a business include:\n\n General partners in a partnership (other than a limited liability partnership), plus anyone who personally owns and operates a business without creating a separate legal entity, are personally liable for the debts and obligations of the business.\n Generally, corporations are required to pay tax just like \"real\" people. In some tax systems, this can give rise to so-called double taxation, because first the corporation pays tax on the profit, and then when the corporation distributes its profits to its owners, individuals have to include dividends in their income when they complete their personal tax returns, at which point a second layer of income tax is imposed.\n In most countries, there are laws that treat small corporations differently from large ones. They may be exempt from certain legal filing requirements or labor laws, have simplified procedures in specialized areas, and have simplified, advantageous, or slightly different tax treatment.\n \"Going public\" through a process known as an initial public offering (IPO) means that part of the business will be owned by members of the public. This requires the organization as a distinct entity, to disclose information to the public, and adhering to a tighter set of laws and procedures. Most public entities are corporations that have sold shares, but increasingly there are also public LLC's that sell units (sometimes also called shares), and other more exotic entities as well, such as, for example, real estate investment trusts in the US, and unit trusts in the UK. A general partnership cannot \"go public\".\n\nCommercial law \n\nA very detailed and well-established body of rules that evolved over a very long period of time applies to commercial transactions. The need to regulate trade and commerce and resolve business disputes helped shape the creation of law and courts. The Code of Hammurabi dates back to about 1772 BC for example and contains provisions that relate, among other matters, to shipping costs and dealings between merchants and brokers. The word \"corporation\" derives from the Latin corpus, meaning body, and the Maurya Empire in Iron-Age India accorded legal rights to business entities.\n\nIn many countries, it is difficult to compile all the laws that can affect a business into a single reference source. Laws can govern the treatment of labour and employee relations, worker protection and safety, discrimination on the basis of age, gender, disability, race, and in some jurisdictions, sexual orientation, and the minimum wage,  as well as unions, worker compensation, and working hours and leave.\n\nSome specialized businesses may also require licenses, either due to laws governing entry into certain trades, occupations or professions, that require special education or to raise revenue for local governments. Professions that require special licenses include law, medicine, piloting aircraft, selling liquor, radio broadcasting, selling investment securities, selling used cars, and roofing. Local jurisdictions may also require special licenses and taxes just to operate a business.\n\nSome businesses are subject to ongoing special regulation, for example, public utilities, investment securities, banking, insurance, broadcasting, aviation, and health care providers. Environmental regulations are also very complex and can affect many businesses.\n\nCapital \n When businesses need to raise money (called capital), they sometimes offer securities for sale.\n\nCapital may be raised through private means, by an initial public offering or IPO on a stock exchange, or in other ways.\n\nMajor stock exchanges include the Shanghai Stock Exchange, Singapore Exchange, Hong Kong Stock Exchange, New York Stock Exchange and NASDAQ (the USA), the London Stock Exchange (UK), the Tokyo Stock Exchange (Japan), and Bombay Stock Exchange (India). Most countries with capital markets have at least one.\n\nBusinesses that have gone public are subject to regulations concerning their internal governance, such as how executive officers' compensation is determined, and when and how information is disclosed to shareholders and to the public. In the United States, these regulations are primarily implemented and enforced by the United States Securities and Exchange Commission (SEC). Other western nations have comparable regulatory bodies. The regulations are implemented and enforced by the China Securities Regulation Commission (CSRC) in China. In Singapore, the regulatory authority is the Monetary Authority of Singapore (MAS), and in Hong Kong, it is the Securities and Futures Commission (SFC).\n\nThe proliferation and increasing complexity of the laws governing business have forced increasing specialization in corporate law. It is not unheard of for certain kinds of corporate transactions to require a team of five to ten attorneys due to sprawling regulation. Commercial law spans general corporate law, employment and labor law, health-care law, securities law, mergers and acquisitions, tax law, employee benefit plans, food and drug regulation, intellectual property law on copyrights, patents, trademarks, telecommunications law, and financing.\n\nOther types of capital sourcing include crowdsourcing on the Internet, venture capital, bank loans, and debentures.\n\nIntellectual property \n\nBusinesses often have important \"intellectual property\" that needs protection from competitors for the company to stay profitable. This could require patents, copyrights, trademarks, or preservation of trade secrets. Most businesses have names, logos, and similar branding techniques that could benefit from trademarking. Patents and copyrights in the United States are largely governed by federal law, while trade secrets and trademarking are mostly a matter of state law. Because of the nature of intellectual property, a business needs protection in every jurisdiction in which they are concerned about competitors. Many countries are signatories to international treaties concerning intellectual property, and thus companies registered in these countries are subject to national laws bound by these treaties. In order to protect trade secrets, companies may require employees to sign noncompete clauses which will impose limitations on an employee's interactions with stakeholders, and competitors.\n\nTrade union \n\nA trade union (or labor union) is an organization of workers who have come together to achieve common goals such as protecting the integrity of its trade, improving safety standards, achieving higher pay and benefits such as health care and retirement, increasing the number of employees an employer assigns to complete the work, and better working conditions. The trade union, through its leadership, bargains with the employer on behalf of union members (rank and file members) and negotiates labor contracts (collective bargaining) with employers. The most common purpose of these associations or unions is \"maintaining or improving the conditions of their employment\". This may include the negotiation of wages, work rules, complaint procedures, rules governing hiring, firing, and promotion of workers, benefits, workplace safety and policies.\n\nSee also\n\nReferences\n\nExternal links\n\n \nEntrepreneurship\nMain topic articles",
  "Astronomy": "Astronomy (from , literally meaning the science that studies the laws of the stars) is a natural science that studies celestial objects and phenomena. It uses mathematics, physics, and chemistry in order to explain their origin and evolution. Objects of interest include planets, moons, stars, nebulae, galaxies, and comets. Relevant phenomena include supernova explosions, gamma ray bursts, quasars, blazars, pulsars, and cosmic microwave background radiation. More generally, astronomy studies everything that originates beyond Earth's atmosphere. Cosmology is a branch of astronomy that studies the universe as a whole.\n\nAstronomy is one of the oldest natural sciences. The early civilizations in recorded history made methodical observations of the night sky. These include the Babylonians, Greeks, Indians, Egyptians, Chinese, Maya, and many ancient indigenous peoples of the Americas. In the past, astronomy included disciplines as diverse as astrometry, celestial navigation, observational astronomy, and the making of calendars. Nowadays, professional astronomy is often said to be the same as astrophysics.\n\nProfessional astronomy is split into observational and theoretical branches. Observational astronomy is focused on acquiring data from observations of astronomical objects. This data is then analyzed using basic principles of physics. Theoretical astronomy is oriented toward the development of computer or analytical models to describe astronomical objects and phenomena. These two fields complement each other. Theoretical astronomy seeks to explain observational results and observations are used to confirm theoretical results.\n\nAstronomy is one of the few sciences in which amateurs play an active role. This is especially true for the discovery and observation of transient events. Amateur astronomers have helped with many important discoveries, such as finding new comets.\n\nEtymology\n\nAstronomy (from the Greek \u1f00\u03c3\u03c4\u03c1\u03bf\u03bd\u03bf\u03bc\u03af\u03b1 from \u1f04\u03c3\u03c4\u03c1\u03bf\u03bd astron, \"star\" and -\u03bd\u03bf\u03bc\u03af\u03b1 -nomia from \u03bd\u03cc\u03bc\u03bf\u03c2 nomos, \"law\" or \"culture\") means \"law of the stars\" (or \"culture of the stars\" depending on the translation). Astronomy should not be confused with astrology, the belief system which claims that human affairs are correlated with the positions of celestial objects. Although the two fields share a common origin, they are now entirely distinct.\n\nUse of terms \"astronomy\" and \"astrophysics\"\n\"Astronomy\" and \"astrophysics\" are synonyms. Based on strict dictionary definitions, \"astronomy\" refers to \"the study of objects and matter outside the Earth's atmosphere and of their physical and chemical properties,\" while \"astrophysics\" refers to the branch of astronomy dealing with \"the behavior, physical properties, and dynamic processes of celestial objects and phenomena\". In some cases, as in the introduction of the introductory textbook The Physical Universe by Frank Shu, \"astronomy\" may be used to describe the qualitative study of the subject, whereas \"astrophysics\" is used to describe the physics-oriented version of the subject. However, since most modern astronomical research deals with subjects related to physics, modern astronomy could actually be called astrophysics. Some fields, such as astrometry, are purely astronomy rather than also astrophysics. Various departments in which scientists carry out research on this subject may use \"astronomy\" and \"astrophysics\", partly depending on whether the department is historically affiliated with a physics department, and many professional astronomers have physics rather than astronomy degrees. Some titles of the leading scientific journals in this field include The Astronomical Journal, The Astrophysical Journal, and Astronomy & Astrophysics.\n\nHistory\n\nAncient times\n\nIn early historic times, astronomy only consisted of the observation and predictions of the motions of objects visible to the naked eye. In some locations, early cultures assembled massive artifacts that possibly had some astronomical purpose. In addition to their ceremonial uses, these observatories could be employed to determine the seasons, an important factor in knowing when to plant crops and in understanding the length of the year.\n\nBefore tools such as the telescope were invented, early study of the stars was conducted using the naked eye. As civilizations developed, most notably in Mesopotamia, Greece, Persia, India, China, Egypt, and Central America, astronomical observatories were assembled and ideas on the nature of the Universe began to develop. Most early astronomy consisted of mapping the positions of the stars and planets, a science now referred to as astrometry. From these observations, early ideas about the motions of the planets were formed, and the nature of the Sun, Moon and the Earth in the Universe were explored philosophically. The Earth was believed to be the center of the Universe with the Sun, the Moon and the stars rotating around it. This is known as the geocentric model of the Universe, or the Ptolemaic system, named after Ptolemy.\n\nA particularly important early development was the beginning of mathematical and scientific astronomy, which began among the Babylonians, who laid the foundations for the later astronomical traditions that developed in many other civilizations. The Babylonians discovered that lunar eclipses recurred in a repeating cycle known as a saros.\n\nFollowing the Babylonians, significant advances in astronomy were made in ancient Greece and the Hellenistic world. Greek astronomy is characterized from the start by seeking a rational, physical explanation for celestial phenomena. In the 3rd century BC, Aristarchus of Samos estimated the size and distance of the Moon and Sun, and he proposed a model of the Solar System where the Earth and planets rotated around the Sun, now called the heliocentric model. In the 2nd century BC, Hipparchus discovered precession, calculated the size and distance of the Moon and invented the earliest known astronomical devices such as the astrolabe. Hipparchus also created a comprehensive catalog of 1020 stars, and most of the constellations of the northern hemisphere derive from Greek astronomy. The Antikythera mechanism (c. 150\u201380 BC) was an early analog computer designed to calculate the location of the Sun, Moon, and planets for a given date. Technological artifacts of similar complexity did not reappear until the 14th century, when mechanical astronomical clocks appeared in Europe.\n\nMiddle Ages\n\nMedieval Europe housed a number of important astronomers. Richard of Wallingford (1292\u20131336) made major contributions to astronomy and horology, including the invention of the first astronomical clock, the Rectangulus which allowed for the measurement of angles between planets and other astronomical bodies, as well as an equatorium called the Albion which could be used for astronomical calculations such as lunar, solar and planetary longitudes and could predict eclipses. Nicole Oresme (1320\u20131382) and Jean Buridan (1300\u20131361) first discussed evidence for the rotation of the Earth, furthermore, Buridan also developed the theory of impetus (predecessor of the modern scientific theory of inertia) which was able to show planets were capable of motion without the intervention of angels. Georg von Peuerbach (1423\u20131461) and Regiomontanus (1436\u20131476) helped make astronomical progress instrumental to Copernicus's development of the heliocentric model decades later.\n\nAstronomy flourished in the Islamic world and other parts of the world. This led to the emergence of the first astronomical observatories in the Muslim world by the early 9th century. In 964, the Andromeda Galaxy, the largest galaxy in the Local Group, was described by the Persian Muslim astronomer Abd al-Rahman al-Sufi in his Book of Fixed Stars. The SN 1006 supernova, the brightest apparent magnitude stellar event in recorded history, was observed by the Egyptian Arabic astronomer Ali ibn Ridwan and Chinese astronomers in 1006. Some of the prominent Islamic (mostly Persian and Arab) astronomers who made significant contributions to the science include Al-Battani, Thebit, Abd al-Rahman al-Sufi, Biruni, Ab\u016b Ish\u0101q Ibr\u0101h\u012bm al-Zarq\u0101l\u012b, Al-Birjandi, and the astronomers of the Maragheh and Samarkand observatories. Astronomers during that time introduced many Arabic names now used for individual stars.\n\nIt is also believed that the ruins at Great Zimbabwe and Timbuktu may have housed astronomical observatories. In Post-classical West Africa, Astronomers studied the movement of stars and relation to seasons, crafting charts of the heavens as well as precise diagrams of orbits of the other planets based on complex mathematical calculations. Songhai historian Mahmud Kati documented a meteor shower in August 1583.\nEuropeans had previously believed that there had been no astronomical observation in sub-Saharan Africa during the pre-colonial Middle Ages, but modern discoveries show otherwise.\n\nFor over six centuries (from the recovery of ancient learning during the late Middle Ages into the Enlightenment), the Roman Catholic Church gave more financial and social support to the study of astronomy than probably all other institutions. Among the Church's motives was finding the date for Easter.\n\nScientific revolution\n\nDuring the Renaissance, Nicolaus Copernicus proposed a heliocentric model of the solar system. His work was defended by Galileo Galilei and expanded upon by Johannes Kepler. Kepler was the first to devise a system that correctly described the details of the motion of the planets around the Sun. However, Kepler did not succeed in formulating a theory behind the laws he wrote down. It was Isaac Newton, with his invention of celestial dynamics and his law of gravitation, who finally explained the motions of the planets. Newton also developed the reflecting telescope.\n\nImprovements in the size and quality of the telescope led to further discoveries. The English astronomer John Flamsteed catalogued over 3000 stars, More extensive star catalogues were produced by Nicolas Louis de Lacaille. The astronomer William Herschel made a detailed catalog of nebulosity and clusters, and in 1781 discovered the planet Uranus, the first new planet found.\n\nDuring the 18\u201319th centuries, the study of the three-body problem by Leonhard Euler, Alexis Claude Clairaut, and Jean le Rond d'Alembert led to more accurate predictions about the motions of the Moon and planets. This work was further refined by Joseph-Louis Lagrange and Pierre Simon Laplace, allowing the masses of the planets and moons to be estimated from their perturbations.\n\nSignificant advances in astronomy came about with the introduction of new technology, including the spectroscope and photography. Joseph von Fraunhofer discovered about 600 bands in the spectrum of the Sun in 1814\u201315, which, in 1859, Gustav Kirchhoff ascribed to the presence of different elements. Stars were proven to be similar to the Earth's own Sun, but with a wide range of temperatures, masses, and sizes.\n\nThe existence of the Earth's galaxy, the Milky Way, as its own group of stars was only proved in the 20th century, along with the existence of \"external\" galaxies. The observed recession of those galaxies led to the discovery of the expansion of the Universe. Theoretical astronomy led to speculations on the existence of objects such as black holes and neutron stars, which have been used to explain such observed phenomena as quasars, pulsars, blazars, and radio galaxies. Physical cosmology made huge advances during the 20th century. In the early 1900s the model of the Big Bang theory was formulated, heavily evidenced by cosmic microwave background radiation, Hubble's law, and the cosmological abundances of elements. Space telescopes have enabled measurements in parts of the electromagnetic spectrum normally blocked or blurred by the atmosphere. In February 2016, it was revealed that the LIGO project had detected evidence of gravitational waves in the previous September.\n\nObservational astronomy\n\nThe main source of information about celestial bodies and other objects is visible light, or more generally electromagnetic radiation. Observational astronomy may be categorized according to the corresponding region of the electromagnetic spectrum on which the observations are made. Some parts of the spectrum can be observed from the Earth's surface, while other parts are only observable from either high altitudes or outside the Earth's atmosphere. Specific information on these subfields is given below.\n\nRadio astronomy\n\nRadio astronomy uses radiation with wavelengths greater than approximately one millimeter, outside the visible range. Radio astronomy is different from most other forms of observational astronomy in that the observed radio waves can be treated as waves rather than as discrete photons. Hence, it is relatively easier to measure both the amplitude and phase of radio waves, whereas this is not as easily done at shorter wavelengths.\n\nAlthough some radio waves are emitted directly by astronomical objects, a product of thermal emission, most of the radio emission that is observed is the result of synchrotron radiation, which is produced when electrons orbit magnetic fields. Additionally, a number of spectral lines produced by interstellar gas, notably the hydrogen spectral line at 21\u00a0cm, are observable at radio wavelengths.\n\nA wide variety of other objects are observable at radio wavelengths, including supernovae, interstellar gas, pulsars, and active galactic nuclei.\n\nInfrared astronomy\n\nInfrared astronomy is founded on the detection and analysis of infrared radiation, wavelengths longer than red light and outside the range of our vision. The infrared spectrum is useful for studying objects that are too cold to radiate visible light, such as planets, circumstellar disks or nebulae whose light is blocked by dust. The longer wavelengths of infrared can penetrate clouds of dust that block visible light, allowing the observation of young stars embedded in molecular clouds and the cores of galaxies. Observations from the Wide-field Infrared Survey Explorer (WISE) have been particularly effective at unveiling numerous galactic protostars and their host star clusters.\nWith the exception of infrared wavelengths close to visible light, such radiation is heavily absorbed by the atmosphere, or masked, as the atmosphere itself produces significant infrared emission. Consequently, infrared observatories have to be located in high, dry places on Earth or in space. Some molecules radiate strongly in the infrared. This allows the study of the chemistry of space; more specifically it can detect water in comets.\n\nOptical astronomy\n\nHistorically, optical astronomy, also called visible light astronomy, is the oldest form of astronomy. Images of observations were originally drawn by hand. In the late 19th century and most of the 20th century, images were made using photographic equipment. Modern images are made using digital detectors, particularly using charge-coupled devices (CCDs) and recorded on modern medium. Although visible light itself extends from approximately 4000 \u00c5 to 7000 \u00c5 (400 nm to 700\u00a0nm), that same equipment can be used to observe some near-ultraviolet and near-infrared radiation.\n\nUltraviolet astronomy\n\nUltraviolet astronomy employs ultraviolet wavelengths between approximately 100 and 3200\u00a0\u00c5 (10 to 320\u00a0nm). Light at those wavelengths is absorbed by the Earth's atmosphere, requiring observations at these wavelengths to be performed from the upper atmosphere or from space. Ultraviolet astronomy is best suited to the study of thermal radiation and spectral emission lines from hot blue stars (OB stars) that are very bright in this wave band. This includes the blue stars in other galaxies, which have been the targets of several ultraviolet surveys. Other objects commonly observed in ultraviolet light include planetary nebulae, supernova remnants, and active galactic nuclei. However, as ultraviolet light is easily absorbed by interstellar dust, an adjustment of ultraviolet measurements is necessary.\n\nX-ray astronomy\n\nX-ray astronomy uses X-ray wavelengths. Typically, X-ray radiation is produced by synchrotron emission (the result of electrons orbiting magnetic field lines), thermal emission from thin gases above 107 (10\u00a0million) kelvins, and thermal emission from thick gases above 107 Kelvin. Since X-rays are absorbed by the Earth's atmosphere, all X-ray observations must be performed from high-altitude balloons, rockets, or X-ray astronomy satellites. Notable X-ray sources include X-ray binaries, pulsars, supernova remnants, elliptical galaxies, clusters of galaxies, and active galactic nuclei.\n\nGamma-ray astronomy\n\nGamma ray astronomy observes astronomical objects at the shortest wavelengths of the electromagnetic spectrum. Gamma rays may be observed directly by satellites such as the Compton Gamma Ray Observatory or by specialized telescopes called atmospheric Cherenkov telescopes. The Cherenkov telescopes do not detect the gamma rays directly but instead detect the flashes of visible light produced when gamma rays are absorbed by the Earth's atmosphere.\n\nMost gamma-ray emitting sources are actually gamma-ray bursts, objects which only produce gamma radiation for a few milliseconds to thousands of seconds before fading away. Only 10% of gamma-ray sources are non-transient sources. These steady gamma-ray emitters include pulsars, neutron stars, and black hole candidates such as active galactic nuclei.\n\nFields not based on the electromagnetic spectrum\nIn addition to electromagnetic radiation, a few other events originating from great distances may be observed from the Earth.\n\nIn neutrino astronomy, astronomers use heavily shielded underground facilities such as SAGE, GALLEX, and Kamioka II/III for the detection of neutrinos. The vast majority of the neutrinos streaming through the Earth originate from the Sun, but 24 neutrinos were also detected from supernova 1987A. Cosmic rays, which consist of very high energy particles (atomic nuclei) that can decay or be absorbed when they enter the Earth's atmosphere, result in a cascade of secondary particles which can be detected by current observatories. Some future neutrino detectors may also be sensitive to the particles produced when cosmic rays hit the Earth's atmosphere.\n\nGravitational-wave astronomy is an emerging field of astronomy that employs gravitational-wave detectors to collect observational data about distant massive objects. A few observatories have been constructed, such as the Laser Interferometer Gravitational Observatory LIGO. LIGO made its first detection on 14 September 2015, observing gravitational waves from a binary black hole. A second gravitational wave was detected on 26 December 2015 and additional observations should continue but gravitational waves require extremely sensitive instruments.\n\nThe combination of observations made using electromagnetic radiation, neutrinos or gravitational waves and other complementary information, is known as multi-messenger astronomy.\n\nAstrometry and celestial mechanics\n\nOne of the oldest fields in astronomy, and in all of science, is the measurement of the positions of celestial objects. Historically, accurate knowledge of the positions of the Sun, Moon, planets and stars has been essential in celestial navigation (the use of celestial objects to guide navigation) and in the making of calendars.\n\nCareful measurement of the positions of the planets has led to a solid understanding of gravitational perturbations, and an ability to determine past and future positions of the planets with great accuracy, a field known as celestial mechanics. More recently the tracking of near-Earth objects will allow for predictions of close encounters or potential collisions of the Earth with those objects.\n\nThe measurement of stellar parallax of nearby stars provides a fundamental baseline in the cosmic distance ladder that is used to measure the scale of the Universe. Parallax measurements of nearby stars provide an absolute baseline for the properties of more distant stars, as their properties can be compared. Measurements of the radial velocity and proper motion of stars allow astronomers to plot the movement of these systems through the Milky Way galaxy. Astrometric results are the basis used to calculate the distribution of speculated dark matter in the galaxy.\n\nDuring the 1990s, the measurement of the stellar wobble of nearby stars was used to detect large extrasolar planets orbiting those stars.\n\nTheoretical astronomy\n\nTheoretical astronomers use several tools including analytical models and computational numerical simulations; each has its particular advantages. Analytical models of a process are better for giving broader insight into the heart of what is going on. Numerical models reveal the existence of phenomena and effects otherwise unobserved.\n\nTheorists in astronomy endeavor to create theoretical models and from the results predict observational consequences of those models. The observation of a phenomenon predicted by a model allows astronomers to select between several alternate or conflicting models as the one best able to describe the phenomena.\n\nTheorists also try to generate or modify models to take into account new data. In the case of an inconsistency between the data and the model's results, the general tendency is to try to make minimal modifications to the model so that it produces results that fit the data. In some cases, a large amount of inconsistent data over time may lead to the total abandonment of a model.\n\nPhenomena modeled by theoretical astronomers include: stellar dynamics and evolution; galaxy formation; large-scale distribution of matter in the Universe; origin of cosmic rays; general relativity and physical cosmology, including string cosmology and astroparticle physics. Astrophysical relativity serves as a tool to gauge the properties of large scale structures for which gravitation plays a significant role in physical phenomena investigated and as the basis for black hole (astro)physics and the study of gravitational waves.\n\nSome widely accepted and studied theories and models in astronomy, now included in the Lambda-CDM model are the Big Bang, dark matter and fundamental theories of physics.\n\nA few examples of this process:\n\nAlong with Cosmic inflation, dark matter and dark energy are the current leading topics in astronomy, as their discovery and controversy originated during the study of the galaxies.\n\nSpecific subfields\n\nAstrophysics\n\nAstrophysics is the branch of astronomy that employs the principles of physics and chemistry \"to ascertain the nature of the astronomical objects, rather than their positions or motions in space\". Among the objects studied are the Sun, other stars, galaxies, extrasolar planets, the interstellar medium and the cosmic microwave background. Their emissions are examined across all parts of the electromagnetic spectrum, and the properties examined include luminosity, density, temperature, and chemical composition. Because astrophysics is a very broad subject, astrophysicists typically apply many disciplines of physics, including mechanics, electromagnetism, statistical mechanics, thermodynamics, quantum mechanics, relativity, nuclear and particle physics, and atomic and molecular physics.\n\nIn practice, modern astronomical research often involves a substantial amount of work in the realms of theoretical and observational physics. Some areas of study for astrophysicists include their attempts to determine the properties of dark matter, dark energy, and black holes; whether or not time travel is possible, wormholes can form, or the multiverse exists; and the origin and ultimate fate of the universe. Topics also studied by theoretical astrophysicists include Solar System formation and evolution; stellar dynamics and evolution; galaxy formation and evolution; magnetohydrodynamics; large-scale structure of matter in the universe; origin of cosmic rays; general relativity and physical cosmology, including string cosmology and astroparticle physics.\n\nAstrochemistry\n\nAstrochemistry is the study of the abundance and reactions of molecules in the Universe, and their interaction with radiation. The discipline is an overlap of astronomy and chemistry. The word \"astrochemistry\" may be applied to both the Solar System and the interstellar medium. The study of the abundance of elements and isotope ratios in Solar System objects, such as meteorites, is also called cosmochemistry, while the study of interstellar atoms and molecules and their interaction with radiation is sometimes called molecular astrophysics. The formation, atomic and chemical composition, evolution and fate of molecular gas clouds is of special interest, because it is from these clouds that solar systems form.\n\nStudies in this field contribute to the understanding of the formation of the Solar System, Earth's origin and geology, abiogenesis, and the origin of climate and oceans.\n\nAstrobiology\n\nAstrobiology is an interdisciplinary scientific field concerned with the origins, early evolution, distribution, and future of life in the universe. Astrobiology considers the question of whether extraterrestrial life exists, and how humans can detect it if it does. The term exobiology is similar.\n\nAstrobiology makes use of molecular biology, biophysics, biochemistry, chemistry, astronomy, physical cosmology, exoplanetology and geology to investigate the possibility of life on other worlds and help recognize biospheres that might be different from that on Earth. The origin and early evolution of life is an inseparable part of the discipline of astrobiology. Astrobiology concerns itself with interpretation of existing scientific data, and although speculation is entertained to give context, astrobiology concerns itself primarily with hypotheses that fit firmly into existing scientific theories.\n\nThis interdisciplinary field encompasses research on the origin of planetary systems, origins of organic compounds in space, rock-water-carbon interactions, abiogenesis on Earth, planetary habitability, research on biosignatures for life detection, and studies on the potential for life to adapt to challenges on Earth and in outer space.\n\nPhysical cosmology\n\nCosmology (from the Greek \u03ba\u03cc\u03c3\u03bc\u03bf\u03c2 (kosmos) \"world, universe\" and \u03bb\u03cc\u03b3\u03bf\u03c2 (logos) \"word, study\" or literally \"logic\") could be considered the study of the Universe as a whole.\n\nObservations of the large-scale structure of the Universe, a branch known as physical cosmology, have provided a deep understanding of the formation and evolution of the cosmos. Fundamental to modern cosmology is the well-accepted theory of the Big Bang, wherein our Universe began at a single point in time, and thereafter expanded over the course of 13.8 billion years to its present condition. The concept of the Big Bang can be traced back to the discovery of the microwave background radiation in 1965.\n\nIn the course of this expansion, the Universe underwent several evolutionary stages. In the very early moments, it is theorized that the Universe experienced a very rapid cosmic inflation, which homogenized the starting conditions. Thereafter, nucleosynthesis produced the elemental abundance of the early Universe. (See also nucleocosmochronology.)\n\nWhen the first neutral atoms formed from a sea of primordial ions, space became transparent to radiation, releasing the energy viewed today as the microwave background radiation. The expanding Universe then underwent a Dark Age due to the lack of stellar energy sources.\n\nA hierarchical structure of matter began to form from minute variations in the mass density of space. Matter accumulated in the densest regions, forming clouds of gas and the earliest stars, the Population III stars. These massive stars triggered the reionization process and are believed to have created many of the heavy elements in the early Universe, which, through nuclear decay, create lighter elements, allowing the cycle of nucleosynthesis to continue longer.\n\nGravitational aggregations clustered into filaments, leaving voids in the gaps. Gradually, organizations of gas and dust merged to form the first primitive galaxies. Over time, these pulled in more matter, and were often organized into groups and clusters of galaxies, then into larger-scale superclusters.\n\nVarious fields of physics are crucial to studying the universe. Interdisciplinary studies involve the fields of quantum mechanics, particle physics, plasma physics, condensed matter physics, statistical mechanics, optics, and nuclear physics.\n\nFundamental to the structure of the Universe is the existence of dark matter and dark energy. These are now thought to be its dominant components, forming 96% of the mass of the Universe. For this reason, much effort is expended in trying to understand the physics of these components.\n\nExtragalactic astronomy\n\nThe study of objects outside our galaxy is a branch of astronomy concerned with the formation and evolution of Galaxies, their morphology (description) and classification, the observation of active galaxies, and at a larger scale, the groups and clusters of galaxies. Finally, the latter is important for the understanding of the large-scale structure of the cosmos.\n\nMost galaxies are organized into distinct shapes that allow for classification schemes. They are commonly divided into spiral, elliptical and Irregular galaxies.\n\nAs the name suggests, an elliptical galaxy has the cross-sectional shape of an ellipse. The stars move along random orbits with no preferred direction. These galaxies contain little or no interstellar dust, few star-forming regions, and older stars. Elliptical galaxies are more commonly found at the core of galactic clusters, and may have been formed through mergers of large galaxies.\n\nA spiral galaxy is organized into a flat, rotating disk, usually with a prominent bulge or bar at the center, and trailing bright arms that spiral outward. The arms are dusty regions of star formation within which massive young stars produce a blue tint. Spiral galaxies are typically surrounded by a halo of older stars. Both the Milky Way and one of our nearest galaxy neighbors, the Andromeda Galaxy, are spiral galaxies.\n\nIrregular galaxies are chaotic in appearance, and are neither spiral nor elliptical. About a quarter of all galaxies are irregular, and the peculiar shapes of such galaxies may be the result of gravitational interaction.\n\nAn active galaxy is a formation that emits a significant amount of its energy from a source other than its stars, dust and gas. It is powered by a compact region at the core, thought to be a supermassive black hole that is emitting radiation from in-falling material.\n\nA radio galaxy is an active galaxy that is very luminous in the radio portion of the spectrum, and is emitting immense plumes or lobes of gas. Active galaxies that emit shorter frequency, high-energy radiation include Seyfert galaxies, Quasars, and Blazars. Quasars are believed to be the most consistently luminous objects in the known universe.\n\nThe large-scale structure of the cosmos is represented by groups and clusters of galaxies. This structure is organized into a hierarchy of groupings, with the largest being the superclusters. The collective matter is formed into filaments and walls, leaving large voids between.\n\nGalactic astronomy\n\nThe Solar System orbits within the Milky Way, a barred spiral galaxy that is a prominent member of the Local Group of galaxies. It is a rotating mass of gas, dust, stars and other objects, held together by mutual gravitational attraction. As the Earth is located within the dusty outer arms, there are large portions of the Milky Way that are obscured from view.\n\nIn the center of the Milky Way is the core, a bar-shaped bulge with what is believed to be a supermassive black hole at its center. This is surrounded by four primary arms that spiral from the core. This is a region of active star formation that contains many younger, population I stars. The disk is surrounded by a spheroid halo of older, population II stars, as well as relatively dense concentrations of stars known as globular clusters.\n\nBetween the stars lies the interstellar medium, a region of sparse matter. In the densest regions, molecular clouds of molecular hydrogen and other elements create star-forming regions. These begin as a compact pre-stellar core or dark nebulae, which concentrate and collapse (in volumes determined by the Jeans length) to form compact protostars.\n\nAs the more massive stars appear, they transform the cloud into an H II region (ionized atomic hydrogen) of glowing gas and plasma. The stellar wind and supernova explosions from these stars eventually cause the cloud to disperse, often leaving behind one or more young open clusters of stars. These clusters gradually disperse, and the stars join the population of the Milky Way.\n\nKinematic studies of matter in the Milky Way and other galaxies have demonstrated that there is more mass than can be accounted for by visible matter. A dark matter halo appears to dominate the mass, although the nature of this dark matter remains undetermined.\n\nStellar astronomy\n\nThe study of stars and stellar evolution is fundamental to our understanding of the Universe. The astrophysics of stars has been determined through observation and theoretical understanding; and from computer simulations of the interior. Star formation occurs in dense regions of dust and gas, known as giant molecular clouds. When destabilized, cloud fragments can collapse under the influence of gravity, to form a protostar. A sufficiently dense, and hot, core region will trigger nuclear fusion, thus creating a main-sequence star.\n\nAlmost all elements heavier than hydrogen and helium were created inside the cores of stars.\n\nThe characteristics of the resulting star depend primarily upon its starting mass. The more massive the star, the greater its luminosity, and the more rapidly it fuses its hydrogen fuel into helium in its core. Over time, this hydrogen fuel is completely converted into helium, and the star begins to evolve. The fusion of helium requires a higher core temperature. A star with a high enough core temperature will push its outer layers outward while increasing its core density. The resulting red giant formed by the expanding outer layers enjoys a brief life span, before the helium fuel in the core is in turn consumed. Very massive stars can also undergo a series of evolutionary phases, as they fuse increasingly heavier elements.\n\nThe final fate of the star depends on its mass, with stars of mass greater than about eight times the Sun becoming core collapse supernovae; while smaller stars blow off their outer layers and leave behind the inert core in the form of a white dwarf. The ejection of the outer layers forms a planetary nebula. The remnant of a supernova is a dense neutron star, or, if the stellar mass was at least three times that of the Sun, a black hole. Closely orbiting binary stars can follow more complex evolutionary paths, such as mass transfer onto a white dwarf companion that can potentially cause a supernova. Planetary nebulae and supernovae distribute the \"metals\" produced in the star by fusion to the interstellar medium; without them, all new stars (and their planetary systems) would be formed from hydrogen and helium alone.\n\nSolar astronomy\n\nAt a distance of about eight light-minutes, the most frequently studied star is the Sun, a typical main-sequence dwarf star of stellar class G2 V, and about 4.6 billion years (Gyr) old. The Sun is not considered a variable star, but it does undergo periodic changes in activity known as the sunspot cycle. This is an 11-year oscillation in sunspot number. Sunspots are regions of lower-than- average temperatures that are associated with intense magnetic activity.\n\nThe Sun has steadily increased in luminosity by 40% since it first became a main-sequence star. The Sun has also undergone periodic changes in luminosity that can have a significant impact on the Earth. The Maunder minimum, for example, is believed to have caused the Little Ice Age phenomenon during the Middle Ages.\n\nThe visible outer surface of the Sun is called the photosphere. Above this layer is a thin region known as the chromosphere. This is surrounded by a transition region of rapidly increasing temperatures, and finally by the super-heated corona.\n\nAt the center of the Sun is the core region, a volume of sufficient temperature and pressure for nuclear fusion to occur. Above the core is the radiation zone, where the plasma conveys the energy flux by means of radiation. Above that is the convection zone where the gas material transports energy primarily through physical displacement of the gas known as convection. It is believed that the movement of mass within the convection zone creates the magnetic activity that generates sunspots.\n\nA solar wind of plasma particles constantly streams outward from the Sun until, at the outermost limit of the Solar System, it reaches the heliopause. As the solar wind passes the Earth, it interacts with the Earth's magnetic field (magnetosphere) and deflects the solar wind, but traps some creating the Van Allen radiation belts that envelop the Earth. The aurora are created when solar wind particles are guided by the magnetic flux lines into the Earth's polar regions where the lines then descend into the atmosphere.\n\nPlanetary science\n\nPlanetary science is the study of the assemblage of planets, moons, dwarf planets, comets, asteroids, and other bodies orbiting the Sun, as well as extrasolar planets. The Solar System has been relatively well-studied, initially through telescopes and then later by spacecraft. This has provided a good overall understanding of the formation and evolution of the Sun's planetary system, although many new discoveries are still being made.\n\nThe Solar System is divided into the inner Solar System (subdivided into the inner planets and the asteroid belt), the outer Solar System (subdivided into the outer planets and centaurs), comets, the trans-Neptunian region (subdivided into the Kuiper belt, and the scattered disc) and the farthest regions (e.g., boundaries of the heliosphere, and the Oort Cloud, which may extend as far as a light-year). The inner terrestrial planets consist of Mercury, Venus, Earth, and Mars. The outer giant planets are the gas giants (Jupiter and Saturn) and the ice giants (Uranus and Neptune).\n\nThe planets were formed 4.6 billion years ago in the protoplanetary disk that surrounded the early Sun. Through a process that included gravitational attraction, collision, and accretion, the disk formed clumps of matter that, with time, became protoplanets. The radiation pressure of the solar wind then expelled most of the unaccreted matter, and only those planets with sufficient mass retained their gaseous atmosphere. The planets continued to sweep up, or eject, the remaining matter during a period of intense bombardment, evidenced by the many impact craters on the Moon. During this period, some of the protoplanets may have collided and one such collision may have formed the Moon.\n\nOnce a planet reaches sufficient mass, the materials of different densities segregate within, during planetary differentiation. This process can form a stony or metallic core, surrounded by a mantle and an outer crust. The core may include solid and liquid regions, and some planetary cores generate their own magnetic field, which can protect their atmospheres from solar wind stripping.\n\nA planet or moon's interior heat is produced from the collisions that created the body, by the decay of radioactive materials (e.g. uranium, thorium, and 26Al), or tidal heating caused by interactions with other bodies. Some planets and moons accumulate enough heat to drive geologic processes such as volcanism and tectonics. Those that accumulate or retain an atmosphere can also undergo surface erosion from wind or water. Smaller bodies, without tidal heating, cool more quickly; and their geological activity ceases with the exception of impact cratering.\n\nInterdisciplinary studies\nAstronomy and astrophysics have developed significant interdisciplinary links with other major scientific fields. Archaeoastronomy is the study of ancient or traditional astronomies in their cultural context, utilizing archaeological and anthropological evidence. Astrobiology is the study of the advent and evolution of biological systems in the Universe, with particular emphasis on the possibility of non-terrestrial life. Astrostatistics is the application of statistics to astrophysics to the analysis of a vast amount of observational astrophysical data.\n\nThe study of chemicals found in space, including their formation, interaction and destruction, is called astrochemistry. These substances are usually found in molecular clouds, although they may also appear in low-temperature stars, brown dwarfs and planets. Cosmochemistry is the study of the chemicals found within the Solar System, including the origins of the elements and variations in the isotope ratios. Both of these fields represent an overlap of the disciplines of astronomy and chemistry. As \"forensic astronomy\", finally, methods from astronomy have been used to solve problems of law and history.\n\nAmateur astronomy\n\nAstronomy is one of the sciences to which amateurs can contribute the most.\n\nCollectively, amateur astronomers observe a variety of celestial objects and phenomena sometimes with consumer-level equipment or equipment that they build themselves. Common targets of amateur astronomers include the Sun, the Moon, planets, stars, comets, meteor showers, and a variety of deep-sky objects such as star clusters, galaxies, and nebulae. Astronomy clubs are located throughout the world and many have programs to help their members set up and complete observational programs including those to observe all the objects in the Messier (110 objects) or Herschel 400 catalogues of points of interest in the night sky. One branch of amateur astronomy, astrophotography, involves the taking of photos of the night sky. Many amateurs like to specialize in the observation of particular objects, types of objects, or types of events that interest them.\n\nMost amateurs work at visible wavelengths, but many experiment with wavelengths outside the visible spectrum. This includes the use of infrared filters on conventional telescopes, and also the use of radio telescopes. The pioneer of amateur radio astronomy was Karl Jansky, who started observing the sky at radio wavelengths in the 1930s. A number of amateur astronomers use either homemade telescopes or use radio telescopes which were originally built for astronomy research but which are now available to amateurs (e.g. the One-Mile Telescope).\n\nAmateur astronomers continue to make scientific contributions to the field of astronomy and it is one of the few scientific disciplines where amateurs can still make significant contributions. Amateurs can make occultation measurements that are used to refine the orbits of minor planets. They can also discover comets, and perform regular observations of variable stars. Improvements in digital technology have allowed amateurs to make impressive advances in the field of astrophotography.\n\nUnsolved problems in astronomy\n\nAlthough the scientific discipline of astronomy has made tremendous strides in understanding the nature of the Universe and its contents, there remain some important unanswered questions. Answers to these may require the construction of new ground- and space-based instruments, and possibly new developments in theoretical and experimental physics.\n What is the origin of the stellar mass spectrum? That is, why do astronomers observe the same distribution of stellar masses\u2014the initial mass function\u2014apparently regardless of the initial conditions? A deeper understanding of the formation of stars and planets is needed.\n Is there other life in the Universe? Especially, is there other intelligent life? If so, what is the explanation for the Fermi paradox? The existence of life elsewhere has important scientific and philosophical implications. Is the Solar System normal or atypical?\n What is the nature of dark matter and dark energy? These dominate the evolution and fate of the cosmos, yet their true nature remains unknown. \n What will be the ultimate fate of the universe?\n How did the first galaxies form? How did supermassive black holes form?\n What is creating the ultra-high-energy cosmic rays?\n Why is the abundance of lithium in the cosmos four times lower than predicted by the standard Big Bang model?\n What really happens beyond the event horizon?\n\nSee also\n\n Airmass\n Astronomical acronyms\n Astronomical instruments\n Cosmogony\n International Year of Astronomy\n List of astronomy acronyms\n List of Russian astronomers and astrophysicists\n List of software for astronomy research and education\n Outline of space science\n Science tourism\n Space exploration\n Starlight\n Stellar collision\n Universe: The Infinite Frontier (television series)\n Portal:Astronomy\n\nReferences\n\nBibliography\n\nExternal links\n\n NASA/IPAC Extragalactic Database (NED) (NED-Distances)\n International Year of Astronomy 2009 IYA2009 Main website\n Cosmic Journey: A History of Scientific Cosmology from the American Institute of Physics\n Southern Hemisphere Astronomy\n Celestia Motherlode Educational site for Astronomical journeys through space\n Kroto, Harry, Astrophysical Chemistry Lecture Series.\n Core books and Core journals in Astronomy, from the Smithsonian/NASA Astrophysics Data System\n A Journey with Fred Hoyle by Wickramasinghe, Chandra.\n Astronomy books from the History of Science Collection at Linda Hall Library\n\n \nPhysical sciences",
  "Geophysics": "Geophysics () is a subject of natural science concerned with the physical processes and physical properties of the Earth and its surrounding space environment, and the use of quantitative methods for their analysis. The term geophysics sometimes refers only to solid earth applications: Earth's shape; its gravitational and magnetic fields; its internal structure and composition; its dynamics and their surface expression in plate tectonics, the generation of magmas, volcanism and rock formation. However, modern geophysics organizations and pure scientists use a broader definition that includes the water cycle including snow and ice; fluid dynamics of the oceans and the atmosphere; electricity and magnetism in the ionosphere and magnetosphere and solar-terrestrial physics; and analogous problems associated with the Moon and other planets.\n\nAlthough geophysics was only recognized as a separate discipline in the 19th century, its origins date back to ancient times. The first magnetic compasses were made from lodestones, while more modern magnetic compasses played an important role in the history of navigation. The first seismic instrument was built in 132 AD. Isaac Newton applied his theory of mechanics to the tides and the precession of the equinox; and instruments were developed to measure the Earth's shape, density and gravity field, as well as the components of the water cycle. In the 20th century, geophysical methods were developed for remote exploration of the solid Earth and the ocean, and geophysics played an essential role in the development of the theory of plate tectonics.\n\nGeophysics is applied to societal needs, such as mineral resources, mitigation of natural hazards and environmental protection.  In exploration geophysics, geophysical survey data are used to analyze potential petroleum reservoirs and mineral deposits, locate groundwater, find archaeological relics, determine the thickness of glaciers and soils, and assess sites for environmental remediation.\n\nPhysical phenomena \nGeophysics is a highly interdisciplinary subject, and geophysicists contribute to every area of the Earth sciences. To provide a clearer idea of what constitutes geophysics, this section describes phenomena that are studied in physics and how they relate to the Earth and its surroundings.\nIn Geophysics, principles of Physics are applied to study the \"Interior\" of the Earth. Depending on the problem under study, one has to decide which method should be applied. e.g. for ground water surveys, Electrical method is helpful. For mineral deposits, one can adopt Gravity and/or Magnetic surveys. For Oil & Natural Gas, one has to carry out Gravity, Magnetic surveys to get rough idea about structure of rock formations. If the desired structure is existing, for detailed study of rock formations, one has to carry out Seismic and/or Magneto-telluric surveys.\n\nGravity \n\nThe gravitational pull of the Moon and Sun give rise to two high tides and two low tides every lunar day, or every 24 hours and 50 minutes. Therefore, there is a gap of 12 hours and 25 minutes between every high tide and between every low tide.\n\nGravitational forces make rocks press down on deeper rocks, increasing their density as the depth increases. Measurements of gravitational acceleration and gravitational potential at the Earth's surface and above it can be used to look for mineral deposits (see gravity anomaly and gravimetry). The surface gravitational field provides information on the dynamics of tectonic plates. The geopotential surface called the geoid is one definition of the shape of the Earth. The geoid would be the global mean sea level if the oceans were in equilibrium and could be extended through the continents (such as with very narrow canals).\n\nHeat flow \n\nThe Earth is cooling, and the resulting heat flow generates the Earth's magnetic field through the geodynamo and plate tectonics through mantle convection. The main sources of heat are the primordial heat and radioactivity, although there are also contributions from phase transitions. Heat is mostly carried to the surface by thermal convection, although there are two thermal boundary layers \u2013 the core\u2013mantle boundary and the lithosphere \u2013 in which heat is transported by conduction. Some heat is carried up from the bottom of the mantle by mantle plumes. The heat flow at the Earth's surface is about , and it is a potential source of geothermal energy.\n\nVibrations \n\nSeismic waves are vibrations that travel through the Earth's interior or along its surface. The entire Earth can also oscillate in forms that are called normal modes or free oscillations of the Earth. Ground motions from waves or normal modes are measured using seismographs. If the waves come from a localized source such as an earthquake or explosion, measurements at more than one location can be used to locate the source. The locations of earthquakes provide information on plate tectonics and mantle convection.\n\nRecording of seismic waves from controlled sources provide information on the region that the waves travel through. If the density or composition of the rock changes, waves are reflected. Reflections recorded using Reflection Seismology can provide a wealth of information on the structure of the earth up to several kilometers deep and are used to increase our understanding of the geology as well as to explore for oil and gas. Changes in the travel direction, called refraction, can be used to infer the deep structure of the Earth.\n\nEarthquakes pose a risk to humans. Understanding their mechanisms, which depend on the type of earthquake (e.g., intraplate or deep focus), can lead to better estimates of earthquake risk and improvements in earthquake engineering.\n\nElectricity \nAlthough we mainly notice electricity during thunderstorms, there is always a downward electric field near the surface that averages 120 volts per meter. Relative to the solid Earth, the atmosphere has a net positive charge due to bombardment by cosmic rays. A current of about 1800 amperes flows in the global circuit. It flows downward from the ionosphere over most of the Earth and back upwards through thunderstorms. The flow is manifested by lightning below the clouds and sprites above.\n\nA variety of electric methods are used in geophysical survey. Some measure spontaneous potential, a potential that arises in the ground because of man-made or natural disturbances. Telluric currents flow in Earth and the oceans. They have two causes: electromagnetic induction by the time-varying, external-origin geomagnetic field and motion of conducting bodies (such as seawater) across the Earth's permanent magnetic field. The distribution of telluric current density can be used to detect variations in electrical resistivity of underground structures. Geophysicists can also provide the electric current themselves (see induced polarization and electrical resistivity tomography).\n\nElectromagnetic waves \n\nElectromagnetic waves occur in the ionosphere and magnetosphere as well as in Earth's outer core. Dawn chorus is believed to be caused by high-energy electrons that get caught in the Van Allen radiation belt. Whistlers are produced by lightning strikes. Hiss may be generated by both. Electromagnetic waves may also be generated by earthquakes (see seismo-electromagnetics).\n\nIn the highly conductive liquid iron of the outer core, magnetic fields are generated by electric currents through electromagnetic induction. Alfv\u00e9n waves are magnetohydrodynamic waves in the magnetosphere or the Earth's core. In the core, they probably have little observable effect on the Earth's magnetic field, but slower waves such as magnetic Rossby waves may be one source of geomagnetic secular variation.\n\nElectromagnetic methods that are used for geophysical survey include transient electromagnetics, magnetotellurics, surface nuclear magnetic resonance and electromagnetic seabed logging.\n\nMagnetism \n\nThe Earth's magnetic field protects the Earth from the deadly solar wind and has long been used for navigation. It originates in the fluid motions of the outer core. The magnetic field in the upper atmosphere gives rise to the auroras.\n\nThe Earth's field is roughly like a tilted dipole, but it changes over time (a phenomenon called geomagnetic secular variation). Mostly the geomagnetic pole stays near the geographic pole, but at random intervals averaging 440,000 to a million years or so, the polarity of the Earth's field reverses. These geomagnetic reversals, analyzed within a Geomagnetic Polarity Time Scale, contain 184 polarity intervals in the last 83 million years, with change in frequency over time, with the most recent brief complete reversal of the Laschamp event occurring 41,000 years ago during the last glacial period. Geologists observed geomagnetic reversal recorded in volcanic rocks, through magnetostratigraphy correlation (see natural remanent magnetization) and their signature can be seen as parallel linear magnetic anomaly stripes on the seafloor. These stripes provide quantitative information on seafloor spreading, a part of plate tectonics. They are the basis of magnetostratigraphy, which correlates magnetic reversals with other stratigraphies to construct geologic time scales. In addition, the magnetization in rocks can be used to measure the motion of continents.\n\nRadioactivity \n\nRadioactive decay accounts for about 80% of the Earth's internal heat, powering the geodynamo and plate tectonics. The main heat-producing isotopes are potassium-40, uranium-238, uranium-235, and thorium-232.\nRadioactive elements are used for radiometric dating, the primary method for establishing an absolute time scale in geochronology.\n\nUnstable isotopes decay at predictable rates, and the decay rates of different isotopes cover several orders of magnitude, so radioactive decay can be used to accurately date both recent events and events in past geologic eras. Radiometric mapping using ground and airborne gamma spectrometry can be used to map the concentration and distribution of radioisotopes near the Earth's surface, which is useful for mapping lithology and alteration.\n\nFluid dynamics \n\nFluid motions occur in the magnetosphere, atmosphere, ocean, mantle and core. Even the mantle, though it has an enormous viscosity, flows like a fluid over long time intervals. This flow is reflected in phenomena such as isostasy, post-glacial rebound and mantle plumes. The mantle flow drives plate tectonics and the flow in the Earth's core drives the geodynamo.\n\nGeophysical fluid dynamics is a primary tool in physical oceanography and meteorology. The rotation of the Earth has profound effects on the Earth's fluid dynamics, often due to the Coriolis effect. In the atmosphere it gives rise to large-scale patterns like Rossby waves and determines the basic circulation patterns of storms. In the ocean they drive large-scale circulation patterns as well as Kelvin waves and Ekman spirals at the ocean surface. In the Earth's core, the circulation of the molten iron is structured by Taylor columns.\n\nWaves and other phenomena in the magnetosphere can be modeled using magnetohydrodynamics.\n\nMineral physics \n\nThe physical properties of minerals must be understood to infer the composition of the Earth's interior from seismology, the geothermal gradient and other sources of information. Mineral physicists study the elastic properties of minerals; their high-pressure phase diagrams, melting points and equations of state at high pressure; and the rheological properties of rocks, or their ability to flow. Deformation of rocks by creep make flow possible, although over short times the rocks are brittle. The viscosity of rocks is affected by temperature and pressure, and in turn determines the rates at which tectonic plates move.\n\nWater is a very complex substance and its unique properties are essential for life. Its physical properties shape the hydrosphere and are an essential part of the water cycle and climate. Its thermodynamic properties determine evaporation and the thermal gradient in the atmosphere. The many types of precipitation involve a complex mixture of processes such as coalescence, supercooling and supersaturation. Some precipitated water becomes groundwater, and groundwater flow includes phenomena such as percolation, while the conductivity of water makes electrical and electromagnetic methods useful for tracking groundwater flow. Physical properties of water such as salinity have a large effect on its motion in the oceans.\n\nThe many phases of ice form the cryosphere and come in forms like ice sheets, glaciers, sea ice, freshwater ice, snow, and frozen ground (or permafrost).\n\nRegions of the Earth\n\nSize and form of the Earth \n\nThe Earth is roughly spherical, but it bulges towards the Equator, so it is roughly in the shape of an ellipsoid (see Earth ellipsoid). This bulge is due to its rotation and is nearly consistent with an Earth in hydrostatic equilibrium. The detailed shape of the Earth, however, is also affected by the distribution of continents and ocean basins, and to some extent by the dynamics of the plates.\n\nStructure of the interior \n\nEvidence from seismology, heat flow at the surface, and mineral physics is combined with the Earth's mass and moment of inertia to infer models of the Earth's interior \u2013 its composition, density, temperature, pressure. For example, the Earth's mean specific gravity () is far higher than the typical specific gravity of rocks at the surface (), implying that the deeper material is denser. This is also implied by its low moment of inertia (, compared to  for a sphere of constant density). However, some of the density increase is compression under the enormous pressures inside the Earth. The effect of pressure can be calculated using the Adams\u2013Williamson equation. The conclusion is that pressure alone cannot account for the increase in density. Instead, we know that the Earth's core is composed of an alloy of iron and other minerals.\n\nReconstructions of seismic waves in the deep interior of the Earth show that there are no S-waves in the outer core. This indicates that the outer core is liquid, because liquids cannot support shear. The outer core is liquid, and the motion of this highly conductive fluid generates the Earth's field. Earth's inner core, however, is solid because of the enormous pressure.\n\nReconstruction of seismic reflections in the deep interior indicate some major discontinuities in seismic velocities that demarcate the major zones of the Earth: inner core, outer core, mantle, lithosphere and crust. The mantle itself is divided into the upper mantle, transition zone, lower mantle and D\u2032\u2032 layer. Between the crust and the mantle is the Mohorovi\u010di\u0107 discontinuity.\n\nThe seismic model of the Earth does not by itself determine the composition of the layers. For a complete model of the Earth, mineral physics is needed to interpret seismic velocities in terms of composition. The mineral properties are temperature-dependent, so the geotherm must also be determined. This requires physical theory for thermal conduction and convection and the heat contribution of radioactive elements. The main model for the radial structure of the interior of the Earth is the preliminary reference Earth model (PREM). Some parts of this model have been updated by recent findings in mineral physics (see post-perovskite) and supplemented by seismic tomography. The mantle is mainly composed of silicates, and the boundaries between layers of the mantle are consistent with phase transitions.\n\nThe mantle acts as a solid for seismic waves, but under high pressures and temperatures it deforms so that over millions of years it acts like a liquid. This makes plate tectonics possible.\n\nMagnetosphere \n\nIf a planet's magnetic field is strong enough, its interaction with the solar wind forms a magnetosphere. Early space probes mapped out the gross dimensions of the Earth's magnetic field, which extends about 10 Earth radii towards the Sun. The solar wind, a stream of charged particles, streams out and around the terrestrial magnetic field, and continues behind the magnetic tail, hundreds of Earth radii downstream. Inside the magnetosphere, there are relatively dense regions of solar wind particles called the Van Allen radiation belts.\n\nMethods\n\nGeodesy\n\nGeophysical measurements are generally at a particular time and place. Accurate measurements of position, along with earth deformation and gravity, are the province of geodesy. While geodesy and geophysics are separate fields, the two are so closely connected that many scientific organizations such as the American Geophysical Union, the Canadian Geophysical Union and the International Union of Geodesy and Geophysics encompass both.\n\nAbsolute positions are most frequently determined using the global positioning system (GPS). A three-dimensional position is calculated using messages from four or more visible satellites and referred to the 1980 Geodetic Reference System. An alternative, optical astronomy, combines astronomical coordinates and the local gravity vector to get geodetic coordinates. This method only provides the position in two coordinates and is more difficult to use than GPS. However, it is useful for measuring motions of the Earth such as nutation and Chandler wobble. Relative positions of two or more points can be determined using very-long-baseline interferometry.\n\nGravity measurements became part of geodesy because they were needed to related measurements at the surface of the Earth to the reference coordinate system. Gravity measurements on land can be made using gravimeters deployed either on the surface or in helicopter flyovers. Since the 1960s, the Earth's gravity field has been measured by analyzing the motion of satellites. Sea level can also be measured by satellites using radar altimetry, contributing to a more accurate geoid. In 2002, NASA launched the Gravity Recovery and Climate Experiment (GRACE), wherein two twin satellites map variations in Earth's gravity field by making measurements of the distance between the two satellites using GPS and a microwave ranging system.  Gravity variations detected by GRACE include those caused by changes in ocean currents; runoff and ground water depletion; melting ice sheets and glaciers.\n\nSatellites and space probes\nSatellites in space have made it possible to collect data from not only the visible light region, but in other areas of the electromagnetic spectrum. The planets can be characterized by their force fields: gravity and their magnetic fields, which are studied through geophysics and space physics.\n\nMeasuring the changes in acceleration experienced by spacecraft as they orbit has allowed fine details of the gravity fields of the planets to be mapped. For example, in the 1970s, the gravity field disturbances above lunar maria were measured through lunar orbiters, which led to the discovery of concentrations of mass, mascons, beneath the Imbrium, Serenitatis, Crisium, Nectaris and Humorum basins.\n\nHistory \n\nGeophysics emerged as a separate discipline only in the 19th century, from the intersection of physical geography, geology, astronomy, meteorology, and physics. However, many geophysical phenomena \u2013 such as the Earth's magnetic field and earthquakes \u2013 have been investigated since the ancient era.\n\nAncient and classical eras \n\nThe magnetic compass existed in China back as far as the fourth century BC. It was used as much for feng shui as for navigation on land. It was not until good steel needles could be forged that compasses were used for navigation at sea; before that, they could not retain their magnetism long enough to be useful. The first mention of a compass in Europe was in 1190 AD.\n\nIn circa 240 BC, Eratosthenes of Cyrene deduced that the Earth was round and measured the circumference of Earth with great precision. He developed a system of latitude and longitude.\n\nPerhaps the earliest contribution to seismology was the invention of a seismoscope by the prolific inventor Zhang Heng in 132 AD. This instrument was designed to drop a bronze ball from the mouth of a dragon into the mouth of a toad. By looking at which of eight toads had the ball, one could determine the direction of the earthquake. It was 1571 years before the first design for a seismoscope was published in Europe, by Jean de la Hautefeuille. It was never built.\n\nBeginnings of modern science \nOne of the publications that marked the beginning of modern science was William Gilbert's De Magnete (1600), a report of a series of meticulous experiments in magnetism. Gilbert deduced that compasses point north because the Earth itself is magnetic.\n\nIn 1687 Isaac Newton published his Principia, which not only laid the foundations for classical mechanics and gravitation but also explained a variety of geophysical phenomena such as the tides and the precession of the equinox.\n\nThe first seismometer, an instrument capable of keeping a continuous record of seismic activity, was built by James Forbes in 1844.\n\nSee also\n\nNotes\n\nReferences\n\nExternal links\n\nA reference manual for near-surface geophysics techniques and applications\nCommission on Geophysical Risk and Sustainability (GeoRisk), International Union of Geodesy and Geophysics (IUGG)\nStudy of the Earth's Deep Interior, a Committee of IUGG\nUnion Commissions (IUGG)\nUSGS Geomagnetism Program\nCareer crate: Seismic processor\nSociety of Exploration Geophysicists\n\n \nEarth sciences\nSubfields of geology\nApplied and interdisciplinary physics",
  "Spaceflight": "Spaceflight (or space flight) is an application of astronautics to fly spacecraft into or through outer space, either with or without humans on board. Most spaceflight is uncrewed and conducted mainly with spacecraft such as satellites in orbit around Earth, but also includes space probes for flights beyond Earth orbit. Such spaceflight operates either by telerobotic or autonomous control. The more complex human spaceflight has been pursued soon after the first orbital satellites and has reached the Moon and permanent human presence in space around Earth, particularly with the use of space stations. Human spaceflight programs include the Soyuz, Shenzhou, the past Apollo Moon landing and the Space Shuttle programs, with currently the International Space Station as the main destination of human spaceflight missions while China's Tiangong Space Station is under construction.\n\nSpaceflight is used for placing in Earth's orbit communications satellites, reconnaissance satellites, Earth observation satellites, but also for space exploration such as space observatories and space probes, or even for space tourism.\n\nSpaceflight can be achieved with different types of launch systems, conventionally by rocket launching, which provide the initial thrust to overcome the force of gravity and propel a spacecraft from the surface of the Earth. Once in space, the motion of a spacecraft\u00a0\u2013 both when unpropelled and when under propulsion\u00a0\u2013 is covered by the area of study called astrodynamics.\n\nSome spacecraft remain in space practically indefinitely, which has created the issue of space pollution in the form of light pollution and space junk, which is a hazard to spaceflight. Otherwise spacecraft are terminated by atmospheric reentry, in which they disintegrate, or if they do not, their reentry is mostly controlled to safely reach a surface by landing or impacting, often being dumped in the oceanic spacecraft cemetery. As such spacecraft have been the subject of some space traffic management.\n\nTerminology \nThere are several terms that refer to a flight into or through outer space.\n\nA space mission refers to a spaceflight intended to achieve an objective. Objectives for space missions may include space exploration, space research, and national firsts in spaceflight.\n\nSpace transport is the use of spacecraft to transport people or cargo into or through outer space. This may include human spaceflight and cargo spacecraft flight.\n\nHistory \n\nThe first theoretical proposal of space travel using rockets was published by Scottish astronomer and mathematician William Leitch, in an 1861 essay \"A Journey Through Space\". More well-known (though not widely outside Russia) is Konstantin Tsiolkovsky's work, \"\" (The Exploration of Cosmic Space by Means of Reaction Devices), published in 1903.\n\nSpaceflight became an engineering possibility with the work of Robert H. Goddard's publication in 1919 of his paper A Method of Reaching Extreme Altitudes. His application of the de Laval nozzle to liquid fuel rockets improved efficiency enough for interplanetary travel to become possible. He also proved in the laboratory that rockets would work in the vacuum of space; nonetheless, his work was not taken seriously by the public. His attempt to secure an Army contract for a rocket-propelled weapon in the first World War was defeated by the November 11, 1918 armistice with Germany.\nWorking with private financial support, he was the first to launch a liquid-fueled rocket in 1926. Goddard's papers were highly influential internationally in his field.\n\nThe world's first large-scale experimental rocket program was Opel RAK under the leadership of Fritz von Opel and Max Valier during the late 1920s leading to the first manned rocket cars and rocket planes,  which paved the way for the Nazi era V2 program and US and Soviet activities from 1950 onwards.The Opel RAK program and the spectacular public demonstrations of ground and air vehicles drew large crowds, as well as caused global public excitement as so-called \"Rocket Rumble\" and had a large long-lasting impact on later spaceflight pioneers like e.g. Wernher von Braun.  \n\nIn the course of World War II the first guided rockets, the V-2 were developed and employed as weapons by Nazi Germany. At a test flight in June 1944 one such rocket reached space at an altitude of , becoming the first object in human history to do so. At the end of World War II, most of the V-2 rocket team including its head Wernher von Braun surrendered to the United States, and were expatriated to work on American missiles at what became the Army Ballistic Missile Agency, producing missiles such as Juno I and Atlas.\n\nAt that time the Soviet Union under Joseph Stalin was developing intercontinental ballistic missiles to carry nuclear weapons as a counter measure to United States bomber planes. The Tsiolkovsky influenced Sergey Korolev became the chief rocket designer, derivatives of his R-7 Semyorka missiles were used to launch the world's first artificial Earth satellite, Sputnik 1, on October 4, 1957, and later the first human to orbit the Earth, Yuri Gagarin in Vostok 1, on April 12, 1961.\n\nThe first US satellite was Explorer 1, launched on February 1, 1958, and the first American in orbit, became John Glenn in Friendship 7 on February 20, 1962. As director of the Marshall Space Flight Center, Von Braun oversaw development of a larger class of rocket called Saturn, which allowed the US to send the first two humans, Neil Armstrong and Buzz Aldrin, to the Moon and back on Apollo 11 in July 1969. At the same time, the Soviet Union secretly tried but failed to develop the N1 rocket, meant to give them the capability to land humans on the Moon.\n\nEver since spaceflight has been widely employed for placing satellites into orbit around Earth for a broad range of purposes, for sending uncrewed spacecraft exploring space beyond the Moon and having continuous crewed human presence in space with a series of space stations, from the salyut program to the International Space Station.\n\nPhases\n\nLaunch \n\nRockets are the only means currently capable of reaching orbit or beyond. Other non-rocket spacelaunch technologies have yet to be built, or remain short of orbital speeds.\nA rocket launch for a spaceflight usually starts from a spaceport (cosmodrome), which may be equipped with launch complexes and launch pads for vertical rocket launches and runways for takeoff and landing of carrier airplanes and winged spacecraft. Spaceports are situated well away from human habitation for noise and safety reasons. ICBMs have various special launching facilities.\n\nA launch is often restricted to certain launch windows. These windows depend upon the position of celestial bodies and orbits relative to the launch site. The biggest influence is often the rotation of the Earth itself. Once launched, orbits are normally located within relatively constant flat planes at a fixed angle to the axis of the Earth, and the Earth rotates within this orbit.\n\nA launch pad is a fixed structure designed to dispatch airborne vehicles. It generally consists of a launch tower and flame trench. It is surrounded by equipment used to erect, fuel, and maintain launch vehicles. Before launch, the rocket can weigh many hundreds of tonnes. The Space Shuttle Columbia, on STS-1, weighed  at takeoff.\n\nReaching space \nThe most commonly used definition of outer space is everything beyond the K\u00e1rm\u00e1n line, which is  above the Earth's surface. The United States sometimes defines outer space as everything beyond  in altitude.\n\nRocket engines are the only currently practical means of reaching space. Conventional airplane engines cannot reach space due to the lack of oxygen. Rocket engines expel propellant to provide forward thrust that generates enough delta-v (change in velocity) to reach orbit.\n\nFor crewed launch systems launch escape systems are frequently fitted to allow astronauts to escape in the case of emergency.\n\nAlternatives \n\nMany ways to reach space other than rocket engines have been proposed. Ideas such as the space elevator, and momentum exchange tethers like rotovators or skyhooks require new materials much stronger than any currently known. Electromagnetic launchers such as launch loops might be feasible with current technology. Other ideas include rocket assisted aircraft/spaceplanes such as Reaction Engines Skylon (currently in early stage development), scramjet powered spaceplanes, and RBCC powered spaceplanes. Gun launch has been proposed for cargo.\n\nLeaving orbit \n\nAchieving a closed orbit is not essential to lunar and interplanetary voyages. Early Soviet space vehicles successfully achieved very high altitudes without going into orbit. NASA considered launching Apollo missions directly into lunar trajectories but adopted the strategy of first entering a temporary parking orbit and then performing a separate burn several orbits later onto a lunar trajectory.\n\nThe parking orbit approach greatly simplified Apollo mission planning in several important ways. It acted as a \"time buffer\" and substantially widened the allowable launch windows. The parking orbit gave the crew and controllers several hours to thoroughly check out the spacecraft after the stresses of launch before committing it for a long journey to the Moon.\n\nApollo missions minimized the performance penalty of the parking orbit by keeping its altitude as low as possible. For example, Apollo 15 used an unusually low parking orbit of  which is not sustainable for very long due to friction with the Earth's atmosphere, but the crew would only spend three hours before reigniting the S-IVB third stage to put them on a lunar-bound trajectory.\n\nRobotic missions do not require an abort capability or radiation minimization, and because modern launchers routinely meet \"instantaneous\" launch windows, space probes to the Moon and other planets generally use direct injection to maximize performance. Although some might coast briefly during the launch sequence, they do not complete one or more full parking orbits before the burn that injects them onto an Earth escape trajectory.\n\nThe escape velocity from a celestial body decreases with altitude above that body. However, it is more fuel-efficient for a craft to burn its fuel as close to the ground as possible; see Oberth effect and reference. This is another\nway to explain the performance penalty associated with establishing the safe perigee of a parking orbit.\n\nAstrodynamics \n\nAstrodynamics is the study of spacecraft trajectories, particularly as they relate to gravitational and propulsion effects. Astrodynamics allows for a spacecraft to arrive at its destination at the correct time without excessive propellant use. An orbital maneuvering system may be needed to maintain or change orbits.\n\nNon-rocket orbital propulsion methods include solar sails, magnetic sails, plasma-bubble magnetic systems, and using gravitational slingshot effects.\n\nTransfer energy \nThe term \"transfer energy\" means the total amount of energy imparted by a rocket stage to its payload.  This can be the energy imparted by a first stage of a launch vehicle to an upper stage plus payload, or by an upper stage or spacecraft kick motor to a spacecraft.\n\nReaching space station \n\nIn order to reach towards a space station, a spacecraft would have to arrive at the same orbit and approach to a very close distance (e.g. within visual contact). This is done by a set of orbital maneuvers called space rendezvous.\n\nAfter rendezvousing with the space station, the space vehicle then docks or berths with the station. Docking refers to joining of two separate free-flying space vehicles, while berthing refers to mating operations where an inactive vehicle is placed into the mating interface of another space vehicle by using a robotic arm.\n\nReentry \n\nVehicles in orbit have large amounts of kinetic energy. This energy must be discarded if the vehicle is to land safely without vaporizing in the atmosphere. Typically this process requires special methods to protect against aerodynamic heating. The theory behind reentry was developed by Harry Julian Allen. Based on this theory, reentry vehicles present blunt shapes to the atmosphere for reentry. Blunt shapes mean that less than 1% of the kinetic energy ends up as heat reaching the vehicle, and the remainder heats up the atmosphere.\n\nLanding and recovery \nThe Mercury, Gemini, and Apollo capsules all splashed down in the sea. These capsules were designed to land at relatively low speeds with the help of a parachute. Soviet/Russian capsules for Soyuz make use of a big parachute and braking rockets to touch down on land. Spaceplanes like the Space Shuttle land like a glider.\n\nAfter a successful landing the spacecraft, its occupants, and cargo can be recovered. In some cases, recovery has occurred before landing: while a spacecraft is still descending on its parachute, it can be snagged by a specially designed aircraft. This mid-air retrieval technique was used to recover the film canisters from the Corona spy satellites.\n\nTypes\n\nUncrewed \n\nUncrewed spaceflight is all spaceflight activity without a necessary human presence in space. This includes all space probes, satellites and robotic spacecraft and missions. Uncrewed spaceflight is the opposite of crewed spaceflight, which is usually called human spaceflight. Subcategories of uncrewed spaceflight are \"robotic spacecraft\" (objects) and \"robotic space missions\" (activities). A robotic spacecraft is an uncrewed spacecraft with no humans on board, that is usually under telerobotic control. In some cases, such as with helicopters, a spacecraft may need to act autonomously for short periods of time. A robotic spacecraft designed to make scientific research measurements is often called a space probe.\n\nUncrewed space missions use remote-controlled spacecraft. The first uncrewed space mission was Sputnik, launched October 4, 1957 to orbit the Earth. Space missions where other animals but no humans are on-board are considered uncrewed missions.\n\nBenefits \nMany space missions are more suited to telerobotic rather than crewed operation, due to lower cost and lower risk factors. In addition, some planetary destinations such as Venus or the vicinity of Jupiter are too hostile for human survival, given current technology. Outer planets such as Saturn, Uranus, and Neptune are too distant to reach with current crewed spaceflight technology, so telerobotic probes are the only way to explore them. Telerobotics also allows exploration of regions that are vulnerable to contamination by Earth micro-organisms since spacecraft can be sterilized. Humans can not be sterilized in the same way as a spaceship, as they coexist with numerous micro-organisms, and these micro-organisms are also hard to contain within a spaceship or spacesuit.\n\nTelepresence \nTelerobotics becomes telepresence when the time delay is short enough to permit control of the spacecraft in close to real time by humans. Even the two seconds light speed delay for the Moon is too far away for telepresence exploration from Earth. The L1 and L2 positions permit 400-millisecond round trip delays, which is just close enough for telepresence operation. Telepresence has also been suggested as a way to repair satellites in Earth orbit from Earth. The Exploration Telerobotics Symposium in 2012 explored this and other topics.\n\nHuman \n\nThe first human spaceflight was Vostok 1 on April 12, 1961, on which cosmonaut Yuri Gagarin of the USSR made one orbit around the Earth. In official Soviet documents, there is no mention of the fact that Gagarin parachuted the final seven miles. As of 2020, the only spacecraft regularly used for human spaceflight are Soyuz, Shenzhou, and Crew Dragon. The U.S. Space Shuttle fleet operated from April 1981 until July 2011. SpaceShipOne has conducted two human suborbital spaceflights.\n\nSub-orbital \n\nOn a sub-orbital spaceflight the spacecraft reaches space and then returns to the atmosphere after following a (primarily) ballistic trajectory. This is usually because of insufficient specific orbital energy, in which case a suborbital flight will last only a few minutes, but it is also possible for an object with enough energy for an orbit to have a trajectory that intersects the Earth's atmosphere, sometimes after many hours. Pioneer 1 was NASA's first space probe intended to reach the Moon. A partial failure caused it to instead follow a suborbital trajectory to an altitude of  before reentering the Earth's atmosphere 43 hours after launch.\n\nThe most generally recognized boundary of space is the K\u00e1rm\u00e1n line  above sea level. (NASA alternatively defines an astronaut as someone who has flown more than  above sea level.) It is not generally recognized by the public that the increase in potential energy required to pass the K\u00e1rm\u00e1n line is only about 3% of the orbital energy (potential plus kinetic energy) required by the lowest possible Earth orbit (a circular orbit just above the K\u00e1rm\u00e1n line.) In other words, it is far easier to reach space than to stay there. On May 17, 2004, Civilian Space eXploration Team launched the GoFast rocket on a suborbital flight, the first amateur spaceflight. On June 21, 2004, SpaceShipOne was used for the first privately funded human spaceflight.\n\nPoint-to-point \nPoint-to-point, or Earth to Earth transportation, is a category of sub-orbital spaceflight in which a spacecraft provides rapid transport between two terrestrial locations. A conventional airline route between London and Sydney, a flight that normally lasts over twenty hours, could be traversed in less than one hour. While no company offers this type of transportation today, SpaceX has revealed plans to do so as early as the 2020s using Starship. Suborbital spaceflight over an intercontinental distance requires a vehicle velocity that is only a little lower than the velocity required to reach low Earth orbit. If rockets are used, the size of the rocket relative to the payload is similar to an Intercontinental Ballistic Missile (ICBM). Any intercontinental spaceflight has to surmount problems of heating during atmosphere re-entry that are nearly as large as those faced by orbital spaceflight.\n\nOrbital \n\nA minimal orbital spaceflight requires much higher velocities than a minimal sub-orbital flight, and so it is technologically much more challenging to achieve. To achieve orbital spaceflight, the tangential velocity around the Earth is as important as altitude. In order to perform a stable and lasting flight in space, the spacecraft must reach the minimal orbital speed required for a closed orbit.\n\nInterplanetary \n\nInterplanetary spaceflight is flight between planets within a single planetary system. In practice, the use of the term is confined to travel between the planets of our Solar System. Plans for future crewed interplanetary spaceflight missions often include final vehicle assembly in Earth orbit, such as NASA's Constellation program and Russia's Kliper/Parom tandem.\n\nInterstellar \n\n\u2018\u2019New Horizons\u2019\u2019 is the fifth spacecraft put on an escape trajectory leaving the Solar System.  Voyager 1, Voyager 2, Pioneer 10, Pioneer 11 are the earlier ones.  The one farthest from the Sun is Voyager 1, which is more than 100 AU distant and is moving at 3.6 AU per year. In comparison, Proxima Centauri, the closest star other than the Sun, is 267,000 AU distant. It will take Voyager 1 over 74,000 years to reach this distance. Vehicle designs using other techniques, such as nuclear pulse propulsion are likely to be able to reach the nearest star significantly faster. Another possibility that could allow for human interstellar spaceflight is to make use of time dilation, as this would make it possible for passengers in a fast-moving vehicle to travel further into the future while aging very little, in that their great speed slows down the rate of passage of on-board time.  However, attaining such high speeds would still require the use of some new, advanced method of propulsion.\n\nIntergalactic \n\nIntergalactic travel involves spaceflight between galaxies, and is considered much more technologically demanding than even interstellar travel and, by current engineering terms, is considered science fiction. However, theoretically speaking, there is nothing to conclusively indicate that intergalactic travel is impossible. To date several academics have studied intergalactic travel in a serious manner.\n\nSpacecraft \n\nSpacecraft are vehicles capable of controlling their trajectory through space.\n\nThe first 'true spacecraft' is sometimes said to be Apollo Lunar Module, since this was the only crewed vehicle to have been designed for, and operated only in space; and is notable for its non-aerodynamic shape.\n\nPropulsion \n\nSpacecraft today predominantly use rockets for propulsion, but other propulsion techniques such as ion drives are becoming more common, particularly for uncrewed vehicles, and this can significantly reduce the vehicle's mass and increase its delta-v.\n\nLaunch systems \n\nLaunch systems are used to carry a payload from Earth's surface into outer space.\n\nExpendable \n\nMost current spaceflight uses multi-stage expendable launch systems to reach space.\n\nReusable \n\nThe first reusable spacecraft, the X-15, was air-launched on a suborbital trajectory on 19 July 1963. The first partially reusable orbital spacecraft, the Space Shuttle, was launched by the USA on the 20th anniversary of Yuri Gagarin's flight, on 12 April 1981. During the Shuttle era, six orbiters were built, all of which flown in the atmosphere and five of which flown in space. The Enterprise was used only for approach and landing tests, launching from the back of a Boeing 747 and gliding to deadstick landings at Edwards AFB, California. The first Space Shuttle to fly into space was the Columbia, followed by the Challenger, Discovery, Atlantis, and Endeavour. The Endeavour was built to replace the Challenger, which was lost in January 1986. The Columbia broke up during reentry in February 2003.\n\nThe first automatic partially reusable spacecraft was the Buran (Snowstorm), launched by the USSR on 15 November 1988, although it made only one flight. This spaceplane was designed for a crew and strongly resembled the US Space Shuttle, although its drop-off boosters used liquid propellants and its main engines were located at the base of what would be the external tank in the American Shuttle. Lack of funding, complicated by the dissolution of the USSR, prevented any further flights of Buran.\n\nThe Space Shuttle was retired in 2011 due mainly to its old age and high cost of the program reaching over a billion dollars per flight. The Shuttle's human transport role is to be replaced by the SpaceX Dragon 2 and CST-100 in the 2020s. The Shuttle's heavy cargo transport role is now done by commercial launch vehicles.\n\nScaled Composites SpaceShipOne was a reusable suborbital spaceplane that carried pilots Mike Melvill and Brian Binnie on consecutive flights in 2004 to win the Ansari X Prize. The Spaceship Company has built its successor SpaceShipTwo. A fleet of SpaceShipTwos operated by Virgin Galactic planned to begin reusable private spaceflight carrying paying passengers (space tourists) in 2008, but this was delayed due to an accident in the propulsion development.\n\nSpaceX achieved the first vertical soft landing of a re-usable orbital rocket stage on December 21, 2015, after delivering 11 Orbcomm OG-2 commercial satellites into low Earth orbit.\n\nThe first Falcon 9 second flight occurred on 30 March 2017. SpaceX now routinely recovers and reuses their first stages, with the intent of reusing fairings as well.\n\nChallenges\n\nSpace disasters \n\nAll launch vehicles contain a huge amount of energy that is needed for some part of it to reach orbit. There is therefore some risk that this energy can be released prematurely and suddenly, with significant effects. When a Delta II rocket exploded 13 seconds after launch on January 17, 1997, there were reports of store windows  away being broken by the blast.\n\nSpace is a fairly predictable environment, but there are still risks of accidental depressurization and the potential failure of equipment, some of which may be very newly developed.\n\nIn 2004 the International Association for the Advancement of Space Safety was established in the Netherlands to further international cooperation and scientific advancement in space systems safety.\n\nWeightlessness \n\nIn a microgravity environment such as that provided by a spacecraft in orbit around the Earth, humans experience a sense of \"weightlessness.\" Short-term exposure to microgravity causes space adaptation syndrome, a self-limiting nausea caused by derangement of the vestibular system. Long-term exposure causes multiple health issues. The most significant is bone loss, some of which is permanent, but microgravity also leads to significant deconditioning of muscular and cardiovascular tissues.\n\nRadiation \nOnce above the atmosphere, radiation due to the Van Allen belts, solar radiation and cosmic radiation issues occur and increase. Further away from the Earth, solar flares can give a fatal radiation dose in minutes, and the health threat from cosmic radiation significantly increases the chances of cancer over a decade exposure or more.\n\nLife support \n\nIn human spaceflight, the life support system is a group of devices that allow a human being to survive in outer space. NASA often uses the phrase Environmental Control and Life Support System or the acronym ECLSS when describing these systems for its human spaceflight missions. The life support system may supply: air, water and food. It must also maintain the correct body temperature, an acceptable pressure on the body and deal with the body's waste products. Shielding against harmful external influences such as radiation and micro-meteorites may also be necessary. Components of the life support system are life-critical, and are designed and constructed using safety engineering techniques.\n\nSpace weather \n\nSpace weather is the concept of changing environmental conditions in outer space. It is distinct from the concept of weather within a planetary atmosphere, and deals with phenomena involving ambient plasma, magnetic fields, radiation and other matter in space (generally close to Earth but also in interplanetary, and occasionally interstellar medium). \"Space weather describes the conditions in space that affect Earth and its technological systems. Our space weather is a consequence of the behavior of the Sun, the nature of Earth's magnetic field, and our location in the Solar System.\"\n\nSpace weather exerts a profound influence in several areas related to space exploration and development. Changing geomagnetic conditions can induce changes in atmospheric density causing the rapid degradation of spacecraft altitude in Low Earth orbit. Geomagnetic storms due to increased solar activity can potentially blind sensors aboard spacecraft, or interfere with on-board electronics. An understanding of space environmental conditions is also important in designing shielding and life support systems for crewed spacecraft.\n\nEnvironmental considerations \n\nRockets as a class are not inherently grossly polluting. However, some rockets use toxic propellants, and most vehicles use propellants that are not carbon neutral. Many solid rockets have chlorine in the form of perchlorate or other chemicals, and this can cause temporary local holes in the ozone layer. Re-entering spacecraft generate nitrates which also can temporarily impact the ozone layer. Most rockets are made of metals that can have an environmental impact during their construction.\n\nIn addition to the atmospheric effects there are effects on the near-Earth space environment. There is the possibility that orbit could become inaccessible for generations due to exponentially increasing space debris caused by spalling of satellites and vehicles (Kessler syndrome). Many launched vehicles today are therefore designed to be re-entered after use.\n\nRegulation \n\nA wide range of issues such as space traffic management or liability have been issues of spaceflight regulation.\n\nParticipation and representation of all humanity in spaceflight is an issue of international space law ever since the first phase of space exploration. Even though some rights of non-spacefaring countries have been secured, sharing of space for all humanity is still criticized as imperialist and lacking, understanding spaceflight as a resource.\n\nApplications \n\nCurrent and proposed applications for spaceflight include:\n Earth observation satellites such as spy satellites, weather satellites\n Space exploration\n Communication satellites\n Satellite television\n Satellite navigation\n Space tourism\n Protecting Earth from potentially hazardous objects\n Space colonization\n\nMost early spaceflight development was paid for by governments. However, today major launch markets such as communication satellites and satellite television are purely commercial, though many of the launchers were originally funded by governments.\n\nPrivate spaceflight is a rapidly developing area: space flight that is not only paid for by corporations or even private individuals, but often provided by private spaceflight companies. These companies often assert that much of the previous high cost of access to space was caused by governmental inefficiencies they can avoid. This assertion can be supported by much lower published launch costs for private space launch vehicles such as Falcon 9 developed with private financing. Lower launch costs and excellent safety will be required for the applications such as space tourism and especially space colonization to become feasible for expansion.\n\nSpacefaring civilization: nations and other entities\n\nTo be spacefaring is to be capable of and active in the operation of spacecraft. It involves a knowledge of a variety of topics and development of specialised skills including: aeronautics; astronautics; programs to train astronauts; space weather and forecasting; spacecraft operations; operation of various equipment; spacecraft design and construction; atmospheric takeoff and reentry; orbital mechanics (a.k.a. astrodynamics); communications; engines and rockets; execution of evolutions such as towing, microgravity construction, and space docking; cargo handling equipment, dangerous cargos and cargo storage; spacewalking; dealing with emergencies; survival at space and first aid; fire fighting; life support. The degree of knowledge needed within these areas is dependent upon the nature of the work and the type of vessel employed. \"Spacefaring\" is analogous to seafaring.\n\nThere has never been a crewed mission outside the Earth\u2013Moon system. However, the United States, Russia, China, European Space Agency  (ESA) countries, and a few corporations and enterprises have plans in various stages to travel to Mars (see Human mission to Mars).\n\nSpacefaring entities can be sovereign states, supranational entities, and private corporations. Spacefaring nations are those capable of independently building and launching craft into space. A growing number of private entities have become or are becoming spacefaring.\n\nGlobal \nThe United Nations Office for Outer Space Affairs (UNOOSA) started the first UN space program for a spacefare civilization, in 2016.\n\nCrewed spacefaring nations\n\nCurrently Russia, China, and the United States are the only crewed spacefaring nations.\nSpacefaring nations listed by year of first crewed launch:\n Soviet Union (Russia) (1961)\n United States (1961)\n China (2003)\n\nUncrewed spacefaring nations\n\nThe following nations or organizations have developed their own launch vehicles to launch uncrewed spacecraft into orbit either from their own territory or with foreign assistance (date of first launch in parentheses):\n\n Soviet Union (1957)\n United States (1958)\n France (1965)\n Italy (1967)\u2605\n Australia  (1967)\u2605\n Japan (1970)\n China (1970)\n United Kingdom (1971)\n European Space Agency (1979)\n India (1980)\n Israel (1988)\n Ukraine (1991)*\n Russia (1992)*\n Iran (2009)\n North Korea (2012)\n South Korea (2013)\u2605\n New Zealand (2018)\u2605\n *Previously a major region in the Soviet Union\n \u2605Launch vehicle fully or partially developed by another country\n\nAlso several countries, such as Canada, Italy and Australia, had semi-independent spacefaring capability, launching locally-built satellites on foreign launchers.   Canada had designed and built satellites (Alouette 1 and 2) in 1962 and 1965 which were orbited using US launch vehicles. Italy has designed and built several satellites, as well as pressurized modules for the International Space Station. \nEarly Italian satellites were launched using vehicles provided by NASA, first from Wallops Flight Facility in 1964 and then from a spaceport in Kenya (San Marco Platform) between 1967 and 1988; \nItaly has led the development of the Vega rocket programme within the European Space Agency since 1998.\nThe United Kingdom abandoned its independent space launch program in 1972 in favour of co-operating with the European Launcher Development Organisation (ELDO) on launch technologies until 1974. Australia abandoned its launcher program shortly after the successful launch of WRESAT, and became the only non-European member of ELDO.\n\nConsidering merely launching an object beyond the K\u00e1rm\u00e1n line to be the minimum requirement of spacefaring, Germany, with the V-2 rocket, became the first spacefaring nation in 1944.  The following nations have only achieved suborbital spaceflight capability by launching indigenous rockets or missiles or both into suborbital space.\n\n Germany (June 20, 1944)\n East Germany (April 12, 1957)\n Canada (September 5, 1959)\n Lebanon (November 21, 1962)\n Switzerland (October 27, 1967)\n Argentina (April 16, 1969)\n Brazil (September 21, 1976)\n Spain (February 18, 1981)\n West Germany (March 1, 1981)\n Iraq (June 1984)\n South Africa (June 1, 1989)\n Sweden (May 8, 1991)\n Yemen (May 12, 1994)\n Pakistan (April 6, 1998)\n Taiwan (December 15, 1998)\n Syria (September 1, 2000)\n Indonesia (September 29, 2004)\n Democratic Republic of the Congo\u00a0(2007)\n New Zealand (November 30, 2009)\n Norway (September 27, 2018)\n Netherlands (September 19, 2020)\nTurkey (October 29, 2020)\n\nSee also \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Space travel in science fiction\n\nReferences\n\nFurther reading \n Erik Gregerson (2010): An Explorer's Guide to the Universe \u2013 Unmanned Space Missions, Britannica Educational Publishing,  (eBook)\n\nExternal links \n\n Aerospace engineering at Wikiversity\n Encyclopedia Astronautica\n Basics of Spaceflight\n \n\n \nAstronautics",
  "Health": "Health, according to the World Health Organization, is \"a state of complete physical, mental and social well-being and not merely the absence of disease and infirmity\". A variety of definitions have been used for different purposes over time. Health can be promoted by encouraging healthful activities, such as regular physical exercise and adequate sleep, and by reducing or avoiding unhealthful activities or situations, such as smoking or excessive stress. Some factors affecting health are due to individual choices, such as whether to engage in a high-risk behavior, while others are due to structural causes, such as whether the society is arranged in a way that makes it easier or harder for people to get necessary healthcare services. Still other factors are beyond both individual and group choices, such as genetic disorders.\n\nHistory \nThe meaning of health has evolved over time. In keeping with the biomedical perspective, early definitions of health focused on the theme of the body's ability to function; health was seen as a state of normal function that could be disrupted from time to time by disease. An example of such a definition of health is: \"a state characterized by anatomic, physiologic, and psychological integrity; ability to perform personally valued family, work, and community roles; ability to deal with physical, biological, psychological, and social stress\". Then, in 1948, in a radical departure from previous definitions, the World Health Organization (WHO) proposed a definition that aimed higher, linking health to well-being, in terms of \"physical, mental, and social well-being, and not merely the absence of disease and infirmity\". Although this definition was welcomed by some as being innovative, it was also criticized for being vague and excessively broad and was not construed as measurable. For a long time, it was set aside as an impractical ideal, with most discussions of health returning to the practicality of the biomedical model.\n\nJust as there was a shift from viewing disease as a state to thinking of it as a process, the same shift happened in definitions of health. Again, the WHO played a leading role when it fostered the development of the health promotion movement in the 1980s. This brought in a new conception of health, not as a state, but in dynamic terms of resiliency, in other words, as \"a resource for living\". In 1984, WHO revised the definition of health defined it as \"the extent to which an individual or group is able to realize aspirations and satisfy needs and to change or cope with the environment. Health is a resource for everyday life, not the objective of living; it is a positive concept, emphasizing social and personal resources, as well as physical capacities.\" Thus, health referred to the ability to maintain homeostasis and recover from adverse events. Mental, intellectual, emotional and social health referred to a person's ability to handle stress, to acquire skills, to maintain relationships, all of which form resources for resiliency and independent living. This opens up many possibilities for health to be taught, strengthened and learned.\n\nSince the late 1970s, the federal Healthy People Program has been a visible component of the United States\u2019 approach to improving population health. In each decade, a new version of Healthy People is issued, featuring updated goals and identifying topic areas and quantifiable objectives for health improvement during the succeeding ten years, with assessment at that point of progress or lack thereof. Progress has been limited to many objectives, leading to concerns about the effectiveness of Healthy People in shaping outcomes in the context of a decentralized and uncoordinated US health system. Healthy People 2020 gives more prominence to health promotion and preventive approaches and adds a substantive focus on the importance of addressing social determinants of health. A new expanded digital interface facilitates use and dissemination rather than bulky printed books as produced in the past. The impact of these changes to Healthy People will be determined in the coming years.\n\nSystematic activities to prevent or cure health problems and promote good health in humans are undertaken by health care providers. Applications with regard to animal health are covered by the veterinary sciences. The term \"healthy\" is also widely used in the context of many types of non-living organizations and their impacts for the benefit of humans, such as in the sense of healthy communities, healthy cities or healthy environments. In addition to health care interventions and a person's surroundings, a number of other factors are known to influence the health status of individuals. These are referred to as the \"determinants of health\", which include the individual's background, lifestyle, economic status, social conditions and spirituality; Studies have shown that high levels of stress can affect human health.\n\nIn the first decade of the 21st century, the conceptualization of health as an ability opened the door for self-assessments to become the main indicators to judge the performance of efforts aimed at improving human health. It also created the opportunity for every person to feel healthy, even in the presence of multiple chronic diseases or a terminal condition, and for the re-examination of determinants of health (away from the traditional approach that focuses on the reduction of the prevalence of diseases).\n\nDeterminants\n\nIn general, the context in which an individual lives is of great importance for both his health status and quality of life. It is increasingly recognized that health is maintained and improved not only through the advancement and application of health science, but also through the efforts and intelligent lifestyle choices of the individual and society. According to the World Health Organization, the main determinants of health include the social and economic environment, the physical environment, and the person's individual characteristics and behaviors.\n\nMore specifically, key factors that have been found to influence whether people are healthy or unhealthy include the following:\n\n Income and social status\n Social support networks\n Education and literacy\n Employment/working conditions\n Social environments\n Physical environments\n\n Personal health practices and coping skills\n Healthy child development\n Biology and genetics\n Health care services\n Gender\n Culture\n\nAn increasing number of studies and reports from different organizations and contexts examine the linkages between health and different factors, including lifestyles, environments, health care organization and health policy, one specific health policy brought into many countries in recent years was the introduction of the sugar tax. Beverage taxes came into light with increasing concerns about obesity, particularly among youth. Sugar-sweetened beverages have become a target of anti-obesity initiatives with increasing evidence of their link to obesity.\u2013 such as the 1974 Lalonde report from Canada; the Alameda County Study in California; and the series of World Health Reports of the World Health Organization, which focuses on global health issues including access to health care and improving public health outcomes, especially in developing countries.\n\nThe concept of the \"health field,\" as distinct from medical care, emerged from the Lalonde report from Canada. The report identified three interdependent fields as key determinants of an individual's health. These are:\n Lifestyle: the aggregation of personal decisions (i.e., over which the individual has control) that can be said to contribute to, or cause, illness or death;\n Environmental: all matters related to health external to the human body and over which the individual has little or no control;\n Biomedical: all aspects of health, physical and mental, developed within the human body as influenced by genetic make-up.\n\nThe maintenance and promotion of health is achieved through different combination of physical, mental, and social well-being\u2014a combination sometimes referred to as the \"health triangle.\" The WHO's 1986 Ottawa Charter for Health Promotion further stated that health is not just a state, but also \"a resource for everyday life, not the objective of living. Health is a positive concept emphasizing social and personal resources, as well as physical capacities.\"\n\nFocusing more on lifestyle issues and their relationships with functional health, data from the Alameda County Study suggested that people can improve their health via exercise, enough sleep, spending time in nature, maintaining a healthy body weight, limiting alcohol use, and avoiding smoking. Health and illness can co-exist, as even people with multiple chronic diseases or terminal illnesses can consider themselves healthy.\n\nThe environment is often cited as an important factor influencing the health status of individuals. This includes characteristics of the natural environment, the built environment and the social environment. Factors such as clean water and air, adequate housing, and safe communities and roads all have been found to contribute to good health, especially to the health of infants and children. Some studies have shown that a lack of neighborhood recreational spaces including natural environment leads to lower levels of personal satisfaction and higher levels of obesity, linked to lower overall health and well-being. It has been demonstrated that increased time spent in natural environments is associated with improved self-reported health, suggesting that the positive health benefits of natural space in urban neighborhoods should be taken into account in public policy and land use.\n\nGenetics, or inherited traits from parents, also play a role in determining the health status of individuals and populations. This can encompass both the predisposition to certain diseases and health conditions, as well as the habits and behaviors individuals develop through the lifestyle of their families. For example, genetics may play a role in the manner in which people cope with stress, either mental, emotional or physical. For example, obesity is a significant problem in the United States that contributes to poor mental health and causes stress in the lives of many people. One difficulty is the issue raised by the debate over the relative strengths of genetics and other factors; interactions between genetics and environment may be of particular importance.\n\nPotential issues\nA number of health issues are common around the globe. Disease is one of the most common. According to GlobalIssues.org, approximately 36\u00a0million people die each year from non-communicable (i.e., not contagious) diseases, including cardiovascular disease, cancer, diabetes and chronic lung disease.\n\nAmong communicable diseases, both viral and bacterial, AIDS/HIV, tuberculosis, and malaria are the most common, causing millions of deaths every year.\n\nAnother health issue that causes death or contributes to other health problems is malnutrition, especially among children. One of the groups malnutrition affects most is young children. Approximately 7.5 million children under the age of 5 die from malnutrition, usually brought on by not having the money to find or make food.\n\nBodily injuries are also a common health issue worldwide. These injuries, including bone fractures and burns, can reduce a person's quality of life or can cause fatalities including infections that resulted from the injury (or the severity injury in general).\n\nLifestyle choices are contributing factors to poor health in many cases. These include smoking cigarettes, and can also include a poor diet, whether it is overeating or an overly constrictive diet. Inactivity can also contribute to health issues and also a lack of sleep, excessive alcohol consumption, and neglect of oral hygiene. There are also genetic disorders that are inherited by the person and can vary in how much they affect the person (and when they surface).\n\nAlthough the majority of these health issues are preventable, a major contributor to global ill health is the fact that approximately 1 billion people lack access to health care systems. Arguably, the most common and harmful health issue is that a great many people do not have access to quality remedies.\n\nMental health\n\nThe World Health Organization describes mental health as \"a state of well-being in which the individual realizes his or her own abilities, can cope with the normal stresses of life, can work productively and fruitfully, and is able to make a contribution to his or her community\". Mental health is not just the absence of mental illness.\n\nMental illness is described as 'the spectrum of cognitive, emotional, and behavioral conditions that interfere with social and emotional well-being and the lives and productivity of people. Having a mental illness can seriously impair, temporarily or permanently, the mental functioning of a person. Other terms include: 'mental health problem', 'illness', 'disorder', 'dysfunction'.\n\nApproximately twenty percent of all adults in the US are considered diagnosable with a mental illness. Mental illnesses are the leading cause of disability in the US and Canada. Examples of these illnesses include schizophrenia, ADHD, major depressive disorder, bipolar disorder, anxiety disorder, post-traumatic stress disorder and autism.\n\n\u00a0Many factors contribute to mental health problems, including:\n Biological factors, such as genes or brain chemistry\n Life experiences, such as trauma or abuse\n Family history of mental health problems\n\nMaintaining\nAchieving and maintaining health is an ongoing process, shaped by both the evolution of health care knowledge and practices as well as personal strategies and organized interventions for staying healthy.\n\nDiet\n\nAn important way to maintain one's personal health is to have a healthy diet. A healthy diet includes a variety of plant-based and animal-based foods that provide nutrients to the body. Such nutrients provide the body with energy and keep it running. Nutrients help build and strengthen bones, muscles, and tendons and also regulate body processes (i.e., blood pressure). Water is essential for growth, reproduction and good health. Macronutrients are consumed in relatively large quantities and include proteins, carbohydrates, and fats and fatty acids. Micronutrients \u2013 vitamins and minerals \u2013 are consumed in relatively smaller quantities, but are essential to body processes. The food guide pyramid is a pyramid-shaped guide of healthy foods divided into sections. Each section shows the recommended intake for each food group (i.e., protein, fat, carbohydrates and sugars). Making healthy food choices can lower one's risk of heart disease and the risk of developing some types of cancer, and can help one maintain their weight within a healthy range.\n\nThe Mediterranean diet is commonly associated with health-promoting effects. This is sometimes attributed to the inclusion of bioactive compounds such as phenolic compounds, isoprenoids and alkaloids.\n\nExercise\n\nPhysical exercise enhances or maintains physical fitness and overall health and wellness. It strengthens one's bones and muscles and improves the cardiovascular system. According to the National Institutes of Health, there are four types of exercise: endurance, strength, flexibility, and balance. The CDC states that physical exercise can reduce the risks of heart disease, cancer, type 2 diabetes, high blood pressure, obesity, depression, and anxiety. For the purpose of counteracting possible risks, it is often recommended to start physical exercise gradually as one goes. Participating in any exercising, whether it is housework, yardwork, walking or standing up when talking on the phone, is often thought to be better than none when it comes to health.\n\nSleep\n\nSleep is an essential component to maintaining health. In children, sleep is also vital for growth and development. Ongoing sleep deprivation has been linked to an increased risk for some chronic health problems. In addition, sleep deprivation has been shown to correlate with both increased susceptibility to illness and slower recovery times from illness. In one study, people with chronic insufficient sleep, set as six hours of sleep a night or less, were found to be four times more likely to catch a cold compared to those who reported sleeping for seven hours or more a night. Due to the role of sleep in regulating metabolism, insufficient sleep may also play a role in weight gain or, conversely, in impeding weight loss. Additionally, in 2007, the International Agency for Research on Cancer, which is the cancer research agency for the World Health Organization, declared that \"shiftwork that involves circadian disruption is probably carcinogenic to humans,\" speaking to the dangers of long-term nighttime work due to its intrusion on sleep. In 2015, the National Sleep Foundation released updated recommendations for sleep duration requirements based on age, and concluded that \"Individuals who habitually sleep outside the normal range may be exhibiting signs or symptoms of serious health problems or, if done volitionally, may be compromising their health and well-being.\"\n\nRole of science\n\nHealth science is the branch of science focused on health. There are two main approaches to health science: the study and research of the body and health-related issues to understand how humans (and animals) function, and the application of that knowledge to improve health and to prevent and cure diseases and other physical and mental impairments. The science builds on many sub-fields, including biology, biochemistry, physics, epidemiology, pharmacology, medical sociology. Applied health sciences endeavor to better understand and improve human health through applications in areas such as health education, biomedical engineering, biotechnology and public health.\n\nOrganized interventions to improve health based on the principles and procedures developed through the health sciences are provided by practitioners trained in medicine, nursing, nutrition, pharmacy, social work, psychology, occupational therapy, physical therapy and other health care professions. Clinical practitioners focus mainly on the health of individuals, while public health practitioners consider the overall health of communities and populations. Workplace wellness programs are increasingly being adopted by companies for their value in improving the health and well-being of their employees, as are school health services in order to improve the health and well-being of children.\n\nRole of medicine and medical science\n\nContemporary medicine is in general conducted within health care systems. Legal, credentialing and financing frameworks are established by individual governments, augmented on occasion by international organizations, such as churches. The characteristics of any given health care system have significant impact on the way medical care is provided.\n\nFrom ancient times, Christian emphasis on practical charity gave rise to the development of systematic nursing and hospitals and the Catholic Church today remains the largest non-government provider of medical services in the world. Advanced industrial countries (with the exception of the United States) and many developing countries provide medical services through a system of universal health care that aims to guarantee care for all through a single-payer health care system, or compulsory private or co-operative health insurance. This is intended to ensure that the entire population has access to medical care on the basis of need rather than ability to pay. Delivery may be via private medical practices or by state-owned hospitals and clinics, or by charities, most commonly by a combination of all three.\n\nMost tribal societies provide no guarantee of healthcare for the population as a whole. In such societies, healthcare is available to those that can afford to pay for it or have self-insured it (either directly or as part of an employment contract) or who may be covered by care financed by the government or tribe directly.\n\nTransparency of information is another factor defining a delivery system. Access to information on conditions, treatments, quality, and pricing greatly affects the choice by patients/consumers and, therefore, the incentives of medical professionals. While the US healthcare system has come under fire for lack of openness, new legislation may encourage greater openness. There is a perceived tension between the need for transparency on the one hand and such issues as patient confidentiality and the possible exploitation of information for commercial gain on the other.\n\nDelivery\n\nProvision of medical care is classified into primary, secondary, and tertiary care categories.\n\nPrimary care medical services are provided by physicians, physician assistants, nurse practitioners, or other health professionals who have first contact with a patient seeking medical treatment or care. These occur in physician offices, clinics, nursing homes, schools, home visits, and other places close to patients. About 90% of medical visits can be treated by the primary care provider. These include treatment of acute and chronic illnesses, preventive care and health education for all ages and both sexes.\n\nSecondary care medical services are provided by medical specialists in their offices or clinics or at local community hospitals for a patient referred by a primary care provider who first diagnosed or treated the patient. Referrals are made for those patients who required the expertise or procedures performed by specialists. These include both ambulatory care and inpatient services, Emergency departments, intensive care medicine, surgery services, physical therapy, labor and delivery, endoscopy units, diagnostic laboratory and medical imaging services, hospice centers, etc. Some primary care providers may also take care of hospitalized patients and deliver babies in a secondary care setting.\n\nTertiary care medical services are provided by specialist hospitals or regional centers equipped with diagnostic and treatment facilities not generally available at local hospitals. These include trauma centers, burn treatment centers, advanced neonatology unit services, organ transplants, high-risk pregnancy, radiation oncology, etc.\n\nModern medical care also depends on information \u2013 still delivered in many health care settings on paper records, but increasingly nowadays by electronic means.\n\nIn low-income countries, modern healthcare is often too expensive for the average person. International healthcare policy researchers have advocated that \"user fees\" be removed in these areas to ensure access, although even after removal, significant costs and barriers remain.\n\nSeparation of prescribing and dispensing is a practice in medicine and pharmacy in which the physician who provides a medical prescription is independent from the  pharmacist who provides the prescription drug. In the Western world there are centuries of tradition for separating pharmacists from physicians. In Asian countries, it is traditional for physicians to also provide drugs.\n\nRole of public health\n\nPublic health has been described as \"the science and art of preventing disease, prolonging life and promoting health through the organized efforts and informed choices of society, organizations, public and private, communities and individuals.\" It is concerned with threats to the overall health of a community based on population health analysis. The population in question can be as small as a handful of people or as large as all the inhabitants of several continents (for instance, in the case of a pandemic). Public health has many sub-fields, but typically includes the interdisciplinary categories of epidemiology, biostatistics and health services. Environmental health, community health, behavioral health, and occupational health are also important areas of public health.\n\nThe focus of public health interventions is to prevent and manage diseases, injuries and other health conditions through surveillance of cases and the promotion of healthy behavior, communities, and (in aspects relevant to human health) environments. Its aim is to prevent health problems from happening or re-occurring by implementing educational programs, developing policies, administering services and conducting research. In many cases, treating a disease or controlling a pathogen can be vital to preventing it in others, such as during an outbreak. Vaccination programs and distribution of condoms to prevent the spread of communicable diseases are examples of common preventive public health measures, as are educational campaigns to promote vaccination and the use of condoms (including overcoming resistance to such).\n\nPublic health also takes various actions to limit the health disparities between different areas of the country and, in some cases, the continent or world. One issue is the access of individuals and communities to health care in terms of financial, geographical or socio-cultural constraints. Applications of the public health system include the areas of maternal and child health, health services administration, emergency response, and prevention and control of infectious and chronic diseases.\n\nThe great positive impact of public health programs is widely acknowledged. Due in part to the policies and actions developed through public health, the 20th century registered a decrease in the mortality rates for infants and children and a continual increase in life expectancy in most parts of the world. For example, it is estimated that life expectancy has increased for Americans by thirty years since 1900, and worldwide by six years since 1990.\n\nSelf-care strategies\n\nPersonal health depends partially on the active, passive, and assisted cues people observe and adopt about their own health. These include personal actions for preventing or minimizing the effects of a disease, usually a chronic condition, through integrative care. They also include personal hygiene practices to prevent infection and illness, such as bathing and washing hands with soap; brushing and flossing teeth; storing, preparing and handling food safely; and many others. The information gleaned from personal observations of daily living\u00a0\u2013 such as about sleep patterns, exercise behavior, nutritional intake and environmental features\u00a0\u2013 may be used to inform personal decisions and actions (e.g., \"I feel tired in the morning so I am going to try sleeping on a different pillow\"), as well as clinical decisions and treatment plans (e.g., a patient who notices his or her shoes are tighter than usual may be having exacerbation of left-sided heart failure, and may require diuretic medication to reduce fluid overload).\n\nPersonal health also depends partially on the social structure of a person's life. The maintenance of strong social relationships, volunteering, and other social activities have been linked to positive mental health and also increased longevity. One American study among seniors over age 70, found that frequent volunteering was associated with reduced risk of dying compared with older persons who did not volunteer, regardless of physical health status. Another study from Singapore reported that volunteering retirees had significantly better cognitive performance scores, fewer depressive symptoms, and better mental well-being and life satisfaction than non-volunteering retirees.\n\nProlonged psychological stress may negatively impact health, and has been cited as a factor in cognitive impairment with aging, depressive illness, and expression of disease. Stress management is the application of methods to either reduce stress or increase tolerance to stress. Relaxation techniques are physical methods used to relieve stress. Psychological methods include cognitive therapy, meditation, and positive thinking, which work by reducing response to stress. Improving relevant skills, such as problem solving and time management skills, reduces uncertainty and builds confidence, which also reduces the reaction to stress-causing situations where those skills are applicable.\n\nOccupational\n\nIn addition to safety risks, many jobs also present risks of disease, illness and other long-term health problems. Among the most common occupational diseases are various forms of pneumoconiosis, including silicosis and coal worker's pneumoconiosis (black lung disease). Asthma is another respiratory illness that many workers are vulnerable to. Workers may also be vulnerable to skin diseases, including eczema, dermatitis, urticaria, sunburn, and skin cancer. Other occupational diseases of concern include carpal tunnel syndrome and lead poisoning.\n\nAs the number of service sector jobs has risen in developed countries, more and more jobs have become sedentary, presenting a different array of health problems than those associated with manufacturing and the primary sector. Contemporary problems, such as the growing rate of obesity and issues relating to stress and overwork in many countries, have further complicated the interaction between work and health.\n\nMany governments view occupational health as a social challenge and have formed public organizations to ensure the health and safety of workers. Examples of these include the British Health and Safety Executive and in the United States, the National Institute for Occupational Safety and Health, which conducts research on occupational health and safety, and the Occupational Safety and Health Administration, which handles regulation and policy relating to worker safety and health.\n\nSee also\n\n Disease burden\n Environmental health\n Healing\n Health equity\n Human enhancement\n Men's health\n One Health\n Population health\n Women's health\n Youth health\n  List of health and wellness podcasts\n\nReferences\n\nExternal links\n\n \n\n \nPersonal life\nArticles containing video clips\nMain topic articles",
  "Military": "A military, also known collectively as armed forces, is a heavily armed, highly organized force primarily intended for warfare. It is typically authorized and maintained by a sovereign state, with its members identifiable by their distinct military uniform. It may consist of one or more military branches such as an army, navy, air force, space force, marines, or coast guard. The main task of the military is usually defined as defence of the state and its interests against external armed threats.\n\nIn broad usage, the terms armed forces and military are often treated as synonymous, although in technical usage a distinction is sometimes made in which a country's armed forces may include both its military and other paramilitary forces. There are various forms of irregular military forces, not belonging to a recognized state; though they share many attributes with regular military forces, they are less often referred to as simply military.\n\nA nation's military may function as a discrete social subculture, with dedicated infrastructure such as military housing, schools, utilities, logistics, hospitals, legal services, food production, finance, and banking services. Beyond warfare, the military may be employed in additional sanctioned and non-sanctioned functions within the state, including internal security threats, population control, the promotion of a political agenda, emergency services and reconstruction, protecting corporate economic interests, social ceremonies and national honour guards.\n\nThe profession of soldiering as part of a military is older than recorded history itself. Some of the most enduring images of  classical antiquity portray the power and feats of its military leaders. The Battle of Kadesh in 1274 BC was one of the defining points of Pharaoh Ramses II's reign, and his monuments commemorate it in bas-relief. A thousand years later, the first emperor of unified China, Qin Shi Huang, was so determined to impress the gods with his military might that he had himself buried with an army of  terracotta soldiers.\nThe  Romans paid considerable attention to military matters, leaving to posterity many treatises and writings on the subject, as well as many lavishly carved triumphal arches and victory columns.\n\nEtymology and definitions\n\nThe first recorded use of the word military in English, spelled , was in 1582. It comes from the Latin militaris (from Latin miles, meaning \"soldier\") through French, but is of uncertain etymology, one suggestion being derived from *mil-it- \u2013 going in a body or mass.\n\nAs a noun, the military usually refers generally to a country's armed forces, or sometimes, more specifically, to the senior officers who command them. In general, it refers to the physicality of armed forces, their personnel, equipment, and the physical area which they occupy.\n\nAs an adjective, military originally referred only to soldiers and soldiering, but it soon broadened to apply to land forces in general, and anything to do with their profession. The names of both the Royal Military Academy (1741) and United States Military Academy (1802) reflect this. However, at about the time of the Napoleonic Wars, 'military' began to be used in reference to armed forces as a whole, such as 'military service', 'military intelligence', and 'military history'. As such, it now connotes any activity performed by armed force personnel.\n\nHistory\n\nMilitary history is often considered to be the history of all conflicts, not just the history of the state militaries. It differs somewhat from the history of war, with military history focusing on the people and institutions of war-making, while the history of war focuses on the evolution of war itself in the face of changing technology, governments, and geography.\n\nMilitary history has a number of facets. One main facet is to learn from past accomplishments and mistakes, so as to more effectively wage war in the future. Another is to create a sense of military tradition, which is used to create cohesive military forces. Still, another may be to learn to prevent wars more effectively. Human knowledge about the military is largely based on both recorded and oral history of military conflicts (war), their participating armies and navies and, more recently, air forces.\n\nOrganization\n\nPersonnel and units\n\nDespite the growing importance of military technology, military activity depends above all on people. For example, in 2000 the British Army declared: \"Man is still the first weapon of war.\"\n\nRank and role \nThe military organization is characterized by a strict command hierarchy divided by military rank, with ranks normally grouped (in descending order of authority) as officers (e.g. Colonel), non-commissioned officers (e.g. Sergeant), and personnel at the lowest rank (e.g. Private Soldier). While senior officers make strategic decisions, subordinated military personnel (soldiers, sailors, marines, or airmen) fulfil them. Although rank titles vary by military branch and country, the rank hierarchy is common to all state armed forces worldwide.\n\nIn addition to their rank, personnel occupy one of many trade roles, which are often grouped according to the nature of the role's military tasks on combat operations: combat roles (e.g. infantry), combat support roles (e.g. combat engineers), and combat service support roles (e.g. logistical support).\n\nIn the past, the armed forces of some Communist states, such as the Soviet Union, China and Albania, have attempted to abolish military ranks, but they were later reintroduced due to operational difficulties relating to command and control.\n\nRecruitment \n\nPersonnel may be recruited or conscripted, depending on the system chosen by the state. Most military personnel are males; the minority proportion of female personnel varies internationally (approximately 3% in India, 10% in the UK, 13% in Sweden, 16% in the US, and 27% in South Africa). While two-thirds of states now recruit or conscript only adults, as of 2017 50 states still relied partly on children under the age of 18 (usually aged 16 or 17) to staff their armed forces.\n\nWhereas recruits who join as officers tend to be upwardly-mobile, most enlisted personnel have a childhood background of relative socio-economic deprivation.\u00a0For example, after the US suspended conscription in 1973, \"the military disproportionately attracted African American men, men from lower-status socioeconomic backgrounds, men who had been in nonacademic high school programs, and men whose high school grades tended to be low\".  However, a study released in 2020 on the socio-economic backgrounds of U.S. Armed Forces personnel suggests that they are at parity or slightly higher than the civilian population with respect to socio-economic indicators such as parental income, parental wealth and cognitive abilities. The study found that technological, tactical, operational and doctrinal changes have led to a change in the demand for personnel. Furthermore, the study suggests that the most disadvantaged socio-economic groups are less likely to meet the requirements of the modern U.S. military.\n\nObligations \n\nThe obligations of military employment are many. Full-time military employment normally requires a minimum period of service of several years; between two and six years is typical of armed forces in Australia, the UK and the US, for example, depending on role, branch, and rank. Some armed forces allow a short discharge window, normally during training, when recruits may leave the armed force as of right. Alternatively, part-time military employment, known as reserve service, allows a recruit to maintain a civilian job while training under military discipline at weekends; he or she may be called out to deploy on operations to supplement the full-time personnel complement. After leaving the armed forces, recruits may remain liable for compulsory return to full-time military employment in order to train or deploy on operations.\n\nMilitary law introduces offences not recognised by civilian courts, such as absence without leave (AWOL), desertion, political acts, malingering, behaving disrespectfully, and disobedience (see, for example, offences against military law in the United Kingdom). Penalties range from a summary reprimand to imprisonment for several years following a court martial. Certain fundamental rights are also restricted or suspended, including the freedom of association (e.g. union organizing) and freedom of speech (speaking to the media). Military personnel in some countries have a right of conscientious objection if they believe an order is immoral or unlawful, or cannot in good conscience carry it out.\n\nPersonnel may be posted to bases in their home country or overseas, according to operational need, and may be deployed from those bases on exercises or operations anywhere in the world. During peacetime, when military personnel are generally stationed in garrisons or other permanent military facilities, they mostly conduct administrative tasks, training and education activities, technology maintenance, and recruitment.\n\nTraining \n\nInitial training conditions recruits for the demands of military life, including preparedness to injure and kill other people, and to face mortal danger without fleeing. It is a physically and psychologically intensive process which resocializes recruits for the unique nature of military demands. For example:\n Individuality is suppressed (e.g. by shaving the head of new recruits, issuing uniforms, denying privacy, and prohibiting the use of first names);\n Daily routine is tightly controlled (e.g. recruits must make their beds, polish boots, and stack their clothes in a certain way, and mistakes are punished);\n Continuous stressors deplete psychological resistance to the demands of their instructors (e.g. depriving recruits of sleep, food, or shelter, shouting insults and giving orders intended to humiliate) \n Frequent punishments serve to condition group conformity and discourage poor performance;\n The disciplined drill instructor is presented as a role model of the ideal soldier.\n\nIntelligence\n\nThe next requirement comes as a fairly basic need for the military to identify possible threats it may be called upon to face. For this purpose, some of the commanding forces and other military, as well as often civilian personnel participate in identification of these threats. This is at once an organization, a system and a process collectively called military intelligence (MI).\n\nThe difficulty in using military intelligence concepts and military intelligence methods is in the nature of the secrecy of the information they seek, and the clandestine nature that intelligence operatives work in obtaining what may be plans for a conflict escalation, initiation of combat, or an invasion.\n\nAn important part of the military intelligence role is the military analysis performed to assess military capability of potential future aggressors, and provide combat modelling that helps to understand factors on which comparison of forces can be made. This helps to quantify and qualify such statements as: \"China and India maintain the largest armed forces in the World\" or that \"the U.S. Military is considered to be the world's strongest\".\n\nAlthough some groups engaged in combat, such as militants or resistance movements, refer to themselves using military terminology, notably 'Army' or 'Front', none have had the structure of a national military to justify the reference, and usually have had to rely on support of outside national militaries. They also use these terms to conceal from the MI their true capabilities, and to impress potential ideological recruits.\n\nHaving military intelligence representatives participate in the execution of the national defence policy is important, because it becomes the first respondent and commentator on the policy expected strategic goal, compared to the realities of identified threats. When the intelligence reporting is compared to the policy, it becomes possible for the national leadership to consider allocating resources over and above the officers and their subordinates military pay, and the expense of maintaining military facilities and military support services for them.\n\nEconomics\n\nDefense economics is the financial and monetary efforts made to resource and sustain militaries, and to finance military operations, including war.\n\nThe process of allocating resources is conducted by determining a military budget, which is administered by a military finance organization within the military. Military procurement is then authorized to purchase or contract provision of goods and services to the military, whether in peacetime at a permanent base, or in a combat zone from local population.\n\nCapability development\nCapability development, which is often referred to as the military 'strength', is arguably one of the most complex activities known to humanity; because it requires determining: strategic, operational, and tactical capability requirements to counter the identified threats; strategic, operational, and tactical doctrines by which the acquired capabilities will be used; identifying concepts, methods, and systems involved in executing the doctrines; creating design specifications for the manufacturers who would produce these in adequate quantity and quality for their use in combat; purchase the concepts, methods, and systems; create a forces structure that would use the concepts, methods, and systems most effectively and efficiently; integrate these concepts, methods, and systems into the force structure by providing military education, training, and practice that preferably resembles combat environment of intended use; create military logistics systems to allow continued and uninterrupted performance of military organizations under combat conditions, including provision of health services to the personnel, and maintenance for the equipment; the services to assist recovery of wounded personnel, and repair of damaged equipment; and finally, post-conflict demobilization, and disposal of war stocks surplus to peacetime requirements.\n\nDevelopment of military doctrine is perhaps the more important of all capability development activities, because it determines how military forces are used in conflicts, the concepts and methods used by the command to employ appropriately military skilled, armed and equipped personnel in achievement of the tangible goals and objectives of the war, campaign, battle, engagement, and action. The line between strategy and tactics is not easily blurred, although deciding which is being discussed had sometimes been a matter of personal judgement by some commentators, and military historians. The use of forces at the level of organization between strategic and tactical is called operational mobility.\n\nScience\n\nBecause most of the concepts and methods used by the military, and many of its systems are not found in commercial branches, much of the material is researched, designed, developed, and offered for inclusion in arsenals by military science organizations within the overall structure of the military. Military scientists are therefore found to interact with all Arms and Services of the armed forces, and at all levels of the military hierarchy of command.\n\nAlthough concerned with research into military psychology, particularly combat stress and how it affect troop morale, often the bulk of military science activities is directed at military intelligence technology, military communications, and improving military capability through research. The design, development, and prototyping of weapons, military support equipment, and military technology in general, is also an area in which much effort is invested \u2013 it includes everything from global communication networks and aircraft carriers to paint and food.\n\nLogistics\n\nPossessing military capability is not sufficient if this capability cannot be deployed for, and employed in combat operations. To achieve this, military logistics are used for the logistics management and logistics planning of the forces military supply chain management, the consumables, and capital equipment of the troops.\n\nAlthough mostly concerned with the military transport, as a means of delivery using different modes of transport; from military trucks, to container ships operating from permanent military base, it also involves creating field supply dumps at the rear of the combat zone, and even forward supply points in specific unit's Tactical Area of Responsibility.\n\nThese supply points are also used to provide military engineering services, such as the recovery of defective and derelict vehicles and weapons, maintenance of weapons in the field, the repair and field modification of weapons and equipment; and in peacetime, the life-extension programmes undertaken to allow continued use of equipment. One of the most important role of logistics is the supply of munitions as a primary type of consumable, their storage, and disposal.\n\nIn combat\n\nThe primary reason for the existence of the military is to engage in combat, should it be required to do so by the national defence policy, and to win. This represents an organisational goal of any military, and the primary focus for military thought through military history. How victory is achieved, and what shape it assumes, is studied by most, if not all, military groups on three levels.\n\nStrategic victory\n\nMilitary strategy is the management of forces in wars and military campaigns by a commander-in-chief, employing large military forces, either national and allied as a whole, or the component elements of armies, navies and air forces; such as army groups, naval fleets, and large numbers of aircraft. Military strategy is a long-term projection of belligerents' policy, with a broad view of outcome implications, including outside the concerns of military command. Military strategy is more concerned with the supply of war and planning, than management of field forces and combat between them. The scope of strategic military planning can span weeks, but is more often months or even years.\n\nOperational victory\n\nOperational mobility is, within warfare and military doctrine, the level of command which coordinates the minute details of tactics with the overarching goals of strategy. A common synonym is operational art.\n\nThe operational level is at a scale bigger than one where line of sight and the time of day are important, and smaller than the strategic level, where production and politics are considerations. Formations are of the operational level if they are able to conduct operations on their own, and are of sufficient size to be directly handled or have a significant impact at the strategic level. This concept was pioneered by the German army prior to and during the Second World War. At this level, planning and duration of activities takes from one week to a month, and are executed by Field Armies and Army Corps and their naval and air equivalents.\n\nTactical victory\n\nMilitary tactics concerns itself with the methods for engaging and defeating the enemy in direct combat. Military tactics are usually used by units over hours or days, and are focused on the specific, close proximity tasks and objectives of squadrons, companies, battalions, regiments, brigades, and divisions, and their naval and air force equivalents.\n\nOne of the oldest military publications is The Art of War, by the Chinese philosopher Sun Tzu. Written in the 6th century BCE, the 13-chapter book is intended as military instruction, and not as military theory, but has had a huge influence on Asian military doctrine, and from the late 19th century, on European and United States military planning. It has even been used to formulate business tactics, and can even be applied in social and political areas.\n\nThe Classical Greeks and the Romans wrote prolifically on military campaigning. Among the best-known Roman works are Julius Caesar's commentaries on the Gallic Wars, and the Roman Civil war \u2013 written about 50 BC.\n\nTwo major works on tactics come from the late Roman period: Taktike Theoria by Aelianus Tacticus, and De Re Militari ('On military matters') by Vegetius. Taktike Theoria examined Greek military tactics, and was most influential in the Byzantine world and during the Golden Age of Islam.\n\nDe Re Militari formed the basis of European military tactics until the late 17th century. Perhaps its most enduring maxim is Igitur qui desiderat pacem, praeparet bellum (let he who desires peace prepare for war).\n\nDue to the changing nature of combat with the introduction of artillery in the European Middle Ages, and infantry firearms in the Renaissance, attempts were made to define and identify those strategies, grand tactics, and tactics that would produce a victory more often than that achieved by the Romans in praying to the gods before the battle.\n\nLater this became known as military science, and later still, would adopt the scientific method approach to the conduct of military operations under the influence of the Industrial Revolution thinking. In his seminal book On War, the Prussian Major-General and leading expert on modern military strategy, Carl von Clausewitz defined military strategy as 'the employment of battles to gain the end of war'. According to Clausewitz: strategy forms the plan of the War, and to this end it links together the series of acts which are to lead to the final decision, that is to say, it makes the plans for the separate campaigns and regulates the combats to be fought in each.\nHence, Clausewitz placed political aims above military goals, ensuring civilian control of the military. Military strategy was one of a triumvirate of 'arts' or 'sciences' that governed the conduct of warfare, the others being: military tactics, the execution of plans and manoeuvring of forces in battle, and maintenance of an army.\n\nThe meaning of military tactics has changed over time; from the deployment and manoeuvring of entire land armies on the fields of ancient battles, and galley fleets; to modern use of small unit ambushes, encirclements, bombardment attacks, frontal assaults, air assaults, hit-and-run tactics used mainly by guerrilla forces, and, in some cases, suicide attacks on land and at sea. Evolution of aerial warfare introduced its own air combat tactics. Often, military deception, in the form of military camouflage or misdirection using decoys, is used to confuse the enemy as a tactic.\n\nA major development in infantry tactics came with the increased use of trench warfare in the 19th and 20th centuries. This was mainly employed in World War I in the Gallipoli campaign, and the Western Front. Trench warfare often turned to a stalemate, only broken by a large loss of life, because, in order to attack an enemy entrenchment, soldiers had to run through an exposed 'no man's land' under heavy fire from their opposing entrenched enemy.\n\nTechnology\n\nAs with any occupation, since the ancient times, the military has been distinguished from other members of the society by their tools, the military weapons, and military equipment used in combat. When Stone Age humans first took a sliver of flint to tip the spear, it was the first example of applying technology to improve the weapon.\n\nSince then, the advances made by human societies, and that of weapons, has been irretrievably linked. Stone weapons gave way to Bronze Age weapons, and later, the Iron Age weapons. With each technological change, was realized some tangible increase in military capability, such as through greater effectiveness of a sharper edge in defeating leather armour, or improved density of materials used in manufacture of weapons.\n\nOn land, the first really significant technological advance in warfare was the development of the ranged weapons, and notably, the sling. The next significant advance came with the domestication of the horses and mastering of equestrianism.\n\nArguably, the greatest invention that affected not just the military, but all society, after adoption of fire, was the wheel, and its use in the construction of the chariot. There were no advances in military technology, until, from the mechanical arm action of a slinger, the Greeks, Egyptians, Romans, Persians, Chinese, etc., developed the siege engines. The bow was manufactured in increasingly larger and more powerful versions, to increase both the weapon range, and armour penetration performance. These developed into the powerful composite and recurve bows, and crossbows of Ancient China. These proved particularly useful during the rise of cavalry, as horsemen encased in ever-more sophisticated armour came to dominate the battlefield.\n\nSomewhat earlier, in medieval China, gunpowder had been invented, and was increasingly used by the military in combat. The use of gunpowder in the early vase-like mortars in Europe, and advanced versions of the long bow and cross bow, which all had armour-piercing arrowheads, that put an end to the dominance of the armoured knight. After the long bow, which required great skill and strength to use, the next most significant technological advance was the musket, which could be used effectively, with little training. In time, the successors to muskets and cannon, in the form of rifles and artillery, would become core battlefield technology.\n\nAs the speed of technological advances accelerated in civilian applications, so too warfare became more industrialized. The newly invented machine gun and repeating rifle redefined firepower on the battlefield, and, in part, explains the high casualty rates of the American Civil War. The next breakthrough was the conversion of artillery parks from the muzzle loading guns, to the quicker loading breech loading guns with recoiling barrel that allowed quicker aimed fire and use of a shield. The widespread introduction of low smoke (smokeless) propellant powders since the 1880s also allowed for a great improvement of artillery ranges.\n\nThe development of breech loading had the greatest effect on naval warfare, for the first time since the Middle Ages, altering the way weapons are mounted on warships, and therefore naval tactics, now divorced from the reliance on sails with the invention of the internal combustion. A further advance in military naval technology was the design of the submarine, and its weapon, the torpedo.\n\nMain battle tanks, and other heavy equipment such as armoured fighting vehicles, military aircraft, and ships, are characteristic to organized military forces.\n\nDuring World War I, the need to break the deadlock of trench warfare saw the rapid development of many new technologies, particularly tanks. Military aviation was extensively used, and bombers became decisive in many battles of World War II, which marked the most frantic period of weapons development in history. Many new designs, and concepts were used in combat, and all existing technologies of warfare were improved between 1939 and 1945.\n\nDuring the war, significant advances were made in military communications through increased use of radio, military intelligence through use of the radar, and in military medicine through use of penicillin, while in the air, the guided missile, jet aircraft, and helicopters were seen for the first time. Perhaps the most infamous of all military technologies was the creation of the atomic bomb, although the exact effects of its radiation were unknown until the early 1950s. Far greater use of military vehicles had finally eliminated the cavalry from the military force structure.\n\nAfter World War II, with the onset of the Cold War, the constant technological development of new weapons was institutionalized, as participants engaged in a constant 'arms race' in capability development. This constant state of weapons development continues into the present, and remains a constant drain on national resources, which some blame on the military\u2013industrial complex.\n\nThe most significant technological developments that influenced combat have been the guided missiles, which can be used by all branches of the armed services. More recently, information technology, and its use in surveillance, including space-based reconnaissance systems, have played an increasing role in military operations.\n\nThe impact of information warfare that focuses on attacking command communication systems, and military databases, has been coupled with the new development in military technology, has been the use of robotic systems in intelligence combat, both in hardware and software applications.\n\nRecently, there has also been a particular focus towards the use of renewable fuels for running military vehicles on. Unlike fossil fuels, renewable fuels can be produced in any country, creating a strategic advantage. The US military has committed itself to have 50% of its energy consumption come from alternative sources.\n\nAs part of society\n\nFor much of military history, the armed forces were considered to be for use by the heads of their societies, until recently, the crowned heads of states. In a democracy or other political system run in the public interest, it is a public force.\n\nThe relationship between the military and the society it serves is a complicated and ever-evolving one. Much depends on the nature of the society itself, and whether it sees the military as important, as for example in time of threat or war, or a burdensome expense typified by defence cuts in time of peace.\n\nOne difficult matter in the relation between military and society is control and transparency. In some countries, limited information on military operations and budgeting is accessible for the public. However transparency in the military sector is crucial to fight corruption. This showed the Government Defence Anti-corruption Index Transparency International UK published in 2013.\n\nMilitaries often function as societies within societies, by having their own military communities, economies, education, medicine, and other aspects of a functioning civilian society. Although a 'military' is not limited to nations in of itself as many private military companies (or PMC's) can be used or 'hired' by organizations and figures as security, escort, or other means of protection; where police, agencies, or militaries are absent or not trusted.\n\nIdeology and ethics\n\nMilitarist ideology is the society's social attitude of being best served, or being a beneficiary of a government, or guided by concepts embodied in the military culture, doctrine, system, or leaders.\n\nEither because of the cultural memory, national history, or the potentiality of a military threat, the militarist argument asserts that a civilian population is dependent upon, and thereby subservient to the needs and goals of its military for continued independence. Militarism is sometimes contrasted with the concepts of comprehensive national power, soft power and hard power.\n\nMost nations have separate military laws which regulate conduct in war and during peacetime. An early exponent was Hugo Grotius, whose On the Law of War and Peace (1625) had a major impact of the humanitarian approach to warfare development. His theme was echoed by Gustavus Adolphus.\n\nEthics of warfare have developed since 1945, to create constraints on the military treatment of prisoners and civilians, primarily by the Geneva Conventions; but rarely apply to use of the military forces as internal security troops during times of political conflict that results in popular protests and incitement to popular uprising.\n\nInternational protocols restrict the use, or have even created international bans on some types of weapons, notably weapons of mass destruction (WMD). International conventions define what constitutes a war crime, and provides for war crimes prosecution. Individual countries also have elaborate codes of military justice, an example being the United States' Uniform Code of Military Justice that can lead to court martial for military personnel found guilty of war crimes.\n\nMilitary actions are sometimes argued to be justified by furthering a humanitarian cause, such as disaster relief operations, or in defence of refugees. The term military humanism is used to refer to such actions.\n\nSee also\n\n Arms industry\n Civil defense\n Civilian control of the military\n Command and control\n Conscription\n Court-martial\n Deterrence theory\n Martial arts\n Martial law\n Mercenary\n Militaria\n Military academy\n Military advisor\n Military aid\n Military aid to the civil community (MACC)\n Military aid to the civil power (MACP)\n Military alliance\n Military dictatorship\n Military district\n Military engineering\n Military exercise\n Military fiat\n Military incompetence\n Military junta\n Military meteorology\n Military operations other than war\n Military police\n Military prison\n Military Revolution\n Military sociology\n Military terminology\n Military\u2013industrial complex\n Militarization of police\n Militia\n Ministry of defence\n Mobilization\n Police\n Private military company\n Recruit training\n Staff (military)\n Standing army\n Weapon\n\n Armed forces of the world\n List of countries by number of military and paramilitary personnel\n List of countries by Military Strength Index\n List of countries by level of military equipment\n List of countries by Global Militarization Index\n List of countries without armed forces\n List of countries by military expenditures\n List of countries by past military expenditure\n List of countries by military expenditure per capita\n List of air forces\n List of armies\n List of navies\n\nReferences\n\nExternal links \n\n Military Expenditure % of GDP hosted by Lebanese economy forum, extracted from the World Bank public data.\n \n\n \nDefense\nGovernment institutions\nInternational security\nNational security\nMain topic articles",
  "Philosophy": "Philosophy (from , ) is the study of general and fundamental questions, such as those about existence, reason, knowledge, values, mind, and language. Such questions are often posed as problems to be studied or resolved. Some sources claim the term was coined by Pythagoras (c. 570 \u2013 c. 495 BCE); others dispute this story, arguing that Pythagoreans merely claimed use of a preexisting term.  Philosophical methods include questioning, critical discussion, rational argument, and systematic presentation.\n\nHistorically, philosophy encompassed all bodies of knowledge and a practitioner was known as a philosopher. From the time of Ancient Greek philosopher Aristotle to the 19th century, \"natural philosophy\" encompassed astronomy, medicine, and physics. For example, Newton's 1687 Mathematical Principles of Natural Philosophy later became classified as a book of physics. In the 19th century, the growth of modern research universities led academic philosophy and other disciplines to professionalize and specialize. Since then, various areas of investigation that were traditionally part of philosophy have become separate academic disciplines, and namely the social sciences such as psychology, sociology, linguistics, and economics.\n\nToday, major subfields of academic philosophy include metaphysics, which is concerned with the fundamental nature of existence and reality; epistemology, which studies the nature of knowledge and belief; ethics, which is concerned with moral value; and logic, which studies the rules of inference that allow one to derive conclusions from true premises. Other notable subfields include philosophy of science, political philosophy, aesthetics, philosophy of language, and philosophy of mind.\n\nDefinitions \n\nThere is wide agreement that philosophy (from the ancient Greek , ph\u00edlos: \"love\"; and , soph\u00eda: \"wisdom\") is characterized by various general features: it is a form of rational inquiry, it aims to be systematic, and it tends to critically reflect on its own methods and presuppositions. But approaches that go beyond such vague characterizations to give a more interesting or profound definition are usually controversial. Often, they are only accepted by theorists belonging to a certain philosophical movement and are revisionistic in that many presumed parts of philosophy would not deserve the title \"philosophy\" if they were true. Before the modern age, the term was used in a very wide sense, which included the individual sciences, like physics or mathematics, as its sub-disciplines, but the contemporary usage is more narrow.\n\nSome approaches argue that there is a set of essential features shared by all parts of philosophy while others see only weaker family resemblances or contend that it is merely an empty blanket term. Some definitions characterize philosophy in relation to its method, like pure reasoning. Others focus more on its topic, for example, as the study of the biggest patterns of the world as a whole or as the attempt to answer the big questions. Both approaches have the problem that they are usually either too wide, by including non-philosophical disciplines, or too narrow, by excluding some philosophical sub-disciplines. Many definitions of philosophy emphasize its intimate relation to science. In this sense, philosophy is sometimes understood as a proper science in its own right. Some naturalist approaches, for example, see philosophy as an empirical yet very abstract science that is concerned with very wide-ranging empirical patterns instead of particular observations. Some phenomenologists, on the other hand, characterize philosophy as the science of essences. Science-based definitions usually face the problem of explaining why philosophy in its long history has not made the type of progress as seen in other sciences. This problem is avoided by seeing philosophy as an immature or provisional science whose subdisciplines cease to be philosophy once they have fully developed. In this sense, philosophy is the midwife of the sciences.\n\nOther definitions focus more on the contrast between science and philosophy. A common theme among many such definitions is that philosophy is concerned with meaning, understanding, or the clarification of language. According to one view, philosophy is conceptual analysis, which involves finding the necessary and sufficient conditions for the application of concepts. Another defines philosophy as a linguistic therapy that aims at dispelling misunderstandings to which humans are susceptible due to the confusing structure of natural language. One more approach holds that the main task of philosophy is to articulate the pre-ontological understanding of the world, which acts as a condition of possibility of experience.\n\nMany other definitions of philosophy do not clearly fall into any of the aforementioned categories. An early approach already found in ancient Greek and Roman philosophy is that philosophy is the spiritual practice of developing one's reasoning ability. This practice is an expression of the philosopher's love of wisdom and has the aim of improving one's well-being by leading a reflective life. A closely related approach identifies the development and articulation of worldviews as the principal task of philosophy, i.e. to express how things on the grand scale hang together and which practical stance we should take towards them. Another definition characterizes philosophy as thinking about thinking in order to emphasize its reflective nature.\n\nHistorical overview  \n\nIn one general sense, philosophy is associated with wisdom, intellectual culture, and a search for knowledge. In this sense, all cultures and literate societies ask philosophical questions, such as \"how are we to live\" and \"what is the nature of reality.\" A broad and impartial conception of philosophy, then, finds a reasoned inquiry into such matters as reality, morality, and life in all world civilizations.\n\nWestern philosophy \n\nWestern philosophy is the philosophical tradition of the Western world, dating back to pre-Socratic thinkers who were active in 6th-century Greece (BCE), such as Thales ( \u2013  BCE) and Pythagoras ( \u2013  BCE) who practiced a 'love of wisdom' () and were also termed 'students of nature' ().\n\nWestern philosophy can be divided into three eras:\n\n Ancient (Greco-Roman).\n Medieval philosophy (referring to Christian European thought).\n Modern philosophy (beginning in the 17th century).\n\nAncient era \nWhile our knowledge of the ancient era begins with Thales in the 6th century BCE, little is known about the philosophers who came before Socrates (commonly known as the pre-Socratics). The ancient era was dominated by Greek philosophical schools. Most notable among the schools influenced by Socrates' teachings were Plato, who founded the Platonic Academy, and his student Aristotle, who founded the Peripatetic school. Other ancient philosophical traditions influenced by Socrates included Cynicism, Cyrenaicism, Stoicism, and Academic Skepticism. Two other traditions were influenced by Socrates' contemporary, Democritus: Pyrrhonism and Epicureanism. Important topics covered by the Greeks included metaphysics (with competing theories such as atomism and monism), cosmology, the nature of the well-lived life (eudaimonia), the possibility of knowledge, and the nature of reason (logos). With the rise of the Roman empire, Greek philosophy was increasingly discussed in Latin by Romans such as Cicero and Seneca (see Roman philosophy).\n\nMedieval era \nMedieval philosophy (5th\u201316th centuries) is the period following the fall of the Western Roman Empire and was dominated by the rise of Christianity and hence reflects Judeo-Christian theological concerns as well as retaining a continuity with Greco-Roman thought. Problems such as the existence and nature of God, the nature of faith and reason, metaphysics, the problem of evil were discussed in this period. Some key medieval thinkers include St. Augustine, Thomas Aquinas, Boethius, Anselm and Roger Bacon. Philosophy for these thinkers was viewed as an aid to theology () and hence they sought to align their philosophy with their interpretation of sacred scripture. This period saw the development of scholasticism, a text critical method developed in medieval universities based on close reading and disputation on key texts. The Renaissance period saw increasing focus on classic Greco-Roman thought and on a robust humanism.\n\nModern era \n\nEarly modern philosophy in the Western world begins with thinkers such as Thomas Hobbes and Ren\u00e9 Descartes (1596\u20131650). Following the rise of natural science, modern philosophy was concerned with developing a secular and rational foundation for knowledge and moved away from traditional structures of authority such as religion, scholastic thought and the Church. Major modern philosophers include Spinoza, Leibniz, Locke, Berkeley, Hume, and Kant.\n\n19th-century philosophy (sometimes called late modern philosophy) was influenced by the wider 18th-century movement termed \"the Enlightenment\", and includes figures such as Hegel a key figure in German idealism, Kierkegaard who developed the foundations for existentialism, Nietzsche a famed anti-Christian, John Stuart Mill who promoted utilitarianism, Karl Marx who developed the foundations for communism and the American William James. The 20th century saw the split between analytic philosophy and continental philosophy, as well as philosophical trends such as phenomenology, existentialism, logical positivism, pragmatism and the linguistic turn (see Contemporary philosophy).\n\nMiddle Eastern philosophy\n\nPre-Islamic philosophy \nThe regions of the Fertile Crescent, Iran and Arabia are home to the earliest known philosophical wisdom literature and is today mostly dominated by Islamic culture.\n\nAccording to the assyriologist Marc Van De Mieroop, Babylonian philosophy was a highly developed system of thought with a unique approach to knowledge and a focus on writing, lexicography, divination, and law. It was also a bilingual intellectual culture, based on Sumerian and Akkadian.\n\nEarly Wisdom Literature from the Fertile Crescent was a genre that sought to instruct people on ethical action, practical living, and virtue through stories and proverbs. In Ancient Egypt, these texts were known as sebayt ('teachings') and they are central to our understandings of Ancient Egyptian philosophy. The most well known of these texts is The Maxims of Ptahhotep. Theology and cosmology was a central concern in Egyptian thought. Perhaps the earliest form of a monotheistic theology also emerged in Egypt, with the rise of the Amarna theology (or Atenism) of Akhenaten (14th century BCE), which held that the solar creation deity Aten was the only god. This has been described as a \"monotheistic revolution\" by egyptologist Jan Assmann, though it also drew on previous developments in Egyptian thought, particularly the \"New Solar Theology\" based around Amun-Ra. These theological developments also influenced the post-Amarna Ramesside theology, which retained a focus on a single creative solar deity (though without outright rejection of other gods, which are now seen as manifestations of the main solar deity). This period also saw the development of the concept of the ba (soul) and its relation to god.\n\nJewish philosophy and Christian philosophy are religious-philosophical traditions that developed both in the Middle East and in Europe, which both share certain early Judaic texts (mainly the Tanakh) and monotheistic beliefs. Jewish thinkers such as the Geonim of the Talmudic Academies in Babylonia and Maimonides engaged with Greek and Islamic philosophy. Later Jewish philosophy came under strong Western intellectual influences and includes the works of Moses Mendelssohn who ushered in the Haskalah (the Jewish Enlightenment), Jewish existentialism, and Reform Judaism.\n\nThe various traditions of Gnosticism, which were influenced by both Greek and Abrahamic currents, originated around the first century and emphasized spiritual knowledge (gnosis).\n\nPre-Islamic Iranian philosophy begins with the work of Zoroaster, one of the first promoters of monotheism and of the dualism between good and evil. This dualistic cosmogony influenced later Iranian developments such as Manichaeism, Mazdakism, and Zurvanism.\n\nIslamic philosophy \n\nIslamic philosophy is the philosophical work originating in the Islamic tradition and is mostly done in Arabic. It draws from the religion of Islam as well as from Greco-Roman philosophy. After the Muslim conquests, the translation movement (mid-eighth to the late tenth century) resulted in the works of Greek philosophy becoming available in Arabic.\n\nEarly Islamic philosophy developed the Greek philosophical traditions in new innovative directions. This intellectual work inaugurated what is known as the Islamic Golden Age. The two main currents of early Islamic thought are Kalam, which focuses on Islamic theology, and Falsafa, which was based on Aristotelianism and Neoplatonism. The work of Aristotle was very influential among philosophers such as Al-Kindi (9th century), Avicenna (980 \u2013 June 1037), and Averroes (12th century). Others such as Al-Ghazali were highly critical of the methods of the Islamic Aristotelians and saw their metaphysical ideas as heretical. Islamic thinkers like Ibn al-Haytham and Al-Biruni also developed a scientific method, experimental medicine, a theory of optics, and a legal philosophy. Ibn Khaldun was an influential thinker in philosophy of history.\n\nIslamic thought also deeply influenced European intellectual developments, especially through the commentaries of Averroes on Aristotle. The Mongol invasions and the destruction of Baghdad in 1258 is often seen as marking the end of the Golden Age. Several schools of Islamic philosophy continued to flourish after the Golden Age, however, and include currents such as Illuminationist philosophy, Sufi philosophy, and Transcendent theosophy.\n\nThe 19th- and 20th-century Arab world saw the Nahda movement (literally meaning 'The Awakening'; also known as the 'Arab Renaissance'), which had a considerable influence on contemporary Islamic philosophy.\n\nEastern philosophy\n\nIndian philosophy \n\nIndian philosophy () refers to the diverse philosophical traditions that emerged since the ancient times on the Indian subcontinent. Indian philosophical traditions share various key concepts and ideas, which are defined in different ways and accepted or rejected by the different traditions. These include concepts such as dh\u00e1rma, karma, pram\u0101\u1e47a, du\u1e25kha, sa\u1e43s\u0101ra and mok\u1e63a.\n\nSome of the earliest surviving Indian philosophical texts are the Upanishads of the later Vedic period (1000\u2013500 BCE), which are considered to preserve the ideas of Brahmanism. Indian philosophy is commonly grouped based on their relationship to the Vedas and the ideas contained in them. Jainism and Buddhism originated at the end of the Vedic period, while the various traditions grouped under Hinduism mostly emerged after the Vedic period as independent traditions. Hindus generally classify Indian philosophical traditions as either orthodox (\u0101stika) or heterodox (n\u0101stika) depending on whether they accept the authority of the Vedas and the theories of brahman and \u0101tman found therein.\n\nThe schools which align themselves with the thought of the Upanishads, the so-called \"orthodox\" or \"Hindu\" traditions, are often classified into six dar\u015banas or philosophies:S\u0101nkhya, Yoga, Ny\u0101ya, Vaisheshika, Mim\u0101ms\u0101 and Ved\u0101nta.\n\nThe doctrines of the Vedas and Upanishads were interpreted differently by these six schools of Hindu philosophy, with varying degrees of overlap. They represent a \"collection of philosophical views that share a textual connection,\" according to Chadha (2015). They also reflect a tolerance for a diversity of philosophical interpretations within Hinduism while sharing the same foundation.\n\nHindu philosophers of the six orthodox schools developed systems of epistemology (pramana) and investigated topics such as metaphysics, ethics, psychology (gu\u1e47a), hermeneutics, and soteriology within the framework of the Vedic knowledge, while presenting a diverse collection of interpretations. The commonly named six orthodox schools were the competing philosophical traditions of what has been called the \"Hindu synthesis\" of classical Hinduism.\n\nThere are also other schools of thought which are often seen as \"Hindu\", though not necessarily orthodox (since they may accept different scriptures as normative, such as the Shaiva Agamas and Tantras), these include different schools of Shavism such as Pashupata, Shaiva Siddhanta, non-dual tantric Shavism (i.e. Trika, Kaula, etc.).\n\nThe \"Hindu\" and \"Orthodox\" traditions are often contrasted with the \"unorthodox\" traditions (n\u0101stika, literally \"those who reject\"), though this is a label that is not used by the \"unorthodox\" schools themselves. These traditions reject the Vedas as authoritative and often reject major concepts and ideas that are widely accepted by the orthodox schools (such as \u0100tman, Brahman, and \u012a\u015bvara). These unorthodox schools include Jainism (accepts \u0101tman but rejects \u012a\u015bvara, Vedas and Brahman), Buddhism (rejects all orthodox concepts except rebirth and karma), C\u0101rv\u0101ka (materialists who reject even rebirth and karma) and \u0100j\u012bvika (known for their doctrine of fate).\n\nJain philosophy is one of the only two surviving \"unorthodox\" traditions (along with Buddhism). It generally accepts the concept of a permanent soul (jiva) as one of the five astikayas (eternal, infinite categories that make up the substance of existence). The other four being dh\u00e1rma, adharma, \u0101k\u0101\u015ba ('space'), and pudgala ('matter'). Jain thought holds that all existence is cyclic, eternal and uncreated.\n\nSome of the most important elements of Jain philosophy are the Jain theory of karma, the doctrine of nonviolence (ahi\u1e43s\u0101) and the theory of \"many-sidedness\" or An\u0113k\u0101ntav\u0101da. The Tattvartha Sutra is the earliest known, most comprehensive and authoritative compilation of Jain philosophy.\n\nBuddhist philosophy \n\nBuddhist philosophy begins with the thought of Gautama Buddha (fl. between 6th and 4th century BCE) and is preserved in the early Buddhist texts. It originated in the Indian region of Magadha and later spread to the rest of the Indian subcontinent, East Asia, Tibet, Central Asia, and Southeast Asia. In these regions, Buddhist thought developed into different philosophical traditions which used various languages (like Tibetan, Chinese and Pali). As such, Buddhist philosophy is a trans-cultural and international phenomenon.\n\nThe dominant Buddhist philosophical traditions in East Asian nations are mainly based on Indian Mahayana Buddhism. The philosophy of the Theravada school is dominant in Southeast Asian countries like Sri Lanka, Burma and Thailand.\n\nBecause ignorance to the true nature of things is considered one of the roots of suffering (dukkha), Buddhist philosophy is concerned with epistemology, metaphysics, ethics and psychology. Buddhist philosophical texts must also be understood within the context of meditative practices which are supposed to bring about certain cognitive shifts. Key innovative concepts include the four noble truths as an analysis of dukkha, anicca (impermanence), and anatta (non-self).\n\nAfter the death of the Buddha, various groups began to systematize his main teachings, eventually developing comprehensive philosophical systems termed Abhidharma. Following the Abhidharma schools, Indian Mahayana philosophers such as Nagarjuna and Vasubandhu developed the theories of \u015b\u016bnyat\u0101 ('emptiness of all phenomena') and vij\u00f1apti-matra ('appearance only'), a form of phenomenology or transcendental idealism. The Dign\u0101ga school of pram\u0101\u1e47a ('means of knowledge') promoted a sophisticated form of Buddhist epistemology.\n\nThere were numerous schools, sub-schools, and traditions of Buddhist philosophy in ancient and medieval India. According to Oxford professor of Buddhist philosophy Jan Westerhoff, the major Indian schools from 300 BCE to 1000 CE were: the Mah\u0101s\u0101\u1e43ghika tradition (now extinct), the Sthavira schools (such as Sarv\u0101stiv\u0101da, Vibhajyav\u0101da and Pudgalav\u0101da) and the Mahayana schools. Many of these traditions were also studied in other regions, like Central Asia and China, having been brought there by Buddhist missionaries.\n\nAfter the disappearance of Buddhism from India, some of these philosophical traditions continued to develop in the Tibetan Buddhist, East Asian Buddhist and Theravada Buddhist traditions.\n\nEast Asian philosophy \n\nEast Asian philosophical thought began in Ancient China, and Chinese philosophy begins during the Western Zhou Dynasty and the following periods after its fall when the \"Hundred Schools of Thought\" flourished (6th century to 221 BCE). This period was characterized by significant intellectual and cultural developments and saw the rise of the major philosophical schools of China such as Confucianism (also known as Ruism), Legalism, and Taoism as well as numerous other less influential schools like Mohism and Naturalism. These philosophical traditions developed metaphysical, political and ethical theories such Tao, Yin and yang, Ren and Li.\n\nThese schools of thought further developed during the Han (206 BCE \u2013 220 CE) and Tang (618\u2013907 CE) eras, forming new philosophical movements like Xuanxue (also called Neo-Taoism), and Neo-Confucianism. Neo-Confucianism was a syncretic philosophy, which incorporated the ideas of different Chinese philosophical traditions, including Buddhism and Taoism. Neo-Confucianism came to dominate the education system during the Song dynasty (960\u20131297), and its ideas served as the philosophical basis of the imperial exams for the scholar official class. Some of the most important Neo-Confucian thinkers are the Tang scholars Han Yu and Li Ao as well as the Song thinkers Zhou Dunyi (1017\u20131073) and Zhu Xi (1130\u20131200). Zhu Xi compiled the Confucian canon, which consists of the Four Books (the Great Learning, the Doctrine of the Mean, the Analects of Confucius, and the Mencius). The Ming scholar Wang Yangming (1472\u20131529) is a later but important philosopher of this tradition as well.\n\nBuddhism began arriving in China during the Han Dynasty, through a gradual Silk road transmission and through native influences developed distinct Chinese forms (such as Chan/Zen) which spread throughout the East Asian cultural sphere.\n\nChinese culture was highly influential on the traditions of other East Asian states and its philosophy directly influenced Korean philosophy, Vietnamese philosophy and Japanese philosophy. During later Chinese dynasties like the Ming Dynasty (1368\u20131644) as well as in the Korean Joseon dynasty (1392\u20131897) a resurgent Neo-Confucianism led by thinkers such as Wang Yangming (1472\u20131529) became the dominant school of thought, and was promoted by the imperial state. In Japan, the Tokugawa shogunate (1603\u20131867) was also strongly influenced by Confucian philosophy. Confucianism continues to influence the ideas and worldview of the nations of the Chinese cultural sphere today.\n\nIn the Modern era, Chinese thinkers incorporated ideas from Western philosophy. Chinese Marxist philosophy developed under the influence of Mao Zedong, while a Chinese pragmatism developed under Hu Shih. The old traditional philosophies also began to reassert themselves in the 20th century. For example, New Confucianism, led by figures such as Xiong Shili, has become quite influential. Likewise, Humanistic Buddhism is a recent modernist Buddhist movement.\n\nModern Japanese thought meanwhile developed under strong Western influences such as the study of Western Sciences (Rangaku) and the modernist Meirokusha intellectual society which drew from European enlightenment thought and promoted liberal reforms as well as Western philosophies like Liberalism and Utilitarianism. Another trend in modern Japanese philosophy was the \"National Studies\" (Kokugaku) tradition. This intellectual trend sought to study and promote ancient Japanese thought and culture. Kokugaku thinkers such as Motoori Norinaga sought to return to a pure Japanese tradition which they called Shinto that they saw as untainted by foreign elements.\n\nDuring the 20th century, the Kyoto School, an influential and unique Japanese philosophical school developed from Western phenomenology and Medieval Japanese Buddhist philosophy such as that of Dogen.\n\nAfrican philosophy \n\nAfrican philosophy is philosophy produced by African people, philosophy that presents African worldviews, ideas and themes, or philosophy that uses distinct African philosophical methods. Modern African thought has been occupied with Ethnophilosophy, with defining the very meaning of African philosophy and its unique characteristics and what it means to be African.\n\nDuring the 17th century, Ethiopian philosophy developed a robust literary tradition as exemplified by Zera Yacob. Another early African philosopher was Anton Wilhelm Amo (c. 1703\u20131759) who became a respected philosopher in Germany. Distinct African philosophical ideas include Ujamaa, the Bantu idea of 'Force', N\u00e9gritude, Pan-Africanism and Ubuntu. Contemporary African thought has also seen the development of Professional philosophy and of Africana philosophy, the philosophical literature of the African diaspora which includes currents such as black existentialism by African-Americans. Some modern African thinkers have been influenced by Marxism, African-American literature, Critical theory, Critical race theory, Postcolonialism and Feminism.\n\nIndigenous American philosophy \n\nIndigenous-American philosophical thought consists of a wide variety of beliefs and traditions among different American cultures. Among some of U.S. Native American communities, there is a belief in a metaphysical principle called the 'Great Spirit'  (Siouan: wak\u021f\u00e1\u014b t\u021f\u00e1\u014bka; Algonquian: gitche manitou). Another widely shared concept was that of orenda ('spiritual power'). According to Whiteley (1998), for the Native Americans, \"mind is critically informed by transcendental experience (dreams, visions and so on) as well as by reason.\" The practices to access these transcendental experiences are termed shamanism. Another feature of the indigenous American worldviews was their extension of ethics to non-human animals and plants.\n\nIn Mesoamerica, Nahua philosophy was an intellectual tradition developed by individuals called tlamatini ('those who know something') and its ideas are preserved in various Aztec codices and fragmentary texts. Some of these philosophers are known by name, such as Nezahualcoyotl, Aquiauhtzin, Xayacamach, Tochihuitzin coyolchiuhqui and Cuauhtencoztli.  These authors were also poets and some of their work has survived in the original Nahuatl.  \n\nAztec philosophers developed theories of metaphysics, epistemology, values, and aesthetics. Aztec ethics was focused on seeking tlamatiliztli ('knowledge', 'wisdom') which was based on moderation and balance in all actions as in the Nahua proverb \"the middle good is necessary.\" The Nahua worldview posited the concept of an ultimate universal energy or force called \u014cmete\u014dtl ('Dual Cosmic Energy') which sought a way to live in balance with a constantly changing, \"slippery\" world. The theory of Teotl can be seen as a form of Pantheism. According to James Maffie, Nahua metaphysics posited that teotl is \"a single, vital, dynamic, vivifying, eternally self-generating and self-conceiving as well as self-regenerating and self-reconceiving sacred energy or force.\" This force was seen as the all encompassing life force of the universe and as the universe itself.\n\nThe Inca civilization also had an elite class of philosopher-scholars termed the amawtakuna or amautas who were important in the Inca education system as teachers of philosophy, theology, astronomy, poetry, law, music, morality and history. Young Inca nobles were educated in these disciplines at the state college of Yacha-huasi in Cuzco, where they also learned the art of the quipu. Incan philosophy (as well as the broader category of Andean thought) held that the universe is animated by a single dynamic life force (sometimes termed camaquen or camac, as well as upani and amaya). This singular force also arises as a set of dual complementary yet opposite forces. These \u201ccomplementary opposites\u201d are called yanantin and masintin. They are expressed as various polarities or dualities (such as male\u2013female, dark\u2013light, life and death, above and below) which interdependently contribute to the harmonious whole that is the universe through the process of reciprocity and mutual exchange called ayni. The Inca worldview also included the belief in a creator God (Viracocha) and reincarnation.\n\nWomen in philosophy \n\nAlthough men have generally dominated philosophical discourse, women philosophers have engaged in the discipline throughout history. Ancient examples include Hipparchia of Maroneia (active ) and Arete of Cyrene (active 5th\u20134th centuries BCE). Some women philosophers were accepted during the medieval and modern eras, but none became part of the Western canon until the 20th and 21st century, when many suggest that G.E.M. Anscombe, Hannah Arendt, Simone de Beauvoir, and Susanne Langer entered the canon.\n\nIn the early 1800s, some colleges and universities in the UK and the US began admitting women, producing more female academics. Nevertheless, U.S. Department of Education reports from the 1990s indicate that few women ended up in philosophy and that philosophy is one of the least gender-proportionate fields in the humanities, with women making up somewhere between 17% and 30% of philosophy faculty according to some studies.\n\nPhilosophical progress \nMany philosophical debates that began in ancient times are still debated today. British philosopher Colin McGinn claims that no philosophical progress has occurred during that interval. Australian philosopher David Chalmers, by contrast, sees progress in philosophy similar to that in science. Meanwhile, Talbot Brewer, professor of philosophy at University of Virginia, argues that \"progress\" is the wrong standard by which to judge philosophical activity.\n\nBranches of philosophy \nPhilosophical questions can be grouped into various branches. These groupings allow philosophers to focus on a set of similar topics and interact with other thinkers who are interested in the same questions.\n\nThese divisions are neither exhaustive, nor mutually exclusive. (A philosopher might specialize in Kantian epistemology, or Platonic aesthetics, or modern political philosophy). Furthermore, these philosophical inquiries sometimes overlap with each other and with other inquiries such as science, religion or mathematics.\n\nAesthetics \n\nAesthetics is the \"critical reflection on art, culture and nature.\" It addresses the nature of art, beauty and taste, enjoyment, emotional values, perception and with the creation and appreciation of beauty. It is more precisely defined as the study of sensory or sensori-emotional values, sometimes called judgments of sentiment and taste. Its major divisions are art theory, literary theory, film theory and music theory. An example from art theory is to discern the set of principles underlying the work of a particular artist or artistic movement such as the Cubist aesthetic.\n\nEthics \n\nEthics, also known as moral philosophy, studies what constitutes good and bad conduct, right and wrong values, and good and evil. Its primary investigations include how to live a good life and identifying standards of morality. It also includes investigating whether or not there is a best way to live or a universal moral standard, and if so, how we come to learn about it. The main branches of ethics are normative ethics, meta-ethics and applied ethics.\n\nThe three main views in ethics about what constitute moral actions are:\nConsequentialism, which judges actions based on their consequences. One such view is utilitarianism, which judges actions based on the net happiness (or pleasure) and/or lack of suffering (or pain) that they produce.\nDeontology, which judges actions based on whether or not they are in accordance with one's moral duty. In the standard form defended by Immanuel Kant, deontology is concerned with whether or not a choice respects the moral agency of other people, regardless of its consequences.\nVirtue ethics, which judges actions based on the moral character of the agent who performs them and whether they conform to what an ideally virtuous agent would do.\n\nEpistemology \n\nEpistemology is the branch of philosophy that studies knowledge. Epistemologists examine putative sources of knowledge, including perceptual experience, reason, memory, and testimony. They also investigate questions about the nature of truth, belief, justification, and rationality.\n\nPhilosophical skepticism, which raises doubts about some or all claims to knowledge, has been a topic of interest throughout the history of philosophy. It arose early in Pre-Socratic philosophy and became formalized with Pyrrho, the founder of the earliest Western school of philosophical skepticism. It features prominently in the works of modern philosophers Ren\u00e9 Descartes and David Hume, and has remained a central topic in contemporary epistemological debates.\n\nOne of the most notable epistemological debates is between empiricism and rationalism. Empiricism places emphasis on observational evidence via sensory experience as the source of knowledge. Empiricism is associated with a posteriori knowledge, which is obtained through experience (such as scientific knowledge). Rationalism places emphasis on reason as a source of knowledge. Rationalism is associated with a priori knowledge, which is independent of experience (such as logic and mathematics).\n\nOne central debate in contemporary epistemology is about the conditions required for a belief to constitute knowledge, which might include truth and justification. This debate was largely the result of attempts to solve the Gettier problem. Another common subject of contemporary debates is the regress problem, which occurs when trying to offer proof or justification for any belief, statement, or proposition. The problem is that whatever the source of justification may be, that source must either be without justification (in which case it must be treated as an arbitrary foundation for belief), or it must have some further justification (in which case justification must either be the result of circular reasoning, as in coherentism, or the result of an infinite regress, as in infinitism).\n\nMetaphysics \n\nMetaphysics is the study of the most general features of reality, such as existence, time, objects and their properties, wholes and their parts, events, processes and causation and the relationship between mind and body. Metaphysics includes cosmology, the study of the world in its entirety and ontology, the study of being.\n\nA major point of debate is between realism, which holds that there are entities that exist independently of their mental perception, and idealism, which holds that reality is mentally constructed or otherwise immaterial. Metaphysics deals with the topic of identity. Essence is the set of attributes that make an object what it fundamentally is and without which it loses its identity while accident is a property that the object has, without which the object can still retain its identity. Particulars are objects that are said to exist in space and time, as opposed to abstract objects, such as numbers, and universals, which are properties held by multiple particulars, such as redness or a gender. The type of existence, if any, of universals and abstract objects is an issue of debate.\n\nLogic \n\nLogic is the study of reasoning and argument.\n\nDeductive reasoning is when, given certain premises, conclusions are unavoidably implied. Rules of inference are used to infer conclusions such as, modus ponens, where given \u201cA\u201d and \u201cIf A then B\u201d, then \u201cB\u201d must be concluded.\n\nBecause sound reasoning is an essential element of all sciences, social sciences and humanities disciplines, logic became a formal science. Sub-fields include mathematical logic, philosophical logic, Modal logic, computational logic and non-classical logics. A major question in the philosophy of mathematics is whether mathematical entities are objective and discovered, called mathematical realism, or invented, called mathematical antirealism.\n\nMind and language\n\nPhilosophy of language explores the nature, origins, and use of language. Philosophy of mind explores the nature of the mind and its relationship to the body, as typified by disputes between materialism and dualism. In recent years, this branch has become related to cognitive science.\n\nPhilosophy of science \n\nThe philosophy of science explores the foundations, methods, history, implications and purpose of science. Many of its subdivisions correspond to specific branches of science. For example, philosophy of biology deals specifically with the metaphysical, epistemological and ethical issues in the biomedical and life sciences.\n\nPolitical philosophy \n\nPolitical philosophy is the study of government and the relationship of individuals (or families and clans) to communities including the state. It includes questions about justice, law, property and the rights and obligations of the citizen. Political philosophy, ethics, and aesthetics are traditionally linked subjects, under the general heading of value theory as they involve a normative or evaluative aspect.\n\nPhilosophy of religion\n\nPhilosophy of religion deals with questions that involve religion and religious ideas from a philosophically neutral perspective (as opposed to theology which begins from religious convictions). Traditionally, religious questions were not seen as a separate field from philosophy proper, the idea of a separate field only arose in the 19th century.\n\nIssues include the existence of God, the relationship between reason and faith, questions of religious epistemology, the relationship between religion and science, how to interpret religious experiences, questions about the possibility of an afterlife, the problem of religious language and the existence of souls and responses to religious pluralism and diversity.\n\nMetaphilosophy\n\nMetaphilosophy explores the aims, boundaries and methods of philosophy. It is debated as to whether Metaphilosophy is a subject that comes prior to philosophy or whether it is inherently part of philosophy.\n\nOther subdivisions \nIn section thirteen of his Lives and Opinions of the Eminent Philosophers, the oldest surviving history of philosophy (3rd century), Diogenes La\u00ebrtius presents a three-part division of ancient Greek philosophical inquiry:\n\nNatural philosophy (i.e. physics, from ) was the study of the constitution and processes of transformation in the physical world.\nMoral philosophy (i.e. ethics, from ) was the study of goodness, right and wrong, justice and virtue.\nMetaphysical philosophy (i.e. logic, from ) was the study of existence, causation, God, logic, forms, and other abstract objects. ()\n\nIn Against the Logicians the Pyrrhonist philosopher Sextus Empiricus detailed the variety of ways in which the ancient Greek philosophers had divided philosophy, noting that this three-part division was agreed to by Plato, Aristotle, Xenocrates, and the Stoics. The Academic Skeptic philosopher Cicero also followed this three-part division.\n\nThis division is not obsolete, but has changed: natural philosophy has split into the various natural sciences, especially physics, astronomy, chemistry, biology, and cosmology; moral philosophy has birthed the social sciences, while still including value theory (e.g. ethics, aesthetics, political philosophy, etc.); and metaphysical philosophy has given way to formal sciences such as logic, mathematics and philosophy of science, while still including epistemology, cosmology, etc. For example, Newton's Mathematical Principles of Natural Philosophy (1687), since classified as a book of physics, uses the term natural philosophy as it was understood at the time, encompassing disciplines such as astronomy, medicine and physics that later became associated with the sciences.\n\nApplied and professional philosophy \n\nSome of those who study philosophy become professional philosophers, typically by working as professors who teach, research and write in academic institutions. However, most students of academic philosophy later contribute to law, journalism, religion, sciences, politics, business, or various arts. For example, public figures who have degrees in philosophy include comedians Steve Martin and Ricky Gervais, filmmaker Terrence Malick, Pope John Paul II, Wikipedia co-founder Larry Sanger, technology entrepreneur Peter Thiel, U.S. Supreme Court Justice Stephen Bryer and US vice presidential candidate Carly Fiorina. Curtis White has argued that philosophical tools are essential to humanities, sciences and social sciences.\n\nRecent efforts to avail the general public to the work and relevance of philosophers include the million-dollar Berggruen Prize, first awarded to Charles Taylor in 2016. Some philosophers argue that this professionalization has negatively affected the discipline.\n\nSee also \n\n Criticism of philosophy\n List of important publications in philosophy\n List of years in philosophy\n List of philosophy journals\n List of philosophy awards\n List of unsolved problems in philosophy\n Lists of philosophers\n Social theory\n\nReferences\n\nNotes\n\nCitations\n\nBibliography\n\nFurther reading\n\nGeneral introduction \n\n \n Blumenau, Ralph. Philosophy and Living. \n Craig, Edward. Philosophy: A Very Short Introduction. \n Harrison-Barbet, Anthony, Mastering Philosophy. \n Russell, Bertrand. The Problems of Philosophy. \n Sinclair, Alistair J. What is Philosophy? An Introduction, 2008, \n Sober, Elliott. (2001). Core Questions in Philosophy: A Text with Readings. Upper Saddle River, Prentice Hall. \n Solomon, Robert C. Big Questions: A Short Introduction to Philosophy. \n Warburton, Nigel. Philosophy: The Basics. \n Nagel, Thomas. What Does It All Mean? A Very Short Introduction to Philosophy. \n Classics of Philosophy (Vols. 1, 2, & 3) by Louis P. Pojman\n Cottingham, John. Western Philosophy: An Anthology. 2nd ed. Malden, MA: Blackwell Pub., 2008. Print. Blackwell Philosophy Anthologies.\n Tarnas, Richard. The Passion of the Western Mind: Understanding the Ideas That Have Shaped Our World View.\n\nTopical introductions\n\nAfrican\n Imbo, Samuel Oluoch. An Introduction to African Philosophy.\n\nEastern\n A Source Book in Indian Philosophy by Sarvepalli Radhakrishnan, Charles A. Moore\n Hamilton, Sue. Indian Philosophy: a Very Short Introduction. \n Kupperman, Joel J. Classic Asian Philosophy: A Guide to the Essential Texts. \n Lee, Joe and Powell, Jim. Eastern Philosophy For Beginners. \n Smart, Ninian. World Philosophies. \n Copleston, Frederick. Philosophy in Russia: From Herzen to Lenin and Berdyaev.\n\nIslamic\n Medieval Islamic Philosophical Writings edited by Muhammad Ali Khalidi\n\nHistorical introductions\n\nGeneral\n \n Higgins, Kathleen M. and Solomon, Robert C. A Short History of Philosophy. \n Durant, Will, Story of Philosophy: The Lives and Opinions of the World's Greatest Philosophers, Pocket, 1991,\n\nAncient\n Knight, Kelvin. Aristotelian Philosophy: Ethics and Politics from Aristotle to MacIntyre.\n\nMedieval\n The Phenomenology Reader by Dermot Moran, Timothy Mooney\n Kim, J. and Ernest Sosa, Ed. (1999). Metaphysics: An Anthology. Blackwell Philosophy Anthologies. Oxford, Blackwell Publishers Ltd.\n\nModern & contemporary\n The English Philosophers from Bacon to Mill by Edwin Arthur\n European Philosophers from Descartes to Nietzsche by Monroe Beardsley\n Existentialism: Basic Writings (Second Edition) by Charles Guignon, Derk Pereboom\n Curley, Edwin, A Spinoza Reader, Princeton, 1994, \n Bullock, Alan, R.B. Woodings, and John Cumming, eds. The Fontana Dictionary of Modern Thinkers, in series, Fontana Original[s]. Hammersmith, Eng.: Fontana Press, 1992 [1983]. xxv, 867 p. \n Scruton, Roger. A Short History of Modern Philosophy. \n Contemporary Analytic Philosophy: Core Readings by James Baillie\n Appiah, Kwame Anthony. Thinking it Through\u00a0\u00a0\u2013 An Introduction to Contemporary Philosophy, 2003, \n Critchley, Simon. Continental Philosophy: A Very Short Introduction.\n\nReference works \n\n  \n \n The Cambridge Dictionary of Philosophy by Robert Audi\n The Routledge Encyclopedia of Philosophy (10 vols.) edited by Edward Craig, Luciano Floridi (available online by subscription); or\n The Concise Routledge Encyclopedia of Philosophy edited by Edward Craig (an abridgement)\n ; in 1996, a ninth supplemental volume appeared that updated the classic 1967 encyclopedia.\n International Directory of Philosophy and Philosophers. Charlottesville, Philosophy Documentation Center.\n Directory of American Philosophers. Charlottesville, Philosophy Documentation Center.\n Routledge History of Philosophy (10 vols.) edited by John Marenbon\n History of Philosophy (9 vols.) by Frederick Copleston\n A History of Western Philosophy (5 vols.) by W.T. Jones\n History of Italian Philosophy (2 vols.) by Eugenio Garin. Translated from Italian and Edited by Giorgio Pinton. Introduction by Leon Pompa.\n Encyclopaedia of Indian Philosophies (8 vols.), edited by Karl H. Potter et al. (first 6 volumes out of print)\n Indian Philosophy (2 vols.) by Sarvepalli Radhakrishnan\n A History of Indian Philosophy (5 vols.) by Surendranath Dasgupta\n History of Chinese Philosophy (2 vols.) by Fung Yu-lan, Derk Bodde\n Instructions for Practical Living and Other Neo-Confucian Writings by Wang Yang-ming by Chan, Wing-tsit\n Encyclopedia of Chinese Philosophy edited by Antonio S. Cua\n Encyclopedia of Eastern Philosophy and Religion by Ingrid Fischer-Schreiber, Franz-Karl Ehrhard, Kurt Friedrichs\n Companion Encyclopedia of Asian Philosophy by Brian Carr, Indira Mahalingam\n A Concise Dictionary of Indian Philosophy: Sanskrit Terms Defined in English by John A. Grimes\n History of Islamic Philosophy edited by Seyyed Hossein Nasr, Oliver Leaman\n History of Jewish Philosophy edited by Daniel H. Frank, Oliver Leaman\n A History of Russian Philosophy: From the Tenth to the Twentieth Centuries by Valerii Aleksandrovich Kuvakin\n Ayer, A.J. et al., Ed. (1994) A Dictionary of Philosophical Quotations. Blackwell Reference Oxford. Oxford, Basil Blackwell Ltd.\n Blackburn, S., Ed. (1996)The Oxford Dictionary of Philosophy. Oxford, Oxford University Press.\n Mautner, T., Ed. The Penguin Dictionary of Philosophy. London, Penguin Books.\n Runes, D., Ed. (1942). The Dictionary of Philosophy . New York, The Philosophical Library, Inc.\n Angeles, P.A., Ed. (1992). The Harper Collins Dictionary of Philosophy. New York, Harper Perennial.\n \n Hoffman, Eric, Ed. (1997) Guidebook for Publishing Philosophy. Charlottesville, Philosophy Documentation Center.\n Popkin, R.H. (1999). The Columbia History of Western Philosophy. New York, Columbia University Press.\n Bullock, Alan, and Oliver Stallybrass, jt. eds. The Harper Dictionary of Modern Thought. New York: Harper & Row, 1977. xix, 684 p. N.B.: \"First published in England under the title, The Fontana Dictionary of Modern Thought.\" \n Reese, W.L. Dictionary of Philosophy and Religion: Eastern and Western Thought. Atlantic Highlands, N.J.: Humanities Press, 1980. iv, 644 p.\n\nExternal links \n\n Stanford Encyclopedia of Philosophy\n The Internet Encyclopedia of Philosophy\n Indiana Philosophy Ontology Project\n PhilPapers \u2013 a comprehensive directory of online philosophical articles and books by academic philosophers\n Philosophy Timeline\n Philosophy Magazines and Journals\n \n Philosophy (review)\n Philosophy Documentation Center\n Popular Philosophy\n\n \nArticles containing video clips\nMain topic articles\nHumanities",
  "Archaeology": "Archaeology or archeology is the study of human activity through the recovery and analysis of material culture. The archaeological record consists of artifacts, architecture, biofacts or ecofacts, sites, and cultural landscapes. Archaeology can be considered both a social science and a branch of the humanities. In Europe it is often viewed as either a discipline in its own right or a sub-field of other disciplines, while in North America archaeology is a sub-field of anthropology.\n\nArchaeologists study human prehistory and history, from the development of the first stone tools at Lomekwi in East Africa 3.3\u00a0million years ago up until recent decades. Archaeology is distinct from palaeontology, which is the study of fossil remains. Archaeology is particularly important for learning about prehistoric societies, for which, by definition, there are no written records. Prehistory includes over 99% of the human past, from the Paleolithic until the advent of literacy in societies around the world. Archaeology has various goals, which range from understanding culture history to reconstructing past lifeways to documenting and explaining changes in human societies through time. Derived from the Greek, the term archaeology literally means \u201cthe study of ancient history.\u201d\n\nThe discipline involves surveying, excavation and eventually analysis of data collected to learn more about the past. In broad scope, archaeology relies on cross-disciplinary research.\n\nArchaeology developed out of antiquarianism in Europe during the 19th century, and has since become a discipline practiced around the world. Archaeology has been used by nation-states to create particular visions of the past. Since its early development, various specific sub-disciplines of archaeology have developed, including maritime archaeology, feminist archaeology and archaeoastronomy, and numerous different scientific techniques have been developed to aid archaeological investigation. Nonetheless, today, archaeologists face many problems, such as dealing with pseudoarchaeology, the looting of artifacts, a lack of public interest, and opposition to the excavation of human remains.\n\nHistory\n\nFirst instances of archaeology\n\nIn Ancient Mesopotamia, a foundation deposit of the Akkadian Empire ruler Naram-Sin (ruled circa 2200 BCE) was discovered and analysed by king Nabonidus, circa 550 BCE, who is thus known as the first archaeologist. Not only did he lead the first excavations which were to find the foundation deposits of the temples of \u0160ama\u0161 the sun god, the warrior goddess Anunitu (both located in Sippar), and the sanctuary that Naram-Sin built to the moon god, located in Harran, but he also had them restored to their former glory. He was also the first to date an archaeological artifact in his attempt to date Naram-Sin's temple during his search for it. Even though his estimate was inaccurate by about 1,500 years, it was still a very good one considering the lack of accurate dating technology at the time.\n\nAntiquarians\n\nThe science of archaeology (from Greek , archaiologia from , arkhaios, \"ancient\" and , -logia, \"-logy\") grew out of the older multi-disciplinary study known as antiquarianism. Antiquarians studied history with particular attention to ancient artifacts and manuscripts, as well as historical sites. Antiquarianism focused on the empirical evidence that existed for the understanding of the past, encapsulated in the motto of the 18th-century antiquary, Sir Richard Colt Hoare, \"We speak from facts not theory\". Tentative steps towards the systematization of archaeology as a science took place during the Enlightenment era in Europe in the 17th and 18th centuries.\n\nIn Imperial China during the Song dynasty (960-1279), figures such as Ouyang Xiu and Zhao Mingcheng established the tradition of Chinese epigraphy by investigating, preserving, and analyzing ancient Chinese bronze inscriptions from the Shang and Zhou periods. In his book published in 1088, Shen Kuo criticized contemporary Chinese scholars for attributing ancient bronze vessels as creations of famous sages rather than artisan commoners, and for attempting to revive them for ritual use without discerning their original functionality and purpose of manufacture. Such antiquarian pursuits waned after the Song period, were revived in the 17th century during the Qing dynasty, but were always considered a branch of Chinese historiography rather than a separate discipline of archaeology.\n\nIn Renaissance Europe, philosophical interest in the remains of Greco-Roman civilization and the rediscovery of classical culture began in the late Middle Ages. Flavio Biondo, an Italian Renaissance humanist historian, created a systematic guide to the ruins and topography of ancient Rome in the early 15th century, for which he has been called an early founder of archaeology. Antiquarians of the 16th century, including John Leland and William Camden, conducted surveys of the English countryside, drawing, describing and interpreting the monuments that they encountered.\n\nThe OED first cites \"archaeologist\" from 1824; this soon took over as the usual term for one major branch of antiquarian activity. \"Archaeology\", from 1607 onwards, initially meant what we would call \"ancient history\" generally, with the narrower modern sense first seen in 1837.\n\nFirst excavations\n\nOne of the first sites to undergo archaeological excavation was Stonehenge and other megalithic monuments in England. John Aubrey (1626\u20131697) was a pioneer archaeologist who recorded numerous megalithic and other field monuments in southern England. He was also ahead of his time in the analysis of his findings. He attempted to chart the chronological stylistic evolution of handwriting, medieval architecture, costume, and shield-shapes.\n\nExcavations were also carried out by the Spanish military engineer Roque Joaqu\u00edn de Alcubierre in the ancient towns of Pompeii and Herculaneum, both of which had been covered by ash during the Eruption of Mount Vesuvius in AD 79. These excavations began in 1748 in Pompeii, while in Herculaneum they began in 1738. The discovery of entire towns, complete with utensils and even human shapes, as well the unearthing of frescos, had a big impact throughout Europe.\n\nHowever, prior to the development of modern techniques, excavations tended to be haphazard; the importance of concepts such as stratification and context were overlooked.\n\nDevelopment of archaeological method\n\nThe father of archaeological excavation was William Cunnington (1754\u20131810). He undertook excavations in Wiltshire from around 1798, funded by Sir Richard Colt Hoare. Cunnington made meticulous recordings of Neolithic and Bronze Age barrows, and the terms he used to categorize and describe them are still used by archaeologists today.\n\nOne of the major achievements of 19th-century archaeology was the development of stratigraphy. The idea of overlapping strata tracing back to successive periods was borrowed from the new geological and paleontological work of scholars like William Smith, James Hutton and Charles Lyell. The application of stratigraphy to archaeology first took place with the excavations of prehistorical and Bronze Age sites. In the third and fourth decades of the 19th-century, archaeologists like Jacques Boucher de Perthes and Christian J\u00fcrgensen Thomsen began to put the artifacts they had found in chronological order.\n\nA major figure in the development of archaeology into a rigorous science was the army officer and ethnologist, Augustus Pitt Rivers, who began excavations on his land in England in the 1880s. His approach was highly methodical by the standards of the time, and he is widely regarded as the first scientific archaeologist. He arranged his artifacts by type or \"typologically, and within types by date or \"chronologically\". This style of arrangement, designed to highlight the evolutionary trends in human artifacts, was of enormous significance for the accurate dating of the objects. His most important methodological innovation was his insistence that all artifacts, not just beautiful or unique ones, be collected and catalogued.\n\nWilliam Flinders Petrie is another man who may legitimately be called the Father of Archaeology. His painstaking recording and study of artifacts, both in Egypt and later in Palestine, laid down many of the ideas behind modern archaeological recording; he remarked that \"I believe the true line of research lies in the noting and comparison of the smallest details.\" Petrie developed the system of dating layers based on pottery and ceramic findings, which revolutionized the chronological basis of Egyptology. Petrie was the first to scientifically investigate the Great Pyramid in Egypt during the 1880s. He was also responsible for mentoring and training a whole generation of Egyptologists, including Howard Carter who went on to achieve fame with the discovery of the tomb of 14th-century BC pharaoh Tutankhamun.\n\nThe first stratigraphic excavation to reach wide popularity with public was that of Hissarlik, on the site of ancient Troy, carried out by Heinrich Schliemann, Frank Calvert and Wilhelm D\u00f6rpfeld in the 1870s. These scholars individuated nine different cities that had overlapped with one another, from prehistory to the Hellenistic period. Meanwhile, the work of Sir Arthur Evans at Knossos in Crete revealed the ancient existence of an equally advanced Minoan civilization.\n\nThe next major figure in the development of archaeology was Sir Mortimer Wheeler, whose highly disciplined approach to excavation and systematic coverage in the 1920s and 1930s brought the science on swiftly. Wheeler developed the grid system of excavation, which was further improved by his student Kathleen Kenyon.\n\nArchaeology became a professional activity in the first half of the 20th century, and it became possible to study archaeology as a subject in universities and even schools. By the end of the 20th century nearly all professional archaeologists, at least in developed countries, were graduates. Further adaptation and innovation in archaeology continued in this period, when maritime archaeology and urban archaeology became more prevalent and rescue archaeology was developed as a result of increasing commercial development.\n\nPurpose\n\nThe purpose of archaeology is to learn more about past societies and the development of the human race. Over 99% of the development of humanity has occurred within prehistoric cultures, who did not make use of writing, thereby no written records exist for study purposes. Without such written sources, the only way to understand prehistoric societies is through archaeology. Because archaeology is the study of past human activity, it stretches back to about 2.5\u00a0million years ago when we find the first stone tools \u2013 The Oldowan Industry. Many important developments in human history occurred during prehistory, such as the evolution of humanity during the Paleolithic period, when the hominins developed from the australopithecines in Africa and eventually into modern Homo sapiens. Archaeology also sheds light on many of humanity's technological advances, for instance the ability to use fire, the development of stone tools, the discovery of metallurgy, the beginnings of religion and the creation of agriculture. Without archaeology, we would know little or nothing about the use of material culture by humanity that pre-dates writing.\n\nHowever, it is not only prehistoric, pre-literate cultures that can be studied using archaeology but historic, literate cultures as well, through the sub-discipline of historical archaeology. For many literate cultures, such as Ancient Greece and Mesopotamia, their surviving records are often incomplete and biased to some extent. In many societies, literacy was restricted to the elite classes, such as the clergy or the bureaucracy of court or temple. The literacy even of aristocrats has sometimes been restricted to deeds and contracts. The interests and world-view of elites are often quite different from the lives and interests of the populace. Writings that were produced by people more representative of the general population were unlikely to find their way into libraries and be preserved there for posterity. Thus, written records tend to reflect the biases, assumptions, cultural values and possibly deceptions of a limited range of individuals, usually a small fraction of the larger population. Hence, written records cannot be trusted as a sole source. The material record may be closer to a fair representation of society, though it is subject to its own biases, such as sampling bias and differential preservation.\n\nOften, archaeology provides the only means to learn of the existence and behaviors of people of the past. Across the millennia many thousands of cultures and societies and billions of people have come and gone of which there is little or no written record or existing records are misrepresentative or incomplete. Writing as it is known today did not exist in human civilization until the 4th millennium BC, in a relatively small number of technologically advanced civilizations. In contrast, Homo sapiens has existed for at least 200,000 years, and other species of Homo for millions of years (see Human evolution). These civilizations are, not coincidentally, the best-known; they are open to the inquiry of historians for centuries, while the study of pre-historic cultures has arisen only recently. Even within a literate civilization many events and important human practices are not officially recorded. Any knowledge of the early years of human civilization \u2013 the development of agriculture, cult practices of folk religion, the rise of the first cities \u2013 must come from archaeology.\n\nIn addition to their scientific importance, archaeological remains sometimes have political or cultural significance to descendants of the people who produced them, monetary value to collectors, or simply strong aesthetic appeal. Many people identify archaeology with the recovery of such aesthetic, religious, political, or economic treasures rather than with the reconstruction of past societies.\n\nThis view is often espoused in works of popular fiction, such as Raiders of the Lost Ark, The Mummy, and King Solomon's Mines. When such unrealistic subjects are treated more seriously, accusations of pseudoscience are invariably levelled at their proponents (see Pseudoarchaeology). However, these endeavours, real and fictional, are not representative of modern archaeology.\n\nTheory\n\nThere is no one approach to archaeological theory that has been adhered to by all archaeologists. When archaeology developed in the late 19th century, the first approach to archaeological theory to be practiced was that of cultural-history archaeology, which held the goal of explaining why cultures changed and adapted rather than just highlighting the fact that they did, therefore emphasizing historical particularism. In the early 20th century, many archaeologists who studied past societies with direct continuing links to existing ones (such as those of Native Americans, Siberians, Mesoamericans etc.) followed the direct historical approach, compared the continuity between the past and contemporary ethnic and cultural groups. In the 1960s, an archaeological movement largely led by American archaeologists like Lewis Binford and Kent Flannery arose that rebelled against the established cultural-history archaeology. They proposed a \"New Archaeology\", which would be more \"scientific\" and \"anthropological\", with hypothesis testing and the scientific method very important parts of what became known as processual archaeology.\n\nIn the 1980s, a new postmodern movement arose led by the British archaeologists Michael Shanks, Christopher Tilley, Daniel Miller, and Ian Hodder, which has become known as post-processual archaeology. It questioned processualism's appeals to scientific positivism and impartiality, and emphasized the importance of a more self-critical theoretical reflexivity. However, this approach has been criticized by processualists as lacking scientific rigor, and the validity of both processualism and post-processualism is still under debate. Meanwhile, another theory, known as historical processualism has emerged seeking to incorporate a focus on process and post-processual archaeology's emphasis of reflexivity and history.\n\nArchaeological theory now borrows from a wide range of influences, including neo-evolutionary thought,[35] phenomenology, postmodernism, agency theory, cognitive science, structural functionalism, gender-based and feminist archaeology, and systems theory.\n\nMethods\n\nAn archaeological investigation usually involves several distinct phases, each of which employs its own variety of methods. Before any practical work can begin, however, a clear objective as to what the archaeologists are looking to achieve must be agreed upon. This done, a site is surveyed to find out as much as possible about it and the surrounding area. Second, an excavation may take place to uncover any archaeological features buried under the ground. And, third, the information collected during the excavation is studied and evaluated in an attempt to achieve the original research objectives of the archaeologists. It is then considered good practice for the information to be published so that it is available to other archaeologists and historians, although this is sometimes neglected.\n\nRemote sensing\nBefore actually starting to dig in a location, remote sensing can be used to look where sites are located within a large area or provide more information about sites or regions. There are two types of remote sensing instruments\u2014passive and active. Passive instruments detect natural energy that is reflected or emitted from the observed scene. Passive instruments sense only radiation emitted by the object being viewed or reflected by the object from a source other than the instrument. Active instruments emit energy and record what is reflected. Satellite imagery is an example of passive remote sensing. Here are two active remote sensing instruments:\n\nLidar (Light Detection and Ranging)\nA lidar uses a laser (light amplification by stimulated emission of radiation) to transmit a light pulse and a receiver with sensitive detectors to measure the backscattered or reflected light. Distance to the object is determined by recording the time between the transmitted and backscattered pulses and using the speed of light to calculate the distance travelled. Lidars can determine atmospheric profiles of aerosols, clouds, and other constituents of the atmosphere.\n\nLaser altimeter\nA laser altimeter uses a lidar (see above) to measure the height of the instrument platform above the surface. By independently knowing the height of the platform with respect to the mean Earth's surface, the topography of the underlying surface can be determined.\n\nField survey\n\nThe archaeological project then continues (or alternatively, begins) with a field survey. Regional survey is the attempt to systematically locate previously unknown sites in a region. Site survey is the attempt to systematically locate features of interest, such as houses and middens, within a site. Each of these two goals may be accomplished with largely the same methods.\n\nSurvey was not widely practiced in the early days of archaeology. Cultural historians and prior researchers were usually content with discovering the locations of monumental sites from the local populace, and excavating only the plainly visible features there. Gordon Willey pioneered the technique of regional settlement pattern survey in 1949 in the Viru Valley of coastal Peru, and survey of all levels became prominent with the rise of processual archaeology some years later.\n\nSurvey work has many benefits if performed as a preliminary exercise to, or even in place of, excavation. It requires relatively little time and expense, because it does not require processing large volumes of soil to search out artifacts. (Nevertheless, surveying a large region or site can be expensive, so archaeologists often employ sampling methods.) As with other forms of non-destructive archaeology, survey avoids ethical issues (of particular concern to descendant peoples) associated with destroying a site through excavation. It is the only way to gather some forms of information, such as settlement patterns and settlement structure. Survey data are commonly assembled into maps, which may show surface features and/or artifact distribution.\n\nThe simplest survey technique is surface survey. It involves combing an area, usually on foot but sometimes with the use of mechanized transport, to search for features or artifacts visible on the surface. Surface survey cannot detect sites or features that are completely buried under earth, or overgrown with vegetation. Surface survey may also include mini-excavation techniques such as augers, corers, and shovel test pits. If no materials are found, the area surveyed is deemed sterile.\n\nAerial survey is conducted using cameras attached to airplanes, balloons, UAVs, or even Kites. A bird's-eye view is useful for quick mapping of large or complex sites. Aerial photographs are used to document the status of the archaeological dig. Aerial imaging can also detect many things not visible from the surface. Plants growing above a buried man-made structure, such as a stone wall, will develop more slowly, while those above other types of features (such as middens) may develop more rapidly. Photographs of ripening grain, which changes colour rapidly at maturation, have revealed buried structures with great precision. Aerial photographs taken at different times of day will help show the outlines of structures by changes in shadows. Aerial survey also employs ultraviolet, infrared, ground-penetrating radar wavelengths, LiDAR and thermography.\n\nGeophysical survey can be the most effective way to see beneath the ground. Magnetometers detect minute deviations in the Earth's magnetic field caused by iron artifacts, kilns, some types of stone structures, and even ditches and middens. Devices that measure the electrical resistivity of the soil are also widely used. Archaeological features whose electrical resistivity contrasts with that of surrounding soils can be detected and mapped. Some archaeological features (such as those composed of stone or brick) have higher resistivity than typical soils, while others (such as organic deposits or unfired clay) tend to have lower resistivity.\n\nAlthough some archaeologists consider the use of metal detectors to be tantamount to treasure hunting, others deem them an effective tool in archaeological surveying. Examples of formal archaeological use of metal detectors include musketball distribution analysis on English Civil War battlefields, metal distribution analysis prior to excavation of a 19th-century ship wreck, and service cable location during evaluation. Metal detectorists have also contributed to archaeology where they have made detailed records of their results and refrained from raising artifacts from their archaeological context. In the UK, metal detectorists have been solicited for involvement in the Portable Antiquities Scheme.\n\nRegional survey in underwater archaeology uses geophysical or remote sensing devices such as marine magnetometer, side-scan sonar, or sub-bottom sonar.\n\nExcavation\n\nArchaeological excavation existed even when the field was still the domain of amateurs, and it remains the source of the majority of data recovered in most field projects. It can reveal several types of information usually not accessible to survey, such as stratigraphy, three-dimensional structure, and verifiably primary context.\n\nModern excavation techniques require that the precise locations of objects and features, known as their provenance or provenience, be recorded. This always involves determining their horizontal locations, and sometimes vertical position as well (also see Primary Laws of Archaeology). Likewise, their association, or relationship with nearby objects and features, needs to be recorded for later analysis. This allows the archaeologist to deduce which artifacts and features were likely used together and which may be from different phases of activity. For example, excavation of a site reveals its stratigraphy; if a site was occupied by a succession of distinct cultures, artifacts from more recent cultures will lie above those from more ancient cultures.\n\nExcavation is the most expensive phase of archaeological research, in relative terms. Also, as a destructive process, it carries ethical concerns. As a result, very few sites are excavated in their entirety. Again the percentage of a site excavated depends greatly on the country and \"method statement\" issued. Sampling is even more important in excavation than in survey. Sometimes large mechanical equipment, such as backhoes (JCBs), is used in excavation, especially to remove the topsoil (overburden), though this method is increasingly used with great caution. Following this rather dramatic step, the exposed area is usually hand-cleaned with trowels or hoes to ensure that all features are apparent.\n\nThe next task is to form a site plan and then use it to help decide the method of excavation. Features dug into the natural subsoil are normally excavated in portions to produce a visible archaeological section for recording. A feature, for example a pit or a ditch, consists of two parts: the cut and the fill. The cut describes the edge of the feature, where the feature meets the natural soil. It is the feature's boundary. The fill is what the feature is filled with, and will often appear quite distinct from the natural soil. The cut and fill are given consecutive numbers for recording purposes. Scaled plans and sections of individual features are all drawn on site, black and white and colour photographs of them are taken, and recording sheets are filled in describing the context of each. All this information serves as a permanent record of the now-destroyed archaeology and is used in describing and interpreting the site.\n\nAnalysis\n\nOnce artifacts and structures have been excavated, or collected from surface surveys, it is necessary to properly study them. This process is known as post-excavation analysis, and is usually the most time-consuming part of an archaeological investigation. It is not uncommon for final excavation reports for major sites to take years to be published.\n\nAt a basic level of analysis, artifacts found are cleaned, catalogued and compared to published collections. This comparison process often involves classifying them typologically and identifying other sites with similar artifact assemblages. However, a much more comprehensive range of analytical techniques are available through archaeological science, meaning that artifacts can be dated and their compositions examined. Bones, plants, and pollen collected from a site can all be analyzed using the methods of zooarchaeology, paleoethnobotany, palynology and stable isotopes while any texts can usually be deciphered.\n\nThese techniques frequently provide information that would not otherwise be known, and therefore they contribute greatly to the understanding of a site.\n\nComputational and virtual archaeology\n\nComputer graphics are now used to build virtual 3D models of sites, such as the throne room of an Assyrian palace or ancient Rome. Photogrammetry is also used as an analytical tool, and digital topographical models have been combined with astronomical calculations to verify whether or not certain structures (such as pillars) were aligned with astronomical events such as the sun's position at a solstice. Agent-based modeling and simulation can be used to better understand past social dynamics and outcomes. Data mining can be applied to large bodies of archaeological 'grey literature'.\n\nDrones\n\nArchaeologists around the world use drones to speed up survey work and protect sites from squatters, builders and miners. In Peru, small drones helped researchers produce three-dimensional models of Peruvian sites instead of the usual flat maps \u2013 and in days and weeks instead of months and years.\n\nDrones costing as little as \u00a3650 have proven useful. In 2013, drones have flown over at least six Peruvian archaeological sites, including the colonial Andean town Machu Llacta  above sea level. The drones continue to have altitude problems in the Andes, leading to plans to make a drone blimp, employing open source software.\n\nJeffrey Quilter, an archaeologist with Harvard University said, \"You can go up three metres and photograph a room, 300 metres and photograph a site, or you can go up 3,000 metres and photograph the entire valley.\"\n\nIn September 2014 drones weighing about  were used for 3D mapping of the above-ground ruins of the Greek city of Aphrodisias. The data are being analysed by the Austrian Archaeological Institute in Vienna.\n\nAcademic sub-disciplines\n\nAs with most academic disciplines, there are a very large number of archaeological sub-disciplines characterized by a specific method or type of material (e.g., lithic analysis, music, archaeobotany), geographical or chronological focus (e.g. Near Eastern archaeology, Islamic archaeology, Medieval archaeology), other thematic concern (e.g. maritime archaeology, landscape archaeology, battlefield archaeology), or a specific archaeological culture or civilization (e.g. Egyptology, Indology, Sinology).\n\nHistorical archaeology\n\nHistorical archaeology is the study of cultures with some form of writing.\n\nIn medieval Europe, archaeologists have explored the illicit burial of unbaptized children in medieval texts and cemeteries. In downtown New York City, archaeologists have exhumed the 18th century remains of the African Burial Ground. When remnants of the WWII Siegfried Line were being destroyed, emergency archaeological digs took place whenever any part of the line was removed, to further scientific knowledge and reveal details of the line's construction.\n\nEthnoarchaeology\n\nEthnoarchaeology is the ethnographic study of living people, designed to aid in our interpretation of the archaeological record. The approach first gained prominence during the processual movement of the 1960s, and continues to be a vibrant component of post-processual and other current archaeological approaches. Early ethnoarchaeological research focused on hunter-gatherer or foraging societies; today ethnoarchaeological research encompasses a much wider range of human behaviour.\n\nExperimental archaeology\n\nExperimental archaeology represents the application of the experimental method to develop more highly controlled observations of processes that create and impact the archaeological record. In the context of the logical positivism of processualism with its goals of improving the scientific rigor of archaeological epistemologies the experimental method gained importance. Experimental techniques remain a crucial component to improving the inferential frameworks for interpreting the archaeological record.\n\nArchaeometry\n\nArchaeometry aims to systematize archaeological measurement. It emphasizes the application of analytical techniques from physics, chemistry, and engineering. It is a field of research that frequently focuses on the definition of the chemical composition of archaeological remains for source analysis. Archaeometry also investigates different spatial characteristics of features, employing methods such as space syntax techniques and geodesy as well as computer-based tools such as geographic information system technology. Rare earth elements patterns may also be used.  A relatively nascent subfield is that of archaeological materials, designed to enhance understanding of prehistoric and non-industrial culture through scientific analysis of the structure and properties of materials associated with human activity.\n\nCultural resources management\n\nArchaeology can be a subsidiary activity within Cultural resources management (CRM), also called Cultural heritage management (CHM) in the United Kingdom. CRM archaeologists frequently examine archaeological sites that are threatened by development. Today, CRM accounts for most of the archaeological research done in the United States and much of that in western Europe as well. In the US, CRM archaeology has been a growing concern since the passage of the National Historic Preservation Act (NHPA) of 1966, and most taxpayers, scholars, and politicians believe that CRM has helped preserve much of that nation's history and prehistory that would have otherwise been lost in the expansion of cities, dams, and highways. Along with other statutes, the NHPA mandates that projects on federal land or involving federal funds or permits consider the effects of the project on each archaeological site.\n\nThe application of CRM in the United Kingdom is not limited to government-funded projects. Since 1990, PPG 16 has required planners to consider archaeology as a material consideration in determining applications for new development. As a result, numerous archaeological organizations undertake mitigation work in advance of (or during) construction work in archaeologically sensitive areas, at the developer's expense.\n\nIn England, ultimate responsibility of care for the historic environment rests with the Department for Culture, Media and Sport in association with English Heritage. In Scotland, Wales and Northern Ireland, the same responsibilities lie with Historic Scotland, Cadw and the Northern Ireland Environment Agency respectively.\n\nIn France, the Institut national du patrimoine (The National Institute of Cultural Heritage) trains curators specialized in archaeology. Their mission is to enhance the objects discovered. The curator is the link between scientific knowledge, administrative regulations, heritage objects and the public.\n\nAmong the goals of CRM are the identification, preservation, and maintenance of cultural sites on public and private lands, and the removal of culturally valuable materials from areas where they would otherwise be destroyed by human activity, such as proposed construction. This study involves at least a cursory examination to determine whether or not any significant archaeological sites are present in the area affected by the proposed construction. If these do exist, time and money must be allotted for their excavation. If initial survey and/or test excavations indicate the presence of an extraordinarily valuable site, the construction may be prohibited entirely.\n\nCultural resources management has, however, been criticized. CRM is conducted by private companies that bid for projects by submitting proposals outlining the work to be done and an expected budget. It is not unheard-of for the agency responsible for the construction to simply choose the proposal that asks for the least funding. CRM archaeologists face considerable time pressure, often being forced to complete their work in a fraction of the time that might be allotted for a purely scholarly endeavour. Compounding the time pressure is the vetting process of site reports that are required (in the US) to be submitted by CRM firms to the appropriate State Historic Preservation Office (SHPO). From the SHPO's perspective there is to be no difference between a report submitted by a CRM firm operating under a deadline, and a multi-year academic project. The result is that for a Cultural Resource Management archaeologist to be successful, they must be able to produce academic quality documents at a corporate world pace.\n\nThe annual ratio of open academic archaeology positions (inclusive of post-doc, temporary, and non- tenure track appointments) to the annual number of archaeology MA/MSc and PhD students is disproportionate. Cultural Resource Management, once considered an intellectual backwater for individuals with \"strong backs and weak minds,\" has attracted these graduates, and CRM offices are thus increasingly staffed by advance degreed individuals with a track record of producing scholarly articles but who also have extensive CRM field experience.\n\nProtection\n\nThe protection of archaeological finds for the public from catastrophes, wars and armed conflicts is increasingly being implemented internationally. This happens on the one hand through international agreements and on the other hand through organizations that monitor or enforce protection. United Nations, UNESCO and Blue Shield International deal with the protection of cultural heritage and thus also archaeological sites. This also applies to the integration of United Nations peacekeeping. Blue Shield International has undertaken various fact-finding missions in recent years to protect archaeological sites during the wars in Libya, Syria, Egypt and Lebanon. The importance of archaeological finds for identity, tourism and sustainable economic growth is repeatedly emphasized internationally.\n\nThe President of Blue Shield International, Karl von Habsburg, said during a cultural property protection mission in Lebanon in April 2019 with the United Nations Interim Force in Lebanon: \u201cCultural assets are part of the identity of the people who live in a certain place. If you destroy their culture, you also destroy their identity. Many people are uprooted, often have no prospects anymore and subsequently flee from their homeland.\"\n\nPopular views of archaeology\n\nEarly archaeology was largely an attempt to uncover spectacular artifacts and features, or to explore vast and mysterious abandoned cities and was mostly done by upper class, scholarly men. This general tendency laid the foundation for the modern popular view of archaeology and archaeologists. Many of the public view archaeology as something only available to a narrow demographic. The job of archaeologist is depicted as a \"romantic adventurist occupation\". and as a hobby more than a job in the scientific community. Cinema audiences form a notion of \"who archaeologists are, why they do what they do, and how relationships to the past are constituted\", and is often under the impression that all archaeology takes place in a distant and foreign land, only to collect monetarily or spiritually priceless artifacts. The modern depiction of archaeology has incorrectly formed the public's perception of what archaeology is.\n\nMuch thorough and productive research has indeed been conducted in dramatic locales such as Cop\u00e1n and the Valley of the Kings, but the bulk of activities and finds of modern archaeology are not so sensational. Archaeological adventure stories tend to ignore the painstaking work involved in carrying out modern surveys, excavations, and data processing. Some archaeologists refer to such off-the-mark portrayals as \"pseudoarchaeology\".\nArchaeologists are also very much reliant on public support; the question of exactly who they are doing their work for is often discussed.\n\nCurrent issues and controversy\n\nPublic archaeology\n\nMotivated by a desire to halt looting, curb pseudoarchaeology, and to help preserve archaeological sites through education and fostering public appreciation for the importance of archaeological heritage, archaeologists are mounting public-outreach campaigns. They seek to stop looting by combatting people who illegally take artifacts from protected sites, and by alerting people who live near archaeological sites of the threat of looting. Common methods of public outreach include press releases, the encouragement of school field trips to sites under excavation by professional archaeologists, and making reports and publications accessible outside of academia. Public appreciation of the significance of archaeology and archaeological sites often leads to improved protection from encroaching development or other threats.\n\nOne audience for archaeologists' work is the public. They increasingly realize that their work can benefit non-academic and non-archaeological audiences, and that they have a responsibility to educate and inform the public about archaeology. Local heritage awareness is aimed at increasing civic and individual pride through projects such as community excavation projects, and better public presentations of archaeological sites and knowledge. The U.S.Dept. of Agriculture, Forest Service (USFS) operates a volunteer archaeology and historic preservation program called the Passport in Time (PIT). Volunteers work with professional USFS archaeologists and historians on national forests throughout the U.S. Volunteers are involved in all aspects of professional archaeology under expert supervision.\n\nTelevision programs, web videos and social media can also bring an understanding of underwater archaeology to a broad audience. The Mardi Gras Shipwreck Project integrated a one-hour HD documentary, short videos for public viewing and video updates during the expedition as part of the educational outreach. Webcasting is also another tool for educational outreach. For one week in 2000 and 2001, live underwater video of the Queen Anne's Revenge Shipwreck Project was webcast to the Internet as a part of the QAR DiveLive educational program that reached thousands of children around the world. Created and co-produced by Nautilus Productions and Marine Grafics, this project enabled students to talk to scientists and learn about methods and technologies utilized by the underwater archaeology team.\n\nIn the UK, popular archaeology programs such as Time Team and Meet the Ancestors have resulted in a huge upsurge in public interest. Where possible, archaeologists now make more provisions for public involvement and outreach in larger projects than they once did, and many local archaeological organizations operate within the Community archaeology framework to expand public involvement in smaller-scale, more local projects. Archaeological excavation, however, is best undertaken by well-trained staff that can work quickly and accurately. Often this requires observing the necessary health and safety and indemnity insurance issues involved in working on a modern building site with tight deadlines. Certain charities and local government bodies sometimes offer places on research projects either as part of academic work or as a defined community project. There is also a flourishing industry selling places on commercial training excavations and archaeological holiday tours.\n\nArchaeologists prize local knowledge and often liaise with local historical and archaeological societies, which is one reason why Community archaeology projects are starting to become more common. Often archaeologists are assisted by the public in the locating of archaeological sites, which professional archaeologists have neither the funding, nor the time to do.\n\nArchaeological Legacy Institute (ALI), is a registered 501[c] [3] non-profit, media and education corporation registered in Oregon in 1999. ALI founded a website, The Archaeology Channel to support the organization's mission \"to nurturing and bringing attention to the human cultural heritage, by using media in the most efficient and effective ways possible.\"\n\nPseudoarchaeology\n\nPseudoarchaeology is an umbrella term for all activities that falsely claim to be archaeological but in fact violate commonly accepted and scientific archaeological practices. It includes much fictional archaeological work (discussed above), as well as some actual activity. Many non-fiction authors have ignored the scientific methods of processual archaeology, or the specific critiques of it contained in post-processualism.\n\nAn example of this type is the writing of Erich von D\u00e4niken. His 1968 book, Chariots of the Gods?, together with many subsequent lesser-known works, expounds a theory of ancient contacts between human civilization on Earth and more technologically advanced extraterrestrial civilizations. This theory, known as palaeocontact theory, or Ancient astronaut theory, is not exclusively D\u00e4niken's, nor did the idea originate with him. Works of this nature are usually marked by the renunciation of well-established theories on the basis of limited evidence, and the interpretation of evidence with a preconceived theory in mind.\n\nLooting\n\nLooting of archaeological sites is an ancient problem. For instance, many of the tombs of the Egyptian pharaohs were looted during antiquity. Archaeology stimulates interest in ancient objects, and people in search of artifacts or treasure cause damage to archaeological sites. The commercial and academic demand for artifacts unfortunately contributes directly to the illicit antiquities trade. Smuggling of antiquities abroad to private collectors has caused great cultural and economic damage in many countries whose governments lack the resources and or the will to deter it. Looters damage and destroy archaeological sites, denying future generations information about their ethnic and cultural heritage. Indigenous peoples especially lose access to and control over their 'cultural resources', ultimately denying them the opportunity to know their past.\n\nIn 1937, W. F. Hodge the Director of the Southwest Museum released a statement that the museum would no longer purchase or accept collections from looted contexts. The first conviction of the transport of artifacts illegally removed from private property under the Archaeological Resources Protection Act (ARPA; Public Law 96-95; 93 Statute 721; ) was in 1992 in the State of Indiana.\n\nArchaeologists trying to protect artifacts may be placed in danger by looters or locals trying to protect the artifacts from archaeologists who are viewed as looters by the locals.\n\nSome historical archaeology sites are subjected to looting by metal detector hobbyists who search for artifacts using increasingly advanced technology. Efforts are underway among all major Archaeological organizations to increase education and legitimate cooperation between amateurs and professionals in the metal detecting community.\n\nWhile most looting is deliberate, accidental looting can occur when amateurs, who are unaware of the importance of Archaeological rigor, collect artifacts from sites and place them into private collections.\n\nDescendant peoples\nIn the United States, examples such as the case of Kennewick Man have illustrated the tensions between Native Americans and archaeologists, which can be summarized as a conflict between a need to remain respectful toward sacred burial sites and the academic benefit from studying them. For years, American archaeologists dug on Indian burial grounds and other places considered sacred, removing artifacts and human remains to storage facilities for further study. In some cases human remains were not even thoroughly studied but instead archived rather than reburied. Furthermore, Western archaeologists' views of the past often differ from those of tribal peoples. The West views time as linear; for many natives, it is cyclic. From a Western perspective, the past is long-gone; from a native perspective, disturbing the past can have dire consequences in the present.\n\nAs a consequence of this, American Indians attempted to prevent archaeological excavation of sites inhabited by their ancestors, while American archaeologists believed that the advancement of scientific knowledge was a valid reason to continue their studies. This contradictory situation was addressed by the Native American Graves Protection and Repatriation Act (NAGPRA, 1990), which sought to reach a compromise by limiting the right of research institutions to possess human remains. Due in part to the spirit of postprocessualism, some archaeologists have begun to actively enlist the assistance of indigenous peoples likely to be descended from those under study.\n\nArchaeologists have also been obliged to re-examine what constitutes an archaeological site in view of what native peoples believe to constitute sacred space. To many native peoples, natural features such as lakes, mountains or even individual trees have cultural significance. Australian archaeologists especially have explored this issue and attempted to survey these sites to give them some protection from being developed. Such work requires close links and trust between archaeologists and the people they are trying to help and at the same time study.\n\nWhile this cooperation presents a new set of challenges and hurdles to fieldwork, it has benefits for all parties involved. Tribal elders cooperating with archaeologists can prevent the excavation of areas of sites that they consider sacred, while the archaeologists gain the elders' aid in interpreting their finds. There have also been active efforts to recruit aboriginal peoples directly into the archaeological profession.\n\nRepatriation\nSee Repatriation and reburial of human remains\nA new trend in the heated controversy between First Nations groups and scientists is the repatriation of native artifacts to the original descendants. An example of this occurred on 21 June 2005, when community members and elders from a number of the 10 Algonquian nations in the Ottawa area convened on the Kitigan Zibi reservation near Maniwaki, Quebec, to inter ancestral human remains and burial goods\u2014some dating back 6,000 years. It was not determined, however, if the remains were directly related to the Algonquin people who now inhabit the region. The remains may be of Iroquoian ancestry, since Iroquoian people inhabited the area before the Algonquin. Moreover, the oldest of these remains might have no relation at all to the Algonquin or Iroquois, and belong to an earlier culture who previously inhabited the area.\n\nThe remains and artifacts, including jewelry, tools and weapons, were originally excavated from various sites in the Ottawa Valley, including Morrison and the Allumette Islands. They had been part of the Canadian Museum of Civilization's research collection for decades, some since the late 19th century. Elders from various Algonquin communities conferred on an appropriate reburial, eventually deciding on traditional redcedar and birchbark boxes lined with redcedar chips, muskrat and beaver pelts.\n\nAn inconspicuous rock mound marks the reburial site where close to 80 boxes of various sizes are buried. Because of this reburial, no further scientific study is possible. Although negotiations were at times tense between the Kitigan Zibi community and museum, they were able to reach agreement.\n\nAfrican diaspora archaeology \nSimilar to the experience of Native Americans, the history of African diaspora archaeology is one of controversies over Whiteness in archaeology and anthropology, a lack of inclusion of the African descendant community, and possession of human remains in the collections of universities and museums. In the nineties, anthropologist Michael Blakey was the director of research during the New York African Burial Ground Project where he initiated a protocol for collaborating with the African descendant community. In 2011, the Society of Black Archaeologists was created in the United States. Co-founders Ayana Omilade Flewellen, archaeologist at the University of California, Riverside and Justin Dunnavant, archaeologist and Assistant Professor of Anthropology at the University of California, Los Angeles intend to build a restorative justice-based structure in archaeology. They suggest to define descendants not only in genealogical terms, but also to welcome input of African Americans whose ancestors had a shared historical experience in enslavement.\n\nThe United States Senate unanimously passed a bill in December 2020 that centers African American cemeteries at risk in South Carolina. The bill is made to better protect historic African burial grounds and can lead to the creation of an African American Burial Grounds Network. Barbados, eight days after becoming a republic on November 30, 2021, announced plans for the construction of the Newton Enslaved Burial Ground Memorial as well as a museum dedicated to the history of the Atlantic slave trade. The Ghanaian-British architect David Adjaye is to lead the project that is to commemorate an estimated 570 West Africans buried in unmarked graves at the site of the former Newton sugar plantation. Barbados can be seen as a good example of respectful preservation of an African burial ground. Throughout the Americas however the burial grounds are in danger of being destroyed or human remains are being excavated without the descendant community being involved.\n\nSee also\n\n \n \n \n \n \n Conservation and restoration of archaeological sites\n \n \n \n \n \n \n \n \n\nLists\n List of archaeological periods\n List of archaeological sites by country\n List of archaeologists\n List of archaeology awards\n List of paleoethnobotanists\n\nNotes\n\nReferences\n\nBibliography\n\nFurther reading\n\n Archaeology (magazine)\n Lewis Binford - New Perspectives in Archaeology (1968) \n Glyn Daniel \u2013 A Short History of Archaeology (1991)\n Kevin Greene \u2013 Introduction to Archaeology (1983)\n Thomas Hester, Harry Shafer, and Kenneth L. Feder \u2013 Field Methods in Archaeology 7th edition (1997)\n Ian Hodder & Scott Hutson \u2013 \"Reading the Past\" 3rd. edition (2003)\n \n International Journal of South American Archaeology - IJSA (magazine)\n Internet Archaeology, e-journal\n C.U. Larsen - Sites and Monuments (1992)\n Adrian Praetzellis \u2013 Death by Theory, AltaMira Press (2000).  \n Colin Renfrew & Paul Bahn \u2013 Archaeology: theories, methods and practice, 2nd edition (1996)\n Smekalova, T.N.; Voss O.; & Smekalov S.L. (2008). \"Magnetic Surveying in Archaeology. More than 10 years of using the Overhauser GSM-19 gradiometer\". Wormianum.\n David Hurst Thomas \u2013 Archaeology, 3rd. edition (1998)\n Robert J. Sharer & Wendy Ashmore \u2013 Archaeology: Discovering our Past 2nd edition (1993)\n Bruce Trigger \u2013 \"A History of Archaeological Thought\" 2nd. edition (2007)\n Alison Wylie \u2013 Thinking From Things: Essays in the Philosophy of Archaeology, University of California Press, Berkeley CA, 2002\n\nExternal links\n\n \n\n 400,000 records of archaeological sites and architecture in England\n Archaeolog.org\n Archaeology Daily News\n Archaeology Times | The top archaeology news from around the world\n Council for British Archaeology\n Estudio de Museolog\u00eda Rosario\n Fasti Online \u2013 an online database of archaeological sites\n Great Archaeology\n Kite Aerial Photographers \u2013 Archaeology\n NPS Archeology Program: Visit Archeology (Archeology travel guides)\n Sri Lanka Archaeology\n The Archaeological Institute of America\n The Archaeology Channel\n The Archaeology Data Service \u2013 Open access online archive for UK and global archaeology\n The Archaeology Division of the American Anthropological Association\n The Canadian Museum of Civilization \u2013 Archaeology\n The Society for American Archaeology\n The World Archaeological Congress\n US Forest Service Volunteer program Passport in Time\n World Archaeology News \u2013 weekly update from BBC Radio archaeologist, Win Scutt\n The Italian Archaeological Mission in U\u015fakl\u0131 H\u00f6y\u00fck\n Comprehensive Database of Archaeological Site Reports in Japan\n\n \nAnthropology",
  "Geography": "Geography (from Greek: , geographia, literally \"earth description\") is a field of science devoted to the study of the lands, features, inhabitants, and phenomena of the Earth and planets. The first person to use the word \u03b3\u03b5\u03c9\u03b3\u03c1\u03b1\u03c6\u03af\u03b1 was Eratosthenes (276\u2013194 BC). Geography is an all-encompassing discipline that seeks an understanding of Earth and its human and natural complexities\u2014not merely where objects are, but also how they have changed and come to be.\n\nGeography is often defined in terms of two branches: human geography and physical geography. Human geography is concerned with the study of people and their communities, cultures, economies, and interactions with the environment by studying their relations with and across space and place. Physical geography is concerned with the study of processes and patterns in the natural environment like the atmosphere, hydrosphere, biosphere, and geosphere.\n\nThe four historical traditions in geographical research are spatial analyses of natural and the human phenomena, area studies of places and regions, studies of human-land relationships, and the Earth sciences. Geography has been called \"the world discipline\" and \"the bridge between the human and the physical sciences\".\n\nIntroduction \nGeography is a systematic study of the Universe and its features. Traditionally, geography has been associated with cartography and place names. Although many geographers are trained in toponymy and cartology, this is not their main preoccupation. Geographers study the space and the temporal database distribution of phenomena, processes, and features as well as the interaction of humans and their environment. Because space and place affect a variety of topics, such as economics, health, climate, plants and animals, geography is highly interdisciplinary. The interdisciplinary nature of the geographical approach depends on an attentiveness to the relationship between physical and human phenomena and its spatial patterns.\n\nGeography as a discipline can be split broadly into two main subsidiary fields: human geography and physical geography. The former largely focuses on the built environment and how humans create, view, manage, and influence space. The latter examines the natural environment, and how organisms, climate, soil, water, and landforms produce and interact. The difference between these approaches led to a third field, environmental geography, which combines physical and human geography and concerns the interactions between the environment and humans.\n\nBranches\n\nPhysical \n\nPhysical geography (or physiography) focuses on geography as an Earth science. It aims to understand the physical problems and the issues of lithosphere, hydrosphere, atmosphere, pedosphere, and global flora and fauna patterns (biosphere). Physical geography is the study of earth's seasons, climate, atmosphere, soil, streams, landforms, and oceans.\n\nHuman \n\nHuman geography (or anthropogeography) is a branch of geography that focuses on the study of patterns and processes that shape the human society. It encompasses the human, political, cultural, social, and economic aspects.\n\nVarious approaches to the study of human geography have also arisen through time and include:\n Behavioral geography\n Culture theory\n Feminist geography\n Geosophy\n\nIntegrated \n\nIntegrated geography is concerned with the description of the spatial interactions between humans and the natural world. It requires an understanding of the traditional aspects of physical and human geography, like the ways that human societies conceptualize the environment. Integrated geography has emerged as a bridge between human and physical geography, as a result of the increasing specialisation of the two sub-fields. Since the changing of the human relationship with the environment as a result of globalization and technological change, a new approach was needed to understand the changing and dynamic relationship. Examples of areas of research in environmental geography include: emergency management, environmental management, sustainability, and political ecology.\n\nGeomatics \n\nGeomatics is concerned with the application of computers to the traditional spatial techniques used in cartography and topography. Geomatics emerged from the quantitative revolution in geography in the mid-1950s. Today, geomatics methods include spatial analysis, geographic information systems (GIS), remote sensing, and global positioning systems (GPS). Geomatics has led to a revitalization of some geography departments, especially in Northern America where the subject had a declining status during the 1950s.\n\nRegional \n\nA branch which is concerned with the description of the unique characteristics of the earth's surface, resulting in each area from the combination of its complete natural or elements, as of physical and human environment. The main aim is to understand, or define the uniqueness, or character of a particular region that consists of natural as well as human elements. Attention is paid also to regionalization, which covers the proper techniques of space delimitation into regions.\n\nRelated fields \n Interplanetary sciences: While the discipline of geography is normally concerned with the Earth, the term can also be informally used to describe the study of other worlds, such as the planets of the Solar System and even beyond. The study of systems larger than the Earth itself usually forms part of Astronomy or Cosmology. The study of other planets is usually called planetary science. Alternative terms such as areology (the study of Mars) have been proposed but are not widely used.\n Regional science: In the 1950s, the regional science movement led by Walter Isard arose to provide a more quantitative and analytical base to geographical questions, in contrast to the descriptive tendencies of traditional geography programs. Regional science comprises the body of knowledge in which the spatial dimension plays a fundamental role, such as regional economics, resource management, location theory, urban and regional planning, transport and communication, human geography, population distribution, landscape ecology, and environmental quality.\n Urban planning, regional planning, and spatial planning: Use the science of geography to assist in determining how to develop (or not develop) the land to meet particular criteria, such as safety, beauty, economic opportunities, the preservation of the built or natural heritage, and so on. The planning of towns, cities, and rural areas may be seen as applied geography.\n\nTechniques \n\nAs spatial interrelationships are key to this synoptic science, maps are a key tool. Classical cartography has been joined by a more modern approach to geographical analysis, computer-based geographic information systems (GIS).\n\nIn their study, geographers use four interrelated approaches:\n Analytical\u00a0\u2013 Asks why we find features and populations in a specific geographic area.\n Descriptive\u00a0\u2013 Simply specifies the locations of features and populations.\n Regional\u00a0\u2013 Examines systematic relationships between categories for a specific region or location on the planet.\n Systematic\u00a0\u2013 Groups geographical knowledge into categories that can be explored globally.\n\nCartography \n\nCartography studies the representation of the Earth's surface with abstract symbols (map making). Although other subdisciplines of geography rely on maps for presenting their analyses, the actual making of maps is abstract enough to be regarded separately. Cartography has grown from a collection of drafting techniques into an actual science.\n\nCartographers must learn cognitive psychology and ergonomics to understand which symbols convey information about the Earth most effectively, and behavioural psychology to induce the readers of their maps to act on the information. They must learn geodesy and fairly advanced mathematics to understand how the shape of the Earth affects the distortion of map symbols projected onto a flat surface for viewing. It can be said, without much controversy, that cartography is the seed from which the larger field of geography grew. Most geographers will cite a childhood fascination with maps as an early sign they would end up in the field.\n\nGeographic information systems \n\nGeographic information systems (GIS) deal with the storage of information about the Earth for automatic retrieval by a computer, in an accurate manner appropriate to the information's purpose. In addition to all of the other subdisciplines of geography, GIS specialists must understand computer science and database systems. GIS has revolutionized the field of cartography: nearly all mapmaking is now done with the assistance of some form of GIS software. The science of using GIS software and GIS techniques to represent, analyse, and predict the spatial relationships is called geographic information science (GISc).\n\nRemote sensing \n\nRemote sensing is the science of obtaining information about Earth features from measurements made at a distance. Remotely sensed data comes in many forms, such as satellite imagery, aerial photography, and data obtained from hand-held sensors. Geographers increasingly use remotely sensed data to obtain information about the Earth's land surface, ocean, and atmosphere, because it: (a) supplies objective information at a variety of spatial scales (local to global), (b) provides a synoptic view of the area of interest, (c) allows access to distant and inaccessible sites, (d) provides spectral information outside the visible portion of the electromagnetic spectrum, and (e) facilitates studies of how features/areas change over time. Remotely sensed data may be analysed either independently of, or in conjunction with other digital data layers (e.g., in a geographic information system).\n\nQuantitative methods \n\nGeostatistics deal with quantitative data analysis, specifically the application of statistical methodology to the exploration of geographic phenomena. Geostatistics is used extensively in a variety of fields, including hydrology, geology, petroleum exploration, weather analysis, urban planning, logistics, and epidemiology. The mathematical basis for geostatistics derives from cluster analysis, linear discriminant analysis and non-parametric statistical tests, and a variety of other subjects. Applications of geostatistics rely heavily on geographic information systems, particularly for the interpolation (estimate) of unmeasured points. Geographers are making notable contributions to the method of quantitative techniques.\n\nQualitative methods \n\nGeographic qualitative methods, or ethnographical research techniques, are used by human geographers. In cultural geography there is a tradition of employing qualitative research techniques, also used in anthropology and sociology. Participant observation and in-depth interviews provide human geographers with qualitative data.\n\nHistory \n\nThe oldest known world maps date back to ancient Babylon from the 9th century BC. The best known Babylonian world map, however, is the Imago Mundi of 600 BC. The map as reconstructed by Eckhard Unger shows Babylon on the Euphrates, surrounded by a circular landmass showing Assyria, Urartu, and several cities, in turn surrounded by a \"bitter river\" (Oceanus), with seven islands arranged around it so as to form a seven-pointed star. The accompanying text mentions seven outer regions beyond the encircling ocean. The descriptions of five of them have survived. In contrast to the Imago Mundi, an earlier Babylonian world map dating back to the 9th century BC depicted Babylon as being further north from the center of the world, though it is not certain what that center was supposed to represent.\n\nThe ideas of Anaximander (c. 610\u2013545 BC): considered by later Greek writers to be the true founder of geography, come to us through fragments quoted by his successors. Anaximander is credited with the invention of the gnomon, the simple, yet efficient Greek instrument that allowed the early measurement of latitude. Thales is also credited with the prediction of eclipses. The foundations of geography can be traced to the ancient cultures, such as the ancient, medieval, and early modern Chinese. The Greeks, who were the first to explore geography as both art and science, achieved this through Cartography, Philosophy, and Literature, or through Mathematics. There is some debate about who was the first person to assert that the Earth is spherical in shape, with the credit going either to Parmenides or Pythagoras. Anaxagoras was able to demonstrate that the profile of the Earth was circular by explaining eclipses. However, he still believed that the Earth was a flat disk, as did many of his contemporaries. One of the first estimates of the radius of the Earth was made by Eratosthenes.\n\nThe first rigorous system of latitude and longitude lines is credited to Hipparchus. He employed a sexagesimal system that was derived from Babylonian mathematics. The meridians were sub-divided into 360\u00b0, with each degree further subdivided into 60 (minutes). To measure the longitude at different locations on Earth, he suggested using eclipses to determine the relative difference in time. The extensive mapping by the Romans as they explored new lands would later provide a high level of information for Ptolemy to construct detailed atlases. He extended the work of Hipparchus, using a grid system on his maps and adopting a length of 56.5 miles for a degree.\n\nFrom the 3rd century onwards, Chinese methods of geographical study and writing of geographical literature became much more comprehensive than what was found in Europe at the time (until the 13th century). Chinese geographers such as Liu An, Pei Xiu, Jia Dan, Shen Kuo, Fan Chengda, Zhou Daguan, and Xu Xiake wrote important treatises, yet by the 17th century advanced ideas and methods of Western-style geography were adopted in China.\n\nDuring the Middle Ages, the fall of the Roman empire led to a shift in the evolution of geography from Europe to the Islamic world. Muslim geographers such as Muhammad al-Idrisi produced detailed world maps (such as Tabula Rogeriana), while other geographers such as Yaqut al-Hamawi, Abu Rayhan Biruni, Ibn Battuta, and Ibn Khaldun provided detailed accounts of their journeys and the geography of the regions they visited. Turkish geographer, Mahmud al-Kashgari drew a world map on a linguistic basis, and later so did Piri Reis (Piri Reis map). Further, Islamic scholars translated and interpreted the earlier works of the Romans and the Greeks and established the House of Wisdom in Baghdad for this purpose. Ab\u016b Zayd al-Balkh\u012b, originally from Balkh, founded the \"Balkh\u012b school\" of terrestrial mapping in Baghdad. Suhr\u0101b, a late tenth century Muslim geographer accompanied a book of geographical coordinates, with instructions for making a rectangular world map with equirectangular projection or cylindrical equidistant projection.\n\nAbu Rayhan Biruni (976\u20131048) first described a polar equi-azimuthal equidistant projection of the celestial sphere. He was regarded as the most skilled when it came to mapping cities and measuring the distances between them, which he did for many cities in the Middle East and the Indian subcontinent. He often combined astronomical readings and mathematical equations, in order to develop methods of pin-pointing locations by recording degrees of latitude and longitude. He also developed similar techniques when it came to measuring the heights of mountains, depths of the valleys, and expanse of the horizon. He also discussed human geography and the planetary habitability of the Earth. He also calculated the latitude of Kath, Khwarezm, using the maximum altitude of the Sun, and solved a complex geodesic equation in order to accurately compute the Earth's circumference, which was close to modern values of the Earth's circumference. His estimate of 6,339.9\u00a0km for the Earth radius was only 16.8\u00a0km less than the modern value of 6,356.7\u00a0km. In contrast to his predecessors, who measured the Earth's circumference by sighting the Sun simultaneously from two different locations, al-Biruni developed a new method of using trigonometric calculations, based on the angle between a plain and mountain top, which yielded more accurate measurements of the Earth's circumference, and made it possible for it to be measured by a single person from a single location.\n\nThe European Age of Discovery during the 16th and the 17th centuries, where many new lands were discovered and accounts by European explorers such as Christopher Columbus, Marco Polo, and James Cook revived a desire for both accurate geographic detail, and more solid theoretical foundations in Europe. The problem facing both explorers and geographers was finding the latitude and longitude of a geographic location. The problem of latitude was solved long ago but that of longitude remained; agreeing on what zero meridian should be was only part of the problem. It was left to John Harrison to solve it by inventing the chronometer H-4 in 1760, and later in 1884 for the International Meridian Conference to adopt by convention the Greenwich meridian as zero meridian.\n\nThe 18th and the 19th centuries were the times when geography became recognized as a discrete academic discipline, and became part of a typical university curriculum in Europe (especially Paris and Berlin). The development of many geographic societies also occurred during the 19th century, with the foundations of the Soci\u00e9t\u00e9 de G\u00e9ographie in 1821, the Royal Geographical Society in 1830, Russian Geographical Society in 1845, American Geographical Society in 1851, and the National Geographic Society in 1888. The influence of Immanuel Kant, Alexander von Humboldt, Carl Ritter, and Paul Vidal de la Blache can be seen as a major turning point in geography from a philosophy to an academic subject.\n\nOver the past two centuries, the advancements in technology with computers have led to the development of geomatics and new practices such as participant observation and geostatistics being incorporated into geography's portfolio of tools. In the West during the 20th century, the discipline of geography went through four major phases: environmental determinism, regional geography, the quantitative revolution, and critical geography. The strong interdisciplinary links between geography and the sciences of geology and botany, as well as economics, sociology and demographics have also grown greatly, especially as a result of earth system science that seeks to understand the world in a holistic view.\n\nNotable geographers\n\n Alexander von Humboldt (1769\u20131859)\u00a0\u2013 published Cosmos and founder of the sub-field biogeography.\n Arnold Henry Guyot (1807\u20131884)\u00a0\u2013 noted the structure of glaciers and advanced understanding in glacier motion, especially in fast ice flow.\n Carl O. Sauer (1889\u20131975)\u00a0\u2013 cultural geographer.\n Carl Ritter (1779\u20131859)\u00a0\u2013 occupied the first chair of geography at Berlin University.\n David Harvey (born 1935)\u00a0\u2013 Marxist geographer and author of theories on spatial and urban geography, winner of the Vautrin Lud Prize.\n Doreen Massey (1944\u20132016)\u00a0\u2013 scholar in the space and places of globalization and its pluralities; winner of the Vautrin Lud Prize.\n Edward Soja (1940\u20132015)\u00a0\u2013 worked on regional development, planning and governance and coined the terms Synekism and Postmetropolis; winner of the Vautrin Lud Prize.\n Ellen Churchill Semple (1863\u20131932)\u00a0\u2013 first female president of the Association of American Geographers.\n Eratosthenes ( 276\u2013c. 195/194 BC)\u00a0\u2013 calculated the size of the Earth.\n Ernest Burgess (1886\u20131966)\u00a0\u2013 creator of the concentric zone model.\n Gerardus Mercator (1512\u20131594)\u00a0\u2013 cartographer who produced the mercator projection\n John Francon Williams (1854\u20131911) \u2013 author of The Geography of the Oceans.\n Karl Butzer (1934\u20132016)\u00a0\u2013 German-American geographer, cultural ecologist and environmental archaeologist.\n Michael Frank Goodchild (born 1944)\u00a0\u2013 GIS scholar and winner of the RGS founder's medal in 2003.\n Muhammad al-Idrisi (Arabic: \u0623\u0628\u0648 \u0639\u0628\u062f \u0627\u0644\u0644\u0647 \u0645\u062d\u0645\u062f \u0627\u0644\u0625\u062f\u0631\u064a\u0633\u064a; Latin: Dreses) (1100\u20131165)\u00a0\u2013 author of Nuzhatul Mushtaq.\n Nigel Thrift (born 1949)\u00a0\u2013 originator of non-representational theory.\n Paul Vidal de La Blache (1845\u20131918)\u00a0\u2013 founder of the French school of geopolitics, wrote the principles of human geography.\n Ptolemy (c. 100\u2013c. 170)\u00a0\u2013 compiled Greek and Roman knowledge into the book Geographia.\n Radhanath Sikdar (1813\u20131870)\u00a0\u2013 calculated the height of Mount Everest.\n Sir Halford Mackinder (1861\u20131947)\u00a0\u2013 co-founder of the LSE, Geographical Association.\n Strabo (64/63 BC\u00a0\u2013 c. AD 24)\u00a0\u2013 wrote Geographica, one of the first books outlining the study of geography.\n Walter Christaller (1893\u20131969)\u00a0\u2013 human geographer and inventor of Central place theory.\n William Morris Davis (1850\u20131934)\u00a0\u2013 father of American geography and developer of the cycle of erosion.\n Yi-Fu Tuan (born 1930)\u00a0\u2013 Chinese-American scholar credited with starting Humanistic Geography as a discipline.\n\nInstitutions and societies \n American Association of Geographers (AAG)\n American Geographical Society (US)\n Anton Melik Geographical Institute (Slovenia)\n Institute of Geographical Information Systems (Pakistan)\n Karachi Geographical Society (Pakistan)\n National Geographic Society (US)\n Royal Canadian Geographical Society (Canada)\n Royal Danish Geographical Society (Denmark)\n Royal Geographical Society (UK)\n Russian Geographical Society (Russia)\n\nPublications \n African Geographical Review\n Annals of the American Association of Geographers\n Antipode\n Geographical Review\n The Geographical Journal\n The Professional Geographer\n\nSee also \n Geographical space\n\nNotes\n\nReferences\n\nExternal links \n \n Definition of Geography at Dictionary.com\n Definition of geography by Lexico\n Origin and meaning of geography by Online Etymology Dictionary\n Topic Dictionaries at Oxford Learner's Dictionaries\n\n \nEarth sciences\nSocial sciences\nMain topic articles",
  "Culture": "Culture () is an umbrella term which encompasses the social behavior and norms found in human societies, as well as the knowledge, beliefs, arts, laws, customs, capabilities, and habits of the individuals in these groups.\n\nHumans acquire culture through the learning processes of enculturation and socialization, which is shown by the diversity of cultures across societies.\n\nA cultural norm codifies acceptable conduct in society; it serves as a guideline for behavior, dress, language, and demeanor in a situation, which serves as a template for expectations in a social group.\nAccepting only a monoculture in a social group can bear risks, just as a single species can wither in the face of environmental change, for lack of functional responses to the change. \nThus in military culture, valor is counted a typical behavior for an individual and duty, honor, and loyalty to the social group are counted as virtues or functional responses in the continuum of conflict. In the practice of religion, analogous attributes can be identified in a social group.\n\nDescription \n\nthumb|right| Pygmy music has been polyphonic well before their discovery by non-African explorers of the Baka, Aka, Efe, and other foragers of the Central African forests, in the 1200s, which is at least 200 years before polyphony developed in Europe. Note the multiple lines of singers and dancers. The motifs are independent, with theme and variation interweaving. This type of music is thought to be the first expression of polyphony in world music. \nCulture is considered a central concept in anthropology, encompassing the range of phenomena that are transmitted through social learning in human societies. Cultural universals are found in all human societies. These include expressive forms like art, music, dance, ritual, religion, and technologies like tool usage, cooking, shelter, and clothing. The concept of material culture covers the physical expressions of culture, such as technology, architecture and art, whereas the immaterial aspects of culture such as principles of social organization (including practices of political organization and social institutions), mythology, philosophy, literature (both written and oral), and science comprise the intangible cultural heritage of a society.\n\nIn the humanities, one sense of culture as an attribute of the individual has been the degree to which they have cultivated a particular level of sophistication in the arts, sciences, education, or manners. The level of cultural sophistication has also sometimes been used to distinguish civilizations from less complex societies. Such hierarchical perspectives on culture are also found in class-based distinctions between a high culture of the social elite and a low culture, popular culture, or folk culture of the lower classes, distinguished by the stratified access to cultural capital. In common parlance, culture is often used to refer specifically to the symbolic markers used by ethnic groups to distinguish themselves visibly from each other such as body modification, clothing or jewelry. Mass culture refers to the mass-produced and mass mediated forms of consumer culture that emerged in the 20th century. Some schools of philosophy, such as Marxism and critical theory, have argued that culture is often used politically as a tool of the elites to manipulate the proletariat and create a false consciousness. Such perspectives are common in the discipline of cultural studies. In the wider social sciences, the theoretical perspective of cultural materialism holds that human symbolic culture arises from the material conditions of human life, as humans create the conditions for physical survival, and that the basis of culture is found in evolved biological dispositions.\n\nWhen used as a count noun, a \"culture\" is the set of customs, traditions, and values of a society or community, such as an ethnic group or nation. Culture is the set of knowledge acquired over time. In this sense, multiculturalism values the peaceful coexistence and mutual respect between different cultures inhabiting the same planet. Sometimes \"culture\" is also used to describe specific practices within a subgroup of a society, a subculture (e.g. \"bro culture\"), or a counterculture. Within cultural anthropology, the ideology and analytical stance of cultural relativism hold that cultures cannot easily be objectively ranked or evaluated because any evaluation is necessarily situated within the value system of a given culture.\n\nEtymology \nThe modern term \"culture\" is based on a term used by the ancient Roman orator Cicero in his Tusculanae Disputationes, where he wrote of a cultivation of the soul or \"cultura animi,\" using an agricultural metaphor for the development of a philosophical soul, understood teleologically as the highest possible ideal for human development. Samuel Pufendorf took over this metaphor in a modern context, meaning something similar, but no longer assuming that philosophy was man's natural perfection. His use, and that of many writers after him, \"refers to all the ways in which human beings overcome their original barbarism, and through artifice, become fully human.\"\n\nIn 1986, philosopher Edward S. Casey wrote, \"The very word culture meant 'place tilled' in Middle English, and the same word goes back to Latin colere, 'to inhabit, care for, till, worship' and cultus, 'A cult, especially a religious one.' To be cultural, to have a culture, is to inhabit a place sufficiently intensely to cultivate it\u2014to be responsible for it, to respond to it, to attend to it caringly.\"\n\nCulture described by Richard Velkley: ... originally meant the cultivation of the soul or mind, acquires most of its later modern meaning in the writings of the 18th-century German thinkers, who were on various levels developing Rousseau's criticism of \"modern liberalism and Enlightenment.\" Thus a contrast between \"culture\" and \"civilization\" is usually implied in these authors, even when not expressed as such.\n\nIn the words of anthropologist E.B. Tylor, it is \"that complex whole which includes knowledge, belief, art, morals, law, custom and any other capabilities and habits acquired by man as a member of society.\" Alternatively, in a contemporary variant, \"Culture is defined as a social domain that emphasizes the practices, discourses and material expressions, which, over time, express the continuities and discontinuities of social meaning of a life held in common.\n\nThe Cambridge English Dictionary states that culture is \"the way of life, especially the general customs and beliefs, of a particular group of people at a particular time.\" Terror management theory posits that culture is a series of activities and worldviews that provide humans with the basis for perceiving themselves as \"person[s] of worth within the world of meaning\"\u2014raising themselves above the merely physical aspects of existence, in order to deny the animal insignificance and death that Homo sapiens became aware of when they acquired a larger brain.\n\nThe word is used in a general sense as the evolved ability to categorize and represent experiences with symbols and to act imaginatively and creatively. This ability arose with the evolution of behavioral modernity in humans around 50,000 years ago and is often thought to be unique to humans. However, some other species have demonstrated similar, though much less complicated, abilities for social learning. It is also used to denote the complex networks of practices and accumulated knowledge and ideas that are transmitted through social interaction and exist in specific human groups, or cultures, using the plural form.\n\nChange\n\nIt has been estimated from archaeological data that the human capacity for cumulative culture emerged somewhere between 500,000\u2013170,000 years ago.\n\nRaimon Panikkar identified 29 ways in which cultural change can be brought about, including growth, development, evolution, involution, renovation, reconception, reform, innovation, revivalism, revolution, mutation, progress, diffusion, osmosis, borrowing, eclecticism, syncretism, modernization, indigenization, and transformation. In this context, modernization could be viewed as adoption of Enlightenment era beliefs and practices, such as science, rationalism, industry, commerce, democracy, and the notion of progress. Rein Raud, building on the work of Umberto Eco, Pierre Bourdieu and Jeffrey C. Alexander, has proposed a model of cultural change based on claims and bids, which are judged by their cognitive adequacy and endorsed or not endorsed by the symbolic authority of the cultural community in question.\n\nCultural invention has come to mean any innovation that is new and found to be useful to a group of people and expressed in their behavior but which does not exist as a physical object. Humanity is in a global \"accelerating culture change period,\" driven by the expansion of international commerce, the mass media, and above all, the human population explosion, among other factors. Culture repositioning means the reconstruction of the cultural concept of a society.\n\nCultures are internally affected by both forces encouraging change and forces resisting change. These forces are related to both social structures and natural events, and are involved in the perpetuation of cultural ideas and practices within current structures, which themselves are subject to change.\n\nSocial conflict and the development of technologies can produce changes within a society by altering social dynamics and promoting new cultural models, and spurring or enabling generative action. These social shifts may accompany ideological shifts and other types of cultural change. For example, the U.S. feminist movement involved new practices that produced a shift in gender relations, altering both gender and economic structures. Environmental conditions may also enter as factors. For example, after tropical forests returned at the end of the last ice age, plants suitable for domestication were available, leading to the invention of agriculture, which in turn brought about many cultural innovations and shifts in social dynamics.\n\nCultures are externally affected via contact between societies, which may also produce\u2014or inhibit\u2014social shifts and changes in cultural practices. War or competition over resources may impact technological development or social dynamics. Additionally, cultural ideas may transfer from one society to another, through diffusion or acculturation. In diffusion, the form of something (though not necessarily its meaning) moves from one culture to another. For example, Western restaurant chains and culinary brands sparked curiosity and fascination to the Chinese as China opened its economy to international trade in the late 20th-century. \"Stimulus diffusion\" (the sharing of ideas) refers to an element of one culture leading to an invention or propagation in another. \"Direct borrowing,\" on the other hand, tends to refer to technological or tangible diffusion from one culture to another. Diffusion of innovations theory presents a research-based model of why and when individuals and cultures adopt new ideas, practices, and products.\n\nAcculturation has different meanings. Still, in this context, it refers to the replacement of traits of one culture with another, such as what happened to certain Native American tribes and many indigenous peoples across the globe during the process of colonization. Related processes on an individual level include assimilation (adoption of a different culture by an individual) and transculturation. The transnational flow of culture has played a major role in merging different cultures and sharing thoughts, ideas, and beliefs.\n\nEarly modern discourses\n\nGerman Romanticism\n\nImmanuel Kant (1724\u20131804) formulated an individualist definition of \"enlightenment\" similar to the concept of bildung: \"Enlightenment is man's emergence from his self-incurred immaturity.\" He argued that this immaturity comes not from a lack of understanding, but from a lack of courage to think independently. Against this intellectual cowardice, Kant urged: Sapere Aude, \"Dare to be wise!\" In reaction to Kant, German scholars such as Johann Gottfried Herder (1744\u20131803) argued that human creativity, which necessarily takes unpredictable and highly diverse forms, is as important as human rationality. Moreover, Herder proposed a collective form of Bildung: \"For Herder, Bildung was the totality of experiences that provide a coherent identity, and sense of common destiny, to a people.\"\n\nIn 1795, the Prussian linguist and philosopher Wilhelm von Humboldt (1767\u20131835) called for an anthropology that would synthesize Kant's and Herder's interests. During the Romantic era, scholars in Germany, especially those concerned with nationalist movements\u2014such as the nationalist struggle to create a \"Germany\" out of diverse principalities, and the nationalist struggles by ethnic minorities against the Austro-Hungarian Empire\u2014developed a more inclusive notion of culture as \"worldview\" (Weltanschauung). According to this school of thought, each ethnic group has a distinct worldview that is incommensurable with the worldviews of other groups. Although more inclusive than earlier views, this approach to culture still allowed for distinctions between \"civilized\" and \"primitive\" or \"tribal\" cultures.\n\nIn 1860, Adolf Bastian (1826\u20131905) argued for \"the psychic unity of mankind.\" He proposed that a scientific comparison of all human societies would reveal that distinct worldviews consisted of the same basic elements. According to Bastian, all human societies share a set of \"elementary ideas\" (Elementargedanken); different cultures, or different \"folk ideas\" (V\u00f6lkergedanken), are local modifications of the elementary ideas. This view paved the way for the modern understanding of culture. Franz Boas (1858\u20131942) was trained in this tradition, and he brought it with him when he left Germany for the United States.\n\nEnglish Romanticism\n\nIn the 19th century, humanists such as English poet and essayist Matthew Arnold (1822\u20131888) used the word \"culture\" to refer to an ideal of individual human refinement, of \"the best that has been thought and said in the world.\" This concept of culture is also comparable to the German concept of bildung: \"...culture being a pursuit of our total perfection by means of getting to know, on all the matters which most concern us, the best which has been thought and said in the world.\"\n\nIn practice, culture referred to an elite ideal and was associated with such activities as art, classical music, and haute cuisine. As these forms were associated with urban life, \"culture\" was identified with \"civilization\" (from lat. civitas, city). Another facet of the Romantic movement was an interest in folklore, which led to identifying a \"culture\" among non-elites. This distinction is often characterized as that between high culture, namely that of the ruling social group, and low culture. In other words, the idea of \"culture\" that developed in Europe during the 18th and early 19th centuries reflected inequalities within European societies.\n\nMatthew Arnold contrasted \"culture\" with anarchy; other Europeans, following philosophers Thomas Hobbes and Jean-Jacques Rousseau, contrasted \"culture\" with \"the state of nature.\" According to Hobbes and Rousseau, the Native Americans who were being conquered by Europeans from the 16th centuries on were living in a state of nature; this opposition was expressed through the contrast between \"civilized\" and \"uncivilized.\" According to this way of thinking, one could classify some countries and nations as more civilized than others and some people as more cultured than others. This contrast led to Herbert Spencer's theory of Social Darwinism and Lewis Henry Morgan's theory of cultural evolution. Just as some critics have argued that the distinction between high and low cultures is an expression of the conflict between European elites and non-elites, other critics have argued that the distinction between civilized and uncivilized people is an expression of the conflict between European colonial powers and their colonial subjects.\n\nOther 19th-century critics, following Rousseau, have accepted this differentiation between higher and lower culture, but have seen the refinement and sophistication of high culture as corrupting and unnatural developments that obscure and distort people's essential nature. These critics considered folk music (as produced by \"the folk,\" i.e., rural, illiterate, peasants) to honestly express a natural way of life, while classical music seemed superficial and decadent. Equally, this view often portrayed indigenous peoples as \"noble savages\" living authentic and unblemished lives, uncomplicated and uncorrupted by the highly stratified capitalist systems of the West.\n\nIn 1870 the anthropologist Edward Tylor (1832\u20131917) applied these ideas of higher versus lower culture to propose a theory of the evolution of religion. According to this theory, religion evolves from more polytheistic to more monotheistic forms. In the process, he redefined culture as a diverse set of activities characteristic of all human societies. This view paved the way for the modern understanding of religion.\n\nAnthropology\n\nAlthough anthropologists worldwide refer to Tylor's definition of culture, in the 20th century \"culture\" emerged as the central and unifying concept of American anthropology, where it most commonly refers to the universal human capacity to classify and encode human experiences symbolically, and to communicate symbolically encoded experiences socially. American anthropology is organized into four fields, each of which plays an important role in research on culture: biological anthropology, linguistic anthropology, cultural anthropology, and in the United States and Canada, archaeology. The term Kulturbrille, or \"culture glasses,\" coined by German American anthropologist Franz Boas, refers to the \"lenses\" through which we see our own countries. Martin Lindstrom asserts that Kulturbrille, which allow us to make sense of the culture we inhabit, also \"can blind us to things outsiders pick up immediately.\"\n\nSociology\n\nThe sociology of culture concerns culture as manifested in society. For sociologist Georg Simmel (1858\u20131918), culture referred to \"the cultivation of individuals through the agency of external forms which have been objectified in the course of history.\" As such, culture in the sociological field can be defined as the ways of thinking, the ways of acting, and the material objects that together shape a people's way of life. Culture can be any of two types, non-material culture or material culture. Non-material culture refers to the non-physical ideas that individuals have about their culture, including values, belief systems, rules, norms, morals, language, organizations, and institutions, while material culture is the physical evidence of a culture in the objects and architecture they make or have made. The term tends to be relevant only in archeological and anthropological studies, but it specifically means all material evidence which can be attributed to culture, past or present.\n\nCultural sociology first emerged in Weimar Germany (1918\u20131933), where sociologists such as Alfred Weber used the term Kultursoziologie (cultural sociology). Cultural sociology was then \"reinvented\" in the English-speaking world as a product of the \"cultural turn\" of the 1960s, which ushered in structuralist and postmodern approaches to social science. This type of cultural sociology may be loosely regarded as an approach incorporating cultural analysis and critical theory. Cultural sociologists tend to reject scientific methods, instead hermeneutically focusing on words, artifacts and symbols. \"Culture\" has since become an important concept across many branches of sociology, including resolutely scientific fields like social stratification and social network analysis. As a result, there has been a recent influx of quantitative sociologists to the field. Thus, there is now a growing group of sociologists of culture who are, confusingly, not cultural sociologists. These scholars reject the abstracted postmodern aspects of cultural sociology, and instead, look for a theoretical backing in the more scientific vein of social psychology and cognitive science.\n\nEarly researchers and development of cultural sociology\nThe sociology of culture grew from the intersection between sociology (as shaped by early theorists like Marx, Durkheim, and Weber) with the growing discipline of anthropology, wherein researchers pioneered ethnographic strategies for describing and analyzing a variety of cultures around the world. Part of the legacy of the early development of the field lingers in the methods (much of cultural, sociological research is qualitative), in the theories (a variety of critical approaches to sociology are central to current research communities), and in the substantive focus of the field. For instance, relationships between popular culture, political control, and social class were early and lasting concerns in the field.\n\nCultural studies\n\nIn the United Kingdom, sociologists and other scholars influenced by Marxism such as Stuart Hall (1932\u20132014) and Raymond Williams (1921\u20131988) developed cultural studies. Following nineteenth-century Romantics, they identified \"culture\" with consumption goods and leisure activities (such as art, music, film, food, sports, and clothing). They saw patterns of consumption and leisure as determined by relations of production, which led them to focus on class relations and the organization of production.\n\nIn the United Kingdom, cultural studies focuses largely on the study of popular culture; that is, on the social meanings of mass-produced consumer and leisure goods. Richard Hoggart coined the term in 1964 when he founded the Birmingham Centre for Contemporary Cultural Studies or CCCS. It has since become strongly associated with Stuart Hall, who succeeded Hoggart as Director. Cultural studies in this sense, then, can be viewed as a limited concentration scoped on the intricacies of consumerism, which belongs to a wider culture sometimes referred to as \"Western civilization\" or \"globalism.\"\n\nFrom the 1970s onward, Stuart Hall's pioneering work, along with that of his colleagues Paul Willis, Dick Hebdige, Tony Jefferson, and Angela McRobbie, created an international intellectual movement. As the field developed, it began to combine political economy, communication, sociology, social theory, literary theory, media theory, film/video studies, cultural anthropology, philosophy, museum studies, and art history to study cultural phenomena or cultural texts. In this field researchers often concentrate on how particular phenomena relate to matters of ideology, nationality, ethnicity, social class, and/or gender. Cultural studies is concerned with the meaning and practices of everyday life. These practices comprise the ways people do particular things (such as watching television or eating out) in a given culture. It also studies the meanings and uses people attribute to various objects and practices. Specifically, culture involves those meanings and practices held independently of reason. Watching television to view a public perspective on a historical event should not be thought of as culture unless referring to the medium of television itself, which may have been selected culturally; however, schoolchildren watching television after school with their friends to \"fit in\" certainly qualifies since there is no grounded reason for one's participation in this practice.\n\nIn the context of cultural studies, the idea of a text includes not only written language, but also films, photographs, fashion or hairstyles: the texts of cultural studies comprise all the meaningful artifacts of culture. Similarly, the discipline widens the concept of \"culture.\" \"Culture\" for a cultural-studies researcher not only includes traditional high culture (the culture of ruling social groups) and popular culture, but also everyday meanings and practices. The last two, in fact, have become the main focus of cultural studies. A further and recent approach is comparative cultural studies, based on the disciplines of comparative literature and cultural studies.\n\nScholars in the United Kingdom and the United States developed somewhat different versions of cultural studies after the late 1970s. The British version of cultural studies had originated in the 1950s and 1960s, mainly under the influence of Richard Hoggart, E.P. Thompson, and Raymond Williams, and later that of Stuart Hall and others at the Centre for Contemporary Cultural Studies at the University of Birmingham. This included overtly political, left-wing views, and criticisms of popular culture as \"capitalist\" mass culture; it absorbed some of the ideas of the Frankfurt School critique of the \"culture industry\" (i.e. mass culture). This emerges in the writings of early British cultural-studies scholars and their influences: see the work of (for example) Raymond Williams, Stuart Hall, Paul Willis, and Paul Gilroy.\n\nIn the United States, Lindlof and Taylor write, \"Cultural studies [were] grounded in a pragmatic, liberal-pluralist tradition.\" The American version of cultural studies initially concerned itself more with understanding the subjective and appropriative side of audience reactions to, and uses of, mass culture; for example, American cultural-studies advocates wrote about the liberatory aspects of fandom. The distinction between American and British strands, however, has faded. Some researchers, especially in early British cultural studies, apply a Marxist model to the field. This strain of thinking has some influence from the Frankfurt School, but especially from the structuralist Marxism of Louis Althusser and others. The main focus of an orthodox Marxist approach concentrates on the production of meaning. This model assumes a mass production of culture and identifies power as residing with those producing cultural artifacts. In a Marxist view, the mode and relations of production form the economic base of society, which constantly interacts and influences superstructures, such as culture. Other approaches to cultural studies, such as feminist cultural studies and later American developments of the field, distance themselves from this view. They criticize the Marxist assumption of a single, dominant meaning, shared by all, for any cultural product. The non-Marxist approaches suggest that different ways of consuming cultural artifacts affect the meaning of the product. This view comes through in the book Doing Cultural Studies: The Story of the Sony Walkman (by Paul du Gay et al.), which seeks to challenge the notion that those who produce commodities control the meanings that people attribute to them. Feminist cultural analyst, theorist, and art historian Griselda Pollock contributed to cultural studies from viewpoints of art history and psychoanalysis. The writer Julia Kristeva is among influential voices at the turn of the century, contributing to cultural studies from the field of art and psychoanalytical French feminism.\n\nPetrakis and Kostis (2013) divide cultural background variables into two main groups:\n\n The first group covers the variables that represent the \"efficiency orientation\" of the societies: performance orientation, future orientation, assertiveness, power distance, and uncertainty avoidance.\n The second covers the variables that represent the \"social orientation\" of societies, i.e., the attitudes and lifestyles of their members. These variables include gender egalitarianism, institutional collectivism, in-group collectivism, and human orientation.\nIn 2016, a new approach to culture was suggested by Rein Raud, who defines culture as the sum of resources available to human beings for making sense of their world and proposes a two-tiered approach, combining the study of texts (all reified meanings in circulation) and cultural practices (all repeatable actions that involve the production, dissemination or transmission of purposes), thus making it possible to re-link anthropological and sociological study of culture with the tradition of textual theory.\n\nPsychology \n\nStarting in the 1990s, psychological research on culture influence began to grow and challenge the universality assumed in general psychology. Culture psychologists began to try to explore the relationship between emotions and culture, and answer whether the human mind is independent from culture. For example, people from collectivistic cultures, such as the Japanese, suppress their positive emotions more than their American counterparts. Culture may affect the way that people experience and express emotions. On the other hand, some researchers try to look for differences between people's personalities across cultures. As different cultures dictate distinctive norms, culture shock is also studied to understand how people react when they are confronted with other cultures. Cognitive tools may not be accessible or they may function differently cross culture. For example, people who are raised in a culture with an abacus are trained with distinctive reasoning style. Cultural lenses may also make people view the same outcome of events differently. Westerners are more motivated by their successes than their failures, while East Asians are better motivated by the avoidance of failure. Culture is important for psychologists to consider when understanding the human mental operation.\n\nProtection of culture \n\nThere are a number of international agreements and national laws relating to the protection of culture and cultural heritage. UNESCO and its partner organizations such as Blue Shield International coordinate international protection and local implementation.\nBasically, the Hague Convention for the Protection of Cultural Property in the Event of Armed Conflict and the UNESCO Convention for the Protection of Cultural Diversity deal with the protection of culture. Article 27 of the Universal Declaration of Human Rights deals with cultural heritage in two ways: it gives people the right to participate in cultural life on the one hand and the right to the protection of their contributions to cultural life on the other.\n\nThe protection of culture and cultural goods is increasingly taking up a large area nationally and internationally. Under international law, the UN and UNESCO try to set up and enforce rules for this. The aim is not to protect a person's property, but rather to preserve the cultural heritage of humanity, especially in the event of war and armed conflict. According to Karl von Habsburg, President of Blue Shield International, the destruction of cultural assets is also part of psychological warfare. The target of the attack is the identity of the opponent, which is why symbolic cultural assets become a main target. It is also intended to affect the particularly sensitive cultural memory, the growing cultural diversity and the economic basis (such as tourism) of a state, region or municipality.\n\nAnother important issue today is the impact of tourism on the various forms of culture. On the one hand, this can be physical impact on individual objects or the destruction caused by increasing environmental pollution and, on the other hand, socio-cultural effects on society.\n\nSee also \n\n Animal culture\n Anthropology\n Cultural area\n Cultural studies\n Cultural tourism\n Culture 21 \u2013 United Nations plan of action\n \n Outline of culture\n Recombinant culture\n Semiotics of culture\n\nReferences\n\nFurther reading\n\nBooks\n \n  \n  \n  \n \n  \n  \n  \n \"Adolf Bastian\", Encyclop\u00e6dia Britannica Online, January 27, 2009\n \n Arnold, Matthew. 1869. Culture and Anarchy. New York: Macmillan. Third edition, 1882, available online. Retrieved: 2006-06-28.\n Bakhtin, M.M. (1981) The Dialogic Imagination: Four Essays. Ed. Michael Holquist. Trans. Caryl Press. .\n Barzilai, Gad. 2003. Communities and Law: Politics and Cultures of Legal Identities University of Michigan Press. \n \n Bourdieu, Pierre. 1977. Outline of a Theory of Practice. Cambridge University Press. \n Michael C. Carhart, The Science of Culture in Enlightenment Germany, Cambridge, Harvard University press, 2007.\n Cohen, Anthony P. 1985. The Symbolic Construction of Community. Routledge: New York,\n Dawkins, R. 1982. The Extended Phenotype: The Long Reach of the Gene. Paperback ed., 1999. Oxford Paperbacks. \n Findley & Rothney. Twentieth-Century World (Houghton Mifflin, 1986)\n Geertz, Clifford. 1973. The Interpretation of Cultures: Selected Essays. New York. .\n \n Goodall, J. 1986. The Chimpanzees of Gombe: Patterns of Behavior. Cambridge, Massachusetts: Belknap Press of Harvard University Press. \n Hoult, T.F., ed. 1969. Dictionary of Modern Sociology. Totowa, New Jersey, United States: Littlefield, Adams & Co.\n Jary, D. and J. Jary. 1991. The HarperCollins Dictionary of Sociology. New York: HarperCollins. \n Keiser, R. Lincoln 1969. The Vice Lords: Warriors of the Streets. Holt, Rinehart, and Winston. .\n Kroeber, A.L. and C. Kluckhohn, 1952. Culture: A Critical Review of Concepts and Definitions. Cambridge, Massachusetts: Peabody Museum\n Kim, Uichol (2001). \"Culture, science and indigenous psychologies: An integrated analysis.\" In D. Matsumoto (Ed.), Handbook of culture and psychology. Oxford: Oxford University Press\n McClenon, James. \"Tylor, Edward B(urnett)\". Encyclopedia of Religion and Society. Ed. William Swatos and Peter Kivisto. Walnut Creek: AltaMira, 1998. 528\u201329.\n Middleton, R. 1990. Studying Popular Music. Philadelphia: Open University Press. .\n O'Neil, D. 2006. Cultural Anthropology Tutorials, Behavioral Sciences Department, Palomar College, San Marco, California. Retrieved: 2006-07-10.\n Reagan, Ronald. \"Final Radio Address to the Nation\", January 14, 1989. Retrieved June 3, 2006.\n Reese, W.L. 1980. Dictionary of Philosophy and Religion: Eastern and Western Thought. New Jersey U.S., Sussex, U.K: Humanities Press.\n \n UNESCO. 2002. Universal Declaration on Cultural Diversity, issued on International Mother Language Day, February 21, 2002. Retrieved: 2006-06-23.\n White, L. 1949. The Science of Culture: A study of man and civilization. New York: Farrar, Straus and Giroux.\n Wilson, Edward O. (1998). Consilience: The Unity of Knowledge. Vintage: New York. .\n Wolfram, Stephen. 2002 A New Kind of Science. Wolfram Media, Inc. .\n\nArticles\n The Meaning of \"Culture\" (2014-12-27), Joshua Rothman, The New Yorker\n\nExternal links\n\n Cultura: International Journal of Philosophy of Culture and Axiology\n What Is Culture?\n\n \nSocial concepts\nSocial constructionism\nMain topic articles",
  "Theatre": "Theatre or theater is a collaborative form of performing art that uses live performers, usually actors or actresses, to present the experience of a real or imagined event before a live audience in a specific place, often a stage. The performers may communicate this experience to the audience through combinations of gesture, speech, song, music, and dance. Elements of art, such as painted scenery and stagecraft such as lighting are used to enhance the physicality, presence and immediacy of the experience. The specific place of the performance is also named by the word \"theatre\" as derived from the Ancient Greek \u03b8\u03ad\u03b1\u03c4\u03c1\u03bf\u03bd (th\u00e9atron, \"a place for viewing\"), itself from \u03b8\u03b5\u03ac\u03bf\u03bc\u03b1\u03b9 (the\u00e1omai, \"to see\", \"to watch\", \"to observe\").\n\nModern Western theatre comes, in large measure, from the theatre of ancient Greece, from which it borrows technical terminology, classification into genres, and many of its themes, stock characters, and plot elements. Theatre artist Patrice Pavis defines theatricality, theatrical language, stage writing and the specificity of theatre as synonymous expressions that differentiate theatre from the other performing arts, literature and the arts in general.\n\nModern theatre includes performances of plays and musical theatre. The art forms of ballet and opera are also theatre and use many conventions such as acting, costumes and staging. They were influential to the development of musical theatre; see those articles for more information.\n\nHistory of theatre\n\nClassical and Hellenistic Greece\n\nThe city-state of Athens is where western theatre originated. It was part of a broader culture of theatricality and performance in classical Greece that included festivals, religious rituals, politics, law, athletics and gymnastics, music, poetry, weddings, funerals, and symposia.\n\nParticipation in the city-state's many festivals\u2014and mandatory attendance at the City Dionysia as an audience member (or even as a participant in the theatrical productions) in particular\u2014was an important part of citizenship. Civic participation also involved the evaluation of the rhetoric of orators evidenced in performances in the law-court or political assembly, both of which were understood as analogous to the theatre and increasingly came to absorb its dramatic vocabulary. The Greeks also developed the concepts of dramatic criticism and theatre architecture. Actors were either amateur or at best semi-professional. The theatre of ancient Greece consisted of three types of drama: tragedy, comedy, and the satyr play.\n\nThe origins of theatre in ancient Greece, according to Aristotle (384\u2013322 BCE), the first theoretician of theatre, are to be found in the festivals that honoured Dionysus. The performances were given in semi-circular auditoria cut into hillsides, capable of seating 10,000\u201320,000 people. The stage consisted of a dancing floor (orchestra), dressing room and scene-building area (skene). Since the words were the most important part, good acoustics and clear delivery were paramount. The actors (always men) wore masks appropriate to the characters they represented, and each might play several parts.\n\nAthenian tragedy\u2014the oldest surviving form of tragedy\u2014is a type of dance-drama that formed an important part of the theatrical culture of the city-state. Having emerged sometime during the 6th century BCE, it flowered during the 5th century BCE (from the end of which it began to spread throughout the Greek world), and continued to be popular until the beginning of the Hellenistic period.\n\nNo tragedies from the 6th century BCE and only 32 of the more than a thousand that were performed in during the 5th century BCE have survived. We have complete texts extant by Aeschylus, Sophocles, and Euripides. The origins of tragedy remain obscure, though by the 5th century BCE it was institutionalised in competitions (agon) held as part of festivities celebrating Dionysus (the god of wine and fertility). As contestants in the City Dionysia's competition (the most prestigious of the festivals to stage drama) playwrights were required to present a tetralogy of plays (though the individual works were not necessarily connected by story or theme), which usually consisted of three tragedies and one satyr play. The performance of tragedies at the City Dionysia may have begun as early as 534 BCE; official records (didaskaliai) begin from 501 BCE, when the satyr play was introduced.\n\nMost Athenian tragedies dramatise events from Greek mythology, though The Persians\u2014which stages the Persian response to news of their military defeat at the Battle of Salamis in 480 BCE\u2014is the notable exception in the surviving drama. When Aeschylus won first prize for it at the City Dionysia in 472 BCE, he had been writing tragedies for more than 25 years, yet its tragic treatment of recent history is the earliest example of drama to survive. More than 130 years later, the philosopher Aristotle analysed 5th-century Athenian tragedy in the oldest surviving work of dramatic theory\u2014his Poetics (c. 335 BCE).\n\nAthenian comedy is conventionally divided into three periods, \"Old Comedy\", \"Middle Comedy\", and \"New Comedy\". Old Comedy survives today largely in the form of the eleven surviving plays of Aristophanes, while Middle Comedy is largely lost (preserved only in relatively short fragments in authors such as Athenaeus of Naucratis). New Comedy is known primarily from the substantial papyrus fragments of Menander. Aristotle defined comedy as a representation of laughable people that involves some kind of blunder or ugliness that does not cause pain or disaster.\n\nIn addition to the categories of comedy and tragedy at the City Dionysia, the festival also included the Satyr Play. Finding its origins in rural, agricultural rituals dedicated to Dionysus, the satyr play eventually found its way to Athens in its most well-known form. Satyr's themselves were tied to the god Dionysus as his loyal woodland  companions, often engaging in drunken revelry and mischief at his side. The satyr play itself was classified as tragicomedy, erring on the side of the more modern burlesque traditions of the early twentieth century. The plotlines of the plays were typically concerned with the dealings of the pantheon of Gods and their involvement in human affairs, backed by the chorus of Satyrs. However, according to Webster, satyr actors did not always perform typical satyr actions and would break from the acting traditions assigned to the character type of a mythical forest creature.\n\nRoman theatre\n\nWestern theatre developed and expanded considerably under the Romans. The Roman historian Livy wrote that the Romans first experienced theatre in the 4th century BCE, with a performance by Etruscan actors. Beacham argues that they had been familiar with \"pre-theatrical practices\" for some time before that recorded contact. The theatre of ancient Rome was a thriving and diverse art form, ranging from festival performances of street theatre, nude dancing, and acrobatics, to the staging of Plautus's broadly appealing situation comedies, to the high-style, verbally elaborate tragedies of Seneca. Although Rome had a native tradition of performance, the Hellenization of Roman culture in the 3rd century BCE had a profound and energizing effect on Roman theatre and encouraged the development of Latin literature of the highest quality for the stage. The only surviving plays from the Roman Empire are ten dramas attributed to Lucius Annaeus Seneca (4 BCE\u201365 CE), the Corduba-born Stoic philosopher and tutor of Nero.\n\nIndian theatre\n\nThe earliest-surviving fragments of Sanskrit drama date from the 1st century CE. The wealth of archeological evidence from earlier periods offers no indication of the existence of a tradition of theatre. The ancient Vedas (hymns from between 1500 and 1000 BCE that are among the earliest examples of literature in the world) contain no hint of it (although a small number are composed in a form of dialogue) and the rituals of the Vedic period do not appear to have developed into theatre. The Mah\u0101bh\u0101\u1e63ya by Pata\u00f1jali contains the earliest reference to what may have been the seeds of Sanskrit drama. This treatise on grammar from 140 BCE provides a feasible date for the beginnings of theatre in India.\n\nThe major source of evidence for Sanskrit theatre is A Treatise on Theatre (N\u0101tya\u015b\u0101stra), a compendium whose date of composition is uncertain (estimates range from 200 BCE to 200 CE) and whose authorship is attributed to Bharata Muni. The Treatise is the most complete work of dramaturgy in the ancient world. It addresses acting, dance, music, dramatic construction, architecture, costuming, make-up, props, the organisation of companies, the audience, competitions, and offers a mythological account of the origin of theatre. In doing so, it provides indications about the nature of actual theatrical practices. Sanskrit theatre was performed on sacred ground by priests who had been trained in the necessary skills (dance, music, and recitation) in a [hereditary process]. Its aim was both to educate and to entertain.\n\nUnder the patronage of royal courts, performers belonged to professional companies that were directed by a stage manager (sutradhara), who may also have acted. This task was thought of as being analogous to that of a puppeteer\u2014the literal meaning of \"sutradhara\" is \"holder of the strings or threads\". The performers were trained rigorously in vocal and physical technique. There were no prohibitions against female performers; companies were all-male, all-female, and of mixed gender. Certain sentiments were considered inappropriate for men to enact, however, and were thought better suited to women. Some performers played characters their own age, while others played ages different from their own (whether younger or older). Of all the elements of theatre, the Treatise gives most attention to acting (abhinaya), which consists of two styles: realistic (lokadharmi) and conventional (natyadharmi), though the major focus is on the latter.\n\nIts drama is regarded as the highest achievement of Sanskrit literature. It utilised stock characters, such as the hero (nayaka), heroine (nayika), or clown (vidusaka). Actors may have specialised in a particular type. K\u0101lid\u0101sa in the 1st century BCE, is arguably considered to be ancient India's greatest Sanskrit dramatist. Three famous romantic plays written by K\u0101lid\u0101sa are the M\u0101lavik\u0101gnimitram (M\u0101lavik\u0101 and Agnimitra), Vikramuurvashiiya (Pertaining to Vikrama and Urvashi), and Abhij\u00f1\u0101na\u015b\u0101kuntala (The Recognition of Shakuntala). The last was inspired by a story in the Mahabharata and is the most famous. It was the first to be translated into English and German. \u015aakuntal\u0101 (in English translation) influenced Goethe's Faust (1808\u20131832).\n\nThe next great Indian dramatist was Bhavabhuti (c. 7th century CE). He is said to have written the following three plays: Malati-Madhava, Mahaviracharita and Uttar Ramacharita. Among these three, the last two cover between them the entire epic of Ramayana. The powerful Indian emperor Harsha (606\u2013648) is credited with having written three plays: the comedy Ratnavali, Priyadarsika, and the Buddhist drama Nagananda.\n\nChinese theatre\n\nThe Tang dynasty is sometimes known as \"The Age of 1000 Entertainments\". During this era, Ming Huang formed an acting school known as The Pear Garden to produce a form of drama that was primarily musical. That is why actors are commonly called \"Children of the Pear Garden.\" During the dynasty of Empress Ling, shadow puppetry first emerged as a recognized form of theatre in China. There were two distinct forms of shadow puppetry, Pekingese (northern) and Cantonese (southern). The two styles were differentiated by the method of making the puppets and the positioning of the rods on the puppets, as opposed to the type of play performed by the puppets. Both styles generally performed plays depicting great adventure and fantasy, rarely was this very stylized form of theatre used for political propaganda.\n\nCantonese shadow puppets were the larger of the two. They were built using thick leather which created more substantial shadows. Symbolic color was also very prevalent; a black face represented honesty, a red one bravery. The rods used to control Cantonese puppets were attached perpendicular to the puppets' heads. Thus, they were not seen by the audience when the shadow was created. Pekingese puppets were more delicate and smaller. They were created out of thin, translucent leather (usually taken from the belly of a donkey). They were painted with vibrant paints, thus they cast a very colorful shadow. The thin rods which controlled their movements were attached to a leather collar at the neck of the puppet. The rods ran parallel to the bodies of the puppet then turned at a ninety degree angle to connect to the neck. While these rods were visible when the shadow was cast, they laid outside the shadow of the puppet; thus they did not interfere with the appearance of the figure. The rods attached at the necks to facilitate the use of multiple heads with one body. When the heads were not being used, they were stored in a muslin book or fabric lined box. The heads were always removed at night. This was in keeping with the old superstition that if left intact, the puppets would come to life at night. Some puppeteers went so far as to store the heads in one book and the bodies in another, to further reduce the possibility of reanimating puppets. Shadow puppetry is said to have reached its highest point of artistic development in the eleventh century before becoming a tool of the government.\n\nIn the Song dynasty, there were many popular plays involving acrobatics and music. These developed in the Yuan dynasty into a more sophisticated form known as zaju, with a four- or five-act structure. Yuan drama spread across China and diversified into numerous regional forms, one of the best known of which is Peking Opera which is still popular today.\n\nXiangsheng is a certain traditional Chinese comedic performance in the forms of monologue or dialogue.\n\nIndonesian theatre\n\nIn Indonesia, theatre performances have become an important part of local culture, theatre performances in Indonesia have been developed for thousands of years. Most of Indonesia's oldest theatre forms are linked directly to local literary traditions (oral and written). The prominent puppet theatres \u2014 wayang golek (wooden rod-puppet play) of the Sundanese and wayang kulit (leather shadow-puppet play) of the Javanese and Balinese\u2014draw much of their repertoire from indigenized versions of the Ramayana and Mahabharata. These tales also provide source material for the wayang wong (human theatre) of Java and Bali, which uses actors. Some wayang golek performances, however, also present Muslim stories, called menak. Wayang is an ancient form of storytelling that renowned for its elaborate puppet/human and complex musical styles. The earliest evidence is from the late 1st millennium CE, in medieval-era texts and archeological sites. The oldest known record that concerns wayang is from the 9th century. Around 840 AD an Old Javanese (Kawi) inscriptions called Jaha Inscriptions issued by Maharaja Sri Lokapalaform Medang Kingdom in Central Java mentions three sorts of performers: atapukan, aringgit, and abanol. Aringgit means Wayang puppet show, Atapukan means Mask dance show, and abanwal means joke art. Ringgit is described in an 11th-century Javanese poem as a leather shadow figure.\n\nPost-classical theatre in the West\nTheatre took on many alternative forms in the West between the 15th and 19th centuries, including commedia dell'arte and melodrama. The general trend was away from the poetic drama of the Greeks and the Renaissance and toward a more naturalistic prose style of dialogue, especially following the Industrial Revolution. \n\nTheatre took a big pause during 1642 and 1660 in England because of the Puritan Interregnum. Viewing theatre as something sinful, the Puritans ordered the closure of London theatres in 1642. This stagnant period ended once Charles II came back to the throne in 1660 in the Restoration. Theatre (among other arts) exploded, with influence from French culture, since Charles had been exiled in France in the years previous to his reign. \n\nIn 1660, two companies were licensed to perform, the Duke's Company and the King's Company. Performances were held in converted buildings, such as Lisle's Tennis Court. The first West End theatre, known as Theatre Royal in Covent Garden, London, was designed by Thomas Killigrew and built on the site of the present Theatre Royal, Drury Lane.\n\nOne of the big changes was the new theatre house. Instead of the type of the Elizabethan era, such as the Globe Theatre, round with no place for the actors to really prep for the next act and with no \"theatre manners\", the theatre house became transformed into a place of refinement, with a stage in front and stadium seating facing it. Since seating was no longer all the way around the stage, it became prioritized\u2014some seats were obviously better than others. The king would have the best seat in the house: the very middle of the theatre, which got the widest view of the stage as well as the best way to see the point of view and vanishing point that the stage was constructed around. Philippe Jacques de Loutherbourg was one of the most influential set designers of the time because of his use of floor space and scenery.\n\nBecause of the turmoil before this time, there was still some controversy about what should and should not be put on the stage. Jeremy Collier, a preacher, was one of the heads in this movement through his piece A Short View of the Immorality and Profaneness of the English Stage. The beliefs in this paper were mainly held by non-theatre goers and the remainder of the Puritans and very religious of the time. The main question was if seeing something immoral on stage affects behavior in the lives of those who watch it, a controversy that is still playing out today.\n\nThe seventeenth century had also introduced women to the stage, which was considered inappropriate earlier. These women were regarded as celebrities (also a newer concept, thanks to ideas on individualism that arose in the wake of Renaissance Humanism), but on the other hand, it was still very new and revolutionary that they were on the stage, and some said they were unladylike, and looked down on them. Charles II did not like young men playing the parts of young women, so he asked that women play their own parts. Because women were allowed on the stage, playwrights had more leeway with plot twists, like women dressing as men, and having narrow escapes from morally sticky situations as forms of comedy.\n\nComedies were full of the young and very much in vogue, with the storyline following their love lives: commonly a young roguish hero professing his love to the chaste and free minded heroine near the end of the play, much like Sheridan's The School for Scandal. Many of the comedies were fashioned after the French tradition, mainly Moli\u00e8re, again hailing back to the French influence brought back by the King and the Royals after their exile. Moli\u00e8re was one of the top comedic playwrights of the time, revolutionizing the way comedy was written and performed by combining Italian commedia dell'arte and neoclassical French comedy to create some of the longest lasting and most influential satiric comedies. Tragedies were similarly victorious in their sense of righting political power, especially poignant because of the recent Restoration of the Crown. They were also imitations of French tragedy, although the French had a larger distinction between comedy and tragedy, whereas the English fudged the lines occasionally and put some comedic parts in their tragedies. Common forms of non-comedic plays were sentimental comedies as well as something that would later be called trag\u00e9die bourgeoise, or domestic tragedy\u2014that is, the tragedy of common life\u2014were more popular in England because they appealed more to English sensibilities.\n\nWhile theatre troupes were formerly often travelling, the idea of the national theatre gained support in the 18th century, inspired by Ludvig Holberg. The major promoter of the idea of the national theatre in Germany, and also of the Sturm und Drang poets, was Abel Seyler, the owner of the Hamburgische Entreprise and the Seyler Theatre Company.\n\nThrough the 19th century, the popular theatrical forms of Romanticism, melodrama, Victorian burlesque and the well-made plays of Scribe and Sardou gave way to the problem plays of Naturalism and Realism; the farces of Feydeau; Wagner's operatic Gesamtkunstwerk; musical theatre (including Gilbert and Sullivan's operas); F. C. Burnand's, W. S. Gilbert's and Oscar Wilde's drawing-room comedies; Symbolism; proto-Expressionism in the late works of August Strindberg and Henrik Ibsen; and Edwardian musical comedy.\n\nThese trends continued through the 20th century in the realism of Stanislavski and Lee Strasberg, the political theatre of Erwin Piscator and Bertolt Brecht, the so-called Theatre of the Absurd of Samuel Beckett and Eug\u00e8ne Ionesco, American and British musicals, the collective creations of companies of actors and directors such as Joan Littlewood's Theatre Workshop, experimental and postmodern theatre of Robert Wilson and Robert Lepage, the postcolonial theatre of August Wilson or Tomson Highway, and Augusto Boal's Theatre of the Oppressed.\n\nEastern theatrical traditions\n\nThe first form of Indian theatre was the Sanskrit theatre. It began after the development of Greek and Roman theatre and before the development of theatre in other parts of Asia. It emerged sometime between the 2nd century BCE and the 1st century CE and flourished between the 1st century CE and the 10th, which was a period of relative peace in the history of India during which hundreds of plays were written. Japanese forms of Kabuki, N\u014d, and Ky\u014dgen developed in the 17th century CE. Theatre in the medieval Islamic world included puppet theatre (which included hand puppets, shadow plays and marionette productions) and live passion plays known as ta'ziya, where actors re-enact episodes from Muslim history. In particular, Shia Islamic plays revolved around the shaheed (martyrdom) of Ali's sons Hasan ibn Ali and Husayn ibn Ali. Secular plays were known as akhraja, recorded in medieval adab literature, though they were less common than puppetry and ta'ziya theatre.\n\nTypes\n\nDrama\n\nDrama is the specific mode of fiction represented in performance. The term comes from a Greek word meaning \"action\", which is derived from the verb \u03b4\u03c1\u03ac\u03c9, dr\u00e1\u014d, \"to do\" or \"to act\". The enactment of drama in theatre, performed by actors on a stage before an audience, presupposes collaborative modes of production and a collective form of reception. The structure of dramatic texts, unlike other forms of literature, is directly influenced by this collaborative production and collective reception. The early modern tragedy Hamlet (1601) by Shakespeare and the classical Athenian tragedy Oedipus Rex (c. 429 BCE) by Sophocles are among the masterpieces of the art of drama. A modern example is Long Day's Journey into Night by Eugene O'Neill (1956).\n\nConsidered as a genre of poetry in general, the dramatic mode has been contrasted with the epic and the lyrical modes ever since Aristotle's Poetics (c. 335 BCE); the earliest work of dramatic theory. The use of \"drama\" in the narrow sense to designate a specific type of play dates from the 19th century. Drama in this sense refers to a play that is neither a comedy nor a tragedy\u2014for example, Zola's Th\u00e9r\u00e8se Raquin (1873) or Chekhov's Ivanov (1887). In Ancient Greece however, the word drama encompassed all theatrical plays, tragic, comic, or anything in between.\n\nDrama is often combined with music and dance: the drama in opera is generally sung throughout; musicals generally include both spoken dialogue and songs; and some forms of drama have incidental music or musical accompaniment underscoring the dialogue (melodrama and Japanese N\u014d, for example). In certain periods of history (the ancient Roman and modern Romantic) some dramas have been written to be read rather than performed. In improvisation, the drama does not pre-exist the moment of performance; performers devise a dramatic script spontaneously before an audience.\n\nMusical theatre\n\nMusic and theatre have had a close relationship since ancient times\u2014Athenian tragedy, for example, was a form of dance-drama that employed a chorus whose parts were sung (to the accompaniment of an aulos\u2014an instrument comparable to the modern clarinet), as were some of the actors' responses and their 'solo songs' (monodies). Modern musical theatre is a form of theatre that also combines music, spoken dialogue, and dance. It emerged from comic opera (especially Gilbert and Sullivan), variety, vaudeville, and music hall genres of the late 19th and early 20th century. After the Edwardian musical comedy that began in the 1890s, the Princess Theatre musicals of the early 20th century, and comedies in the 1920s and 1930s (such as the works of Rodgers and Hammerstein), with Oklahoma! (1943), musicals moved in a more dramatic direction. Famous musicals over the subsequent decades included My Fair Lady (1956), West Side Story (1957), The Fantasticks (1960), Hair (1967), A Chorus Line (1975), Les Mis\u00e9rables (1980), Cats (1981), Into the Woods (1986), and The Phantom of the Opera (1986), as well as more contemporary hits including Rent (1994), The Lion King (1997), Wicked (2003), Hamilton (2015) and Frozen (2018).\n\nMusical theatre may be produced on an intimate scale Off-Broadway, in regional theatres, and elsewhere, but it often includes spectacle. For instance, Broadway and West End musicals often include lavish costumes and sets supported by multimillion-dollar budgets.\n\nComedy\n\nTheatre productions that use humour as a vehicle to tell a story qualify as comedies. This may include a modern farce such as Boeing Boeing or a classical play such as As You Like It. Theatre expressing bleak, controversial or taboo subject matter in a deliberately humorous way is referred to as black comedy. Black Comedy can have several genres like slapstick humour, dark and sarcastic comedy.\n\nTragedy\n\nAristotle's phrase \"several kinds being found in separate parts of the play\" is a reference to the structural origins of drama. In it the spoken parts were written in the Attic dialect whereas the choral (recited or sung) ones in the Doric dialect, these discrepancies reflecting the differing religious origins and poetic metres of the parts that were fused into a new entity, the theatrical drama.\n\nTragedy refers to a specific tradition of drama that has played a unique and important role historically in the self-definition of Western civilisation. That tradition has been multiple and discontinuous, yet the term has often been used to invoke a powerful effect of cultural identity and historical continuity\u2014\"the Greeks and the Elizabethans, in one cultural form; Hellenes and Christians, in a common activity,\" as Raymond Williams puts it. From its obscure origins in the theatres of Athens 2,500 years ago, from which there survives only a fraction of the work of Aeschylus, Sophocles and Euripides, through its singular articulations in the works of Shakespeare, Lope de Vega, Racine, and Schiller, to the more recent naturalistic tragedy of Strindberg, Beckett's modernist meditations on death, loss and suffering, and M\u00fcller's postmodernist reworkings of the tragic canon, tragedy has remained an important site of cultural experimentation, negotiation, struggle, and change. In the wake of Aristotle's Poetics (335 BCE), tragedy has been used to make genre distinctions, whether at the scale of poetry in general (where the tragic divides against epic and lyric) or at the scale of the drama (where tragedy is opposed to comedy). In the modern era, tragedy has also been defined against drama, melodrama, the tragicomic, and epic theatre.\n\nImprovisation\n\nImprovisation has been a consistent feature of theatre, with the Commedia dell'arte in the sixteenth century being recognised as the first improvisation form. Popularized by Nobel Prize Winner Dario Fo and troupes such as the Upright Citizens Brigade improvisational theatre continues to evolve with many different streams and philosophies. Keith Johnstone and Viola Spolin are recognized as the first teachers of improvisation in modern times, with Johnstone exploring improvisation as an alternative to scripted theatre and Spolin and her successors exploring improvisation principally as a tool for developing dramatic work or skills or as a form for situational comedy. Spolin also became interested in how the process of learning improvisation was applicable to the development of human potential. Spolin's son, Paul Sills popularized improvisational theatre as a theatrical art form when he founded, as its first director, The Second City in Chicago.\n\nTheories\n\nHaving been an important part of human culture for more than 2,500 years, theatre has evolved a wide range of different theories and practices. Some are related to political or spiritual ideologies, while others are based purely on \"artistic\" concerns. Some processes focus on a story, some on theatre as event, and some on theatre as catalyst for social change. The classical Greek philosopher Aristotle, in his seminal treatise, Poetics (c. 335 BCE) is the earliest-surviving example and its arguments have influenced theories of theatre ever since. In it, he offers an account of what he calls \"poetry\" (a term which in Greek literally means \"making\" and in this context includes drama\u2014comedy, tragedy, and the satyr play\u2014as well as lyric poetry, epic poetry, and the dithyramb). He examines its \"first principles\" and identifies its genres and basic elements; his analysis of tragedy constitutes the core of the discussion.\n\nAristotle argues that tragedy consists of six qualitative parts, which are (in order of importance) mythos or \"plot\", ethos or \"character\", dianoia or \"thought\", lexis or \"diction\", melos or \"song\", and opsis or \"spectacle\". \"Although Aristotle's Poetics is universally acknowledged in the Western critical tradition\", Marvin Carlson explains, \"almost every detail about his seminal work has aroused divergent opinions.\" Important theatre practitioners of the 20th century include Konstantin Stanislavski, Vsevolod Meyerhold, Jacques Copeau, Edward Gordon Craig, Bertolt Brecht, Antonin Artaud, Joan Littlewood, Peter Brook, Jerzy Grotowski, Augusto Boal, Eugenio Barba, Dario Fo, Viola Spolin, Keith Johnstone and Robert Wilson (director).\n\nStanislavski treated the theatre as an art-form that is autonomous from literature and one in which the playwright's contribution should be respected as that of only one of an ensemble of creative artists. His innovative contribution to modern acting theory has remained at the core of mainstream western performance training for much of the last century. That many of the precepts of his system of actor training seem to be common sense and self-evident testifies to its hegemonic success. Actors frequently employ his basic concepts without knowing they do so. Thanks to its promotion and elaboration by acting teachers who were former students and the many translations of his theoretical writings, Stanislavski's 'system' acquired an unprecedented ability to cross cultural boundaries and developed an international reach, dominating debates about acting in Europe and the United States. Many actors routinely equate his 'system' with the North American Method, although the latter's exclusively psychological techniques contrast sharply with Stanislavski's multivariant, holistic and psychophysical approach, which explores character and action both from the 'inside out' and the 'outside in' and treats the actor's mind and body as parts of a continuum.\n\nTechnical aspects\n\nTheatre presupposes collaborative modes of production and a collective form of reception. The structure of dramatic texts, unlike other forms of literature, is directly influenced by this collaborative production and collective reception. The production of plays usually involves contributions from a playwright, director, a cast of actors, and a technical production team that includes a scenic or set designer, lighting designer, costume designer, sound designer, stage manager, production manager and technical director. Depending on the production, this team may also include a composer, dramaturg, video designer or fight director.\n\nStagecraft is a generic term referring to the technical aspects of theatrical, film, and video production. It includes, but is not limited to, constructing and rigging scenery, hanging and focusing of lighting, design and procurement of costumes, makeup, procurement of props, stage management, and recording and mixing of sound. Stagecraft is distinct from the wider umbrella term of scenography. Considered a technical rather than an artistic field, it relates primarily to the practical implementation of a designer's artistic vision.\n\nIn its most basic form, stagecraft is managed by a single person (often the stage manager of a smaller production) who arranges all scenery, costumes, lighting, and sound, and organizes the cast. At a more professional level, for example in modern Broadway houses, stagecraft is managed by hundreds of skilled carpenters, painters, electricians, stagehands, stitchers, wigmakers, and the like. This modern form of stagecraft is highly technical and specialized: it comprises many sub-disciplines and a vast trove of history and tradition. The majority of stagecraft lies between these two extremes. Regional theatres and larger community theatres will generally have a technical director and a complement of designers, each of whom has a direct hand in their respective designs.\n\nSub-categories and organization\nThere are many modern theatre movements which go about producing theatre in a variety of ways. Theatrical enterprises vary enormously in sophistication and purpose. People who are involved vary from novices and hobbyists (in community theatre) to professionals (in Broadway and similar productions). Theatre can be performed with a shoestring budget or on a grand scale with multimillion-dollar budgets. This diversity manifests in the abundance of theatre sub-categories, which include:\n Broadway theatre and West End theatre\n Street theatre\n Community theatre\n Playback theatre\n Dinner theater\n Fringe theatre\n Off-Broadway and Off West End\n Off-Off-Broadway\n Regional theatre in the United States\n Touring theatre\n Summer stock theatre\n\nRepertory companies\n\nWhile most modern theatre companies rehearse one piece of theatre at a time, perform that piece for a set \"run\", retire the piece, and begin rehearsing a new show, repertory companies rehearse multiple shows at one time. These companies are able to perform these various pieces upon request and often perform works for years before retiring them. Most dance companies operate on this repertory system. The Royal National Theatre in London performs on a repertory system.\n\nRepertory theatre generally involves a group of similarly accomplished actors, and relies more on the reputation of the group than on an individual star actor. It also typically relies less on strict control by a director and less on adherence to theatrical conventions, since actors who have worked together in multiple productions can respond to each other without relying as much on convention or external direction.\n\nProducing vs. presenting\n\nIn order to put on a piece of theatre, both a theatre company and a theatre venue are needed. When a theatre company is the sole company in residence at a theatre venue, this theatre (and its corresponding theatre company) are called a resident theatre or a producing theatre, because the venue produces its own work. Other theatre companies, as well as dance companies, who do not have their own theatre venue, perform at rental theatres or at presenting theatres. Both rental and presenting theatres have no full-time resident companies. They do, however, sometimes have one or more part-time resident companies, in addition to other independent partner companies who arrange to use the space when available. A rental theatre allows the independent companies to seek out the space, while a presenting theatre seeks out the independent companies to support their work by presenting them on their stage.\n\nSome performance groups perform in non-theatrical spaces. Such performances can take place outside or inside, in a non-traditional performance space, and include street theatre, and site-specific theatre. Non-traditional venues can be used to create more immersive or meaningful environments for audiences. They can sometimes be modified more heavily than traditional theatre venues, or can accommodate different kinds of equipment, lighting and sets.\n\nA touring company is an independent theatre or dance company that travels, often internationally, being presented at a different theatre in each city.\n\nUnions\nThere are many theatre unions including: Actors' Equity Association (for actors and stage managers), the Stage Directors and Choreographers Society (SDC), and the International Alliance of Theatrical Stage Employees (IATSE, for designers and technicians). Many theatres require that their staff be members of these organizations.\n\nSee also\n\n Acting\n Antitheatricality\n Black light theatre\n Culinary theatre\n Illusionistic tradition\n List of awards in theatre\n List of playwrights\n List of theatre personnel\n List of theatre festivals\n List of theatre directors\n Lists of theatres\n Performance art\n Puppetry\n Reader's theatre\n Site-specific theatre\n Theatre consultant\n Theatre for development\n Theater (structure)\n Theatre technique\n Theatrical style\n Theatrical troupe\n World Theatre Day\n\nExplanatory notes\n\nCitations\n\nGeneral sources\n\nFurther reading\n\n Aston, Elaine, and George Savona. 1991. Theatre as Sign-System: A Semiotics of Text and Performance. London and New York: Routledge. .\n Benjamin, Walter. 1928. The Origin of German Tragic Drama. Trans. John Osborne. London and New York: Verso, 1998. .\n Brown, John Russell. 1997. What is Theatre?: An Introduction and Exploration. Boston and Oxford: Focal P. .\n Bryant, Jye (2018). Writing & Staging A New Musical: A Handbook. Kindle Direct Publishing. .\n Carnicke, Sharon Marie. 2000. \"Stanislavsky's System: Pathways for the Actor\". In Hodge (2000, 11\u201336).\n Dacre, Kathy, and Paul Fryer, eds. 2008. Stanislavski on Stage. Sidcup, Kent: Stanislavski Centre Rose Bruford College. .\n Deleuze, Gilles and F\u00e9lix Guattari. 1972. Anti-\u0152dipus. Trans. Robert Hurley, Mark Seem and Helen R. Lane. London and New York: Continuum, 2004. Vol. 1. New Accents Ser. London and New York: Methuen. .\n Felski, Rita, ed. 2008. Rethinking Tragedy. Baltimore: Johns Hopkins UP. .\n Harrison, Martin. 1998. The Language of Theatre. London: Routledge. .\n Hartnoll, Phyllis, ed. 1983. The Oxford Companion to the Theatre. 4th ed. Oxford: Oxford UP. .\n Hodge, Alison, ed. 2000. Twentieth-Century Actor Training. London and New York: Routledge. .\n \n Leach, Robert, and Victor Borovsky, eds. 1999. A History of Russian Theatre. Cambridge: Cambridge UP. .\n Meyer-Dinkgr\u00e4fe, Daniel. 2001. Approaches to Acting: Past and Present. London and New York: Continuum. .\n Meyerhold, Vsevolod. 1991. Meyerhold on Theatre. Ed. and trans. Edward Braun. Revised edition. London: Methuen. .\n Mitter, Shomit. 1992. Systems of Rehearsal: Stanislavsky, Brecht, Grotowski and Brook. London and NY: Routledge. .\n O'Brien, Nick. 2010. Stanislavski In Practise. London: Routledge. .\n Rayner, Alice. 1994. To Act, To Do, To Perform: Drama and the Phenomenology of Action. Theater: Theory/Text/Performance Ser. Ann Arbor: University of Michigan Press. .\n Roach, Joseph R. 1985. The Player's Passion: Studies in the Science of Acting. Theater:Theory/Text/Performance Ser. Ann Arbor: U of Michigan P. .\n Speirs, Ronald, trans. 1999. The Birth of Tragedy and Other Writings. By Friedrich Nietzsche. Ed. Raymond Geuss and Ronald Speirs. Cambridge Texts in the History of Philosophy ser. Cambridge: Cambridge UP. .\n\nExternal links\n\n Theatre Archive Project (UK) British Library & University of Sheffield.\n University of Bristol Theatre Collection\n Music Hall and Theatre History of Britain and Ireland\n\n \nStage terminology\nPerforming arts",
  "Architecture": "Architecture (Latin architectura, from the Greek \u1f00\u03c1\u03c7\u03b9\u03c4\u03ad\u03ba\u03c4\u03c9\u03bd arkhitekton \"architect\", from \u1f00\u03c1\u03c7\u03b9- \"chief\" and \u03c4\u03ad\u03ba\u03c4\u03c9\u03bd \"creator\") is both the process and the product of planning, designing, and constructing buildings or other structures. Architectural works, in the material form of buildings, are often perceived as cultural symbols and as works of art. Historical civilizations are often identified with their surviving architectural achievements.\n\nThe practice, which began in the prehistoric era, has been used as a way of expressing culture for civilizations on all seven continents. For this reason, architecture is considered to be a form of art. Texts on architecture have been written since ancient time. The earliest surviving text on architectural theory is the 1st century AD treatise De architectura by the Roman architect Vitruvius, according to whom a good building embodies , and  (durability, utility, and beauty). Centuries later, Leon Battista Alberti developed his ideas further, seeing beauty as an objective quality of buildings to be found in their proportions. Giorgio Vasari wrote Lives of the Most Excellent Painters, Sculptors, and Architects and put forward the idea of style in the Western arts in the 16th century. In the 19th century, Louis Sullivan declared that \"form follows function\". \"Function\" began to replace the classical \"utility\" and was understood to include not only practical but also aesthetic, psychological and cultural dimensions. The idea of sustainable architecture was introduced in the late 20th century.\n\nArchitecture began as rural, oral vernacular architecture that developed from trial and error to successful replication. Ancient urban architecture was preoccupied with building religious structures and buildings symbolizing the political power of rulers until Greek and Roman architecture shifted focus to civic virtues. Indian and Chinese architecture influenced forms all over Asia and Buddhist architecture in particular took diverse local flavors. During the European Middle Ages, pan-European styles of Romanesque and Gothic cathedrals and abbeys emerged while the Renaissance favored Classical forms implemented by architects known by name. Later, the roles of architects and engineers became separated. Modern architecture began after World War I as an avant-garde movement that sought to develop a completely new style appropriate for a new post-war social and economic order focused on meeting the needs of the middle and working classes. Emphasis was put on modern techniques, materials, and simplified geometric forms, paving the way for high-rise superstructures. Many architects became disillusioned with modernism which they perceived as ahistorical and anti-aesthetic, and postmodern and contemporary architecture developed.\n\nOver the years, the field of architectural construction has branched out to include everything from ship design to interior decorating.\n\nDefinitions \n\nArchitecture can mean:\n A general term to describe buildings and other physical structures.\n The art and science of designing buildings and (some) nonbuilding structures.\n The style of design and method of construction of buildings and other physical structures.\n A unifying or coherent form or structure.\n Knowledge of art, science, technology, and humanity.\n The design activity of the architect, from the macro-level (urban design, landscape architecture) to the micro-level (construction details and furniture). The practice of the architect, where architecture means offering or rendering professional services in connection with the design and construction of buildings, or built environments.\n\nTheory of architecture\n\nThe philosophy of architecture is a branch of philosophy of art, dealing with aesthetic value of architecture, its semantics and relations with development of culture. Many philosophers and theoreticians from Plato to Michel Foucault, Gilles Deleuze, Robert Venturi and Ludwig Wittgenstein have concerned themselves with the nature of architecture and whether or not architecture is distinguished from building.\n\nHistoric treatises\nThe earliest surviving written work on the subject of architecture is De architectura by the Roman architect Vitruvius in the early 1st century AD. According to Vitruvius, a good building should satisfy the three principles of , commonly known by the original translation \u2013 firmness, commodity and delight. An equivalent in modern English would be:\n Durability \u2013 a building should stand up robustly and remain in good condition\n Utility \u2013 it should be suitable for the purposes for which it is used\n Beauty \u2013 it should be aesthetically pleasing\nAccording to Vitruvius, the architect should strive to fulfill each of these three attributes as well as possible. Leon Battista Alberti, who elaborates on the ideas of Vitruvius in his treatise, De re aedificatoria, saw beauty primarily as a matter of proportion, although ornament also played a part. For Alberti, the rules of proportion were those that governed the idealised human figure, the Golden mean. The most important aspect of beauty was, therefore, an inherent part of an object, rather than something applied superficially, and was based on universal, recognisable truths. The notion of style in the arts was not developed until the 16th century, with the writing of Giorgio Vasari. By the 18th century, his Lives of the Most Excellent Painters, Sculptors, and Architects had been translated into Italian, French, Spanish, and English.\n\nIn the 16th century, Italian Mannerist architect, painter and theorist Sebastiano Serlio wrote Tutte L\u2019Opere D\u2019Architettura et Prospetiva (Complete Works on Architecture and Perspective). This treatise exerted immense influence throughout Europe, being the first handbook that emphasized the practical rather than the theoretical aspects of architecture, and it was the first to catalog the five orders.\n\nIn the early 19th century, Augustus Welby Northmore Pugin wrote Contrasts (1836) that, as the titled suggested, contrasted the modern, industrial world, which he disparaged, with an idealized image of neo-medieval world. Gothic architecture, Pugin believed, was the only \"true Christian form of architecture.\" The 19th-century English art critic, John Ruskin, in his Seven Lamps of Architecture, published 1849, was much narrower in his view of what constituted architecture. Architecture was the \"art which so disposes and adorns the edifices raised by men ... that the sight of them\" contributes \"to his mental health, power, and pleasure\". For Ruskin, the aesthetic was of overriding significance. His work goes on to state that a building is not truly a work of architecture unless it is in some way \"adorned\". For Ruskin, a well-constructed, well-proportioned, functional building needed string courses or rustication, at the very least.\n\nOn the difference between the ideals of architecture and mere construction, the renowned 20th-century architect Le Corbusier wrote: \"You employ stone, wood, and concrete, and with these materials you build houses and palaces: that is construction. Ingenuity is at work. But suddenly you touch my heart, you do me good. I am happy and I say: This is beautiful. That is Architecture\". Le Corbusier's contemporary Ludwig Mies van der Rohe said \"Architecture starts when you carefully put two bricks together. There it begins.\"\n\nModern concepts\nThe notable 19th-century architect of skyscrapers, Louis Sullivan, promoted an overriding precept to architectural design: \"Form follows function\". While the notion that structural and aesthetic considerations should be entirely subject to functionality was met with both popularity and skepticism, it had the effect of introducing the concept of \"function\" in place of Vitruvius' \"utility\". \"Function\" came to be seen as encompassing all criteria of the use, perception and enjoyment of a building, not only practical but also aesthetic, psychological and cultural.\n\nNunzia Rondanini stated, \"Through its aesthetic dimension architecture goes beyond the functional aspects that it has in common with other human sciences. Through its own particular way of expressing values, architecture can stimulate and influence social life without presuming that, in and of itself, it will promote social development.... To restrict the meaning of (architectural) formalism to art for art's sake is not only reactionary; it can also be a purposeless quest for perfection or originality which degrades form into a mere instrumentality\".\n\nAmong the philosophies that have influenced modern architects and their approach to building design are Rationalism, Empiricism, Structuralism, Poststructuralism, Deconstruction and Phenomenology.\n\nIn the late 20th century a new concept was added to those included in the compass of both structure and function, the consideration of sustainability, hence sustainable architecture. To satisfy the contemporary ethos a building should be constructed in a manner which is environmentally friendly in terms of the production of its materials, its impact upon the natural and built environment of its surrounding area and the demands that it makes upon non-sustainable power sources for heating, cooling, water and waste management, and lighting.\n\nHistory\n\nOrigins and vernacular architecture\n\nBuilding first evolved out of the dynamics between needs (shelter, security, worship, etc.) and means (available building materials and attendant skills). As human cultures developed and knowledge began to be formalized through oral traditions and practices, building became a craft, and \"architecture\" is the name given to the most highly formalized and respected versions of that craft. It is widely assumed that architectural success was the product of a process of trial and error, with progressively less trial and more replication as the results of the process proved increasingly satisfactory. What is termed vernacular architecture continues to be produced in many parts of the world.\n\nPrehistoric architecture\n\nEarly human settlements were mostly rural. Expending economies resulted in the creation of urban areas which in some cases grew and evolved very rapidly, such as that of \u00c7atal H\u00f6y\u00fck in Anatolia and Mohenjo Daro of the Indus Valley Civilization in modern-day Pakistan.\n\nNeolithic settlements and \"cities\" include G\u00f6bekli Tepe and \u00c7atalh\u00f6y\u00fck in Turkey, Jericho in the Levant, Mehrgarh in Pakistan, Knap of Howar and Skara Brae, Orkney Islands, Scotland, and the  Cucuteni-Trypillian culture settlements in Romania, Moldova and Ukraine.\n\nAncient architecture\n\nIn many ancient civilizations such as those of Egypt and Mesopotamia, architecture and urbanism reflected the constant engagement with the divine and the supernatural, and many ancient cultures resorted to monumentality in architecture to represent symbolically the political power of the ruler, the ruling elite, or the state itself.\n\nThe architecture and urbanism of the Classical civilizations such as the Greek and the Roman evolved from civic ideals rather than religious or empirical ones and new building types emerged. Architectural \"style\" developed in the form of the Classical orders. Roman architecture was influenced by Greek architecture as they incorporated many Greek elements into their building practices.\n\nTexts on architecture have been written since ancient time. These texts provided both general advice and specific formal prescriptions or canons. Some examples of canons are found in the writings of the 1st-century BCE Roman Architect Vitruvius. Some of the most important early examples of canonic architecture are religious.\n\nAsian architecture\n\nThe architecture of different parts of Asia developed along different lines from that of Europe; Buddhist, Hindu and Sikh architecture each having different characteristics. Indian and Chinese architecture have had great influence on the surrounding regions, while Japanese architecture has not.  Buddhist architecture, in particular, showed great regional diversity. Hindu temple architecture, which developed from around the 5th century CE, is in theory governed by concepts laid down in the Shastras, and is concerned with expressing the macrocosm and the microcosm. In many Asian countries, pantheistic religion led to architectural forms that were designed specifically to enhance the natural landscape.\n\nIn many parts of Asia, even the grandest houses were relatively lightweight structures mainly using wood until recent times, and there are few survivals of great age.  Buddhism was associated with a move to stone and brick religious structures, probably beginning as rock-cut architecture, which has often survived very well.  \n\nEarly Asian writings on architecture include the Kao Gong Ji of China from the 7th\u20135th centuries BCE; the Shilpa Shastras of ancient India;  Manjusri Vasthu Vidya Sastra of Sri Lanka and Araniko of Nepal .\n\nIslamic architecture\n\nIslamic architecture began in the 7th century CE, incorporating architectural forms from the ancient Middle East and Byzantium, but also developing features to suit the religious and social needs of the society. Examples can be found throughout the Middle East, Turkey, North Africa, the Indian Sub-continent  and in parts of Europe, such as Spain, Albania, and the Balkan States, as the result of the expansion of the Ottoman Empire.\n\nMiddle Ages\n\nIn Europe during the Medieval period, guilds were formed by craftsmen to organize their trades and written contracts have survived, particularly in relation to ecclesiastical buildings. The role of architect was usually one with that of master mason, or Magister lathomorum as they are sometimes described in contemporary documents.\n\nThe major architectural undertakings were the buildings of abbeys and cathedrals. From about 900 CE onward, the movements of both clerics and tradesmen carried architectural knowledge across Europe, resulting in the pan-European styles Romanesque and Gothic.\n\nAlso, a significant part of the Middle Ages architectural heritage is numerous fortifications across the continent. From Balkans to Spain, and from Malta to Estonia, these buildings represent an important part of European heritage.\n\nRenaissance and the architect\n\nIn Renaissance Europe, from about 1400 onwards, there was a revival of Classical learning accompanied by the development of Renaissance humanism, which placed greater emphasis on the role of the individual in society than had been the case during the Medieval period. Buildings were ascribed to specific architects \u2013 Brunelleschi, Alberti, Michelangelo, Palladio \u2013 and the cult of the individual had begun. There was still no dividing line between artist, architect and engineer, or any of the related vocations, and the appellation was often one of regional preference.\n\nA revival of the Classical style in architecture was accompanied by a burgeoning of science and engineering, which affected the proportions and structure of buildings. At this stage, it was still possible for an artist to design a bridge as the level of structural calculations involved was within the scope of the generalist.\n\nEarly modern and the industrial age\n\nWith the emerging knowledge in scientific fields and the rise of new materials and technology, architecture and engineering began to separate, and the architect began to concentrate on aesthetics and the humanist aspects, often at the expense of technical aspects of building design. There was also the rise of the \"gentleman architect\" who usually dealt with wealthy clients and concentrated predominantly on visual qualities derived usually from historical prototypes, typified by the many country houses of Great Britain that were created in the Neo Gothic or Scottish baronial styles.\nFormal architectural training in the 19th century, for example at \u00c9cole des Beaux-Arts in France, gave much emphasis to the production of beautiful drawings and little to context and feasibility.\n\nMeanwhile, the Industrial Revolution laid open the door for mass production and consumption. Aesthetics became a criterion for the middle class as ornamented products, once within the province of expensive craftsmanship, became cheaper under machine production.\n\nVernacular architecture became increasingly ornamental. Housebuilders could use current architectural design in their work by combining features found in pattern books and architectural journals.\n\nModernism\n\nAround the beginning of the 20th century, general dissatisfaction with the emphasis on revivalist architecture and elaborate decoration gave rise to many new lines of thought that served as precursors to Modern architecture. Notable among these is the Deutscher Werkbund, formed in 1907 to produce better quality machine-made objects. The rise of the profession of industrial design is usually placed here. Following this lead, the Bauhaus school, founded in Weimar, Germany in 1919, redefined the architectural bounds prior set throughout history, viewing the creation of a building as the ultimate synthesis\u2014the apex\u2014of art, craft, and technology.\n\nWhen modern architecture was first practised, it was an avant-garde movement with moral, philosophical, and aesthetic underpinnings. Immediately after World War I, pioneering modernist architects sought to develop a completely new style appropriate for a new post-war social and economic order, focused on meeting the needs of the middle and working classes. They rejected the architectural practice of the academic refinement of historical styles which served the rapidly declining aristocratic order. The approach of the Modernist architects was to reduce buildings to pure forms, removing historical references and ornament in favor of functional details. Buildings displayed their functional and structural elements, exposing steel beams and concrete surfaces instead of hiding them behind decorative forms. Architects such as Frank Lloyd Wright developed organic architecture, in which the form was defined by its environment and purpose, with an aim to promote harmony between human habitation and the natural world with prime examples being Robie House and Fallingwater.\n\nArchitects such as Mies van der Rohe, Philip Johnson and Marcel Breuer worked to create beauty based on the inherent qualities of building materials and modern construction techniques, trading traditional historic forms for simplified geometric forms, celebrating the new means and methods made possible by the Industrial Revolution, including steel-frame construction, which gave birth to high-rise superstructures. Fazlur Rahman Khan's development of the tube structure was a technological break-through in building ever higher.  By mid-century, Modernism had morphed into the International Style, an aesthetic epitomized in many ways by the Twin Towers of New York's World Trade Center designed by Minoru Yamasaki.\n\nPostmodernism\n\nMany architects resisted modernism, finding it devoid of the decorative richness of historical styles. As the first generation of modernists began to die after World War II, the second generation of architects including Paul Rudolph, Marcel Breuer, and Eero Saarinen tried to expand the aesthetics of modernism with Brutalism, buildings with expressive sculptural fa\u00e7ades made of unfinished concrete. But an even new younger postwar generation critiqued modernism and Brutalism for being too austere, standardized, monotone, and not taking into account the richness of human experience offered in historical buildings across time and in different places and cultures.\n\nOne such reaction to the cold aesthetic of modernism and Brutalism is the school of metaphoric architecture, which includes such things as biomorphism and zoomorphic architecture, both using nature as the primary source of inspiration and design.  While it is considered by some to be merely an aspect of postmodernism, others consider it to be a school in its own right and a later development of expressionist architecture.\n\nBeginning in the late 1950s and 1960s, architectural phenomenology emerged as an important movement in the early reaction against modernism, with architects like Charles Moore in the United States, Christian Norberg-Schulz in Norway, and Ernesto Nathan Rogers and Vittorio Gregotti, Michele Valori, Bruno Zevi in Italy, who collectively popularized an interest in a new contemporary architecture aimed at expanding human experience using historical buildings as models and precedents. Postmodernism produced a style that combined contemporary building technology and cheap materials, with the aesthetics of older pre-modern and non-modern styles, from high classical architecture to popular or vernacular regional building styles. Robert Venturi famously defined postmodern architecture as a \"decorated shed\" (an ordinary building which is functionally designed inside and embellished on the outside) and upheld it against modernist and brutalist \"ducks\" (buildings with unnecessarily expressive tectonic forms).\n\nArchitecture today\n\nSince the 1980s, as the complexity of buildings began to increase (in terms of structural systems, services, energy and technologies), the field of architecture became multi-disciplinary with specializations for each project type, technological expertise or project delivery methods. Moreover, there has been an increased separation of the 'design' architect  from the 'project' architect who ensures that the project meets the required standards and deals with matters of liability. The preparatory processes for the design of any large building have become increasingly complicated, and require preliminary studies of such matters as durability, sustainability, quality, money, and compliance with local laws. A large structure can no longer be the design of one person but must be the work of many.\nModernism and Postmodernism have been criticised by some members of the architectural profession who feel that successful architecture is not a personal, philosophical, or aesthetic pursuit by individualists; rather it has to consider everyday needs of people and use technology to create liveable environments, with the design process being informed by studies of behavioral, environmental, and social sciences.\n\nEnvironmental sustainability has become a mainstream issue, with a profound effect on the architectural profession. Many developers, those who support the financing of buildings, have become educated to encourage the facilitation of environmentally sustainable design, rather than solutions based primarily on immediate cost. Major examples of this can be found in passive solar building design, greener roof designs, biodegradable materials, and more attention to a structure's energy usage. This major shift in architecture has also changed architecture schools to focus more on the environment. There has been an acceleration in the number of buildings that seek to meet green building sustainable design principles. Sustainable practices that were at the core of vernacular architecture increasingly provide inspiration for environmentally and socially sustainable contemporary techniques. The U.S. Green Building Council's LEED (Leadership in Energy and Environmental Design) rating system has been instrumental in this.\n\nConcurrently, the recent movements of New Urbanism, Metaphoric architecture, Complementary architecture and New Classical architecture promote a sustainable approach towards construction that appreciates and develops smart growth, architectural tradition and classical design. This in contrast to modernist and globally uniform architecture, as well as leaning against solitary housing estates and suburban sprawl. Glass curtain walls, which were the hallmark of the ultra modern urban life in many countries surfaced even in developing countries like Nigeria where international styles had been represented since the mid 20th Century mostly because of the leanings of foreign-trained architects.\n\nOther types of architecture\n\nLandscape architecture\n\nLandscape architecture is the design of outdoor public areas, landmarks, and structures to achieve environmental, social-behavioral, or aesthetic outcomes. It involves the systematic investigation of existing social, ecological, and soil conditions and processes in the landscape, and the design of interventions that will produce the desired outcome.  The scope of the profession includes landscape design; site planning; stormwater management; environmental restoration; parks and recreation planning; visual resource management; green infrastructure planning and provision; and private estate and residence landscape master planning and design; all at varying scales of design, planning and management. A practitioner in the profession of landscape architecture is called a landscape architect.\n\nInterior architecture\n\nInterior architecture is the design of a space which has been created by structural boundaries and the human interaction within these boundaries.  It can also be the initial design and plan for use, then later redesigned to accommodate a changed purpose, or a significantly revised design for adaptive reuse of the building shell. The latter is often part of sustainable architecture practices, conserving resources through \"recycling\" a structure by adaptive redesign.  Generally referred to as the spatial art of environmental design, form and practice, interior architecture is the process through which the interiors of buildings are designed, concerned with all aspects of the human uses of structural spaces.  Put simply, interior architecture is the design of an interior in architectural terms.\n\nNaval architecture\n\nNaval architecture, also known as naval engineering, is an engineering discipline dealing with the engineering design process, shipbuilding, maintenance, and operation of marine vessels and structures. Naval architecture involves basic and applied research, design, development, design evaluation and calculations during all stages of the life of a marine vehicle. Preliminary design of the vessel, its detailed design, construction, trials, operation and maintenance, launching and dry-docking are the main activities involved. Ship design calculations are also required for ships being modified (by means of conversion, rebuilding, modernization, or repair). Naval architecture also involves the formulation of safety regulations and damage control rules and the approval and certification of ship designs to meet statutory and non-statutory requirements.\n\nUrban design\n\nUrban design is the process of designing and shaping the physical features of cities, towns, and villages. In contrast to architecture, which focuses on the design of individual buildings, urban design deals with the larger scale of groups of buildings, streets and public spaces, whole neighborhoods and districts, and entire cities, with the goal of making urban areas functional, attractive, and sustainable.\n\nUrban design is an interdisciplinary field that utilizes elements of many built environment professions, including landscape architecture, urban planning, architecture, civil engineering and municipal engineering. It is common for professionals in all these disciplines to practice urban design. In more recent times different sub-subfields of urban design have emerged such as strategic urban design, landscape urbanism, water-sensitive urban design, and sustainable urbanism.\n\nMetaphorical \"architectures\"\n\"Architecture\" is used as a metaphor for many modern techniques or fields for structuring abstractions.  These include:\n Computer architecture, a set of rules and methods that describe the functionality, organization, and implementation of computer systems, with software architecture, hardware architecture and network architecture covering more specific aspects. \n Business architecture, defined as \"a blueprint of the enterprise that provides a common understanding of the organization and is used to align strategic objectives and tactical demands\",  Enterprise architecture is another term.\nCognitive architecture theories about the structure of the human mind\nSystem architecture a conceptual model that defines the structure, behavior, and more views of any type of system.\n\nSeismic architecture\n\nThe term 'seismic architecture' or 'earthquake architecture' was first introduced in 1985 by Robert Reitherman. The phrase \u201cearthquake architecture\u201d is used to describe a degree of architectural expression of earthquake resistance or implication of architectural configuration, form or style in earthquake resistance. It is also used to describe buildings in which seismic design considerations impacted its architecture. It may be considered a new aesthetic approach in designing structures in seismic prone areas.  The wide breadth of expressive possibilities ranges from metaphorical uses of seismic issues, to the more straightforward exposure of seismic\ntechnology. While outcomes of an earthquake architecture can be very diverse in their physical manifestations, architectural expression of seismic principles can also take many forms and levels of sophistication.\n\nSee also\n\n Architectural engineering\n Architectural technology\n Index of architecture articles\n Outline of architecture\n Philosophy of architecture\n Reverse architecture\n Timeline of architecture\n\nNotes\n\nReferences\n\nExternal links\n\n World Architecture Community\n Architecture.com, published by Royal Institute of British Architects\n Architectural centers and museums in the world, list of links from the UIA\n American Institute of Architects\n Glossary of Architectural Terms  \n Cities and Buildings Database \u2013 Collection of digitized images of buildings and cities drawn from across time and throughout the world from the University of Washington Library\n \"Architecture and Power\", BBC Radio 4 discussion with Adrian Tinniswood, Gillian Darley and Gavin Stamp (In Our Time, Oct. 31, 2002)\n\n \nArchitectural design",
  "Linguistics": "Linguistics is the scientific study of human language, meaning that it is a comprehensive, systematic, objective, and precise study of language. Linguistics encompasses the analysis of every aspect of language, as well as the methods for studying and modelling them.\n\nThe traditional areas of linguistic analysis include phonetics, phonology, morphology, syntax, semantics, and pragmatics. Each of these areas roughly corresponds to phenomena found in human linguistic systems: sounds (and gesture, in the case of signed languages), minimal units (phonemes, words, morphemes), phrases and sentences, and meaning and its use.\n\nLinguistics studies these phenomena in diverse ways and from various perspectives. Theoretical linguistics (including traditional descriptive linguistics) is concerned with building models of these systems, their parts (ontologies), and their combinatorics. Psycholinguistics builds theories of the processing and production of all these phenomena. These phenomena may be studied synchronically or diachronically (through history), in monolinguals or polyglots, in children or adults, as they are acquired or statically, as abstract objects or as embodied cognitive structures, using texts (corpora) or through experimental elicitation, by gathering data mechanically, through fieldwork, or through introspective judgment tasks. Computational linguistics implements theoretical constructs to parse or produce natural language or homologues. Neurolinguistics investigates linguistic phenomena by experiments on actual brain responses involving linguistic stimuli.\n\nLinguistics is related to philosophy of language, stylistics and rhetorics, semiotics, lexicography, and translation.  Data collection is the beginning steps in understanding and describing any language.  While this process is very time consuming it is critical to preform each of the hypotheses in order to maintain accuracy of elicitation.\n\nMajor subdisciplines\n\nHistorical linguistics \n\nHistorical linguistics is the study of language changes in history, particularly with regard to a specific language or a group of languages. Western trends in historical linguistics date back to roughly the late 18th century, when the discipline grew out of philology (the study of ancient texts and antique documents).\n\nHistorical linguistics emerged as one of the first few sub-disciplines in the field, and was most widely practiced during the late 19th century. Despite a shift in focus in the twentieth century towards formalism and generative grammar, which studies the universal properties of language, historical research today still remains a significant field of linguistic inquiry. Subfields of the discipline include language change and grammaticalisation.\n\nHistorical linguistics studies language change either diachronically (through a comparison of different time periods in the past and present) or in a synchronic manner (by observing developments between different variations that exist within the current linguistic stage of a language).\n\nAt first, historical linguistics served as the cornerstone of comparative linguistics, which involves a study of the relationship between different languages. During this time, scholars of historical linguistics were only concerned with creating different categories of language families, and reconstructing prehistoric proto languages by using the comparative method and the method of internal reconstruction. Internal reconstruction is the method by which an element that contains a certain meaning is re-used in different contexts or environments where there is a variation in either sound or analogy.\n\nThe reason for this had been to describe well-known Indo-European languages, many of which used to have long written histories. Scholars of historical linguistics also studied Uralic languages, another European language family for which very little written material existed back then. After this, there was significant work that followed on the corpora of other languages too, such as that of the Austronesian languages as well as of Native American language families.\n\nThe above approach of comparativism in linguistics is now, however, only a small part of the much broader discipline called historical linguistics. The comparative study of specific Indo-European languages is considered a highly specialised field today, while comparative research is carried out over the subsequent internal developments in a language. In particular, it is carried out over the development of modern standard varieties of languages, or over the development of a language from its standardised form to its varieties.\n\nFor instance, some scholars also undertook a study attempting to establish super-families, linking, for example, Indo-European, Uralic, and other language families to Nostratic. While these attempts are still not widely accepted as credible methods, they provide necessary information to establish relatedness in language change, something that is not easily available as the depth of time increases. The time-depth of linguistic methods is generally limited, due to the occurrence of chance word resemblances and variations between language groups, but a limit of around 10,000 years is often assumed for the functional purpose of conducting research. Difficulty also exists in the dating of various proto languages. Even though several methods are available, only approximate results can be obtained in terms of arriving at dates for these languages.\n\nToday, with a subsequent re-development of grammatical studies, historical linguistics studies the change in language on a relational basis between dialect to dialect during one period, as well as between those in the past and the present period, and looks at evolution and shifts taking place morphologically, syntactically, as well as phonetically.\n\nSyntax and morphology\n\nSyntax and morphology are branches of linguistics concerned with the order and structure of meaningful linguistic units such as words and morphemes. Syntacticians study the rules and constraints that govern how speakers of a language can organize words into sentences. Morphologists study similar rules for the order of morphemes\u2014sub-word units such as prefixes and suffixes\u2014and how they may be combined to form words.\n\nWhile words, along with clitics, are generally accepted as being the smallest units of syntax, in most languages, if not all, many words can be related to other words by rules that collectively describe the grammar for that language. For example, English speakers recognize that the words dog and dogs are closely related, differentiated only by the plurality morpheme \"-s\", only found bound to noun phrases. Speakers of English, a fusional language, recognize these relations from their innate knowledge of English's rules of word formation. They infer intuitively that dog is to dogs as cat is to cats; and, in similar fashion, dog is to dog catcher as dish is to dishwasher. By contrast, Classical Chinese has very little morphology, using almost exclusively unbound morphemes (\"free\" morphemes) and depending on word order to convey meaning. (Most words in modern Standard Chinese [\"Mandarin\"], however, are compounds and most roots are bound.) These are understood as grammars that represent the morphology of the language. The rules understood by a speaker reflect specific patterns or regularities in the way words are formed from smaller units in the language they are using, and how those smaller units interact in speech. In this way, morphology is the branch of linguistics that studies patterns of word formation within and across languages and attempts to formulate rules that model the knowledge of the speakers of those languages.\n\nPhonological and orthographic modifications between a base word and its origin may be partial to literacy skills. Studies have indicated that the presence of modification in phonology and orthography makes morphologically complex words harder to understand and that the absence of modification between a base word and its origin makes morphologically complex words easier to understand. Morphologically complex words are easier to comprehend when they include a base word.\n\nPolysynthetic languages, such as Chukchi, have words composed of many morphemes. The Chukchi word \"t\u0259mey\u014b\u0259levtp\u0259\u03b3t\u0259rk\u0259n\", for example, meaning \"I have a fierce headache\", is composed of eight morphemes t-\u0259-mey\u014b-\u0259-levt-p\u0259\u03b3t-\u0259-rk\u0259n that may be glossed. The morphology of such languages allows for each consonant and vowel to be understood as morphemes, while the grammar of the language indicates the usage and understanding of each morpheme.\n\nThe discipline that deals specifically with the sound changes occurring within morphemes is morphophonology.\n\nSemantics and pragmatics \n\nSemantics and pragmatics are branches of linguistics concerned with meaning. These subfields have traditionally been divided according to aspects of meaning thought to arise from the grammar versus linguistic and social context. Semantics in this conception is concerned with grammatical and lexical meanings and pragmatics concerned with meaning in context. The framework of formal semantics studies the denotations of sentences and the way they are composed from the meanings of their constituent expressions. Formal semantics draws heavily on philosophy of language and uses formal tools from logic and computer science. Cognitive semantics ties linguistic meaning to general aspects of cognition, drawing on ideas from cognitive science such as prototype theory.\n\nPragmatics encompasses phenomena such as speech acts, implicature, and talk in interaction. Unlike semantics, which examines meaning that is conventional or \"coded\" in a given language, pragmatics studies how the transmission of meaning depends not only on structural and linguistic knowledge (grammar, lexicon, etc.) of the speaker and listener but also on the context of the utterance, any pre-existing knowledge about those involved, the inferred intent of the speaker, and other factors. In that respect, pragmatics explains how language users are able to overcome apparent ambiguity since meaning relies on the manner, place, time, etc. of an utterance.\n\nPhonetics and phonology \n\nPhonetics and phonology are branches of linguistics concerned with sounds (or the equivalent aspects of sign languages). Phonetics is largely concerned with the physical aspects of sounds such as their articulation, acoustics, production, and perception. Phonology is concerned with the linguistic abstractions and categorizations of sounds.\n\nTypology\n\nLanguage varieties \n\nLanguages exist on a wide continuum of conventionalization with blurry divisions between concepts such as dialects and languages. Languages can undergo internal changes which lead to the development of subvarieties such as linguistic registers, accents, and dialects. Similarly, languages can undergo changes caused by contact with speakers of other languages, and new language varieties may be born from these contact situations through the process of language genesis.\n\nContact varieties \n\nContact varieties such as pidgins and creoles are language varieties that often arise in situations of sustained contact between communities that speak different languages. Pidgins are language varieties with limited conventionalization where ideas are conveyed through simplified grammars that may grow more complex as linguistic contact continues. Creole languages are language varieties similar to pidgins but with greater conventionalization and stability. As children grow up in contact situations, they may learn a local pidgin as their native language. Through this process of acquisition and transmission, new grammatical features and lexical items are created and introduced to fill gaps in the pidgin eventually developing into a complete language.\n\nNot all language contact situations result in the development of a pidgin or creole, and researchers have studied the features of contact situations that make contact varieties more likely to develop. Often these varieties arise in situations of colonization and enslavement, where power imbalances prevent the contact groups from learning the other's language but sustained contact is nevertheless maintained. The subjugated language in the power relationship is the substrate language, while the dominant language serves as the superstrate. Often the words and lexicon of a contact variety come from the superstrate, making it the lexifier, while grammatical structures come from the substrate, but this is not always the case.\n\nDialect \nA dialect is a variety of language that is characteristic of a particular group among the language's speakers. The group of people who are the speakers of a dialect are usually bound to each other by social identity. This is what differentiates a dialect from a register or a discourse, where in the latter case, cultural identity does not always play a role. Dialects are speech varieties that have their own grammatical and phonological rules, linguistic features, and stylistic aspects, but have not been given an official status as a language. Dialects often move on to gain the status of a language due to political and social reasons. Other times, dialects remain marginalized, particularly when they are associated with marginalized social groups. Differentiation amongst dialects (and subsequently, languages) is based upon the use of grammatical rules, syntactic rules, and stylistic features, though not always on lexical use or vocabulary. The popular saying that \"a language is a dialect with an army and navy\" is attributed as a definition formulated by Max Weinreich.\n\nStandard language \n\nWhen a dialect is documented sufficiently through the linguistic description of its grammar, which has emerged through the consensual laws from within its community, it gains political and national recognition through a country or region's policies. That is the stage when a language is considered a standard variety, one whose grammatical laws have now stabilised from within the consent of speech community participants, after sufficient evolution, improvisation, correction, and growth. The English language, besides perhaps the French language, may be examples of languages that have arrived at a stage where they are said to have become standard varieties.\n\nRelativity \nAs constructed popularly through the Sapir\u2013Whorf hypothesis, relativists believe that the structure of a particular language is capable of influencing the cognitive patterns through which a person shapes his or her world view. Universalists believe that there are commonalities between human perception as there is in the human capacity for language, while relativists believe that this varies from language to language and person to person. While the Sapir\u2013Whorf hypothesis is an elaboration of this idea expressed through the writings of American linguists Edward Sapir and Benjamin Lee Whorf, it was Sapir's student Harry Hoijer who termed it thus. The 20th century German linguist Leo Weisgerber also wrote extensively about the theory of relativity. Relativists argue for the case of differentiation at the level of cognition and in semantic domains. The emergence of cognitive linguistics in the 1980s also revived an interest in linguistic relativity. Thinkers like George Lakoff have argued that language reflects different cultural metaphors, while the French philosopher of language Jacques Derrida's writings, especially about deconstruction, have been seen to be closely associated with the relativist movement in linguistics, for which he was heavily criticized in the media at the time of his death.\n\nStructures \n\nLinguistic structures are pairings of meaning and form. Any particular pairing of meaning and form is a Saussurean sign.  For instance, the meaning \"cat\" is represented worldwide with a wide variety of different sound patterns (in oral languages), movements of the hands and face (in sign languages), and written symbols (in written languages). Linguistic patterns have proven their importance for the knowledge engineering field especially with the ever-increasing amount of available data.\n\nLinguists focusing on structure attempt to understand the rules regarding language use that native speakers know (not always consciously).  All linguistic structures can be broken down into component parts that are combined according to (sub)conscious rules, over multiple levels of analysis.  For instance, consider the structure of the word \"tenth\" on two different levels of analysis.  On the level of internal word structure (known as morphology), the word \"tenth\" is made up of one linguistic form indicating a number and another form indicating ordinality.  The rule governing the combination of these forms ensures that the ordinality marker \"th\" follows the number \"ten.\"  On the level of sound structure (known as phonology), structural analysis shows that the \"n\" sound in \"tenth\" is made differently from the \"n\" sound in \"ten\" spoken alone.  Although most speakers of English are consciously aware of the rules governing internal structure of the word pieces of \"tenth\", they are less often aware of the rule governing its sound structure.  Linguists focused on structure find and analyze rules such as these, which govern how native speakers use language.\n\nGrammar \nGrammar is a system of rules which governs the production and use of utterances in a given language. These rules apply to sound as well as meaning, and include componential subsets of rules, such as those pertaining to phonology (the organisation of phonetic sound systems), morphology (the formation and composition of words), and syntax (the formation and composition of phrases and sentences). Modern frameworks that deal with the principles of grammar include structural and functional linguistics, and generative linguistics.\n\nSub-fields that focus on a grammatical study of language include the following:\n Phonetics, the study of the physical properties of speech sound production and perception, and delves into their acoustic and articulatory properties\n Phonology, the study of sounds as abstract elements in the speaker's mind that distinguish meaning (phonemes)\n Morphology, the study of morphemes, or the internal structures of words and how they can be modified\n Syntax, the study of how words combine to form grammatical phrases and sentences\n Semantics, the study of lexical and grammatical aspects of meaning\n Pragmatics, the study of how utterances are used in communicative acts, and the role played by situational context and non-linguistic knowledge in the transmission of meaning\n Discourse analysis, the analysis of language use in texts (spoken, written, or signed)\n Stylistics, the study of linguistic factors (rhetoric, diction, stress) that place a discourse in context\n Semiotics, the study of signs and sign processes (semiosis), indication, designation, likeness, analogy, metaphor, symbolism, signification, and communication\n\nDiscourse \nDiscourse is language as social practice (Baynham, 1995) and is a multilayered concept.  As a social practice, discourse embodies different ideologies through written and spoken texts. Discourse analysis can examine or expose these ideologies.  Discourse influences genre, which is chosen in response to different situations and finally, at micro level, discourse influences language as text (spoken or written) at the phonological or lexico-grammatical level. Grammar and discourse are linked as parts of a system.  A particular discourse becomes a language variety when it is used in this way for a particular purpose, and is referred to as a register. There may be certain lexical additions (new words) that are brought into play because of the expertise of the community of people within a certain domain of specialization. Registers and discourses therefore differentiate themselves through the use of vocabulary, and at times through the use of style too. People in the medical fraternity, for example, may use some medical terminology in their communication that is specialized to the field of medicine. This is often referred to as being part of the \"medical discourse\", and so on.\n\nLexicon \nThe lexicon is a catalogue of words and terms that are stored in a speaker's mind. The lexicon consists of words and bound morphemes, which are parts of words that can't stand alone, like affixes. In some analyses, compound words and certain classes of idiomatic expressions and other collocations are also considered to be part of the lexicon. Dictionaries represent attempts at listing, in alphabetical order, the lexicon of a given language; usually, however, bound morphemes are not included. Lexicography, closely linked with the domain of semantics, is the science of mapping the words into an encyclopedia or a dictionary. The creation and addition of new words (into the lexicon) is called coining or neologization, and the new words are called neologisms.\n\nIt is often believed that a speaker's capacity for language lies in the quantity of words stored in the lexicon. However, this is often considered a myth by linguists. The capacity for the use of language is considered by many linguists to lie primarily in the domain of grammar, and to be linked with competence, rather than with the growth of vocabulary. Even a very small lexicon is theoretically capable of producing an infinite number of sentences.\n\nStyle \nStylistics also involves the study of written, signed, or spoken discourse through varying speech communities, genres, and editorial or narrative formats in the mass media. It involves the study and interpretation of texts for aspects of their linguistic and tonal style. Stylistic analysis entails the analysis of description of particular dialects and registers used by speech communities. Stylistic features include rhetoric, diction, stress, satire, irony, dialogue, and other forms of phonetic variations. Stylistic analysis can also include the study of language in canonical works of literature, popular fiction, news, advertisements, and other forms of communication in popular culture as well. It is usually seen as a variation in communication that changes from speaker to speaker and community to community. In short, Stylistics is the interpretation of text.\n\nIn the 1960s, Jacques Derrida, for instance, further distinguished between speech and writing, by proposing that written language be studied as a linguistic medium of communication in itself. Palaeography is therefore the discipline that studies the evolution of written scripts (as signs and symbols) in language. The formal study of language also led to the growth of fields like psycholinguistics, which explores the representation and function of language in the mind; neurolinguistics, which studies language processing in the brain; biolinguistics, which studies the biology and evolution of language; and language acquisition, which investigates how children and adults acquire the knowledge of one or more languages.\n\nApproaches\n\nHumanistic \nThe fundamental principle of humanistic linguistics is that language is an invention created by people. A semiotic tradition of linguistic research considers language a sign system which arises from the interaction of meaning and form. The organisation of linguistic levels is considered computational. Linguistics is essentially seen as relating to social and cultural studies because different languages are shaped in social interaction by the speech community. Frameworks representing the humanistic view of language include structural linguistics, among others.\n\nStructural analysis means dissecting each linguistic level: phonetic, morphological, syntactic, and discourse, to the smallest units. These are collected into inventories (e.g. phoneme, morpheme, lexical classes, phrase types) to study their interconnectedness within a hierarchy of structures and layers. Functional analysis adds to structural analysis the assignment of semantic and other functional roles that each unit may have. For example, a noun phrase may function as the subject or object of the sentence; or the agent or patient.\n\nFunctional linguistics, or functional grammar, is a branch of structural linguistics. In the humanistic reference, the terms structuralism and functionalism are related to their meaning in other human sciences. The difference between formal and functional structuralism lies in the way that the two approaches explain why languages have the properties they have. Functional explanation entails the idea that language is a tool for communication, or that communication is the primary function of language. Linguistic forms are consequently explained by an appeal to their functional value, or usefulness. Other structuralist approaches take the perspective that form follows from the inner mechanisms of the bilateral and multilayered language system.\n\nBiological \n\nApproaches such as cognitive linguistics and generative grammar study linguistic cognition with a view towards uncovering the biological underpinnings of language. In Generative Grammar, these underpinning are understood as including innate domain-specific grammatical knowledge. Thus, one of the central concerns of the approach is to discover what aspects of linguistic knowledge are innate and which are not.\n\nCognitive Linguistics, in contrast, rejects the notion of innate grammar, and studies how the human mind creates linguistic constructions from event schemas, and the impact of cognitive constraints and biases on human language. Similarly to neuro-linguistic programming, language is approached via the senses.\n\nA closely related approach is evolutionary linguistics which includes the study of linguistic units as cultural replicators. It is possible to study how language replicates and adapts to the mind of the individual or the speech community. Construction grammar is a framework which applies the meme concept to the study of syntax.\n\nThe generative versus evolutionary approach are sometimes called formalism and functionalism, respectively. This reference is however different from the use of the terms in human sciences.\n\nMethodology \n\nLinguistics is primarily descriptive. Linguists describe and explain features of language without making subjective judgments on whether a particular feature or usage is \"good\" or \"bad\". This is analogous to practice in other sciences: a zoologist studies the animal kingdom without making subjective judgments on whether a particular species is \"better\" or \"worse\" than another.\n\nPrescription, on the other hand, is an attempt to promote particular linguistic usages over others, often favouring a particular dialect or \"acrolect\". This may have the aim of establishing a linguistic standard, which can aid communication over large geographical areas. It may also, however, be an attempt by speakers of one language or dialect to exert influence over speakers of other languages or dialects (see Linguistic imperialism). An extreme version of prescriptivism can be found among censors, who attempt to eradicate words and structures that they consider to be destructive to society. Prescription, however, may be practised appropriately in language instruction, like in ELT, where certain fundamental grammatical rules and lexical items need to be introduced to a second-language speaker who is attempting to acquire the language.\n\nSources \nMost contemporary linguists work under the assumption that spoken data and signed data are more fundamental than written data. This is because\n Speech appears to be universal to all human beings capable of producing and perceiving it, while there have been many cultures and speech communities that lack written communication;\n Features appear in speech which aren't always recorded in writing, including phonological rules, sound changes, and speech errors;\n All natural writing systems reflect a spoken language (or potentially a signed one), even with pictographic scripts like Dongba writing Naxi homophones with the same pictogram, and text in writing systems used for two languages changing to fit the spoken language being recorded;\n Speech evolved before human beings invented writing;\n Individuals learn to speak and process spoken language more easily and earlier than they do with writing.\n\nNonetheless, linguists agree that the study of written language can be worthwhile and valuable. For research that relies on corpus linguistics and computational linguistics, written language is often much more convenient for processing large amounts of linguistic data. Large corpora of spoken language are difficult to create and hard to find, and are typically transcribed and written. In addition, linguists have turned to text-based discourse occurring in various formats of computer-mediated communication as a viable site for linguistic inquiry.\n\nThe study of writing systems themselves, graphemics, is, in any case, considered a branch of linguistics.\n\nAnalysis \nBefore the 20th century, linguists analysed language on a diachronic plane, which was historical in focus. This meant that they would compare linguistic features and try to analyse language from the point of view of how it had changed between then and later. However, with the rise of Saussurean linguistics in the 20th century, the focus shifted to a more synchronic approach, where the study was geared towards analysis and comparison between different language variations, which existed at the same given point of time.\n\nAt another level, the syntagmatic plane of linguistic analysis entails the comparison between the way words are sequenced, within the syntax of a sentence. For example, the article \"the\" is followed by a noun, because of the syntagmatic relation between the words. The paradigmatic plane on the other hand, focuses on an analysis that is based on the paradigms or concepts that are embedded in a given text. In this case, words of the same type or class may be replaced in the text with each other to achieve the same conceptual understanding.\n\nHistory \n\nThe earliest activities in the description of language have been attributed to the 6th-century-BC Indian grammarian P\u0101\u1e47ini who wrote a formal description of the Sanskrit language in his . Today, modern-day theories on grammar employ many of the principles that were laid down then.\n\nNomenclature \nBefore the 20th century, the term philology, first attested in 1716, was commonly used to refer to the study of language, which was then predominantly historical in focus. Since Ferdinand de Saussure's insistence on the importance of synchronic analysis, however, this focus has shifted and the term philology is now generally used for the \"study of a language's grammar, history, and literary tradition\", especially in the United States (where philology has never been very popularly considered as the \"science of language\").\n\nAlthough the term linguist in the sense of \"a student of language\" dates from 1641, the term linguistics is first attested in 1847. It is now the usual term in English for the scientific study of language, though linguistic science is sometimes used.\n\nLinguistics is a multi-disciplinary field of research that combines tools from natural sciences, social sciences, formal sciences, and the humanities. Many linguists, such as David Crystal, conceptualize the field as being primarily scientific.  The term linguist applies to someone who studies language or is a researcher within the field, or to someone who uses the tools of the discipline to describe and analyse specific languages.\n\nEarly grammarians \n\nThe formal study of language began in India with P\u0101\u1e47ini, the 6th century BC grammarian who formulated 3,959 rules of Sanskrit morphology. P\u0101\u1e47ini's systematic classification of the sounds of Sanskrit into consonants and vowels, and word classes, such as nouns and verbs, was the first known instance of its kind. In the Middle East, Sibawayh, a Persian, made a detailed description of Arabic in AD 760 in his monumental work, Al-kitab fii an-na\u0127w (, The Book on Grammar), the first known author to distinguish between sounds and phonemes (sounds as units of a linguistic system).  Western interest in the study of languages began somewhat later than in the East, but the grammarians of the classical languages did not use the same methods or reach the same conclusions as their contemporaries in the Indic world. Early interest in language in the West was a part of philosophy, not of grammatical description. The first insights into semantic theory were made by Plato in his Cratylus dialogue, where he argues that words denote concepts that are eternal and exist in the world of ideas. This work is the first to use the word etymology to describe the history of a word's meaning. Around 280 BC, one of Alexander the Great's successors founded a university (see Musaeum) in Alexandria, where a school of philologists studied the ancient texts in and taught Greek to speakers of other languages. While this school was the first to use the word \"grammar\" in its modern sense, Plato had used the word in its original meaning as \"t\u00e9chn\u0113 grammatik\u1e17\" (), the \"art of writing\", which is also the title of one of the most important works of the Alexandrine school by Dionysius Thrax. Throughout the Middle Ages, the study of language was subsumed under the topic of philology, the study of ancient languages and texts, practised by such educators as Roger Ascham, Wolfgang Ratke, and John Amos Comenius.\n\nComparative philology\nIn the 18th century, the first use of the comparative method by William Jones sparked the rise of comparative linguistics. Bloomfield attributes \"the first great scientific linguistic work of the world\" to Jacob Grimm, who wrote Deutsche Grammatik. It was soon followed by other authors writing similar comparative studies on other language groups of Europe. The study of language was broadened from Indo-European to language in general by Wilhelm von Humboldt, of whom Bloomfield asserts:\n\n20th-century developments \nThere was a shift of focus from historical and comparative linguistics to synchronic analysis in early 20th century. Structural analysis was improved by Leonard Bloomfield, Louis Hjelmslev; and Zellig Harris who also developed methods of discourse analysis. Functional analysis was developed by the Prague linguistic circle and Andr\u00e9 Martinet. As sound recording devices became commonplace in the 1960s, dialectal recordings were made and archived, and the audio-lingual method provided a technological solution to foreign language learning. The 1960s also saw a new rise of comparative linguistics: the study of language universals in linguistic typology. Towards the end of the century the field of linguistics became divided into further areas of interest with the advent of language technology and digitalised corpora.\n\nAreas of research\n\nSociolinguistics \n\nSociolinguistics is the study of how language is shaped by social factors. This sub-discipline focuses on the synchronic approach of linguistics, and looks at how a language in general, or a set of languages, display variation and varieties at a given point in time. The study of language variation and the different varieties of language through dialects, registers, and idiolects can be tackled through a study of style, as well as through analysis of discourse. Sociolinguists research both style and discourse in language, as well as the theoretical factors that are at play between language and society.\n\nDevelopmental linguistics \n\nDevelopmental linguistics is the study of the development of linguistic ability in individuals, particularly the acquisition of language in childhood. Some of the questions that developmental linguistics looks into is how children acquire different languages, how adults can acquire a second language, and what the process of language acquisition is.\n\nNeurolinguistics \n\nNeurolinguistics is the study of the structures in the human brain that underlie grammar and communication. Researchers are drawn to the field from a variety of backgrounds, bringing along a variety of experimental techniques as well as widely varying theoretical perspectives. Much work in neurolinguistics is informed by models in psycholinguistics and theoretical linguistics, and is focused on investigating how the brain can implement the processes that theoretical and psycholinguistics propose are necessary in producing and comprehending language. Neurolinguists study the physiological mechanisms by which the brain processes information related to language, and evaluate linguistic and psycholinguistic theories, using aphasiology, brain imaging, electrophysiology, and computer modelling. Amongst the structures of the brain involved in the mechanisms of neurolinguistics, the cerebellum which contains the highest numbers of neurons has a major role in terms of predictions required to produce language.\n\nApplied linguistics \n\nLinguists are largely concerned with finding and describing the generalities and varieties both within particular languages and among all languages. Applied linguistics takes the results of those findings and \"applies\" them to other areas. Linguistic research is commonly applied to areas such as language education, lexicography, translation, language planning, which involves governmental policy implementation related to language use, and natural language processing. \"Applied linguistics\" has been argued to be something of a misnomer. Applied linguists actually focus on making sense of and engineering solutions for real-world linguistic problems, and not literally \"applying\" existing technical knowledge from linguistics. Moreover, they commonly apply technical knowledge from multiple sources, such as sociology (e.g., conversation analysis) and anthropology. (Constructed language fits under Applied linguistics.)\n\nToday, computers are widely used in many areas of applied linguistics. Speech synthesis and speech recognition use phonetic and phonemic knowledge to provide voice interfaces to computers. Applications of computational linguistics in machine translation, computer-assisted translation, and natural language processing are areas of applied linguistics that have come to the forefront. Their influence has had an effect on theories of syntax and semantics, as modelling syntactic and semantic theories on computers constraints.\n\nLinguistic analysis is a sub-discipline of applied linguistics used by many governments to verify the claimed nationality of people seeking asylum who do not hold the necessary documentation to prove their claim. This often takes the form of an interview by personnel in an immigration department. Depending on the country, this interview is conducted either in the asylum seeker's native language through an interpreter or in an international lingua franca like English. Australia uses the former method, while Germany employs the latter; the Netherlands uses either method depending on the languages involved. Tape recordings of the interview then undergo language analysis, which can be done either by private contractors or within a department of the government. In this analysis, linguistic features of the asylum seeker are used by analysts to make a determination about the speaker's nationality. The reported findings of the linguistic analysis can play a critical role in the government's decision on the refugee status of the asylum seeker.\n\nLanguage documentation \nLanguage documentation combines anthropological inquiry (into the history and culture of language) with linguistic inquiry, in order to describe languages and their grammars. Lexicography involves the documentation of words that form a vocabulary. Such a documentation of a linguistic vocabulary from a particular language is usually compiled in a dictionary. Computational linguistics is concerned with the statistical or rule-based modeling of natural language from a computational perspective. Specific knowledge of language is applied by speakers during the act of translation and interpretation, as well as in language education \u2013 the teaching of a second or foreign language. Policy makers work with governments to implement new plans in education and teaching which are based on linguistic research.\n\nSince the inception of the discipline of linguistics, linguists have been concerned with describing and analysing previously undocumented languages. Starting with Franz Boas in the early 1900s, this became the main focus of American linguistics until the rise of formal linguistics in the mid-20th century. This focus on language documentation was partly motivated by a concern to document the rapidly disappearing languages of indigenous peoples. The ethnographic dimension of the Boasian approach to language description played a role in the development of disciplines such as sociolinguistics, anthropological linguistics, and linguistic anthropology, which investigate the relations between language, culture, and society.\n\nThe emphasis on linguistic description and documentation has also gained prominence outside North America, with the documentation of rapidly dying indigenous languages becoming a focus in some university programmes in linguistics. Language description is a work-intensive endeavour, usually requiring years of field work in the language concerned, so as to equip the linguist to write a sufficiently accurate reference grammar. Further, the task of documentation requires the linguist to collect a substantial corpus in the language in question, consisting of texts and recordings, both sound and video, which can be stored in an accessible format within open repositories, and used for further research.\n\nTranslation \nThe sub-field of translation includes the translation of written and spoken texts across media, from digital to print and spoken. To translate literally means to transmute the meaning from one language into another. Translators are often employed by organizations such as travel agencies and governmental embassies to facilitate communication between two speakers who do not know each other's language. Translators are also employed to work within computational linguistics setups like Google Translate, which is an automated program to translate words and phrases between any two or more given languages. Translation is also conducted by publishing houses, which convert works of writing from one language to another in order to reach varied audiences. Academic translators specialize in or are familiar with various other disciplines such as technology, science, law, economics, etc.\n\nClinical linguistics \n\nClinical linguistics is the application of linguistic theory to the field of speech-language pathology. Speech language pathologists work on corrective measures to treat communication and swallowing disorders.\n\nChaika (1990) showed that people with schizophrenia who display speech disorders like rhyming inappropriately have attentional dysfunction, as when a patient was shown a color chip and then asked to identify it, responded \"looks like clay. Sounds like gray. Take you for a roll in the hay. Heyday, May Day.\" The color chip was actually clay-colored, so his first response was correct.'\n\nHowever, most people suppress or ignore words which rhyme with what they've said unless they are deliberately producing a pun, poem or rap. Even then, the speaker shows connection between words chosen for rhyme and an overall meaning in discourse. People with schizophrenia with speech dysfunction show no such relation between rhyme and reason. Some even produce stretches of gibberish combined with recognizable words.\n\nComputational linguistics \n\nComputational linguistics is the study of linguistic issues in a way that is \"computationally responsible\", i.e., taking careful note of computational consideration of algorithmic specification and computational complexity, so that the linguistic theories devised can be shown to exhibit certain desirable computational properties and their implementations. Computational linguists also work on computer language and software development.\n\nEvolutionary linguistics \n\nEvolutionary linguistics is the study of the emergence of the language faculty through human evolution, and also the application of evolutionary theory to the study of cultural evolution among different languages. It is also a study of the dispersal of various languages across the globe, through movements among ancient communities. Evolutionary linguistics is a highly interdisciplinary field, including linguists, biologists, neuroscientists, psychologists, mathematicians, and others. By shifting the focus of investigation in linguistics to a comprehensive scheme that embraces the natural sciences, it seeks to yield a framework by which the fundamentals of language are understood.\n\nForensic linguistics \n\nForensic linguistics is the application of linguistic analysis to forensics. Forensic analysis investigates the style, language, lexical use, and other linguistic and grammatical features used in the legal context to provide evidence in courts of law. Forensic linguists have also used their expertise in the framework of criminal cases.\n\nSee also \n\n Articulatory synthesis\n Axiom of categoricity\n Critical discourse analysis\n Cryptanalysis\n Decipherment\n Global language system\n Hermeneutics\n Integrational linguistics\n Integrationism\n Interlinguistics\n Language engineering\n Language geography\n Metalinguistics\n Metacommunicative competence\n Microlinguistics\n Onomastics\n Reading\n Speech processing\n Stratificational linguistics\n Outline and lists\n Index of linguistics articles\n List of departments of linguistics\n List of summer schools of linguistics\n List of schools of linguistics\n List of unsolved problems in linguistics\n\nReferences\n\nBibliography\n\nExternal links \n\n The Linguist List, a global online linguistics community with news and information updated daily\n Glossary of linguistic terms by SIL International (last updated 2004)\n Glottopedia, MediaWiki-based encyclopedia of linguistics, under construction\n Linguistic sub-fields \u2013 according to the Linguistic Society of America\n Linguistics and language-related wiki articles on Scholarpedia and Citizendium\n \"Linguistics\" section \u2013 A Bibliography of Literary Theory, Criticism and Philology, ed. J.A. Garc\u00eda Landa (University of Zaragoza, Spain)\n \n \n\n \nCognitive science\nLanguage\nIndian inventions",
  "Military history": "Military history is a humanities discipline within the scope of general historical recording of armed conflict in the history of humanity, and its impact on the societies, cultures and economies thereof, as well as the resulting changes to local and international relationships.\n\nProfessional historians normally focus on military affairs that had a major impact on the societies involved as well as the aftermath of conflicts, while amateur historians and hobbyists often take a larger interest in the details of battles, equipment and uniforms in use.\n\nThe essential subjects of military history study are the causes of war, the social and cultural foundations, military doctrine on each side, the logistics, leadership, technology, strategy, and tactics used, and how these changed over time. On the other hand, Just War Theory explores the moral dimensions of warfare, and to better limit the destructive reality caused by war, seeks to establish a doctrine of military ethics.\n\nAs an applied field, military history has been studied at academies and service schools because the military command seeks to not repeat past mistakes, and improve upon its current performance by instilling an ability in commanders to perceive historical parallels during a battle, so as to capitalize on the lessons learned from the past.  When certifying military history instructors the Combat Studies Institute deemphasizes rote detail memorization and focuses on themes and context in relation to current and future conflict, using the motto \"Past is Prologue.\"\n\nThe discipline of military history is dynamic, changing with development as much of the subject area as the societies and organisations that make use of it. The dynamic nature of the discipline of military history is largely related to the rapidity of change the military forces, and the art and science of managing them, as well as the frenetic pace of technological development that had taken place during the period known as the Industrial Revolution, and more recently in the nuclear and information ages.  An important recent concept is the Revolution in Military Affairs (RMA) which attempts to explain how warfare has been shaped by emerging technologies, such as gunpowder. It highlights the short outbursts of rapid change followed by periods of relative stability.\n\nPopular versus academic military history\nIn terms of the history profession in major countries, military history is an orphan, despite its enormous popularity with the general public. William H. McNeill points out:\nThis branch of our discipline flourishes in an intellectual ghetto. The 144 books in question [published in 1968-78] fall into two distinct classes: works aimed at a popular readership, written by journalists and men of letters outside academic circles, and professional work nearly always produced within the military establishment.... The study of military history in universities remains seriously underdeveloped. Indeed, lack of interest in and disdain for military history probably constitute one of the strangest prejudices of the profession.\n\nIn recent decades University level courses in military history remain popular; often they use films to humanize the combat experience. For example, Eugene P. A. Scleh, history professor at the University of Maine, has explored the advantages and problems of teaching a course of \"Modern War and Its Images\" entirely through films. Students said they found the documentaries more valuable than the dramas.  However, military historians are frustrated by their marginal status in major history departments.\n\nHistoriography of military history\nHistoriography is the study of the history and method of the discipline of history or the study of a specialised topic. In this case, military history with an eye to gaining an accurate assessment of conflicts using all available sources. For this reason military history is periodised, creating overlaying boundaries of study and analysis in which descriptions of battles by leaders may be unreliable due to the inclination to minimize mention of failure and exaggerate success. Military historians use Historiographical analysis in an effort to allow an unbiased, contemporary view of records.\n\nOne military historian, Jeremy Black, outlined problems 21st-century military historians face as an inheritance of their predecessors: Eurocentricity, a technological bias, a focus on leading military powers and dominant military systems, the separation of land from sea and recently air conflicts, the focus on state-to-state conflict, a lack of focus on political \"tasking\" in how forces are used.\n\nIf these challenges were not sufficient for the military historians, the limits of method are complicated by the lack of records, either destroyed or never recorded for its value as a military secret that may prevent some salient facts from being reported at all; scholars still do not know the exact nature of Greek fire for instance. Researching Operation Enduring Freedom and Operation Iraqi Freedom, for example, have presented unique challenges to historians due to records that were destroyed to protect classified military information, among other reasons. Historians utilize their knowledge of government regulation and military organization, and employing a targeted and systematic research strategy to piece together war histories. Despite these limits, wars are some of the most studied and detailed periods of human history.\n\nMilitary historians have often compared organization, tactical and strategic ideas, leadership, and national support of the militaries of different nations.\n\nIn the early 1980s, historian Jeffrey Kimball studied the influence of a historian's political position on current events on interpretive disagreement regarding the causes of 20th century wars.  He surveyed the ideological preferences of 109 active diplomatic historians in the United States as well as 54 active military historians. He finds that their current political views are moderately correlated with their historiographical interpretations. A clear position on the left-right continuum regarding capitalism was apparent in most cases.  All groups agreed with the proposition, \"historically, Americans have tended to view questions of their national security in terms of such extremes as good vs. evil.\"  Though the Socialists were split, the other groups agreed that \"miscalculation and/or misunderstanding of the situation\" had caused U.S. interventionism.\"  Kimball reports that:\nOf historians in the field of diplomatic history, 7% are Socialist, 19% are Other, 53% are Liberal, 11% are None and 10% Conservative. Of military historians, 0% are Socialist, 8% are Other, 35% are Liberal, 18% are None and 40% are Conservative.\n\nOnline resources\nPeople interested in military history from all periods of time, and all subtopics, are increasingly turning to the Internet for many more resources than are typically available in nearby libraries.  Since 1993, one of the most popular sites, with over 4000 members (subscriptions are free) has been H-WAR, sponsored by the H-Net network based at Michigan State University. H-War has six coeditors, and an academic advisory board that sets policy.  It sponsors daily moderated discussions of current topics, announcements of new publications and conferences, and reports on developments at conferences. The H-Net family of lists has sponsored and published over 46,000 scholarly book reviews, thousands of which deal with books in military history broadly conceived.  Wikipedia itself has a very wide coverage of military history, with over 180,000 articles. Its editors sponsor Wikipedia:WikiProject Military history and encourage readers to join.\n\nMilitary and war museums \n\nMilitary museums specialize in military histories; they are often organized from a national point of view, where a museum in a particular country will have displays organized around conflicts in which that country has taken part. They typically take a broad view of warfare's role in the nation's history.  They typically include displays of weapons and other military equipment, uniforms, wartime propaganda, and exhibits on civilian life during wartime, and decorations, among others. A military museum may be dedicated to a particular or area, such as the Imperial War Museum Duxford for military aircraft, Deutsches Panzermuseum for tanks, the Lange Max Museum for the Western Front (World War I), the International Spy Museum for espionage, The National World War I Museum for World War I, the \"D-Day Paratroopers Historical Center\" (Normandy) for WWII airborne, or more generalist, such as the Canadian War Museum or the Mus\u00e9e de l'Arm\u00e9e. For the Italian alpine wall one can find the most popular museum of bunkers in the small museum n8bunker at Olang / Kronplatz in the heard of the dolomites of South Tyrol.  The U.S. Army and the state National Guards operate 98 military history museums across the United States and three abroad.\n\nCurators debate how or whether the goal of providing diverse representations of war, in terms of positive and negative aspects of warfare.  War is seldom presented as a good thing, but soldiers are heavily praised. David Lowenthal has observed that in today's museums, \"nothing seems too horrendous to commemorate\". Yet as Andrew Whitmarsh notes, \"museums frequently portray a sanitised version of warfare.\" The actual bomber that dropped the atomic bomb on Japan became the focus of an angry national controversy with veterans attacking curators and historians when the Smithsonian Institution planned to put its fuselage on public display in 1995. The uproar led to cancellation of the exhibit.\n\nEarly historians\nThe documentation of military history begins with the confrontation between Sumer (current Iraq) and Elam (current Iran) c. 2700 BC near the modern Basra. Other prominent records in military history are the Trojan War in Homer's Iliad (though its historicity has been challenged), The Histories by Herodotus (484 BC \u2013 425 BC) who is often called the \"father of history\". Next was Thucydides whose impartiality, despite being an Athenian, allowed him to take advantage of his exile to research the war from different perspectives by carefully examining documents and interviewing eyewitnesses. An approach centered on the analysis of a leader was taken by Xenophon (430 BC \u2013 355 BC) in Anabasis, recording the expedition of Cyrus the Younger into Anatolia.\n\nThe records of the Roman Julius Caesar (100 BC \u2013 44 BC) enable a comparative approach for campaigns such as Commentarii de Bello Gallico and Commentarii de Bello Civili.\n\nTechnological evolution\n\nNew weapons development can dramatically alter the face of war, the cost of warfare, the preparations, and the training of soldiers and leaders. A rule of thumb is that if your enemy has a potentially war winning weapon, you have to either match it or neutralize it.\n\nAncient era\nChariots originated around 2000 BC. The chariot was an effective, fast weapon; while one man controlled the maneuvering of the chariot, a second bowman could shoot arrows at enemy soldiers. These became crucial to the maintenance of several governments, including the New Egyptian Kingdom and the Shang dynasty and the nation states of the early to middle Zhou dynasty.\n\nSome of the military unit types and technologies which were developed in the ancient world are:\n Slinger\n Hoplite\n Auxiliaries\n Infantry\n Archery\n Chariots\n Cavalry\n\nFor settled agrarian civilizations, the infantry became the core of military action. The infantry started as opposing armed groups of soldiers underneath commanders. The Greeks and early Romans used rigid, heavily armed phalanxes. The Macedonians and Hellenistic states would adopt phalanx formations with sarissa pikemen. The Romans would later adopt more flexible maniples from their neighbors which made them extremely successful in the field of battle. The kingdoms of the Warring States in East Asia also adopted infantry combat, a transition from chariot warfare from centuries earlier.\n\nArchers were a major component of many ancient armies, notably those of the Persians, Scythians, Egyptians, Nubians, Indians, Koreans, Chinese, and Japanese.\n\nCavalry became an important tool. In the Sicilian Expedition, led by Athens in an attempt to subdue Syracuse, the well-trained Syracusan cavalry became crucial to the success of the Syracusans. Macedonian Alexander the Great effectively deployed his cavalry forces to secure victories. In battles such as the Battle of Cannae of the Second Punic War, and the Battle of Carrhae of the Roman-Persian Wars, the importance of the cavalry would be repeated.\n\nThere were also horse archers, who had the ability to shoot on horseback\u00a0\u2013 the Parthians, Scythians, Mongols, and other various steppe people were especially fearsome with this tactic. By the 3rd\u20134th century AD, heavily armored cavalry became widely adopted by the Parthians, Sasanians, Byzantines, Eastern Han dynasty and Three Kingdoms, etc.\n\nThe early Indo-Iranians developed the use of chariots in warfare. The scythed chariot was later invented in India and soon adopted by the Persians.\n\nWar elephants were sometimes deployed for fighting in ancient warfare. They were first used in India and later adopted by the Persians. War elephants were also used in the Battle of the Hydaspes River, and by Hannibal in the Second Punic War against the Romans. One of the most important military transactions of the ancient world was Chandragupta Maurya's gift of 500 elephants to Seleucus I Nicator.\n\nNaval warfare was often crucial to military success. Early navies used sailing ships without cannons; often the goal was to ram the enemy ships and cause them to sink. There was human oar power, often using slaves, built up to ramming speed. Galleys were used in the 3rd millennium BC by the Cretans. The Greeks later advanced these ships.\n\nIn 1210 BC, the first recorded naval battle was fought between Suppiluliuma II, king of the Hittites, and Cyprus, which was defeated. In the Greco-Persian Wars, the navy became of increasing importance.\n\nTriremes were involved in more complicated sea-land operations. Themistocles helped to build up a stronger Greek navy, composed of 310 ships, and defeated the Persians at the Battle of Salamis, ending the Persian invasion of Greece.\n\nIn the First Punic War, the war between Carthage and Rome started with an advantage to Carthage because of their naval experience. A Roman fleet was built in 261 BC, with the addition of the corvus that allowed Roman soldiers to board enemy ships. The bridge would prove effective at the Battle of Mylae, resulting in a Roman victory.\n\nThe Vikings, in the 8th century AD, invented a ship propelled by oars with a dragon decorating the prow, hence called the Drakkar. The 12th century AD Song Dynasty invented ships with watertight bulkhead compartments while the 2nd century BC Han dynasty invented rudders and sculled oars for their warships.\n\nFortifications are important in warfare. Early hill-forts were used to protect inhabitants in the Iron Age. They were primitive forts surrounded by ditches filled with water.  Forts were then built out of mud bricks, stones, wood, and other available materials. Romans used rectangular fortresses built out of wood and stone. As long as there have been fortifications, there have been contraptions to break in, dating back to the times of Romans and earlier. Siege warfare is often necessary to capture forts.\n\nMiddle-ages\n\nSome of the military unit types and technologies which were used in the medieval period are:\n Artillery\n Cataphract\n Condottieri\n Fyrd\n Rashidun\n Mobile guard\n Mamluk\n Janissary\n Knight (see also: Chivalry)\n Crossbow\n Pikeman\n Samurai\n Sipahi\n Trebuchet\n\nBows and arrows were often used by combatants. Egyptians shot arrows from chariots effectively. The crossbow was developed around 500 BC in China, and was used a lot in the Middle Ages. The English/Welsh longbow from the 12th century also became important in the Middle Ages. It helped to give the English a large early advantage in the Hundred Years' War, even though the English were eventually defeated. The Battle of Cr\u00e9cy and the Battle of Agincourt are excellent examples of how to destroy an enemy using a longbow. It dominated battlefields for over a century.\n\nGunpowder\n\nThere is evidence for gunpowder evolving slowly from formulations by Chinese alchemists as early as the 4th century, at first as experiments for life force and metal transmutation, and later experiments as pyrotechnics and incendiaries. By the 10th century, the developments in gunpowder led to many new weapons that were improved over time. The Chinese used incendiary devices based on this in siege warfare against the Mongols starting in the mid 13th century. \"Pots with wicks of flax or cotton were used, containing a combination of sulfur, saltpeter (potassium nitrate), aconitine, oil, resin, ground charcoal and wax.\" Joseph Needham argued the Chinese were able to destroy buildings and walls using such devices. Such experimentation was not present in Western Europe, where the combination of saltpeter, sulfur and charcoal were used exclusively for explosives and as a propellant in firearms. What the Chinese often referred to as the \"fire drug\" arrived in Europe, fully fleshed out, as gunpowder.\n\nCannons were first used in Europe in the early 14th century, and played a vital role in the Hundred Years' War. The first cannons were simply welded metal bars in the form of a cylinder, and the first cannonballs were made of stone. By 1346, at the Battle of Cr\u00e9cy, the cannon had been used; at the Battle of Agincourt they would be used again.\n\nThe first infantry firearms, from fire lances to hand cannons, were held in one hand, while the explosive charge was ignited by a lit match or hot coal held in the other hand. In the mid-15th century came the matchlock, allowing the gun to be aimed and fired while held steady with both hands, as used in the arquebus. Starting about 1500, clever but complicated firing mechanisms were invented to generate sparks to ignite the powder instead of a lit match, starting with the wheel lock, snaplock, snaphance, and finally the flintlock mechanism, which was simple and reliable, becoming standard with the musket by the early 17th century.\n\nAt the beginning of the 16th century, the first European fire ships were used. Ships were filled with flammable materials, set on fire, and sent to enemy lines. This tactic was successfully used by Francis Drake to scatter the Spanish Armada at the Battle of Gravelines, and would later be used by the Chinese, Russians, Greeks, and several other countries in naval battles.\n\nNaval mines were invented in the 17th century, though they were not used in great numbers until the American Civil War. They were used heavily in the First and Second World Wars. Air-deployed naval mines were used to mine the North Vietnamese port of Haiphong during the Vietnam War. The Iraqi Navy of Saddam Hussein used naval mines extensively during the Tanker War, as part of the Iran\u2013Iraq War.\n\nThe first navigable submarine was built in 1624 by Cornelius Drebbel, it could cruise at a depth of 15 feet (5\u00a0m). However, the first military submarine was constructed in 1885 by Isaac Peral.\n\nThe Turtle was developed by David Bushnell during the American Revolution. Robert Fulton then improved the submarine design by creating the Nautilus.\n\nThe Howitzer, a type of field artillery, was developed in the 17th century to fire high trajectory explosive shells at targets that could not be reached by flat trajectory projectiles.\n\nOrganizational changes resulting in better training and intercommunication, made the concept combined arms possible, allowing the use of infantry, cavalry, and artillery in a coordinated way.\n\nBayonets also became of wide usage to infantry soldiers. Bayonet is named after Bayonne, France where it was first manufactured in the 16th century. It is used often in infantry charges to fight in hand-to-hand combat. General Jean Martinet introduced the bayonet to the French army. They were used heavily in the American Civil War, and continued to be used in modern wars like the Invasion of Iraq.\n\nBalloons were first used in warfare at the end of the 18th century. It was first introduced in Paris of 1783; the first balloon traveled over 5\u00a0miles (8\u00a0km). Previously military scouts could only see from high points on the ground, or from the mast of a ship. Now they could be high in the sky, signalling to troops on the ground. This made it much more difficult for troop movements to go unobserved.\n\nAt the end of the 18th century, iron-cased artillery rockets were successfully used militarily in India against the British by Tipu Sultan of the Kingdom of Mysore during the Anglo-Mysore Wars. Rockets were generally inaccurate at that time, though William Hale, in 1844, was able to develop a better rocket. The new rocket no longer needed the rocket stick, and had a higher accuracy.\n\nIn the 1860s there were a series of advancements in rifles. The first repeating rifle was designed in 1860 by a company bought out by Winchester, which made new and improved versions. Springfield rifles arrived in the mid-19th century also. Machine guns arrived in the late 19th century. Automatic rifles and light machine guns first arrived at the beginning of the 20th century.\n\nIn the later part of the 19th century, the self-propelled torpedo was developed. The HNoMS Rap was the world's first torpedo boat.\n\nEarly guns and artillery \nThe fire lance, the predecessor of the gun, was invented in China between the tenth and eleventh century.  The barrel was originally designed out of bamboo shoots, later with metal. Joseph Needham notes \"all the long preparations and tentative experiments were made in China, and everything came to Islam and the West fully fledged, whether it was the fire lance or the explosive bomb, the rocket or the metal-barrel handgun and bombard.\" By the 1320s Europe had guns, but scholars state that the exact time and method of migration from China remains a mystery. Evidence of firearms is found in Iran and Central Asia in the late fourteenth century.  It was not until roughly 1442 that guns were referenced in India.  Reliable references to guns in Russia begins around 1382.\n\nAn illustration of a \"pot-shaped gun\" found in the Holkham Hall Milemete manuscript dated to 1326 shows earliest advent of firearms in European history. The illustration shows an arrow, set in the pot-shaped gun pointed directly at a structure. Archaeological evidence of such \"gun arrows\" were discovered in Eltz Castle, \"dated by relation to a historical event (a feud with the Archbishop of Trier in 1331-36 leading to a siege), seem to confirm again that this was at least one of the types of guns like the Milemete used in these very early examples.\"\n\nAccording to Peter Fraser Purton, the best evidence of the earliest gun in Europe is the Loshult gun, dated to the fourteenth century. Discovered in 1861, the Loshult was made of bronze measured 11.8 inches in length. A replica of the Loshult was created, using similar gunpowder compounds with present-day materials, to determine the effectiveness of the weapon. The Gunpowder Research Group, who designed the recreation, found that at high elevations, the Loshult could fire as far as 1300 meters.  Though inaccurate, missing targets further than 200 meters, the Loshult could fire a range of projectiles such as arrows and shot. It was determined that the Loshult could be effectively fired at ranks of soldiers and structures.\n\nWritten works from the Cabinet des Titres of the Imperial Library of Paris has found evidence of canons in France in 1338.  The works illustrate canons being used on-board ships at the Rouen during that time.  \"...an iron Fire-arm, which was provided with forty-eight bolts, made of iron and freather; also one pound of saltpetre and half a pound of sulphur to make the powder propel arrows.\"\n\nResearchers have been unable to determine the sizes of these canons and others, outside the artifacts recovered.  Sir Henry Brackenbury was able to surmise the approximate size of these cannons by comparing receipts for both the firearms and the corresponding amounts of gunpowder purchased.  The receipts show a transaction for \"25 Livres for 5 canons.\"  Brackenbury was able to deduce, when comparing the costs of the cannons and the gunpowder apportioned, that they each iron cannon weighed approximately 25 lbs, while the brass cannons weighed roughly 22 lbs.\n\nPhilip the Bold (1363-1404) is credited with creating the most effective artillery power in Europe in the late fourteenth century, effectively creating the Burgundian estate.  Philip's development of a large artillery army made the small country a reputable force against larger empires such as England and France.  Philip had achieved this by establishing a large scale artillery manufacturing economy in Burgundy.  Philip used his new cache of artillery to help the French capture an English-held fortress of Odruik.  The artillery used to take Odruik used cannonballs measuring to about 450 pounds.\n\nLarge artillery was a major contributing factor to the fall of Constantinople at the hands of Mehmed the Conqueror (1432-1481).  Having resigned his position as ruler due to youth and inexperience in 1446, Mehmed moved to the Ottoman capital of Manisa.  After his uncle, Murad II died in 1451, Mehmed once again became Sultan.  He turned his attention to claiming the Byzantine capital, Constantinople.  Mehmed, like Philip, started mass-producing cannons by enticing craftsmen to his cause with money and freedom.  For 55 days, Constantinople was bombarded with artillery fire, throwing cannonballs as large as 800 lbs at its walls.  On May 29, 1453, Constantinople fell into Ottoman control.\n\nEarly firearm tactics \nAs guns and artillery became more advanced and prevalent, so to did the tactics by which they were implemented.  According to Historian Michael Roberts \"...a military revolution began with the broad adoption of firearms and artillery by late sixteenth-century European armies.\"  Infantry with firearms replaced cavalry.  Empires adapted their strongholds to withstand artillery fire.  Eventually drilling strategies and battlefield tactics were adapted for the evolution in firearms use.\n\nIn Japan, at the same time during the sixteenth-century, this military evolution was also taking hold.  These changes included a universal adoption of firearms, tactical developments for effective use, logistical restructuring within the military itself, and \"the emergence of centralized and political and institutional relationships indicative of the early modern order.\"\n\nTactically, beginning with Oda Nobunaga, the technique known as \"volleying\" or countermarch drills were implemented.  Volley fire is an organized implementation of firearms, where infantry are structured in ranks.  The ranks will alternate between loading and firing positions, allowing more consistent rates of fire and preventing enemies from taking over a position while members reload.\n\nHistorical evidence shows that Oda Nobunaga implemented his volley technique successfully in 1575, twenty years before evidence of such a technique is shown in Europe.  The first indications of the countermarch technique in Europe was by Lord William Louis of Nassau (1538-1574) in the mid-1590s.\n\nKorea also seemed to be adapting the volley technique, earlier than even the Japanese.  \"Koreans seem to have employed some kind of volley principle with guns by 1447, when the Korean King Sejong the Great instructed his gunners to shoot their 'fire barrels' in squads of five, taking turns firing and loading.\"\n\nThis was on display during what Kenneth Swope called the First Great East Asian War, when Japan was trying to take control and subjugate Korea. Toyotomi Hideyoshi (1537\u20131598) made a failed invasion of Korea, which lasted six years, eventually pushed back by the Koreans with the aid of Ming China.  Japan, using overwhelming firepower, had many early victories on the Korean peninsula's.  Though the Korean's had similar manpower, \"the curtain of arrows thrown up by defenders was wiped out by (Japanese) gunfire.\" After the Japanese were finally pushed back in 1598, sweeping military reforms took place in Korea, largely based on updating and implementing the volley technique with firearms.\n\nIt was Qi Jiguang, a Ming Chinese General that provided the original treatise, disseminated to Koreans, that aided in this venture.  In these manuals, Qi \"...gave detailed instructions in the use of small group tactics, psychological warfare, and other 'modern' techniques.\"  Qi emphasized repetitive drilling, dividing men into smaller groups, separating the strong from weak.  Qi's ethos was one of synthesizing smaller groups, trained in various tactical formations, into larger companies, battalions and armies.  By doing this they could \"operate as eyes, hands, and feet...\" aiding to overall unit cohesion.\n\nModern technologies\nAt the start of the World Wars, various nations had developed weapons that were a surprise to their adversaries, leading to a need to learn from this, and alter how to combat them. Flame throwers were first used in the First World War. The French were the first to introduce the armored car in 1902. Then in 1918, the British produced the first armored troop carrier. Many early tanks were proof of concept but impractical until further development. In World War I, the British and French held a crucial advantage due to their superiority in tanks; the Germans had only a few dozen A7V tanks, as well as 170 captured tanks. The British and French both had several hundred each. The French tanks included the 13 ton Schneider-Creusot, with a 75\u00a0mm gun, and the British had the Mark IV and Mark V tanks.\n\nOn December 17, 1903, the Wright Brothers performed the first controlled, powered, heavier-than-air flight; it went 39 meters (120\u00a0ft). In 1907, the first helicopter flew, but it wasn't practical for usage. Aviation became important in World War I, in which several aces gained fame. In 1911 an aircraft took off from a warship for the first time. Landings on a cruiser were another matter. This led to the development of an aircraft carrier with a decent unobstructed flight deck.\n\nChemical warfare exploded into the public consciousness in World War I but may have been used in earlier wars without as much human attention. The Germans used gas-filled shells at the Battle of Bolimov on January 3, 1915. These were not lethal, however. In April 1915, the Germans developed a chlorine gas that was highly lethal, and used it to moderate effect at the Second Battle of Ypres. Gas masks were invented in matter of weeks, and poison gas proved ineffective at winning battles. It was made illegal by all nations in the 1920s.\n\nWorld War II gave rise to even more technology. The worth of the aircraft carrier was proved in the battles between the United States and Japan like the Battle of Midway. Radar was independently invented by the Allies and Axis powers. It used radio waves to detect objects. Molotov cocktails were invented by General Franco in the Spanish Civil War, directing the Nationalists to use them against Soviet tanks in the assault on Toledo. The atomic bomb was developed by the Manhattan Project and dropped on Hiroshima and Nagasaki in 1945, quickly ending World War II.\n\nDuring the Cold War, the main powers engaged in a Nuclear arms race. In the space race, both nations attempted to launch human beings into space to the moon. Other technological advances centered on intelligence (like the spy satellite) and missiles (ballistic missiles, cruise missiles). Nuclear submarine, invented in 1955. This meant submarines no longer had to surface as often, and could run more quietly. They evolved into becoming underwater missile platforms.\n\nPeriods of military history\n\nAncient warfare\n\nMuch of what we know of ancient history is the history of militaries: their conquests, their movements, and their technological innovations. There are many reasons for this. Kingdoms and empires, the central units of control in the ancient world, could only be maintained through military force. Due to limited agricultural ability, there were relatively few areas that could support large communities, so fighting was common.\n\nWeapons and armor, designed to be sturdy, tended to last longer than other artifacts, and thus a great deal of surviving artifacts recovered tend to fall in this category as they are more likely to survive. Weapons and armor were also mass-produced to a scale that makes them quite plentiful throughout history, and thus more likely to be found in archaeological digs.\n\nSuch items were also considered signs of prosperity or virtue, and thus were likely to be placed in tombs and monuments to prominent warriors. And writing, when it existed, was often used for kings to boast of military conquests or victories.\n\nWriting, when used by the common man, also tended to record such events, as major battles and conquests constituted major events that many would have considered worthy of recording either in an epic such as the Homeric writings pertaining to the Trojan War, or even personal writings. Indeed, the earliest stories center on warfare, as war was both a common and dramatic aspect of life; the witnessing of a major battle involving many thousands of soldiers would be quite a spectacle, even today, and thus considered worthy both of being recorded in song and art, but also in realistic histories, as well as being a central element in a fictional work.\n\nLastly, as nation states evolved and empires grew, the increased need for order and efficiency lead to an increase in the number of records and writings. Officials and armies would have good reason for keeping detailed records and accounts involving any and all things concerning a matter such as warfare that, in the words of Sun Tzu, was \"a matter of vital importance to the state\". For all these reasons, military history comprises a large part of ancient history.\n\nNotable militaries in the ancient world included the Egyptians, Assyrians, Babylonians, Persians, Ancient Greeks (notably the Spartans and Macedonians), Kushites, Indians (notably the Magadhas, Gangaridais, Gandharas and Cholas), Early Imperial Chinese (notably the Qin and Han Dynasties), Xiongnu Confederation, Ancient Romans, and Carthaginians.\n\nThe fertile crescent of Mesopotamia was the center of several prehistoric conquests. Mesopotamia was conquered by the Sumerians, Akkadians, Babylonians, Assyrians and Persians. Iranians were the first nation to introduce cavalry into their army.\n\nEgypt began growing as an ancient power, but eventually fell to the Libyans, Nubians, Assyrians, Persians, Greeks, Romans, Byzantines and Arabs.\n\nThe earliest recorded battle in India was the Battle of the Ten Kings. The Indian epics Mahabharata and Ramayana are centered on conflicts and refer to military formations, theories of warfare and esoteric weaponry. Chanakya's Arthashastra contains a detailed study on ancient warfare, including topics on espionage and war elephants.\n\nAlexander the Great invaded Northwestern India and defeated King Porus in the Battle of the Hydaspes River. The same region was soon re conquered by Chandragupta Maurya after defeating the Macedonians and Seleucids. He also went on to conquer the Nanda Empire and unify Northern India. Most of Southern Asia was unified under his grandson Ashoka the Great after the Kalinga War, though the empire collapsed not long after his reign.\n\nIn China, the Shang dynasty and Zhou dynasty had risen and collapsed. This led to a Warring States period, in which several states continued to fight with each other over territory. Philosopher-strategists such as Confucius and Sun Tzu wrote various manuscripts on ancient warfare (as well as international diplomacy).\n\nThe Warring States era philosopher Mozi (Micius) and his Mohist followers invented various siege weapons and siegecraft, including the Cloud Ladder (a four-wheeled, extendable ramp) to scale fortified walls during a siege of an enemy city. The warring states were first unified by Qin Shi Huang after a series of military conquests, creating the first empire in China.\n\nHis empire was succeeded by the Han dynasty, which expanded into Central Asia, Northern China/Manchuria, Southern China, and present day Korea and Vietnam. The Han came into conflict with settled people such as the Wiman Joseon, and proto-Vietnamese Nanyue. They also came into conflict with the Xiongnu (Huns), Yuezhi, and other steppe civilizations.\n\nThe Han defeated and drove the Xiongnus west, securing the city-states along the silk route that continued into the Parthian Empire. After the decline of central imperial authority, the Han Dynasty collapsed into an era of civil war and continuous warfare during the Three Kingdoms period in the 3rd century AD.\n\nThe Achaemenid Persian Empire was founded by Cyrus the Great after conquering the Median Empire, Neo-Babylonian Empire, Lydia and Asia Minor. His successor Cambyses went on to conquer the Egyptian Empire, much of Central Asia, and parts of Greece, India and Libya. The empire later fell to Alexander the Great after defeating Darius III. After being ruled by the Seleucid dynasty, the Persian Empire was subsequently ruled by the Parthian and Sassanid dynasties, which were the Roman Empire's greatest rivals during the Roman-Persian Wars.\n\nIn Greece, several city-states rose to power, including Athens and Sparta. The Greeks successfully stopped two Persian invasions, the first at the Battle of Marathon, where the Persians were led by Darius the Great, and the second at the Battle of Salamis, a naval battle where the Greek ships were deployed by orders of Themistocles and the Persians were under Xerxes I, and the land engagement of the Battle of Plataea.\n\nThe Peloponnesian War then erupted between the two Greek powers Athens and Sparta. Athens built a long wall to protect its inhabitants, but the wall helped to facilitate the spread of a plague that killed about 30,000 Athenians, including Pericles. After a disastrous campaign against Syracuse, the Athenian navy was decisively defeated by Lysander at the Battle of Aegospotami.\n\nThe Macedonians, underneath Philip II of Macedon and Alexander the Great, invaded Persia and won several major victories, establishing Macedonia as a major power. However, following Alexander's death at an early age, the empire quickly fell apart.\n\nMeanwhile, Rome was gaining power, following a rebellion against the Etruscans. During the three Punic Wars, the Romans defeated the neighboring power of Carthage. The First Punic War centered on naval warfare. The Second Punic War started with Hannibal's invasion of Italy by crossing the Alps. He famously won the encirclement at the Battle of Cannae. However, after Scipio invaded Carthage, Hannibal was forced to follow and was defeated at the Battle of Zama, ending the role of Carthage as a power.\n\nAfter defeating Carthage the Romans went on to become the Mediterranean's dominant power, successfully campaigning in Greece, (Aemilius Paulus decisive victory over Macedonia at the Battle of Pydna), in the Middle East (Lucius Licinius Lucullus, Gnaeus Pompeius Magnus), in Gaul (Gaius Julius Caesar) and defeating several Germanic tribes (Gaius Marius, Germanicus). While Roman armies suffered several major losses, their large population and ability (and will) to replace battlefield casualties, their training, organization, tactical and technical superiority enabled Rome to stay a predominant military force for several centuries, utilizing well trained and maneuverable armies to routinely overcome the much larger \"tribal\" armies of their foes (see Battles of Aquae Sextiae, Vercellae, Tigranocerta, Alesia).\n\nIn 54 BC the Roman triumvir Marcus Licinius Crassus took the offensive against the Parthian Empire in the east. In a decisive battle at Carrhae Romans were defeated and the golden Aquilae (legionary battle standards) were taken as trophies to Ctesiphon. The battle was one of the worst defeats suffered by the Roman Republic in its entire history.\n\nWhile successfully dealing with foreign opponents, Rome experienced numerous civil wars, notably the power struggles of Roman generals such as Marius and Sulla during the end of the Republic. Caesar was also notable for his role in the civil war against the other member of the Triumvirate (Pompey) and against the Roman Senate.\n\nThe successors of Caesar\u00a0\u2013 Octavian and Mark Anthony, also fought a civil war with Caesar's assassins (Senators Brutus, Cassius, etc.). Octavian and Mark Anthony eventually fought another civil war between themselves to determine the sole ruler of Rome. Octavian emerged victorious and Rome was turned into an empire with a huge standing army of professional soldiers.\n\nBy the time of Marcus Aurelius, the Romans had expanded to the Atlantic Ocean in the west and to Mesopotamia in the east and controlled Northern Africa and Central Europe up to the Black Sea. However, Aurelius marked the end of the Five Good Emperors, and Rome quickly fell into decline.\n\nThe Huns, Goths, and other barbaric groups invaded Rome, which continued to suffer from inflation and other internal strifes. Despite the attempts of Diocletian, Constantine I, and Theodosius I, western Rome collapsed and was eventually conquered in 476. The Byzantine empire continued to prosper, however.\n\nMedieval warfare\n\nWhen stirrups came into use some time during the Dark Ages militaries were forever changed. This invention coupled with technological, cultural, and social developments had forced a dramatic transformation in the character of warfare from antiquity, changing military tactics and the role of cavalry and artillery.\n\nSimilar patterns of warfare existed in other parts of the world. In China around the 5th century armies moved from massed infantry to cavalry based forces, copying the steppe nomads. The Middle East and North Africa used similar, if often more advanced, technologies than Europe.\n\nIn Japan the Medieval warfare period is considered by many to have stretched into the 19th century. In Africa along the Sahel and Sudan states like the Kingdom of Sennar and Fulani Empire employed Medieval tactics and weapons well after they had been supplanted in Europe.\n\nIn the Medieval period, feudalism was firmly implanted, and there existed many landlords in Europe. Landlords often owned castles to protect their territory.\n\nThe Islamic Arab Empire began rapidly expanding throughout the Middle East, North Africa, and Central Asia, initially led by Rashidun Caliphate, and later under the Umayyads. While their attempts to invade Europe by way of the Balkans were defeated by Byzantium and Bulgaria, the Arabs expanded to the Iberian Peninsula in the west and the Indus Valley in the east. The Abassids then took over the Arab Empire, though the Umayyads remained in control of Islamic Spain.\n\nAt the Battle of Tours, the Franks under Charles Martel stopped short a Muslim invasion. The Abassids defeated the Tang Chinese army at the Battle of Talas, but were later defeated by the Seljuk Turks and the Mongols centuries later, until the Arab Empire eventually came to an end after the Battle of Baghdad in 1258.\n\nIn China, the Sui dynasty had risen and conquered the Chen Dynasty of the south. They invaded Vietnam (northern Vietnam had been in Chinese control since the Han dynasty), fighting the troops of Champa, who had cavalry mounted on elephants. After decades of economic turmoil and a failed invasion of Korea, the Sui collapsed and was followed by the Tang dynasty, who fought with various Turkic groups, the Tibetans of Lhasa, the Tanguts, the Khitans, and collapsed due to political fragmentation of powerful regional military governors (jiedushi). The innovative Song dynasty followed next, inventing new weapons of war that employed the use of Greek Fire and gunpowder (see section below) against enemies such as the Jurchens.\n\nThe Mongols under Genghis Khan, \u00d6gedei Khan, M\u00f6ngke Khan, and Kublai Khan conquered most of Eurasia. They took over China, Persia, Turkestan, and Russia. After Kublai Khan took power and created the Yuan dynasty, the divisions of the empire ceased to cooperate with each other, and the Mongol Empire was only nominally united.\n\nIn New Zealand, prior to European discovery, oral histories, legends and whakapapa include many stories of battles and wars. M\u0101ori warriors were held in high esteem. One group of Polynesians migrated to the Chatham Islands, where they developed the largely pacifist Moriori culture. Their pacifism left the Moriori unable to defend themselves when the islands were invaded by mainland M\u0101ori in the 1830s.\n\nThey proceeded to massacre the Moriori and enslave the survivors. Warrior culture also developed in the isolated Hawaiian Islands. During the 1780s and 1790s the chiefs and alii were constantly fighting for power. After a series of battles the Hawaiian Islands were united for the first time under a single ruler who would become known as Kamehameha I.\n\nGunpowder warfare\n\nAfter gunpowder weapons were first developed in Song dynasty China (see also Technology of Song Dynasty), the technology later spread west to the Ottoman Empire, from where it spread to the Safavid Empire of Persia and the Mughal Empire of India. The arquebus was later adopted by European armies during the Italian Wars of the early 16th century.\n\nThis all brought an end to the dominance of armored cavalry on the battlefield. The simultaneous decline of the feudal system\u00a0\u2013 and the absorption of the medieval city-states into larger states\u00a0\u2013 allowed the creation of professional standing armies to replace the feudal levies and mercenaries that had been the standard military component of the Middle Ages.\n\nIn Africa, Ahmad ibn Ibrihim al-Ghazi, was the first African commander to use gunpowder on the continent in the Ethiopian\u2013Adal War, that lasted for fourteen years (1529\u20131543).\n\nThe period spanning between the 1648 Peace of Westphalia and the 1789 French Revolution is also known as Kabinettskriege (Princes' warfare) as wars were mainly carried out by imperial or monarchics states, decided by cabinets and limited in scope and in their aims. They also involved quickly shifting alliances, and mainly used mercenaries.\n\nOver the course of the 18th-19th centuries all military arms and services underwent significant developments that included a more mobile field artillery, the transition from use of battalion infantry drill in close order to open order formations and the transfer of emphasis from the use of bayonets to the rifle that replaced the musket, and virtual replacement of all types of cavalry with the universal dragoons, or mounted infantry.\n\nMilitary Revolution\n\nThe Military Revolution is a conceptual schema for explaining the transformation of European military strategy, tactics and technology in the early modern period. The argument is that dramatic advances in technology, government finance, and public administration transformed and modernized European armies, tactics, and logistics. Since warfare was so central to the European state, the transformation had a major impact on modernizing government bureaucracies, taxation, and the national economy. The concept was introduced by Michael Roberts in the 1950s as he focused on Sweden 1560\u20131660. Roberts emphasized the introduction of muskets that could not be aimed at small targets, but could be very effective when fired in volleys by three ranks of infantry soldiers, with one firing while the other two ranks reloaded.  All three ranks march forward to demolish the enemy. The infantry now had the firepower that had been reserved to the artillery, and had mobility that could rapidly advance in the battlefield, which the artillery lacked. The infantry thereby surpassed the artillery in tactical maneuvering on the battlefield.  Roberts linked these advances with larger historical consequences, arguing that innovations in tactics, drill and doctrine by the Dutch and Swedes 1560\u20131660 led to a need for more and better trained troops and thus for permanent forces (standing armies).  Armies grew much larger and more expensive. These changes in turn had major political consequences in the level of administrative support and the supply of money, men and provisions, producing new financial demands and the creation of new governmental institutions. \"Thus, argued Roberts, the modern art of war made possible\u2014and necessary\u2014the creation of the modern state\". In the 1990s the concept was modified and extended by Geoffrey Parker, who argued that developments in fortification and siege warfare caused the revolution.  The concept of a military revolution based upon technology has given way to models based more on a slow evolution in which technology plays a minor role to organization, command and control, logistics and in general non-material improvements. The revolutionary nature of these changes was only visible after a long evolution that handed Europe a predominant place in warfare, a place that the industrial revolution would confirm.\n\nThe concept of a military revolution in the sixteenth and seventeenth centuries has received a mixed reception among historians. Noted military historians Michael Duffy and Jeremy Black have strongly criticised it as misleading, exaggerated and simplistic.\n\nIndustrial warfare\n\nAs weapons\u2014particularly small arms\u2014became easier to use, countries began to abandon a complete reliance on professional soldiers in favor of conscription. Technological advances became increasingly important; while the armies of the previous period had usually had similar weapons, the industrial age saw encounters such as the Battle of Sadowa, in which possession of a more advanced technology played a decisive role in the outcome.  Conscription was employed in industrial warfare to increase the number of military personnel that were available for combat. Conscription was notably used by Napoleon Bonaparte and the major parties during the two World Wars.\n\nTotal war was used in industrial warfare, the objective being to prevent the opposing nation to engage in war.  Napoleon was the innovator. William Tecumseh Sherman's \"March to the Sea\" and Philip Sheridan's burning of the Shenandoah Valley during the American Civil War were examples. On the largest scale the strategic bombing of enemy cities and industrial factories during World War II was total warfare.\n\nModern warfare\n\nSince the 1940s, preparation for a major war has been based on technological arms races involving all sorts of new weapons systems, such as nuclear and biological, as well as computerized control systems, and the opening of new venues, such as seen in the Space race involving the United States, the Soviet Union, and more recently, China.\n\nModern war also saw the improvement of armored tank technology. While tanks were present in the First World War, and the Second World War, armored warfare technology came to a head with the start of the Cold War. Many of the technologies commonly seen on main battle tanks today, such as composite armor, high caliber cannons, and advanced targeting systems, would be developed during this time.\n\nA distinctive feature since 1945 is the absence of wars between major powers\u2014indeed the near absence of any traditional wars between established countries. The major exceptions were the Indo-Pakistani War of 1971, the Iran\u2013Iraq War 1980\u20131988, and the Gulf War of 1990\u201391.  Instead actual fighting has largely been a matter of civil wars and insurgencies.\n\nSee also\n\nWar Studies\nAncient Greek warfare\nMilitary science\nList of military writers\nMaritime history\nMilitary globalization\nNaval history\nRoman warfare\nSociety for Military History\nMilitary history of ancient Rome\nMilitary history of Africa\nMilitary history of Asia\nMilitary history of Europe\nMilitary history of Oceania\nMilitary history of North America\nMilitary history of South America\nMilitary history by country\n Journal of Military History, scholarly journal\n War in History, scholarly journal\n War & Society, scholarly journal\nHistory of physical training and fitness\n\nNotes and references\n\nFurther reading\n\n Archer, I. John R. Ferris, Holger H. Herwig, and Timothy H. E. Travers. World History of Warfare (2nd ed. 2008) 638 pp\n Black, Jeremy. Warfare in the Western World, 1775\u20131882 (2001) 240 pp.\n Black, Jeremy. Warfare in the Western World, 1882\u20131975 (2002), 256 pp.\n Chambers, John Whiteclay, ed. The Oxford Companion to American Military History (2000) online\n Cowley, Robert, and Geoffrey Parker, eds. The Reader's Companion to Military History (2001) excellent coverage by scholars. Complete text online free of 1996 edition\n Dear, I. C. B., and M. R. D. Foot, eds. Oxford Companion to World War II (2005; 2nd ed. 2010) online\n Doughty, Robert, Ira D. Gruber, Roy K. Flint, and Mark Grimsley. Warfare In The Western World (2 vol 1996), comprehensive textbook; online vol 1 to 1871\n Dupuy, R. Ernest and Trevor N. Dupuy. The Encyclopedia of Military History: From 3500 B.C. to the Present (1977), 1465 pp; comprehensive discussion focused on wars and battles; online\n Holmes, Richard, ed. The Oxford Companion to Military History (2001) 1071 pp; online at OUP\n Jones, Archer, The Art of War in the Western World (2001)\n \n Kohn, George C. Dictionary of Wars (3rd ed. 2006) 704 pp; very useful summary across world history\n Karsten, Peter. ed., Encyclopedia of War and American Society (3 vols., 2005).\n Keegan, John. The Face of Battle (1976)  excerpt\n Keegan, John. The Price of Admiralty: The Evolution of Naval Warfare (1989)\n Lamphear, John, ed. African Military History (Routledge, 2007).\n Lee, Wayne E. Waging War: Conflict, Culture, and Innovation in World History (2015) excerpt\n Lynn, John A. Battle: A Cultural History of Combat and Culture (2003).\n Muehlbauer, Matthew S., and David J. Ulbrich, eds. The Routledge History of Global War and Society (Routledge, 2018).\n Nolan, Cathal J. The Allure of Battle: A History of How Wars Have Been Won and Lost (2017)\n Nolan, Cathal J. The Age of Wars of Religion, 1000-1650: An Encyclopedia of Global Warfare and Civilization (2 vol 2006)\n Townshend, Charles, ed. The Oxford History of Modern War (2nd ed. 2005)\n\nHistoriography and memory\n Barnett, Correlli, Shelford Bidwell, Brian Bond, and John Terraine. Old Battles and New Defences: Can We Learn from Military History? (1986). online edition\n Black, Jeremy. \"Determinisms and Other Issues\", Journal of Military History, 68 (Oct. 2004), 1217\u201332. in Project MUSE\n Black, Jeremy. Rethinking Military History (2004) online edition\n Bucholz, Arden. \"Hans Delbruck and Modern Military History.\" The Historian vol 55#3 (1993) pp.\u00a0517+.\n Chambers II, John Whiteclay. \"The New Military History: Myth and Reality\", Journal of Military History, 55 (July 1991), 395\u2013406\n Chambers, John Whiteclay. \"\u2018All Quiet on the Western Front\u2019 (1930): the antiwar film and the image of the First World War.\" Historical journal of film, radio and television 14.4 (1994): 377-411.\n Charters, David A., Marc Milner, and J. Brent Wilson. eds. Military History and the Military Profession, (1992)\n Citino, Robert M. \"Military Histories Old and New: A Reintroduction\", The American Historical Review Vol. 112, no. 4 (October 2007), pp.\u00a01070\u201390 online version\n Grimsley, Mark. \"Why Military History Sucks\", Nov. 1996, War Historian.org, online at \n Higham, John, ed. A Guide to the Sources of British Military History  (2015) 654 pages excerpt\n Hughes, Matthew, and W. Philpott, eds. Palgrave Advances in Modern Military History (2006)  excerpt\n Karsten, Peter. \"The 'New' American Military History: A Map of the Territory, Explored and Unexplored\", American Quarterly, 36 #3, (1984), 389\u2013418 in JSTOR\n Kimball, Jeffrey. \"The Influence of Ideology on Interpretive Disagreement: A Report on a Survey of Diplomatic, Military and Peace Historians on the Causes of 20th Century U. S. Wars,\" History Teacher 17#3 (1984) pp.\u00a0355\u2013384 DOI: 10.2307/493146  online\n Kohn, Richard H. \"The Social History of the American Soldier: A Review and Prospectus for Research\", American Historical Review, 86 (June 1981), 553\u201367. in JSTOR\n Lee, Wayne E. \"Mind and Matter \u2013 Cultural Analysis in American Military History: A Look at the State of the Field\", Journal of American History, 93 (March 2007), 1116\u201342. Fulltext: History Cooperative and Ebsco\n Lynn, John A. \"Rally Once Again: The Embattled Future of Academic Military History\", Journal of Military History, 61 (Oct. 1997), 777\u201389.\n Mearsheimer, John J. Liddell Hart and the Weight of History. (1988). 234 pp.\n Messenger, Charles, ed. Reader's Guide to Military History (Routledge, 2001), 948 pp; detailed guide to the historiography of 500 topics excerpt and text search\n Morillo, Stephen. What is Military History (2006)\n Moyar, Mark. \"The Current State of Military History\", The Historical Journal (2007), 50: 225\u201340 online at CJO\nMuehlbauer, Matthew S., and David J. Ulbrich, eds. The Routledge History of Global War and Society (2018)  \nMuehlbauer, Matthew S., and David J. Ulbrich. Ways of War: American Military History from the Colonial Era to the Twenty-First Century (2018)  \n Murray, Williamson and Richard Hart Sinnreich, eds. The Past as Prologue: The Importance of History to the Military Profession (2006).\n Noe, Kenneth W., George C. Rable and Carol Reardon. \"Battle Histories: Reflections on Civil War Military Studies\" Civil War History 53#3 2007. pp.\u00a0229+. online edition\n Porch, Douglas. \"Writing History in the 'End of History' Era: Reflections on Historians and the GWOT\" Journal of Military History 2006 70(4): 1065\u201379. on war on terror, 2001\u2013present\n Reardon, Carol. Soldiers and Scholars: The U.S. Army and the Uses of Military History, 1865\u20131920. U. Press of Kansas 1990. 270 pp.\u00a0.\n Reid, Brian Holden. \"American Military History: the Need for Comparative Analysis.\" Journal of American History 2007 93(4): 1154\u201357. \n Reid, Brian Holden, and Joseph G. Dawson III, eds., \"Special Issue: The Vistas of American Military History, 1800\u20131898\", American Nineteenth Century History, 7 (June 2006), 139\u2013321.\n Riseman, Noah. \"The Rise of Indigenous Military History.\" History Compass (2014) 12#12 pp.\u00a0901\u201311. cover 20th century. DOI: 10.1111/hic3.12205.\n Rogers, Clifford J. ed. The Military Revolution Debate: Readings On The Military Transformation Of Early Modern Europe (1995) \n Sharman, Jason C. \"Myths of military revolution: European expansion and Eurocentrism.\" European Journal of International Relations 24.3 (2018): 491-513 online\n Schleh, Eugene P. \"Books About Film and War.\" Film & History: An Interdisciplinary Journal of Film and Television Studies 8.1 (1978): 11\u201314.\n Schleh, Eugene P. \"All Quiet on the Western Front: A History Teacher's Reappraisal.\" Film & History 8.4 (1978): 66\u201369.\n Spector, Ronald H. \"Teetering on the Brink of Respectability.\" Journal of American History 2007 93(4): 1158\u201360. online\n Spiller, Roger. \"Military History and its Fictions.\" Journal of Military History 2006 70(4): 1081\u201397. online\n Winter, Jay, and Antoine Prost. The Great War in History Debates and Controversies, 1914 to the Present (Cambridge UP, 2005) excerpt\n Wolters, Timothy S. \"Harvey A. DeWeerd and the Dawn of Academic Military History in the United States.\" Journal of Military History (Jan 2021) 85#1 pp 95\u2013133.\n\nExternal links\n\nInternational Bibliography of Military History of the International Commission of Military History \u2013 from Brill.nl\nH-WAR, daily discussion group for military historians \u2013 from Michigan State University Department of History, H-Net Humanities & Social Sciences Online\nWeb Sources for Military History \u2013 from AmericanHistoryProjects.com\n\n \nHistory\nHistory",
  "Nobility": "Nobility is a social class  normally ranked immediately below royalty and found in some societies that have a formal aristocracy.  Nobility has often been an estate of the realm that possessed more acknowledged privilege and higher social status than most other classes in society.  The privileges associated with nobility may constitute substantial advantages over or relative to non-nobles or may be largely honorary (e.g., precedence), and vary by country and era. Membership in the nobility, including rights and responsibilities, is typically hereditary.\n\nMembership in the nobility has historically been granted by a monarch or government. Nonetheless, acquisition of sufficient power, wealth, military prowess, or royal favour has occasionally enabled commoners to ascend into the nobility.\n\nThere are often a variety of ranks within the noble class. Legal recognition of nobility has been more common in monarchies, but nobility also existed in such regimes as the Dutch Republic (1581\u20131795), the Republic of Genoa (1005\u20131815), the Republic of Venice (697\u20131797), and the Old Swiss Confederacy (1300\u20131798), and remains part of the legal social structure of some non-hereditary regimes, e.g., San Marino, and the Vatican City in Europe. In Classical Antiquity, the  (nobles) of the Roman Republic were families descended from persons who had achieved the consulship. Those who belonged to the hereditary patrician families were nobles, but plebeians whose ancestors were consuls were also considered . In the Roman Empire, the nobility were descendants of this Republican aristocracy. While ancestry of contemporary noble families from ancient Roman nobility might technically be possible, no well-researched, historically-documented generation-by-generation genealogical descents from ancient Roman times are known to exist in Europe.\n\nHereditary titles and styles added to names (such as \"Prince\", \"Lord\", or \"Lady\"), as well as honorifics, often distinguish nobles from non-nobles in conversation and written speech. In many nations, most of the nobility have been untitled, and some hereditary titles do not indicate nobility (e.g., vidame). Some countries have had non-hereditary nobility, such as the Empire of Brazil or life peers in the United Kingdom.\n\nHistory\n\nThe term derives from Latin , the abstract noun of the adjective  (\"noble but also secondarily well-known, famous, notable\"). In ancient Roman society,  originated as an informal designation for the political governing class who had allied interests, including both patricians and plebeian families () with an ancestor who had risen to the consulship through his own merit (see , \"new man\").\n\nIn modern usage, \"nobility\" is applied to the highest social class in pre-modern societies. In the feudal system (in Europe and elsewhere), the nobility were generally those who held a fief, often land or office, under vassalage, i.e., in exchange for allegiance and various, mainly military, services to a suzerain, who might be a higher-ranking nobleman or a monarch. It rapidly came to be seen as a hereditary caste, sometimes associated with a right to bear a hereditary title and, for example in pre-revolutionary France, enjoying fiscal and other privileges.\n\nWhile noble status formerly conferred significant privileges in most jurisdictions, by the 21st century it had become a largely honorary dignity in most societies, although a few, residual privileges may still be preserved legally (e.g., Netherlands, Spain, UK) and some Asian, Pacific and African cultures continue to attach considerable significance to formal hereditary rank or titles. (Compare the entrenched position and leadership expectations of the nobility of the Kingdom of Tonga.) More than a third of British land is in the hands of aristocrats and traditional landed gentry.\n\nNobility is a historical, social and often legal notion, differing from high socio-economic status in that the latter is mainly based on income, possessions or lifestyle. Being wealthy or influential cannot  make one noble, nor are all nobles wealthy or influential (aristocratic families have lost their fortunes in various ways, and the concept of the 'poor nobleman' is almost as old as nobility itself).\n\nAlthough many societies have a privileged upper class with substantial wealth and power, the status is not necessarily hereditary and does not entail a distinct legal status, nor differentiated forms of address. Various republics, including European countries such as Greece, Turkey, Austria and former Iron Curtain countries and places in the Americas such as Mexico and the United States, have expressly abolished the conferral and use of titles of nobility for their citizens. This is distinct from countries which have not abolished the right to inherit titles, but which do not grant legal recognition or protection to them, such as Germany and Italy, although Germany recognizes their use as part of the legal surname. Still other countries and authorities allow their use, but forbid attachment of any privilege thereto, e.g., Finland, Norway and the European Union, while French law also protects lawful titles against usurpation.\n\nNoble privileges\n\nNot all of the benefits of nobility derived from noble status . Usually privileges were granted or recognised by the monarch in association with possession of a specific title, office or estate. Most nobles' wealth derived from one or more estates, large or small, that might include fields, pasture, orchards, timberland, hunting grounds, streams, etc. It also included infrastructure such as castle, well and mill to which local peasants were allowed some access, although often at a price. Nobles were expected to live \"nobly\", that is, from the proceeds of these possessions. Work involving manual labour or subordination to those of lower rank (with specific exceptions, such as in military or ecclesiastic service) was either forbidden (as derogation from noble status) or frowned upon socially. On the other hand, membership in the nobility was usually a prerequisite for holding offices of trust in the realm and for career promotion, especially in the military, at court and often the higher functions in the government, judiciary and church.\n\nPrior to the French Revolution, European nobles typically commanded tribute in the form of entitlement to cash rents or usage taxes, labour or a portion of the annual crop yield from commoners or nobles of lower rank who lived or worked on the noble's manor or within his seigneurial domain. In some countries, the local lord could impose restrictions on such a commoner's movements, religion or legal undertakings. Nobles exclusively enjoyed the privilege of hunting. In France, nobles were exempt from paying the taille, the major direct tax. Peasants were not only bound to the nobility by dues and services, but the exercise of their rights was often also subject to the jurisdiction of courts and police from whose authority the actions of nobles were entirely or partially exempt. In some parts of Europe the right of private war long remained the privilege of every noble.\n\nDuring the early Renaissance, duelling established the status of a respectable gentleman, and was an accepted manner of resolving disputes.\n\nSince the end of World War I the hereditary nobility entitled to special rights has largely been abolished in the Western World as intrinsically discriminatory, and discredited as inferior in efficiency to individual meritocracy in the allocation of societal resources. Nobility came to be associated with social rather than legal privilege, expressed in a general expectation of deference from those of lower rank. By the 21st century even that deference had become increasingly minimised. In general, the present nobility present in the European monarchies has no more privileges than the citizens decorated in republics.\n\nEnnoblement\n\nIn France, a  (lordship) might include one or more manors surrounded by land and villages subject to a noble's prerogatives and disposition.  could be bought, sold or mortgaged. If erected by the crown into, e.g., a barony or countship, it became legally entailed for a specific family, which could use it as their title. Yet most French nobles were untitled (\"seigneur of Montagne\" simply meant ownership of that lordship but not, if one was not otherwise noble, the right to use a title of nobility, as commoners often purchased lordships). Only a member of the nobility who owned a countship was allowed, , to style himself as its , although this restriction came to be increasingly ignored as the  drew to its close.\n\nIn other parts of Europe, sovereign rulers arrogated to themselves the exclusive prerogative to act as  within their realms. For example, in the United Kingdom royal letters patent are necessary to obtain a title of the peerage, which also carries nobility and formerly a seat in the House of Lords, but never came with automatic entail of land nor rights to the local peasants' output.\n\nRank within the nobility\n\nNobility might be either inherited or conferred by a fons honorum. It is usually an acknowledged preeminence that is hereditary, i.e. the status descends exclusively to some or all of the legitimate, and usually male-line, descendants of a nobleman. In this respect, the nobility as a class has always been much more extensive than the primogeniture-based titled nobility, which included peerages in France and in the United Kingdom, grandezas in Portugal and Spain, and some noble titles in Belgium, Italy, the Netherlands, Prussia and Scandinavia. In Russia, Scandinavia and non-Prussian Germany, titles usually descended to all male-line descendants of the original titleholder, including females. In Spain, noble titles are now equally heritable by females and males. Noble estates, on the other hand, gradually came to descend by primogeniture in much of western Europe aside from Germany. In Eastern Europe, by contrast, with the exception of a few Hungarian estates, they usually descended to all sons or even all children.\n\nIn France, some wealthy bourgeois, most particularly the members of the various parlements, were ennobled by the king, constituting the noblesse de robe. The old nobility of landed or knightly origin, the noblesse d'\u00e9p\u00e9e, increasingly resented the influence and pretensions of this parvenu nobility. In the last years of the ancien r\u00e9gime the old nobility pushed for restrictions of certain offices and orders of chivalry to noblemen who could demonstrate that their lineage had extended \"quarterings\", i.e. several generations of noble ancestry, to be eligible for offices and favours at court along with nobles of medieval descent, although historians such as William Doyle have disputed this so-called \"Aristocratic Reaction\". Various court and military positions were reserved by tradition for nobles who could \"prove\" an ancestry of at least seize quartiers (16 quarterings), indicating exclusively noble descent (as displayed, ideally, in the family's coat of arms) extending back five generations (all 16 great-great grandparents).\n\nThis illustrates the traditional link in many countries between heraldry and nobility; in those countries where heraldry is used, nobles have almost always been armigerous, and have used heraldry to demonstrate their ancestry and family history. However, heraldry has never been restricted to the noble classes in most countries, and being armigerous does not necessarily demonstrate nobility. Scotland, however, is an exception. In a number of recent cases in Scotland the Lord Lyon King of Arms has controversially ( Scotland's Salic law) granted the arms and allocated the chiefships of medieval noble families to female-line descendants of lords, even when they were not of noble lineage in the male line, while persons of legitimate male-line descent may still survive (e.g. the modern Chiefs of Clan MacLeod).\n\nIn some nations, hereditary titles, as distinct from noble rank, were not always recognised in law, e.g., Poland's Szlachta. European ranks of nobility lower than baron or its equivalent, are commonly referred to as the petty nobility, although baronets of the British Isles are deemed titled gentry. Most nations traditionally had an untitled lower nobility in addition to titled nobles. An example is the landed gentry of the British Isles. Unlike England's gentry, the Junkers of Germany, the noblesse de robe of France, the hidalgos of Spain and the nobili of Italy were explicitly acknowledged by the monarchs of those countries as members of the nobility, although untitled. In Scandinavia, the Benelux nations and Spain there are still untitled as well as titled families recognised in law as noble.\n\nIn Hungary members of the nobility always theoretically enjoyed the same rights. In practice, however, a noble family's financial assets largely defined its significance. Medieval Hungary's concept of nobility originated in the notion that nobles were \"free men\", eligible to own land. This basic standard explains why the noble population was relatively large, although the economic status of its members varied widely. Untitled nobles were not infrequently wealthier than titled families, while considerable differences in wealth were also to be found within the titled nobility. The custom of granting titles was introduced to Hungary in the 16th century by the House of Habsburg. Historically, once nobility was granted, if a nobleman served the monarch well he might obtain the title of baron, and might later be elevated to the rank of count. As in other countries of post-medieval central Europe, hereditary titles were not attached to a particular land or estate but to the noble family itself, so that all patrilineal descendants shared a title of baron or count (cf. peerage). Neither nobility nor titles could be transmitted through women.\n\nSome con artists sell fake titles of nobility, often with impressive-looking documentation. This may be illegal, depending on local law. They are more often illegal in countries that actually have nobilities, such as European monarchies. In the United States, such commerce may constitute actionable fraud rather than criminal usurpation of an exclusive right to use of any given title by an established class.\n\nOther terms\n\n\"Aristocrat\" and \"aristocracy\", in modern usage, refer colloquially and broadly to persons who inherit elevated social status, whether due to membership in the (formerly) official nobility or the monied upper class.\n\nBlue blood is an English idiom recorded since 1811 in the Annual Register  and in 1834  for noble birth or descent; it is also known as a translation of the Spanish phrase sangre azul, which described the Spanish royal family and high nobility who claimed to be of Visigothic descent, in contrast to the Moors. The idiom originates from ancient and medieval societies of Europe and distinguishes an upper class (whose superficial veins appeared blue through their untanned skin) from a working class of the time. The latter consisted mainly of agricultural peasants who spent most of their time working outdoors and thus had tanned skin, through which superficial veins appear less prominently.\n\nRobert Lacey explains the genesis of the blue blood concept:It was the Spaniards who gave the world the notion that an aristocrat's blood is not red but blue. The Spanish nobility started taking shape around the ninth century in classic military fashion, occupying land as warriors on horseback. They were to continue the process for more than five hundred years, clawing back sections of the peninsula from its Moorish occupiers, and a nobleman demonstrated his pedigree by holding up his sword arm to display the filigree of blue-blooded veins beneath his pale skin\u2014proof that his birth had not been contaminated by the dark-skinned enemy.\n\nEurope\n\nEuropean nobility originated in the feudal/seignorial system that arose in Europe during the Middle Ages. Originally, knights or nobles were mounted warriors who swore allegiance to their sovereign and promised to fight for him in exchange for an allocation of land (usually together with serfs living thereon). During the period known as the Military Revolution, nobles gradually lost their role in raising and commanding private armies, as many nations created cohesive national armies.\n\nThis was coupled with a loss of the socio-economic power of the nobility, owing to the economic changes of the Renaissance and the growing economic importance of the merchant classes, which increased still further during the Industrial Revolution. In countries where the nobility was the dominant class, the bourgeoisie gradually grew in power; a rich city merchant came to be more influential than a nobleman, and the latter sometimes sought inter-marriage with families of the former to maintain their noble lifestyles.\n\nHowever, in many countries at this time, the nobility retained substantial political importance and social influence: for instance, the United Kingdom's government was dominated by the (unusually small) nobility until the middle of the 19th century. Thereafter the powers of the nobility were progressively reduced by legislation. However, until 1999, all hereditary peers were entitled to sit and vote in the House of Lords. Since then, only 92 of them have this entitlement, of whom 90 are elected by the hereditary peers as a whole to represent the peerage.\n\nThe countries with the highest proportion of nobles were Castile (probably 10%),  Polish\u2013Lithuanian Commonwealth (15% of an 18th-century population of 800,000), Spain (722,000 in 1768 which was 7\u20138% of the entire population) and other countries with lower percentages, such as Russia in 1760 with 500,000\u2013600,000 nobles (2\u20133% of the entire population), and pre-revolutionary France where there were no more than 300,000 prior to 1789, which was 1% of the population (although some scholars believe this figure is an overestimate). In 1718 Sweden had between 10,000 and 15,000 nobles, which was 0.5% of the population. In Germany it was 0.01%.\n\nIn the Kingdom of Hungary nobles made up 5% of the population. All the nobles in 18th-century Europe numbered perhaps 3\u20134 million out of a total of 170\u2013190 million inhabitants.  By contrast, in 1707, when England and Scotland united into Great Britain, there were only 168 English peers, and 154 Scottish ones, though their immediate families were recognised as noble.\n\nApart from the hierarchy of noble titles, in England rising through baron, viscount, earl, and marquess to duke, many countries had categories at the top or bottom of the nobility. The gentry, relatively small landowners with perhaps one or two villages, were mostly noble in most countries, for example the Polish landed gentry.  At the top, Poland had a far smaller class of \"magnates\", who were hugely rich and politically powerful.  In other countries the small groups of Spanish Grandee or Peer of France had great prestige but little additional power.\n\nAsia\n\nIndia, Pakistan, Bangladesh and Nepal\n\nIn the Indian Subcontinent during the British Raj, many members of the nobility were elevated to royalty as they became the monarchs of their princely states and vice versa as many princely state rulers were reduced from royals to noble Zamindars. Hence, many nobles in the subcontinent had royal titles of Raja, Rai, Rana, Rao, etc. In Nepal, Kaji () was a title and position used by nobility of Gorkha Kingdom (1559\u20131768) and Kingdom of Nepal  (1768\u20131846). Historian Mahesh Chandra Regmi suggests that Kaji is derived from Sanskrit word Karyi which meant functionary.\n\nOther noble and aristocratic titles were Thakur, Sardar, Dewan, Pradhan, Kaji etc.\n\nChina\nIn East Asia the system was often modelled on imperial China, the leading culture. Emperors conferred titles of nobility. Imperial descendants formed the highest class of ancient Chinese nobility, their status based upon the rank of the empress or concubine from which they descend maternally (as emperors were polygamous). Numerous titles such as Taizi (crown prince), and equivalents of \"prince\" were accorded, and due to complexities in dynastic rules, rules were introduced for Imperial descendants. The titles of the junior princes were gradually lowered in rank by each generation while the senior heir continued to inherit their father's titles.\n\nIt was a custom in China for the new dynasty to ennoble and enfeoff a member of the dynasty which they overthrew with a title of nobility and a fief of land so that they could offer sacrifices to their ancestors, in addition to members of other preceding dynasties.\n\nChina had a feudal system in the Shang and Zhou dynasties, which gradually gave way to a more bureaucratic one beginning in the Qin dynasty (221 BC). This continued through the Song dynasty, and by its peak power shifted from nobility to bureaucrats.\n\nThis development was gradual and generally only completed in full by the Song dynasty. In the Han dynasty, for example, even though noble titles were no longer given to those other than the Emperor's relatives, the fact that the process of selecting officials was mostly based on a vouching system by current officials as officials usually vouched for their own sons or those of other officials meant that a de facto aristocracy continued to exist. This process was further deepened during the Three Kingdoms period with the introduction of the Nine-rank system.\n\nBy the Sui dynasty, however, the institution of the Imperial examination system marked the transformation of a power shift towards a full bureaucracy, though the process would not be truly completed until the Song dynasty.\n\nTitles of nobility became symbolic along with a stipend while governance of the country shifted to scholar officials.\n\nIn the Qing dynasty titles of nobility were still granted by the emperor, but served merely as honorifics based on a loose system of favours to the Qing emperor.\n\nUnder a centralized system, the empire's governance was the responsibility of the Confucian-educated scholar-officials and the local gentry, while the literati were accorded gentry status. For male citizens, advancement in status was possible via garnering the top three positions in imperial examinations.\n\nThe Qing appointed the Ming imperial descendants to the title of Marquis of Extended Grace.\n\nThe oldest held continuous noble title in Chinese history was that held by the descendants of Confucius, as Duke Yansheng, which was renamed as the Sacrificial Official to Confucius in 1935 by the Republic of China. The title is held by Kung Tsui-chang. There is also a \"Sacrificial Official to Mencius\" for a descendant of Mencius, a \"Sacrificial Official to Zengzi\" for a descendant of Zengzi, and a \"Sacrificial Official to Yan Hui\" for a descendant of Yan Hui.\n\nThe bestowal of titles was abolished upon the establishment of the People's Republic of China in 1949, as part of a larger effort to remove feudal influences and practises from Chinese society.\n\nIslamic world\nIn some Islamic countries, there are no definite noble titles (titles of hereditary rulers being distinct from those of hereditary intermediaries between monarchs and commoners). Persons who can trace legitimate descent from Muhammad or the clans of Quraysh, as can members of several present or formerly reigning dynasties, are widely regarded as belonging to the ancient, hereditary Islamic nobility. In some Islamic countries they inherit (through mother or father) hereditary titles, although without any other associated privilege, e.g., variations of the title Sayyid and Sharif. Regarded as more religious than the general population, many people turn to them for clarification or guidance in religious matters.\n\nIn Iran, historical titles of the nobility including Mirza, Khan, ed-Dowleh and Shahzada (\"Son of a Shah), are now no longer recognised. An aristocratic family is now recognised by their family name, often derived from the post held by their ancestors, considering the fact that family names in Iran only appeared in the beginning of the 20th century.\nSultans have been an integral part of Islamic history .\n\nDuring the Ottoman Empire in the Imperial Court and the provinces there were many Ottoman titles and appellations forming a somewhat unusual and complex system in comparison with the other Islamic countries. The bestowal of noble and aristocratic titles was widespread across the empire even after its fall by independent monarchs. One of the most elaborate examples is that of the Egyptian aristocracy's largest clan, the Abaza family.\n\nJapan\n\nMedieval Japan developed a feudal system similar to the European system, where land was held in exchange for military service. The daimy\u014d class, or hereditary landowning nobles, held great socio-political power. As in Europe, they commanded private armies made up of samurai, an elite warrior class; for long periods, these held the real power without a real central government, and often plunged the country into a state of civil war. The daimy\u014d class can be compared to European peers, and the samurai to European knights, but important differences exist.\n\nFeudal title and rank were abolished during the Meiji Restoration in 1868, and was replaced by the kazoku, a five-rank peerage system after the British example, which granted seats in the upper house of the Imperial Diet; this ended in 1947 following Japan's defeat in World War II.\n\nPhilippines\n\nLike other Southeast Asian countries, many regions in the Philippines have indigenous nobility, partially influenced by Hindu, Chinese, and Islamic custom. Since ancient times, Datu was the common title of a chief or monarch of the many pre-colonial principalities and sovereign dominions throughout the isles; in some areas the term Apo was also used. With the titles Sultan and Rajah, Datu (and its Malay cognate, Datok) are currently used in some parts of the Philippines, Indonesia, Malaysia and Brunei. These titles are the rough equivalents of European titles, albeit dependent on the actual wealth and prestige of the bearer.\n\nRecognition by the Spanish Crown\n\nUpon the islands' Christianisation, the datus retained governance of their territories despite annexation to the Spanish Empire. In a law signed 11 June 1594, King Philip II of Spain ordered that the indigenous rulers continue to receive the same honours and privileges accorded them prior their conversion to Catholicism. The baptised nobility subsequently coalesced into the exclusive, landed ruling class of the lowlands known as the Principal\u00eda.\n\nOn 22 March 1697, King Charles II of Spain confirmed the privileges granted by his predecessors (in Title VII, Book VI of the Laws of the Indies) to indigenous nobilities of the Crown colonies, including the Principales of the Philippines, and extended to them and to their descendants the preeminence and honors customarily attributed to the Hidalgos of Castile.\n\nFilipino nobles during the Spanish era\nThe Laws of the Indies and other pertinent Royal Decrees were enforced in the Philippines and benefited many indigenous nobles. It can be seen very clearly and irrefutably that, during the colonial period, indigenous chiefs were equated with the Spanish Hidalgos, and the most resounding proof of the application of this comparison is the General Military Archive in Segovia, where the qualifications of \"Nobility\" (found in the Service Records) are attributed to those Filipinos who were admitted to the Spanish Military Academies and whose ancestors were caciques, encomenderos, notable Tagalogs, chieftains,  governors or those  who held positions in the municipal administration or government in all different regions of the large islands of the Archipelago, or of the many small islands of which it is composed. In the context of the ancient tradition and norms of Castilian nobility, all descendants of a noble are considered noble, regardless of fortune.\n\nAt the Real Academia de la Historia, there is a substantial number of records providing reference to the Philippine Islands, and while most parts correspond to the history of these islands, the Academia did not exclude among its documents the presence of many genealogical records. The archives of the Academia and its royal stamp recognized the appointments of hundreds of natives of the Philippines who, by virtue of their social position, occupied posts in the administration of the territories and were classified as \"nobles\". The presence of these notables demonstrates the cultural concern of Spain in those Islands to prepare the natives and the collaboration of these in the government of the Archipelago. This aspect of Spanish rule in the Philippines appears much more strongly implemented than in the Americas. Hence in the Philippines, the local nobility, by reason of charge accorded to their social class, acquired greater importance than in the Indies of the New World.\n\nWith the recognition of the Spanish monarchs came the privilege of being addressed as Don or Do\u00f1a, a mark of esteem and distinction in Europe reserved for a person of noble or royal status during the colonial period. Other honors and high regard were also accorded to the Christianized Datus by the Spanish Empire. For example, the Gobernadorcillos (elected leader of the Cabezas de Barangay or the Christianized Datus) and Filipino officials of justice received the greatest consideration from the Spanish Crown officials. The colonial officials were under obligation to show them the honor corresponding to their respective duties. They were allowed to sit in the houses of the Spanish Provincial Governors, and in any other places. They were not left to remain standing. It was not permitted for Spanish Parish Priests to treat these Filipino nobles with less consideration.\n\nThe Gobernadorcillos exercised the command of the towns. They were Port Captains in coastal towns. They also had the rights and powers to elect assistants and several lieutenants and alguaciles, proportionate in number to the inhabitants of the town.\n\nCurrent status questionis\n\nThe recognition of the rights and privileges accorded to the Filipino Principal\u00eda as Hijosdalgos of Castile seems to facilitate entrance of Filipino nobles into institutions of  under the Spanish Crown, either civil or religious, which required proofs of nobility. However, to see such recognition as an approximation or comparative estimation of rank or status might not be correct since in reality, although the principales were vassals of the Crown, their rights as sovereign in their former dominions were guaranteed by the Laws of the Indies, more particularly the Royal Decree of Philip II of 11 June 1594, which Charles II confirmed for the purpose stated above in order to satisfy the requirements of the existing laws in the Peninsula.\n\nIt must be recalled that ever since the beginning of the colonialization, the conquistador Miguel L\u00f3pez de Legazpi did not strip the ancient sovereign rulers of the Archipelago (who vowed allegiance to the Spanish Crown) of their legitimate rights. Many of them accepted the Catholic religion and were his allies from the very beginning. He only demanded from these local rulers vassalage to the Spanish Crown, replacing the similar overlordship, which previously existed in a few cases, e.g., Sultanate of Brunei's overlordship of the Kingdom of Maynila. Other independent polities which were not vassals to other States, e.g., Confederation of Madja-as and the Rajahnate of Cebu, were more of Protectorates/Suzerainties having had alliances with the Spanish Crown before the Kingdom took total control of most parts of the Archipelago. An interesting question remains after the cessession of the Spanish rule in the Philippines, that is, what is the equivalent of the rank of the Filipino Principal\u00eda, freed from vassalage yet not able to exercise their sovereignty within the democratic society in the Archipelago?\n\nOne logical conclusion would be the reassumption of their ancestral Royal and noble title as Datus while retaining the Hidalgu\u00eda of Castile (their former protector State), as a subsidiary title, appears most suitable to the hispanized Filipino nobles. Besides, as stated in the above-mentioned Royal Decree of Charles II, the ancient nobility of the Filipino Principales \"is still retained and acknowledged\".\n\nJust like the deposed royal families elsewhere in the world, which still lay claim to their hereditary rights as pretenders to the former thrones of their ancestors, the descendants of the Principal\u00eda have the same de iure claims to the historical domains of their forebears.\n\nAfrica\nAfrica has a plethora of ancient lineages in its various constituent nations. Some, such as the numerous sharifian families of North Africa, the Keita dynasty of Mali, the Solomonic dynasty of Ethiopia, the De Souza family of Benin and the Sherbro Tucker clan of Sierra Leone, claim descent from notables from outside of the continent. Most, such as those composed of the descendants of Shaka and Moshoeshoe of Southern Africa, belong to peoples that have been resident in the continent for millennia. Generally their royal or noble status is recognized by and derived from the authority of traditional custom. A number of them also enjoy either a constitutional or a statutory recognition of their high social positions.\n\nEthiopia\n\nEthiopia has a nobility that is almost as old as the country itself. Throughout the history of the Ethiopian Empire most of the titles of nobility have been tribal or military in nature. However the Ethiopian nobility resembled its European counterparts in some respects;  until 1855, when Tewodros II ended the Zemene Mesafint its aristocracy was organised similarly to the feudal system in Europe during the Middle Ages. For more than seven centuries, Ethiopia (or Abyssinia, as it was then known) was made up of many small kingdoms, principalities, emirates and imamates, which owed their allegiance to the n\u0259gus\u00e4 n\u00e4g\u00e4st (literally \"King of Kings\"). Despite its being a Christian monarchy, various Muslim states paid tribute to the emperors of Ethiopia for centuries: including the Adal Sultanate, the Emirate of Harar, and the Awsa sultanate.\n\nEthiopian nobility were divided into two different categories: Mesafint (\"prince\"), the hereditary nobility that formed the upper echelon of the ruling class; and the Mekwanin (\"governor\") who were appointed nobles, often of humble birth, who formed the bulk of the nobility (cf. the Ministerialis of the Holy Roman Empire). In  Ethiopia there were titles of nobility among the Mesafint borne by those at the apex of medieval Ethiopian society. The highest royal title (after that of emperor) was Negus (\"king\") which was held by hereditary governors of the provinces of Begemder, Shewa, Gojjam, and Wollo. The next highest seven titles were Ras, Dejazmach, Fit'awrari, Grazmach, Qenyazmach, Azmach and Balambaras. The title of Le'ul Ras was accorded to the heads of various noble families and cadet branches of the Solomonic dynasty, such as the princes of Gojjam, Tigray, and Selalle. The heirs of the Le'ul Rases were titled Le'ul Dejazmach, indicative of the higher status they enjoyed relative to Dejazmaches who were not of the blood imperial. There were various hereditary titles in Ethiopia: including that of Jantirar, reserved for males of the family of Empress Menen Asfaw who ruled over the mountain fortress of Ambassel in Wollo; Wagshum, a title created for the descendants of the deposed Zagwe dynasty; and Shum Agame, held by the descendants of Dejazmach Sabagadis, who ruled over the Agame district of Tigray. The  vast majority of titles borne by nobles were not, however, hereditary.\n\nDespite being largely dominated by Christian elements, some Muslims obtained entr\u00e9e into the Ethiopian nobility as part of their quest for aggrandizement during the 1800s. To do so they were generally obliged to abandon their faith and some are believed to have feigned conversion to Christianity for the sake of acceptance by the old Christian aristocratic families. One such family, the Wara Seh (more commonly called the \"Yejju dynasty\") converted to Christianity and eventually wielded power for over a century, ruling with the sanction of the Solomonic emperors. The last such Muslim noble to join the ranks of Ethiopian society was Mikael of Wollo who converted, was made Negus of Wollo, and later King of Zion, and even married into the Imperial family. He lived to see his son, Iyasu V, inherit the throne in 1913\u2014only to be deposed in 1916 because of his conversion to Islam.\n\nMadagascar\n\nThe nobility in Madagascar are known as the Andriana. In much of Madagascar, before French colonization of the island, the Malagasy people were organised into a rigid social caste system, within which the Andriana exercised both spiritual and political leadership. The word \"Andriana\" has been used to denote nobility in various ethnicities in Madagascar: including  the Merina, the Betsileo, the Betsimisaraka, the Tsimihety, the Bezanozano, the Antambahoaka and the Antemoro.\n\nThe word Andriana has often formed part of the names of Malagasy kings, princes and nobles. Linguistic evidence suggests that the origin of the title Andriana is traceable back to an ancient Javanese title of nobility. Before the colonization by France in the 1890s, the Andriana held various privileges, including land ownership, preferment for senior government posts, free labor from members of lower classes, the right to have their tombs constructed within town limits, etc. The Andriana rarely married outside their caste: a high-ranking woman who married a lower-ranking man took on her husband's lower rank, but a high-ranking man marrying a woman of lower rank did not forfeit his status, although his children could not inherit his rank or property (cf. morganatic marriage).\n\nIn 2011, the Council of Kings and Princes of Madagascar endorsed the revival of a Christian Andriana monarchy that would blend modernity and tradition.\n\nNigeria\n\nContemporary Nigeria has a class of traditional notables which is led by its reigning monarchs, the Nigerian traditional rulers. Though their functions are largely ceremonial, the titles of the country's noblemen and women are often centuries old and are usually vested in the membership of historically prominent families in the various subnational kingdoms of the country.\n\nMembership of initiatory societies that have inalienable functions within the kingdoms is also a common feature of Nigerian nobility, particularly among the southern tribes, where such figures as the Ogboni of the Yoruba, the Nze na Ozo of the Igbo and the Ekpe of the Efik are some of the most famous examples. Although many of their traditional functions have become dormant due to the advent of modern governance, their members retain precedence of a traditional nature and are especially prominent during festivals.\n\nOutside of this, many of the traditional nobles of Nigeria continue to serve as privy counsellors and viceroys in the service of their traditional sovereigns in a symbolic continuation of the way that their titled ancestors and predecessors did during the pre-colonial and colonial periods. Many of them are also members of the country's political elite due to their not being covered by the prohibition from involvement in politics that governs the activities of the traditional rulers.\n\nHolding a chieftaincy title, either of the traditional variety (which involves taking part in ritual re-enactments of your title's history during annual festivals, roughly akin to a British peerage) or the honorary variety (which does not involve the said re-enactments, roughly akin to a knighthood), grants an individual the right to use the word \"chief\" as a pre-nominal honorific while in Nigeria.\n\nLatin America\nIn addition to a variety of indigenous peoples (such as the Aymara and the Quechua, who have long traditions of being led by monarchs and nobles called Apu Mallkus and Mallkus), aristocratic connections exist among a number of other groups. Peerage traditions dating to the colonial period of such countries as Brazil, Cuba and Mexico have left noble families in each of them that have ancestral ties to those nations' native tribes, while such figures as the Afro-Bolivian king and the high priestess of the Ile Maroia Laji sect of Brazilian Candombl\u00e9 trace their ancestries to and derive their prestige from ancient monarchs and nobles of the pre-colonial African continent.\n\nBolivia \n\nIn addition to the Criollo upper class that dates to the era of Colonial Bolivia and that has ancestral ties to the Spanish nobility, the South American country also has a ceremonial monarchy that is recognized as part of the Plurinational State of Bolivia and that is led by a titular ruler who is known as the Afro-Bolivian king. \n\nThe members of the royal house that he belongs to are the direct descendants of an old African tribal monarchy that were brought to Bolivia as slaves. They have provided leadership to the Afro-Bolivian community ever since that event and have been officially recognized by Bolivia's government since 2007.\n\nBrazil \n\nThe nobility in Brazil began during the colonial era with the Portuguese nobility. When Brazil became a united kingdom with Portugal in 1815, the first Brazilian titles of nobility were granted by the King of Portugal, Brazil and the Algarves.\n\nWith the independence of Brazil in 1822 as a constitutional monarchy, the titles of nobility initiated by the King of Portugal were continued and new titles of nobility were created by the Emperor of Brazil. However, according to the Brazilian Constitution of 1824, the Emperor conferred titles of nobility, which were personal and therefore non-hereditary, unlike the earlier Portuguese and Portuguese-Brazilian titles, being inherited exclusively to the royal titles of the Brazilian Imperial Family.\n\nDuring the existence of the Empire of Brazil, 1,211 noble titles were acknowledged.  With the proclamation of the First Brazilian Republic, in 1889, the Brazilian nobility was extinguished. It was also prohibited, under penalty of accusation of high treason and the suspension of political rights, to accept noble titles and foreign decorations without the proper permission of the State. In particular, the nobles of greater distinction, by respect and tradition, were allowed to use their titles during the republican regime. The Imperial Family also could not return to the Brazilian soil until 1921, when the Banishment Law was repealed.\n\nNobility by nation\n\nA list of noble titles for different European countries can be found at Royal and noble ranks.\n\nAfrica\n Botswanan chieftaincy\n Kgosi\n Burundian nobility\n Egyptian nobility\n Ethiopian nobility\n Ghanaian chieftaincy\n Akan chieftaincy\n Malagasy nobility\n Malian nobility\n Nigerian chieftaincy\n Nigerian traditional rulers\n Lamido\nHakimi\n Oba\nOgboni\n Eze\nNze na Ozo\n Rwandan nobility\n Somali nobility\n Zimbabwean chieftaincy\n\nAmerica\n Canadian peers and baronets\n Brazilian nobility\n Cuban nobility\n Incan nobility\n Mexican nobility\n Pipiltin\n\nAsia\n Armenian nobility\n Chinese nobility\n Filipino nobility\n Indian peers and baronets\nKaji (Nepal)\nPande family \nBasnyat family \nThapa family \nKunwar family or Rana dynasty\nIndonesian (Dutch East Indies) nobility\nNoblesse de robe\n Japanese nobility\n Kuge\n Daimy\u014d\n  Burmese nobility\n Burmese Mon nobility\n Shan nobility\n Kachin nobility\n Korean nobility\n Vietnamese nobility\n Malay nobility\n Mongolian nobility\n Ottoman titles\n Thai nobility\n\nEurope\n Albanian nobility\n Austrian nobility\n Baltic nobility - ethnically Baltic German nobility in the modern area of Estonia and Latvia\n Belgian nobility\n British nobility                               \n British peerage \n Peerage of Great Britain\n Peerage of the United Kingdom\n English peerage\n Scottish noblesse\nScottish peerage\nBarons\nLairds\n Welsh Peers\n Irish nobility\n Chiefs of the Name\n Irish peerage\n\n Byzantine aristocracy and bureaucracy\nPhanariotes\n Croatian nobility\n Czech nobility\n Danish nobility\n Dutch nobility\n Finnish nobility\n French nobility\n German nobility\n Freiherr\n Graf\n Junker\n Hungarian nobility\n Icelandic nobility\n Italian nobility\n Black Nobility\n Lithuanian nobility\n Montenegrin nobility\n Norwegian nobility\n Polish nobility\n Magnates\n Portuguese nobility\n Russian nobility\n Boyars\n Serbian nobility\n Spanish nobility\n Swedish nobility\n Swiss nobility\n\nOceania\n Australian peers and baronets\n Fijian nobility\n Polynesian nobility\n Samoan nobility\n Tongan nobles\n\nSee also\n\n Almanach de Gotha\n Aristocracy (class)\n Ascribed status\n Baig\n Caste (social hierarchy of India)\n Debutante\n False titles of nobility\n Gentleman\n Gentry\n Grand Burgher (German: Gro\u00dfb\u00fcrger)\n Heraldry\n Honour\n Kaji (Nepal)\n King\n List of fictional nobility\n List of noble houses\n Magnate\n Military elite\n Military Revolution\n Nobiliary particle\n Noblesse oblige\n Nze na Ozo\n Ogboni\n Pasha\n Patrician (ancient Rome)\n Patrician (post-Roman Europe)\n Peerage\n Petty nobility\n Princely state\n Raja\n Redorer son blason\n Royal descent\n Social environment\n Symbolic capital\n\nReferences\n\nExternal links\n\n WW-Person, an on-line database of European noble genealogy\n Worldroots, a selection of art and genealogy of European nobility\n Worldwidewords\n Etymology OnLine\n Genesis of European Nobility\n A few notes about grants of titles of nobility by modern Serbian Monarchs\n\n \nEstates (social groups)\nFeudalism\nOligarchy\nSocial classes",
  "Communication": "Communication (from Latin communicare, meaning \"to share\" or \"to be in relation with\") is \"an apparent answer to the painful divisions between self and other, private and public, and inner thought and outer world.\" As this definition indicates, communication is difficult to define in a consistent manner, because it is commonly used to refer to a wide range of different behaviors (broadly: \"the transfer of information\"), or to limit what can be included in the category of communication (for example, requiring a \"conscious intent\" to persuade). John Peters argues the difficulty of defining communication emerges from the fact that communication is both a universal phenomenon (because everyone communicates) and a specific discipline of institutional academic study.\n\nOne possible definition of communication is the act of developing meaning among entities or groups through the use of sufficiently mutually understood signs, symbols, and semiotic conventions.\n\nIn Claude Shannon's and Warren Weaver's influential model, human communication was imagined to function like a telephone or telegraph. Accordingly, they conceptualized communication as involving discrete steps:\n\n The formation of communicative motivation or reason.\n Message composition (further internal or technical elaboration on what exactly to express).\n Message encoding (for example, into digital data, written text, speech, pictures, gestures and so on).\n Transmission of the encoded message as a sequence of signals using a specific channel or medium.\n Noise sources such as natural forces and in some cases human activity (both intentional and accidental) begin influencing the quality of signals propagating from the sender to one or more receivers.\n Reception of signals and reassembling of the encoded message from a sequence of received signals.\n Decoding of the reassembled encoded message.\n Interpretation and making sense of the presumed original message.\n\nThese elements are now understood to be substantially overlapping and recursive activities rather than steps in a sequence. For example, communicative actions can commence before a communicator formulates a conscious attempt to do so, as in the case of phatics; likewise, communicators modify their intentions and formulations of a message in response to real-time feedback (e.g., a change in facial expression). Practices of decoding and interpretation are culturally enacted, not just by individuals (genre conventions, for instance, trigger anticipatory expectations for how a message is to be received), and receivers of any message operationalize their own frames of reference in interpretation.\n\nThe scientific study of communication can be divided into:\n Information theory which studies the quantification, storage, and communication of information in general;\n Communication studies which concerns human communication;\n Biosemiotics which examines communication in and between living organisms in general.\n Biocommunication which exemplifies sign-mediated interactions in and between organisms of all domains of life, including viruses.\n\nCommunication can be realized visually (through images and written language), through auditory, tactile/haptic (e.g. Braille or other physical means), olfactory, electromagnetic, or biochemical means (or any combination thereof). Human communication is unique for its extensive use of abstract language.\n\nTypes\n\nNon-verbal communication\n\nNonverbal communication explains the processes that convey a type of information in a form of non-linguistic representations. Examples of nonverbal communication include haptic communication, chronemic communication, gestures, body language, facial expressions, eye contact etc. Nonverbal communication also relates to the intent of a message. Examples of intent are voluntary, intentional movements like shaking a hand or winking, as well as involuntary, such as sweating. Speech also contains nonverbal elements known as paralanguage, e.g. rhythm, intonation, tempo, and stress. It affects communication most at the subconscious level and establishes trust. Likewise, written texts include nonverbal elements such as handwriting style, the spatial arrangement of words and the use of emoticons to convey emotion.\n\nNonverbal communication demonstrates one of Paul Watzlawick's laws: you cannot not communicate. Once proximity has formed awareness, living creatures begin interpreting any signals received. Some of the functions of nonverbal communication in humans are to complement and illustrate, to reinforce and emphasize, to replace and substitute, to control and regulate, and to contradict the denotative message.\n\nNonverbal cues are heavily relied on to express communication and to interpret others' communication and can replace or substitute verbal messages. \n\nThere are several reasons as to why non-verbal communication plays a vital role in communication:\n\n\"Non-verbal communication is omnipresent.\" They are included in every single communication act. To have total communication, all non-verbal channels such as the body, face, voice, appearance, touch, distance, timing, and other environmental forces must be engaged during face-to-face interaction. Written communication can also have non-verbal attributes. E-mails, web chats, and the social media have options to change text font colours, stationery, add emoticons, capitalization, and pictures in order to capture non-verbal cues into a verbal medium.\n\n\"Non-verbal behaviours are multifunctional.\" Many different non-verbal channels are engaged at the same time in communication acts and allow the chance for simultaneous messages to be sent and received.\n\n\"Non-verbal behaviours may form a universal language system.\" Smiling, crying, pointing, caressing, and glaring are non-verbal behaviours that are used and understood by people regardless of nationality. Such non-verbal signals allow the most basic form of communication when verbal communication is not effective due to language barriers.\n\nWhen verbal messages contradict non-verbal messages, observation of non-verbal behaviour is relied on to judge another's attitudes and feelings, rather than assuming the truth of the verbal message alone.\n\nVerbal communication\nVerbal communication is the spoken or written conveyance of a message. Human language can be defined as a system of symbols (sometimes known as lexemes) and the grammars (rules) by which the symbols are manipulated. The word \"language\" also refers to common properties of languages. Language learning normally occurs most intensively during human childhood. Most of the large number of human languages use patterns of sound or gesture for symbols which enable communication with others around them. Languages tend to share certain properties, although there are exceptions. Constructed languages such as Esperanto, programming languages, and various mathematical formalisms are not necessarily restricted to the properties shared by human languages.\n\nAs previously mentioned, language can be characterized as symbolic. Charles Ogden and I.A Richards developed The Triangle of Meaning model to explain the symbol (the relationship between a word), the referent (the thing it describes), and the meaning (the thought associated with the word and the thing).\n\nThe properties of language are governed by rules. Language follows phonological rules (sounds that appear in a language), syntactic rules (arrangement of words and punctuation in a sentence), semantic rules (the agreed upon meaning of words), and pragmatic rules (meaning derived upon context).\n\nThe meanings that are attached to words can be literal, or otherwise known as denotative; relating to the topic being discussed, or, the meanings take context and relationships into account, otherwise known as connotative; relating to the feelings, history, and power dynamics of the communicators.\n\nContrary to popular belief, signed languages of the world (e.g., American Sign Language) are considered to be verbal communication because their sign vocabulary, grammar, and other linguistic structures abide by all the necessary classifications as spoken languages. There are however, nonverbal elements to signed languages, such as the speed, intensity, and size of signs that are made. A signer might sign \"yes\" in response to a question, or they might sign a sarcastic-large slow yes to convey a different nonverbal meaning. The sign yes is the verbal message while the other movements add nonverbal meaning to the message.\n\nWritten communication and its historical development\nOver time the forms of and ideas about communication have evolved through the continuing progression of technology. Advances include communications psychology and media psychology, an emerging field of study.\n\nThe progression of written communication can be divided into three \"information communication revolutions\":\n\n Written communication first emerged through the use of pictographs. The pictograms were made in stone, hence written communication was not yet mobile. Pictograms began to develop standardized and simplified forms.\n The next step occurred when writing began to appear on paper, papyrus, clay, wax, and other media with commonly shared writing systems, leading to adaptable alphabets. Communication became mobile.\n The final stage is characterized by the transfer of information through controlled waves of electromagnetic radiation (i.e., radio, microwave, infrared) and other electronic signals.\n\nCommunication is thus a process by which meaning is assigned and conveyed in an attempt to create shared understanding. Gregory Bateson called it \"the replication of tautologies in the universe. This process, which requires a vast repertoire of skills in interpersonal processing, listening, observing, speaking, questioning, analyzing, gestures, and evaluating enables collaboration and cooperation.\n\nCommunication models\n\nThe first major model for communication was introduced by Claude Shannon and Warren Weaver for Bell Laboratories in 1949 The original model was designed to mirror the functioning of radio and telephone technologies. Their initial model consisted of three primary parts: sender, channel, and receiver. The sender was the part of a telephone a person spoke into, the channel was the telephone itself, and the receiver was the part of the phone where one could hear the other person. Shannon and Weaver also recognized that often there is static that interferes with one listening to a telephone conversation, which they deemed noise.\n\nIn a simple model, often referred to as the transmission model or standard view of communication, information or content (e.g. a message in natural language) is sent in some form (as spoken language) from an emitter (emisor in the picture)/sender/encoder to a destination/receiver/decoder. This common conception of communication simply views communication as a means of sending and receiving information. The strengths of this model are simplicity, generality, and quantifiability. Claude Shannon and Warren Weaver structured this model based on the following elements:\n An information source, which produces a message.\n A transmitter, which encodes the message into signals.\n A channel, to which signals are adapted for transmission.\n A noise source, which distorts the signal while it propagates through the channel.\n A receiver, which 'decodes' (reconstructs) the message from the signal.\n A destination, where the message arrives.\n\nShannon and Weaver argued that there were three levels of problems for communication within this theory.\n The technical problem: how accurately can the message be transmitted?\n The semantic problem: how precisely is the meaning conveyed?\n The effectiveness problem: how effectively does the received meaning affect behavior?\n\nDaniel Chandler critiques the transmission model by stating:\n It assumes communicators are isolated individuals.\n No allowance for differing purposes.\n No allowance for differing interpretations.\n No allowance for unequal power relations.\n No allowance for situational contexts.\n\nIn 1960, David Berlo expanded on Shannon and Weaver's (1949) linear model of communication and created the SMCR Model of Communication. The Sender-Message-Channel-Receiver Model of communication separated the model into clear parts and has been expanded upon by other scholars.\n\nCommunication is usually described along a few major dimensions: message (what type of things are communicated), source/emisor/sender/encoder (from whom), form (in which form), channel (through which medium), destination/receiver/target/decoder (to whom). Wilbur Schram (1954) also indicated that we should also examine the impact that a message has (both desired and undesired) on the target of the message. Between parties, communication includes acts that confer knowledge and experiences, give advice and commands, and ask questions. These acts may take many forms, in one of the various manners of communication. The form depends on the abilities of the group communicating. Together, communication content and form make messages that are sent towards a destination. The target can be oneself, another person or being, another entity (such as a corporation or group of beings).\n\nCommunication can be seen as processes of information transmission with three levels of semiotic rules:\n Pragmatic (concerned with the relations between signs/expressions and their users).\n Semantic (study of relationships between signs and symbols and what they represent).\n Syntactic (formal properties of signs and symbols).\n\nTherefore, communication is social interaction where at least two interacting agents share a common set of signs and a common set of semiotic rules. This commonly held rule in some sense ignores autocommunication, including intrapersonal communication via diaries or self-talk, both secondary phenomena that followed the primary acquisition of communicative competences within social interactions.\n\nIn light of these weaknesses, Barnlund (2008) proposed a transactional model of communication. The basic premise of the transactional model of communication is that individuals are simultaneously engaging in the sending and receiving of messages.\n\nIn a slightly more complex form a sender and a receiver are linked reciprocally. This second attitude of communication, referred to as the constitutive model or constructionist view, focuses on how an individual communicates as the determining factor of the way the message will be interpreted. Communication is viewed as a conduit; a passage in which information travels from one individual to another and this information becomes separate from the communication itself. A particular instance of communication is called a speech act. The sender's personal filters and the receiver's personal filters may vary depending upon different regional traditions, cultures, or gender; which may alter the intended meaning of message contents. In the presence of \"communication noise\" on the transmission channel (air, in this case), reception and decoding of content may be faulty, and thus the speech act may not achieve the desired effect. One problem with this encode-transmit-receive-decode model is that the processes of encoding and decoding imply that the sender and receiver each possess something that functions as a codebook, and that these two code books are, at the very least, similar if not identical. Although something like code books is implied by the model, they are nowhere represented in the model, which creates many conceptual difficulties.\n\nTheories of coregulation describe communication as a creative and dynamic continuous process, rather than a discrete exchange of information. Canadian media scholar Harold Innis had the theory that people use different types of media to communicate and which one they choose to use will offer different possibilities for the shape and durability of society. His famous example of this is using ancient Egypt and looking at the ways they built themselves out of media with very different properties stone and papyrus. Papyrus is what he called 'Space Binding'. it made possible the transmission of written orders across space, empires and enables the waging of distant military campaigns and colonial administration. The other is stone and 'Time Binding', through the construction of temples and the pyramids can sustain their authority generation to generation, through this media they can change and shape communication in their society.\n\nAs academic discipline with distinct fields of study\n\nThe academic discipline that deals with processes of human communication is communication studies. The discipline encompasses a range of topics, from face-to-face conversation to mass media outlets such as television broadcasting. Communication studies also examines how messages are interpreted through the political, cultural, economic, semiotic, hermeneutic, and social dimensions of their contexts. Statistics, as a quantitative approach to communication science, has also been incorporated into research on communication science in order to help substantiate claims.\n\nOrganizational communication\n\nBusiness communication is used for a wide variety of activities including, but not limited to: strategic communications planning, media relations, internal communications, public relations (which can include social media, broadcast and written communications, and more), brand management, reputation management, speech-writing, customer-client relations, and internal/employee communications.\n\nCompanies with limited resources may choose to engage in only a few of these activities, while larger organizations may employ a full spectrum of communications. Since it is relatively difficult to develop such a broad range of skills, communications professionals often specialize in one or two of these areas but usually have at least a working knowledge of most of them. By far, the most important qualifications communications professionals must possess are excellent writing ability, good 'people' skills, and the capacity to think critically and strategically.\n\nBusiness communication could also refer to the style of communication within a given corporate entity (i.e. email conversation styles, or internal communication styles).\n\nPolitical communication\nCommunication is one of the most relevant tools in political strategies, including persuasion and propaganda. In mass media research and online media research, the effort of the strategist is that of getting a precise decoding, avoiding \"message reactance\", that is, message refusal. The reaction to a message is referred also in terms of approach to a message, as follows:\n In \"radical reading\" the audience rejects the meanings, values, and viewpoints built into the text by its makers. Effect: message refusal.\n In \"dominant reading\", the audience accepts the meanings, values, and viewpoints built into the text by its makers. Effect: message acceptance.\n In \"subordinate reading\" the audience accepts, by and large, the meanings, values, and worldview built into the text by its makers. Effect: obey to the message.\nHolistic approaches are used by communication campaign leaders and communication strategists in order to examine all the options, \"actors\" and channels that can generate change in the semiotic landscape, that is, change in perceptions, change in credibility, change in the \"memetic background\", change in the image of movements, of candidates, players and managers as perceived by key influencers that can have a role in generating the desired \"end-state\".\n\nThe modern political communication field is highly influenced by the framework and practices of \"information operations\" doctrines that derive their nature from strategic and military studies. According to this view, what is really relevant is the concept of acting on the Information Environment. The information environment is the aggregate of individuals, organizations, and systems that collect, process, disseminate, or act on information. This environment consists of three interrelated dimensions, which continuously interact with individuals, organizations, and systems. These dimensions are known as physical, informational, and cognitive.\n\nInterpersonal communication\n\nIn simple terms, interpersonal communication is the communication between one person and another (or others). It is often referred to as face-to-face communication between two (or more) people. Both verbal and nonverbal communication, or body language, play a part in how one person understands another, and attribute to one's own soft skills. In verbal interpersonal communication there are two types of messages being sent: a content message and a relational message. Content messages are messages about the topic at hand and relational messages are messages about the relationship itself. This means that relational messages come across in how one says something and it demonstrates a person's feelings, whether positive or negative, towards the individual they are talking to, indicating not only how they feel about the topic at hand, but also how they feel about their relationship with the other individual.\n\nThere are many different aspects of interpersonal communication including:\n Audiovisual Perception of Communication Problems. The concept follows the idea that our words change what form they take based on the stress level or urgency of the situation. It also explores the concept that stuttering during speech shows the audience that there is a problem or that the situation is more stressful.\n The Attachment Theory. This is the combined work of John Bowlby and Mary Ainsworth (Ainsworth & Bowlby, 1991) This theory follows the relationships that builds between a mother and child, and the impact it has on their relationships with others.\n Emotional Intelligence and Triggers. Emotional Intelligence focuses on the ability to monitor ones own emotions as well as those of others. Emotional Triggers focus on events or people that tend to set off intense, emotional reactions within individuals.\n Attribution Theory. This is the study of how individuals explain what causes different events and behaviors.\n The Power of Words (Verbal communications). Verbal communication focuses heavily on the power of words, and how those words are said. It takes into consideration tone, volume, and choice of words.\n Nonverbal Communication. It focuses heavily on the setting that the words are conveyed in, as well as the physical tone of the words.\n Ethics in Personal Relations. It is about a space of mutual responsibility between two individuals, it's about giving and receiving in a relationship. This theory is explored by Dawn J. Lipthrott in the article What IS Relationship? What is Ethical Partnership?\n Deception in Communication. This concept goes into that everyone lies, and how this can impact relationships. This theory is explored by James Hearn in his article Interpersonal Deception Theory: Ten Lessons for Negotiators.\n Conflict in Couples. This focuses on the impact that social media has on relationships, as well as how to communicate through conflict. This theory is explored by Amanda Lenhart and Maeve Duggan in their paper Couples, the Internet, and Social Media.\n\nFamily communication \nFamily communication is the study of the communication perspective in a broadly defined family, with intimacy and trusting relationship. The main goal of family communication is to understand the interactions of family and the pattern of behaviors of family members in different circumstances. Open and honest communication creates an atmosphere that allows family members to express their differences as well as love and admiration for one another. It also helps to understand the feelings of one another.\n\nFamily communication study looks at topics such as family rules, family roles or family dialectics and how those factors could affect the communication between family members. Researchers develop theories to understand communication behaviors. Family communication study also digs deep into certain time periods of family life such as marriage, parenthood or divorce and how communication stands in those situations. It is important for family members to understand communication as a trusted way which leads to a well constructed family.\n\nRhetoric\n\nAccording to scholar Anne Beaufort, communication is also interested in rhetoric as a method of investigating \"oral and written communications, particularly with regard to the desired effect on an audience, and lately, with visual communications as well.\"\n\nBarriers to effectiveness\n\nBarriers to effective communication can retard or distort the message or intention of the message being conveyed. This may result in failure of the communication process or cause an effect that is undesirable. These include filtering, selective perception, information overload, emotions, language, silence, communication apprehension, gender differences and political correctness.\n\nThis also includes a lack of expressing \"knowledge-appropriate\" communication, which occurs when a person uses ambiguous or complex legal words, medical jargon, or descriptions of a situation or environment that is not understood by the recipient.\n Physical barriers \u2013 Physical barriers are often due to the nature of the environment. An example of this is the natural barrier which exists when workers are located in different buildings or on different sites. Likewise, poor or outdated equipment, particularly the failure of management to introduce new technology, may also cause problems. Staff shortages are another factor which frequently causes communication difficulties for an organization.\n System design \u2013 System design faults refer to problems with the structures or systems in place in an organization. Examples might include an organizational structure which is unclear and therefore makes it confusing to know whom to communicate with. Other examples could be inefficient or inappropriate information systems, a lack of supervision or training, and a lack of clarity in roles and responsibilities which can lead to staff being uncertain about what is expected of them.\n Attitudinal barriers\u2013 Attitudinal barriers come about as a result of problems with staff in an organization. These may be brought about, for example, by such factors as poor management, lack of consultation with employees, personality conflicts which can result in people delaying or refusing to communicate, the personal attitudes of individual employees which may be due to lack of motivation or dissatisfaction at work, brought about by insufficient training to enable them to carry out particular tasks, or simply resistance to change due to entrenched attitudes and ideas.\n Ambiguity of words/phrases \u2013 Words sounding the same but having different meaning can convey a different meaning altogether. Hence the communicator must ensure that the receiver receives the same meaning. It is better if such words are avoided by using alternatives whenever possible.\n Individual linguistic ability \u2013 The use of jargon, difficult or inappropriate words in communication can prevent the recipients from understanding the message. Poorly explained or misunderstood messages can also result in confusion. However, research in communication has shown that confusion can lend legitimacy to research when persuasion fails.\n Physiological barriers \u2013 These may result from individuals' personal discomfort, caused\u2014for example\u2014by ill health, poor eyesight or hearing difficulties.\n Bypassing \u2013 This happens when the communicators (the sender and the receiver) do not attach the same symbolic meanings to their words. It is when the sender is expressing a thought or a word but the receiver gives it a different meaning. For example- ASAP, Rest room.\n Technological multi-tasking and absorbency \u2013 With a rapid increase in technologically-driven communication in the past several decades, individuals are increasingly faced with condensed communication in the form of e-mail, text, and social updates. This has, in turn, led to a notable change in the way younger generations communicate and perceive their own self-efficacy to communicate and connect with others. With the ever-constant presence of another \"world\" in one's pocket, individuals are multi-tasking both physically and cognitively as constant reminders of something else happening somewhere else bombard them. Though perhaps too new an advancement to yet see long-term effects, this is a notion currently explored by such figures as Sherry Turkle.\n Fear of being criticized \u2013 This is a major factor that prevents good communication. If we exercise simple practices to improve our communication skill, we can become effective communicators. For example, read an article from the newspaper or collect some news from the television and present it in front of the mirror. This will not only boost your confidence but also improve your language and vocabulary.\n Gender barriers \u2013 Most communicators whether aware or not, often have a set agenda. This is very notable among the different genders. For example, many women are found to be more critical when addressing conflict. It's also been noted that men are more likely than women to withdraw from conflict.\n\nNoise\nIn any communication model, noise is interference with the decoding of messages sent over the channel by an encoder. There are many examples of noise:\n Environmental noise. Noise that physically disrupts communication, such as standing next to loud speakers at a party, or the noise from a construction site next to a classroom making it difficult to hear the professor.\n Physiological-impairment noise. Physical maladies that prevent effective communication, such as actual deafness or blindness preventing messages from being received as they were intended.\n Semantic noise. Different interpretations of the meanings of certain words. For example, the word \"weed\" can be interpreted as an undesirable plant in a yard, or as a euphemism for marijuana.\n Syntactical noise. Mistakes in grammar can disrupt communication, such as abrupt changes in verb tense during a sentence.\n Organizational noise. Poorly structured communication can prevent the receiver from accurate interpretation. For example, unclear and badly stated directions can make the receiver even more lost.\n Cultural noise. Stereotypical assumptions can cause misunderstandings, such as unintentionally offending a non-Christian person by wishing them a \"Merry Christmas\".\n Psychological noise. Certain attitudes can also make communication difficult. For instance, great anger or sadness may cause someone to lose focus on the present moment. Disorders such as autism may also severely hamper effective communication.\nTo face communication noise, redundancy and acknowledgement must often be used. Acknowledgements are messages from the addressee informing the originator that his/her communication has been received and is understood. Message repetition and feedback about message received are necessary in the presence of noise to reduce the probability of misunderstanding.\nThe act of disambiguation regards the attempt of reducing noise and wrong interpretations, when the semantic value or meaning of a sign can be subject to noise, or in presence of multiple meanings, which makes the sense-making difficult. Disambiguation attempts to decrease the likelihood of misunderstanding. This is also a fundamental skill in communication processes activated by counselors, psychotherapists, interpreters, and in coaching sessions based on colloquium. In Information Technology, the disambiguation process and the automatic disambiguation of meanings of words and sentences has also been an interest and concern since the earliest days of computer treatment of language.\n\nCultural aspects\nCultural differences exist within countries (tribal/regional differences, dialects and so on), between religious groups and in organisations or at an organisational level \u2013 where companies, teams and units may have different expectations, norms and idiolects. Families and family groups may also experience the effect of cultural barriers to communication within and between different family members or groups. For example: words, colours and symbols have different meanings in different cultures. In most parts of the world, nodding your head means agreement, shaking your head means \"no\", but this is not true everywhere.\n\nCommunication to a great extent is influenced by culture and cultural variables. Understanding cultural aspects of communication refers to having knowledge of different cultures in order to communicate effectively with cross culture people. Cultural aspects of communication are of great relevance in today's world which is now a global village, thanks to globalisation. Cultural aspects of communication are the cultural differences which influence communication across borders.\n\n Verbal communication refers to a form of communication which uses spoken and written words for expressing and transferring views and ideas. Language is the most important tool of verbal communication. Countries have different languages. A knowledge of languages of different countries can improve cross-cultural understanding.\n Non-verbal communication is a very wide concept and it includes all the other forms of communication which do not use written or spoken words. Non verbal communication takes the following forms:\n Paralinguistics are the elements other than language where the voice is involved in communication and includes tones, pitch, vocal cues etc. It also includes sounds from throat and all these are greatly influenced by cultural differences across borders.\n Proxemics deals with the concept of the space element in communication. Proxemics explains four zones of spaces, namely intimate, personal, social and public. This concept differs from culture to culture as the permissible space varies in different countries.\n Artifactics studies the non verbal signals or communication which emerges from personal accessories such as the dress or fashion accessories worn and it varies with culture as people of different countries follow different dress codes.\n Chronemics deals with the time aspects of communication and also includes the importance given to time. Some issues explaining this concept are pauses, silences and response lag during an interaction. This aspect of communication is also influenced by cultural differences as it is well known that there is a great difference in the value given by different cultures to time.\n Kinesics mainly deals with body language such as postures, gestures, head nods, leg movements, etc. In different countries, the same gestures and postures are used to convey different messages. Sometimes even a particular kinesic indicating something good in a country may have a negative meaning in another culture.\n\nSo in order to have an effective communication across the world it is desirable to have a knowledge of cultural variables effecting communication.\n\nAccording to Michael Walsh and Ghil'ad Zuckermann, Western conversational interaction is typically \"dyadic\", between two particular people, where eye contact is important and the speaker controls the interaction; and \"contained\" in a relatively short, defined time frame. However, traditional Aboriginal conversational interaction is \"communal\", broadcast to many people, eye contact is not important, the listener controls the interaction; and \"continuous\", spread over a longer, indefinite time frame.\n\nNonhuman\n\nEvery information exchange between living organisms \u2014 i.e. transmission of signals that involve a living sender and receiver can be considered a form of communication; and even primitive creatures such as corals are competent to communicate. Nonhuman communication also include cell signaling, cellular communication, and chemical transmissions between primitive organisms like bacteria and within the plant and fungal kingdoms.\n\nAnimals\nThe broad field of animal communication encompasses most of the issues in ethology. Animal communication can be defined as any behavior of one animal that affects the current or future behavior of another animal. The study of animal communication, called zoo semiotics (distinguishable from anthroposemiotics, the study of human communication) has played an important part in the development of ethology, sociobiology, and the study of animal cognition. Animal communication, and indeed the understanding of the animal world in general, is a rapidly growing field, and even in the 21st century so far, a great share of prior understanding related to diverse fields such as personal symbolic name use, animal emotions, animal culture and learning, and even sexual conduct, long thought to be well understood, has been revolutionized.\n\nPlants and fungi\nCommunication is observed within the plant organism, i.e. within plant cells and between plant cells, between plants of the same or related species, and between plants and non-plant organisms, especially in the root zone. Plant roots communicate with rhizome bacteria, fungi, and insects within the soil. Recent research has shown that most of the microorganism plant communication processes are neuron-like. Plants also communicate via volatiles when exposed to herbivory attack behavior, thus warning neighboring plants. In parallel they produce other volatiles to attract parasites which attack these herbivores.\n\nFungi communicate to coordinate and organize their growth and development such as the formation of mycelia and fruiting bodies. Fungi communicate with their own and related species as well as with non fungal organisms in a great variety of symbiotic interactions, especially with bacteria, unicellular eukaryote, plants and insects through biochemicals of biotic origin. The biochemicals trigger the fungal organism to react in a specific manner, while if the same chemical molecules are not part of biotic messages, they do not trigger the fungal organism to react. This implies that fungal organisms can differentiate between molecules taking part in biotic messages and similar molecules being irrelevant in the situation. So far five different primary signalling molecules are known to coordinate different behavioral patterns such as filamentation, mating, growth, and pathogenicity. Behavioral coordination and production of signaling substances is achieved through interpretation processes that enables the organism to differ between self or non-self, a biotic indicator, biotic message from similar, related, or non-related species, and even filter out \"noise\", i.e. similar molecules without biotic content.\n\nBacteria quorum sensing\nCommunication is not a tool used only by humans, plants and animals, but it is also used by microorganisms like bacteria. The process is called quorum sensing. Through quorum sensing, bacteria can sense the density of cells, and regulate gene expression accordingly. This can be seen in both gram positive and gram negative bacteria.\nThis was first observed by Fuqua et al. in marine microorganisms like V. harveyi and V. fischeri.\n\nSee also\n\nReferences\n\nFurther reading\n\nExternal links\n \n \n\n \nCommunication studies\nScoutcraft\nMain topic articles",
  "Drink": "A drink (or beverage) is a liquid intended for human consumption. In addition to their basic function of satisfying thirst, drinks play important roles in human culture. Common types of drinks include plain drinking water, milk, juice, smoothies and soft drinks. Traditionally warm beverages include coffee, tea, and hot chocolate. Caffeinated drinks that contain the stimulant caffeine have a long history.\n\nIn addition, alcoholic drinks such as wine, beer, and liquor, which contain the drug ethanol, have been part of human culture for more than 8,000 years. Non-alcoholic drinks often signify drinks that would normally contain alcohol, such as beer, wine and cocktails, but are made with a sufficiently low concentration of alcohol by volume. The category includes drinks that have undergone an alcohol removal process such as non-alcoholic beers and de-alcoholized wines.\n\nBiology \nWhen the human body becomes dehydrated, a person experiences thirst. This craving of fluids results in an instinctive need to drink. Thirst is regulated by the hypothalamus in response to subtle changes in the body's electrolyte levels, and also as a result of changes in the volume of blood circulating. The complete deprivation of drinks (that is, water) will result in death faster than the removal of any other substance besides oxygen. Water and milk have been basic drinks throughout history. As water is essential for life, it has also been the carrier of many diseases.\n\nAs society developed, techniques were discovered to create alcoholic drinks from the plants that were available in different areas. The earliest archaeological evidence of wine production yet found has been at sites in Georgia ( BCE) and Iran ( BCE). Beer may have been known in Neolithic Europe as far back as 3000 BCE, and was mainly brewed on a domestic scale. The invention of beer (and bread) has been argued to be responsible for humanity's ability to develop technology and build civilization. Tea likely originated in Yunnan, China, during the Shang Dynasty (1500 BCE\u20131046 BCE) as a medicinal drink.\n\nHistory \n\nDrinking has been a large part of socialising throughout the centuries. In Ancient Greece, a social gathering for the purpose of drinking was known as a symposium, where watered down wine would be drunk. The purpose of these gatherings could be anything from serious discussions to direct indulgence. In Ancient Rome, a similar concept of a convivium took place regularly.\n\nMany early societies considered alcohol a gift from the gods, leading to the creation of gods such as Dionysus. Other religions forbid, discourage, or restrict the drinking of alcoholic drinks for various reasons. In some regions with a dominant religion the production, sale, and consumption of alcoholic drinks is forbidden to everybody, regardless of religion.\n\nToasting is a method of honouring a person or wishing good will by taking a drink. Another tradition is that of the loving cup, at weddings or other celebrations such as sports victories a group will share a drink in a large receptacle, shared by everyone until empty.\n\nIn East Africa and Yemen, coffee was used in native religious ceremonies. As these ceremonies conflicted with the beliefs of the Christian church, the Ethiopian Church banned the secular consumption of coffee until the reign of Emperor Menelik II. The drink was also banned in Ottoman Turkey during the 17th century for political reasons and was associated with rebellious political activities in Europe.\n\nProduction \nA drink is a form of liquid which has been prepared for human consumption. The preparation can include a number of different steps, some prior to transport, others immediately prior to consumption.\n\nPurification of water \n\nWater is the chief constituent in all drinks, and the primary ingredient in most. Water is purified prior to drinking. Methods for purification include filtration and the addition of chemicals, such as chlorination. The importance of purified water is highlighted by the World Health Organization, who point out 94% of deaths from diarrhea \u2013 the third biggest cause of infectious death worldwide at 1.8 million annually \u2013 could be prevented by improving the quality of the victim's environment, particularly safe water.\n\nPasteurisation \nPasteurisation is the process of heating a liquid for a period of time at a specified temperature, then immediately cooling. The process reduces the growth of microorganisms within the liquid, thereby increasing the time before spoilage. It is primarily used on milk, which prior to pasteurisation is commonly infected with pathogenic bacteria and therefore is more likely than any other part of the common diet in the developed world to cause illness.\n\nJuicing \n\nThe process of extracting juice from fruits and vegetables can take a number of forms. Simple crushing of most fruits will provide a significant amount of liquid, though a more intense pressure can be applied to get the maximum amount of juice from the fruit. Both crushing and pressing are processes used in the production of wine.\n\nInfusion \nInfusion is the process of extracting flavours from plant material by allowing the material to remain suspended within water. This process is used in the production of teas, herbal teas and can be used to prepare coffee (when using a coffee press).\n\nPercolation \n\nThe name is derived from the word \"percolate\" which means to cause (a solvent) to pass through a permeable substance especially for extracting a soluble constituent.\nIn the case of coffee-brewing the solvent is water, the permeable substance is the coffee grounds, and the soluble constituents are the chemical compounds that give coffee its color, taste, aroma, and stimulating properties.\n\nCarbonation \nCarbonation is the process of dissolving carbon dioxide into a liquid, such as water.\n\nFermentation \n\nFermentation is a metabolic process that converts sugar to ethanol. Fermentation has been used by humans for the production of drinks since the Neolithic age. In winemaking, grape juice is combined with yeast in an anaerobic environment to allow the fermentation. The amount of sugar in the wine and the length of time given for fermentation determine the alcohol level and the sweetness of the wine.\n\nWhen brewing beer, there are four primary ingredients \u2013 water, grain, yeast and hops. The grain is encouraged to germinate by soaking and drying in heat, a process known as malting. It is then milled before soaking again to create the sugars needed for fermentation. This process is known as mashing. Hops are added for flavouring, then the yeast is added to the mixture (now called wort) to start the fermentation process.\n\nDistillation \n\nDistillation is a method of separating mixtures based on differences in volatility of components in a boiling liquid mixture. It is one of the methods used in the purification of water. It is also a method of producing spirits from milder alcoholic drinks.\n\nMixing \n\nAn alcoholic mixed drink that contains two or more ingredients is referred to as a cocktail. Cocktails were originally a mixture of spirits, sugar, water, and bitters. The term is now often used for almost any mixed drink that contains alcohol, including mixers, mixed shots, etc. A cocktail today usually contains one or more kinds of spirit and one or more mixers, such as soda or fruit juice. Additional ingredients may be sugar, honey, milk, cream, and various herbs.\n\nType\n\nNon-alcoholic drinks \n\nA non-alcoholic drink is one that contains little or no alcohol. This category includes low-alcohol beer, non-alcoholic wine, and apple cider if they contain a sufficiently low concentration of alcohol by volume (ABV). The exact definition of what is \"non-alcoholic\" and what is not depends on local laws: in the United Kingdom, \"alcohol-free beer\" is under 0.05% ABV, \"de-alcoholised beer\" is under 0.5%, while \"low-alcohol beer\" can contain no more than 1.2% ABV. The term \"soft drink\" specifies the absence of alcohol in contrast to \"hard drink\" and \"drink\". The term \"drink\" is theoretically neutral, but often is used in a way that suggests alcoholic content. Drinks such as soda pop, sparkling water, iced tea, lemonade, root beer, fruit punch, milk, hot chocolate, tea, coffee, milkshakes, and tap water and energy drinks are all soft drinks.\n\nWater \n\nWater is the world's most consumed drink, however, 97% of water on Earth is non-drinkable salt water. Fresh water is found in rivers, lakes, wetlands, groundwater, and frozen glaciers. Less than 1% of the Earth's fresh water supplies are accessible through surface water and underground sources which are cost effective to retrieve.\n\nIn western cultures, water is often drunk cold.  In the Chinese culture, it is typically drunk hot.\n\nMilk \nMilk is regarded as one of the \"original\" drinks, milk is the primary source of nutrition for babies. In many cultures of the world, especially the Western world, humans continue to consume dairy milk beyond infancy, using the milk of other animals (especially cattle, goats and sheep) as a drink.\n\nSoft drinks \n\nCarbonated drinks refer to drinks which have carbon dioxide dissolved into them. This can happen naturally through fermenting and in natural water spas or artificially by the dissolution of carbon dioxide under pressure. The first commercially available artificially carbonated drink is believed to have been produced by Thomas Henry in the late 1770s.\nCola, orange, various roots, ginger, and lemon/lime are commonly used to create non-alcoholic carbonated drinks; sugars and preservatives may be added later.\n\nThe most consumed carbonated soft drinks are produced by three major global brands: Coca-Cola, PepsiCo and the Dr Pepper Snapple Group.\n\nJuice and plant drinks \n\nFruit juice is a natural product that contains few or no additives. Citrus products such as orange juice and tangerine juice are familiar breakfast drinks, while grapefruit juice, pineapple, apple, grape, lime, and lemon juice are also common. Coconut water is a highly nutritious and refreshing juice. Many kinds of berries are crushed; their juices are mixed with water and sometimes sweetened. Raspberry, blackberry and currants are popular juices drinks but the percentage of water also determines their nutritive value. Grape juice allowed to ferment produces wine.\n\nFruits are highly perishable so the ability to extract juices and store them was of significant value. Some fruits are highly acidic and mixing them with water and sugars or honey was often necessary to make them palatable. Fruits can also be blended with ice and other ingredients to make a smoothie. Early storage of fruit juices was labor-intensive, requiring the crushing of the fruits and the mixing of the resulting pure juices with sugars before bottling.\n\nVegetable juices are usually served warm or cold. Different types of vegetables can be used to make vegetable juice such as carrots, tomatoes, cucumbers, celery and many more. Some vegetable juices are mixed with some fruit juice to make the vegetable juice taste better. Many popular vegetable juices, particularly ones with high tomato content, are high in sodium, and therefore consumption of them for health must be carefully considered. Some vegetable juices provide the same health benefits as whole vegetables in terms of reducing risks of cardiovascular disease and cancer.\n\nPlant milk is a general term for any milk-like product that is derived from a plant source. The most common varieties internationally are soy milk, almond milk, rice milk and coconut milk.\n\nSleep drinks \nA nightcap is a drink taken shortly before bedtime to induce sleep. For example, a small alcoholic drink or a cup of warm milk can supposedly promote a good night's sleep. Today, most nightcaps and relaxation drinks are generally non-alcoholic beverages containing calming ingredients. They are considered beverages which serve to relax a person. Unlike other calming beverages, such as tea, warm milk or milk with honey; relaxation drinks almost universally contain more than one active ingredient. Relaxation drinks have been known to contain other natural ingredients and are usually free of caffeine and alcohol but some have claimed to contain marijuana.\n\nAlcoholic drinks \n\nA drink is considered \"alcoholic\" if it contains ethanol, commonly known as alcohol (although in chemistry the definition of \"alcohol\" includes many other compounds). Beer has been a part of human culture for 8,000 years.\n\nIn many countries, imbibing alcoholic drinks in a local bar or pub is a cultural tradition.\n\nBeer \n\nBeer is an alcoholic drink produced by the saccharification of starch and fermentation of the resulting sugar. The starch and saccharification enzymes are often derived from malted cereal grains, most commonly malted barley and malted wheat. Most beer is also flavoured with hops, which add bitterness and act as a natural preservative, though other flavourings such as herbs or fruit may occasionally be included. The preparation of beer is called brewing. Beer is the world's most widely consumed alcoholic drink, and is the third-most popular drink overall, after water and tea. It is said to have been discovered by goddess Ninkasi around 5300 BCE, when she accidentally discovered yeast after leaving grain in jars that were later rained upon and left for several days. Women have been the chief creators of beer throughout history due to its association with domesticity and it, throughout much of history, being brewed in the home for family consumption. Only in recent history have men begun to dabble in the field. It is thought by some to be the oldest fermented drink.\n\nSome of humanity's earliest known writings refer to the production and distribution of beer: the Code of Hammurabi included laws regulating beer and beer parlours, and \"The Hymn to Ninkasi\", a prayer to the Mesopotamian goddess of beer, served as both a prayer and as a method of remembering the recipe for beer in a culture with few literate people. Today, the brewing industry is a global business, consisting of several dominant multinational companies and many thousands of smaller producers ranging from brewpubs to regional breweries.\n\nCider \nCider is a fermented alcoholic drink made from fruit juice, most commonly and traditionally apple juice, but also the juice of peaches, pears (\"Perry\" cider) or other fruit. Cider may be made from any variety of apple, but certain cultivars grown solely for use in cider are known as cider apples. The United Kingdom has the highest per capita consumption of cider, as well as the largest cider-producing companies in the world, , the U.K. produces 600 million litres of cider each year (130 million imperial gallons).\n\nWine \n\nWine is an alcoholic drink made from fermented grapes or other fruits. The natural chemical balance of grapes lets them ferment without the addition of sugars, acids, enzymes, water, or other nutrients. Yeast consumes the sugars in the grapes and converts them into alcohol and carbon dioxide. Different varieties of grapes and strains of yeasts produce different styles of wine. The well-known variations result from the very complex interactions between the biochemical development of the fruit, reactions involved in fermentation, terroir and subsequent appellation, along with human intervention in the overall process. The final product may contain tens of thousands of chemical compounds in amounts varying from a few percent to a few parts per billion.\n\nWines made from produce besides grapes are usually named after the product from which they are produced (for example, rice wine, pomegranate wine, apple wine and elderberry wine) and are generically called fruit wine. The term \"wine\" can also refer to starch-fermented or fortified drinks having higher alcohol content, such as barley wine, huangjiu, or sake.\n\nWine has a rich history dating back thousands of years, with the earliest production so far discovered having occurred \u00a0BC in Georgia. It had reached the Balkans by \u00a0BC and was consumed and celebrated in ancient Greece and Rome.\n\nFrom its earliest appearance in written records, wine has also played an important role in religion. Red wine was closely associated with blood by the ancient Egyptians, who, according to Plutarch, avoided its free consumption as late as the 7th-century BC Saite dynasty, \"thinking it to be the blood of those who had once battled against the gods\". The Greek cult and mysteries of Dionysus, carried on by the Romans in their Bacchanalia, were the origins of western theater. Judaism incorporates it in the Kiddush and Christianity in its Eucharist, while alcohol consumption was forbidden in Islam.\n\nSpirits \n\nSpirits are distilled beverages that contain no added sugar and have at least 20% alcohol by volume (ABV). Popular spirits include borovi\u010dka, brandy, gin, rum, slivovitz, tequila, vodka, and whisky. Brandy is a spirit created by distilling wine, whilst vodka may be distilled from any starch- or sugar-rich plant matter; most vodka today is produced from grains such as sorghum, corn, rye or wheat.\n\nHot drinks\n\nCoffee \n\nCoffee is a brewed drink prepared from the roasted seeds of several species of an evergreen shrub of the genus Coffea. The two most common sources of coffee beans are the highly regarded Coffea arabica, and the \"robusta\" form of the hardier Coffea canephora. Coffee plants are cultivated in more than 70 countries. Once ripe, coffee \"berries\" are picked, processed, and dried to yield the seeds inside. The seeds are then roasted to varying degrees, depending on the desired flavor, before being ground and brewed to create coffee.\n\nCoffee is slightly acidic (pH 5.0\u20135.1) and can have a stimulating effect on humans because of its caffeine content. It is one of the most popular drinks in the world. It can be prepared and presented in a variety of ways. The effect of coffee on human health has been a subject of many studies; however, results have varied in terms of coffee's relative benefit.\n\nCoffee cultivation first took place in southern Arabia; the earliest credible evidence of coffee-drinking appears in the middle of the 15th century in the Sufi shrines of Yemen.\n\nCoffee may have been used socially in the renaissance period of the 17th century. The increasing trades between Europe and North Africa regions made coffee more widely available to Europeans gathering at social locations that served coffee, possibly contributing to the growth of coffeehouses.\n\nHot chocolate\nHot chocolate, also known as drinking chocolate or cocoa, is a heated drink consisting of shaved chocolate, melted chocolate or cocoa powder, heated milk or water, and usually a sweetener. Hot chocolate may be topped with whipped cream. Hot chocolate made with melted chocolate is sometimes called drinking chocolate, characterized by less sweetness and a thicker consistency.\n\nThe first chocolate drink is believed to have been created by the Mayans around 2,500-3,000 years ago, and a cocoa drink was an essential part of Aztec culture by 1400 AD, by which they referred to as xoc\u014dl\u0101tl. The drink became popular in Europe after being introduced from Mexico in the New World and has undergone multiple changes since then. Until the 19th century, hot chocolate was even used medicinally to treat ailments such as liver and stomach diseases.Hot chocolate is consumed throughout the world and comes in multiple variations, including the spiced chocolate para mesa of Latin America, the very thick cioccolata calda served in Italy and chocolate a la taza served in Spain, and the thinner hot cocoa consumed in the United States. Prepared hot chocolate can be purchased from a range of establishments, including cafeterias, fast food restaurants, coffeehouses and teahouses. Powdered hot chocolate mixes, which can be added to boiling water or hot milk to make the drink at home, are sold at grocery stores and online.\n\nTea \n\nTea, the second most consumed drink in the world, is produced from infusing dried leaves of the camellia sinensis shrub, in boiling water. There are many ways in which tea is prepared for consumption: lemon or milk and sugar are among the most common additives worldwide. Other additions include butter and salt in Bhutan, Nepal, and Tibet; bubble tea in Taiwan; fresh ginger in Indonesia, Malaysia and Singapore; mint in North Africa and Senegal; cardamom in Central Asia; rum to make Jagertee in Central Europe; and coffee to make yuanyang in Hong Kong. Tea is also served differently from country to country: in China and Japan tiny cups are used to serve tea; in Thailand and the United States tea is often served cold (as \"iced tea\") or with a lot of sweetener; Indians boil tea with milk and a blend of spices as masala chai; tea is brewed with a samovar in Iran, Kashmir, Russia and Turkey; and in the Australian Outback it is traditionally brewed in a billycan.\nTea leaves can be processed in different ways resulting in a drink which appears and tastes different. Chinese yellow and green tea are steamed, roasted and dried; Oolong tea is semi-oxidised and appears green-black and black teas are fully oxidised.\n\nHerbal tea \n\nAround the world, people refer to other herbal infusions as \"teas\"; it is also argued that these were popular long before the Camellia sinensis shrub was used for tea making. Leaves, flowers, roots or bark can be used to make a herbal infusion and can be bought fresh, dried or powdered.\n\nIn culture\n\nPlaces to drink \n\nThroughout history, people have come together in establishments to socialise whilst drinking. This includes caf\u00e9s and coffeehouses, focus on providing hot drinks as well as light snacks. Many coffee houses in the Middle East, and in West Asian immigrant districts in the Western world, offer shisha (nargile in Turkish and Greek), flavored tobacco smoked through a hookah. Espresso bars are a type of coffeehouse that specialize in serving espresso and espresso-based drinks.\n\nIn China and Japan, the establishment would be a tea house, where people would socialise while drinking tea. Chinese scholars have used the teahouse as a place to share ideas.\n\nAlcoholic drinks are served in drinking establishments, which have different cultural connotations. For example, pubs are fundamental to the culture of Britain, Ireland, Australia, Canada, New England, Metro Detroit, South Africa and New Zealand. In many places, especially in villages, a pub can be the focal point of the community. The writings of Samuel Pepys describe the pub as the heart of England. Many pubs are controlled by breweries, so cask ale or keg beer may be a better value than wines and spirits.\n\nIn contrast, types of bars range from seedy bars or nightclubs, sometimes termed \"dive bars\", to elegant places of entertainment for the elite. Bars provide stools or chairs that are placed at tables or counters for their patrons. The term \"bar\" is derived from the specialized counter on which drinks are served. Some bars have entertainment on a stage, such as a live band, comedians, go-go dancers, or strippers. Patrons may sit or stand at the bar and be served by the bartender, or they may sit at tables and be served by cocktail servers.\n\nMatching with food \n\nFood and drink are often paired together to enhance the taste experience. This primarily happens with wine and a culture has grown up around the process. Weight, flavors and textures can either be contrasted or complemented. In recent years, food magazines began to suggest particular wines with recipes and restaurants would offer multi-course dinners matched with a specific wine for each course.\n\nPresentation \nDifferent drinks have unique receptacles for their consumption. This is sometimes purely for presentations purposes, such as for cocktails. In other situations, the drinkware has practical application, such as coffee cups which are designed for insulation or brandy snifters which are designed to encourage evaporation but trap the aroma within the glass.\n\nMany glasses include a stem, which allows the drinker to hold the glass without affecting the temperature of the drink. In champagne glasses, the bowl is designed to retain champagne's signature carbonation, by reducing the surface area at the opening of the bowl. Historically, champagne has been served in a champagne coupe, the shape of which allowed carbonation to dissipate even more rapidly than from a standard wine glass.\n\nCommercial trade\n\nInternational exports and imports \n\nAn important export commodity, coffee was the top agricultural export for twelve countries in 2004,\nand it was the world's seventh-largest legal agricultural export by value in 2005. Green (unroasted) coffee is one of the most traded agricultural commodities in the world.\n\nInvestment \nSome drinks, such as wine, can be used as an alternative investment. This can be achieved by either purchasing and reselling individual bottles or cases of particular wines, or purchasing shares in an investment wine fund that pools investors' capital.\n\nSee also \n\n List of beverages\n List of hot drinks\n List of national drinks\n\nReferences\n\nBibliography\n\nExternal links \n\n \n \n Health-EU Portal \u2013 Alcohol\n Wikibooks Cookbook\n Women and Beer: A Forgotten Pairing (National Women's History Museum)\n\nDrinks",
  "Death": "Death is the permanent, irreversible cessation of all biological functions that sustain an organism. Brain death is sometimes used as a legal definition of death. The remains of a former organism normally begin to decompose shortly after death. Death is an inevitable, universal process that eventually occurs in all organisms.\n\nDeath is generally applied to whole organisms; the similar process seen in individual components of an organism, such as cells or tissues, is necrosis. Something that is not considered an organism, such as a virus, can be physically destroyed but is not said to die.\n\nAs of the early 21st century, over 150,000 humans die each day, with aging being by far the most common cause of death.\n\nDeath, particularly of humans, has commonly been considered a sad or unpleasant occasion, due to the affection for the deceased and the termination of social and familial bonds. Other concerns include fear of death or anxiety from the thought of death, necrophobia, feelings of sorrow, grief, depression, solitude or saudade for the deceased and/or feelings of sympathy or compassion for the deceased or the loved ones of the deceased.\n\nMany cultures and religions have the idea of an afterlife, and also may hold the idea of judgement of good and bad deeds in one's life (Heaven, Hell, Karma).\n\nDiagnosis\n\nProblems of definition\n\nThe concept of death is a key to human understanding of the phenomenon. There are many scientific approaches and various interpretations of the concept. Additionally, the advent of life-sustaining therapy and the numerous criteria for defining death from both a medical and legal standpoint, have made it difficult to create a single unifying definition.\n\nOne of the challenges in defining death is in distinguishing it from life. As a point in time, death would seem to refer to the moment at which life ends. Determining when death has occurred is difficult, as cessation of life functions is often not simultaneous across organ systems. Such determination, therefore, requires drawing precise conceptual boundaries between life and death. This is difficult, due to there being little consensus on how to define life.\n\nIt is possible to define life in terms of consciousness. When consciousness ceases, an organism can be said to have died. One of the flaws in this approach is that there are many organisms that are alive but probably not conscious (for example, single-celled organisms). Another problem is in defining consciousness, which has many different definitions given by modern scientists, psychologists and philosophers.  Additionally, many religious traditions, including Abrahamic and Dharmic traditions, hold that death does not (or may not) entail the end of consciousness. In certain cultures, death is more of a process than a single event. It implies a slow shift from one spiritual state to another.\n\nOther definitions for death focus on the character of cessation of something. More specifically, death occurs when a living entity experiences irreversible cessation of all functioning. As it pertains to human life, death is an irreversible process where someone loses their existence as a person.\n\nHistorically, attempts to define the exact moment of a human's death have been subjective, or imprecise. Death was once defined as the cessation of heartbeat (cardiac arrest) and of breathing, but the development of CPR and prompt defibrillation have rendered that definition inadequate because breathing and heartbeat can sometimes be restarted. This type of death where circulatory and respiratory arrest happens is known as the circulatory definition of death (DCDD). Proponents of the DCDD believe that this definition is reasonable because a person with permanent loss of circulatory and respiratory function should be considered dead. Critics of this definition state that while cessation of these functions may be permanent, it does not mean the situation is irreversible, because if CPR was applied, the person could be revived. Thus, the arguments for and against the DCDD boil down to a matter of defining the actual words \"permanent\" and \"irreversible,\" which further complicates the challenge of defining death. Furthermore, events which were causally linked to death in the past no longer kill in all circumstances; without a functioning heart or lungs, life can sometimes be sustained with a combination of life support devices, organ transplants and artificial pacemakers.\n\nToday, where a definition of the moment of death is required, doctors and coroners usually turn to \"brain death\" or \"biological death\" to define a person as being dead; people are considered dead when the electrical activity in their brain ceases. It is presumed that an end of electrical activity indicates the end of consciousness. Suspension of consciousness must be permanent, and not transient, as occurs during certain sleep stages, and especially a coma. In the case of sleep, EEGs can easily tell the difference.\n\nThe category of \"brain death\" is seen as problematic by some scholars. For instance, Dr. Franklin Miller, senior faculty member at the Department of Bioethics, National Institutes of Health, notes: \"By the late 1990s... the equation of brain death with death of the human being was increasingly challenged by scholars, based on evidence regarding the array of biological functioning displayed by patients correctly diagnosed as having this condition who were maintained on mechanical ventilation for substantial periods of time. These patients maintained the ability to sustain circulation and respiration, control temperature, excrete wastes, heal wounds, fight infections and, most dramatically, to gestate fetuses (in the case of pregnant \"brain-dead\" women).\"\n\nWhile \"brain death\" is viewed as problematic by some scholars, there are certainly proponents of it that believe this definition of death is the most reasonable for distinguishing life from death. The reasoning behind the support for this definition is that brain death has a set of criteria that is reliable and reproducible. Also, the brain is crucial in determining our identity or who we are as human beings. The distinction should be made that \"brain death\" cannot be equated with one who is in a vegetative state or coma, in that the former situation describes a state that is beyond recovery.\n\nThose people maintaining that only the neo-cortex of the brain is necessary for consciousness sometimes argue that only electrical activity should be considered when defining death. Eventually it is possible that the criterion for death will be the permanent and irreversible loss of cognitive function, as evidenced by the death of the cerebral cortex. All hope of recovering human thought and personality is then gone given current and foreseeable medical technology. At present, in most places the more conservative definition of death\u00a0\u2013 irreversible cessation of electrical activity in the whole brain, as opposed to just in the neo-cortex\u00a0\u2013 has been adopted (for example the Uniform Determination Of Death Act in the United States). In 2005, the Terri Schiavo case brought the question of brain death and artificial sustenance to the front of American politics.\n\nEven by whole-brain criteria, the determination of brain death can be complicated. EEGs can detect spurious electrical impulses, while certain drugs, hypoglycemia, hypoxia, or hypothermia can suppress or even stop brain activity on a temporary basis. Because of this, hospitals have protocols for determining brain death involving EEGs at widely separated intervals under defined conditions.\n\nIn the past, adoption of this whole-brain definition was a conclusion of the President's Commission for the Study of Ethical Problems in Medicine and Biomedical and Behavioral Research in 1980. They concluded that this approach to defining death sufficed in reaching a uniform definition nationwide. A multitude of reasons were presented to support this definition including: uniformity of standards in law for establishing death; consumption of a family's fiscal resources for artificial life support; and legal establishment for equating brain death with death in order to proceed with organ donation.\n\nAside from the issue of support of or dispute against brain death, there is another inherent problem in this categorical definition: the variability of its application in medical practice. In 1995, the American Academy of Neurology (AAN), established a set of criteria that became the medical standard for diagnosing neurologic death. At that time, three clinical features had to be satisfied in order to determine \"irreversible cessation\" of the total brain including: coma with clear etiology, cessation of breathing, and lack of brainstem reflexes. This set of criteria was then updated again most recently in 2010, but substantial discrepancies still remain across hospitals and medical specialties.\n\nThe problem of defining death is especially imperative as it pertains to the dead donor rule, which could be understood as one of the following interpretations of the rule: there must be an official declaration of death in a person before starting organ procurement or that organ procurement cannot result in death of the donor. A great deal of controversy has surrounded the definition of death and the dead donor rule. Advocates of the rule believe the rule is legitimate in protecting organ donors while also countering against any moral or legal objection to organ procurement. Critics, on the other hand, believe that the rule does not uphold the best interests of the donors and that the rule does not effectively promote organ donation.\n\nSigns\n\nSigns of death or strong indications that a warm-blooded animal is no longer alive are:\n Respiratory arrest (no breathing)\n Cardiac arrest (no pulse)\n Brain death (no neuronal activity)\n\nThe stages that follow after death are:\n , paleness which happens in the 15\u2013120 minutes after death\n , the reduction in body temperature following death. This is generally a steady decline until matching ambient temperature\n , the limbs of the corpse become stiff (Latin rigor) and difficult to move or manipulate\n , a settling of the blood in the lower (dependent) portion of the body\n Putrefaction, the beginning signs of decomposition\n Decomposition, the reduction into simpler forms of matter, accompanied by a strong, unpleasant odor.\n Skeletonization, the end of decomposition, where all soft tissues have decomposed, leaving only the skeleton.\n Fossilization, the natural preservation of the skeletal remains formed over a very long period\n\nLegal\n\nThe death of a person has legal consequences that may vary between different jurisdictions.\nA death certificate is issued in most jurisdictions, either by a doctor, or by an administrative office upon presentation of a doctor's declaration of death.\n\nMisdiagnosed\n\nThere are many anecdotal references to people being declared dead by physicians and then \"coming back to life\", sometimes days later in their own coffin, or when embalming procedures are about to begin. From the mid-18th century onwards, there was an upsurge in the public's fear of being mistakenly buried alive, and much debate about the uncertainty of the signs of death. Various suggestions were made to test for signs of life before burial, ranging from pouring vinegar and pepper into the corpse's mouth to applying red hot pokers to the feet or into the rectum. Writing in 1895, the physician J.C. Ouseley claimed that as many as 2,700 people were buried prematurely each year in England and Wales, although others estimated the figure to be closer to 800.\n\nIn cases of electric shock, cardiopulmonary resuscitation (CPR) for an hour or longer can allow stunned nerves to recover, allowing an apparently dead person to survive. People found unconscious under icy water may survive if their faces are kept continuously cold until they arrive at an emergency room. This \"diving response\", in which metabolic activity and oxygen requirements are minimal, is something humans share with cetaceans called the mammalian diving reflex.\n\nAs medical technologies advance, ideas about when death occurs may have to be re-evaluated in light of the ability to restore a person to vitality after longer periods of apparent death (as happened when CPR and defibrillation showed that cessation of heartbeat is inadequate as a decisive indicator of death). The lack of electrical brain activity may not be enough to consider someone scientifically dead. Therefore, the concept of information-theoretic death has been suggested as a better means of defining when true death occurs, though the concept has few practical applications outside the field of cryonics.\n\nThere have been some scientific attempts to bring dead organisms back to life, but with limited success. In science fiction scenarios where such technology is readily available, real death is distinguished from reversible death.\n\nCauses \n\nThe leading cause of human death in developing countries is infectious disease. The leading causes in developed countries are atherosclerosis (heart disease and stroke), cancer, and other diseases related to obesity and aging. By an extremely wide margin, the largest unifying cause of death in the developed world is biological aging, leading to various complications known as aging-associated diseases. These conditions cause loss of homeostasis, leading to cardiac arrest, causing loss of oxygen and nutrient supply, causing irreversible deterioration of the brain and other tissues. Of the roughly 150,000 people who die each day across the globe, about two thirds die of age-related causes. In industrialized nations, the proportion is much higher, approaching 90%. With improved medical capability, dying has become a condition to be managed. Home deaths, once commonplace, are now rare in the developed world.\n\nIn developing nations, inferior sanitary conditions and lack of access to modern medical technology makes death from infectious diseases more common than in developed countries. One such disease is tuberculosis, a bacterial disease which killed 1.8M people in 2015. Malaria causes about 400\u2013900M cases of fever and 1\u20133M deaths annually. AIDS death toll in Africa may reach 90\u2013100M by 2025.\n\nAccording to Jean Ziegler (United Nations Special Reporter on the Right to Food, 2000 \u2013 Mar 2008), mortality due to malnutrition accounted for 58% of the total mortality rate in 2006. Ziegler says worldwide approximately 62M people died from all causes and of those deaths more than 36M died of hunger or diseases due to deficiencies in micronutrients.\n\nTobacco smoking killed 100\u00a0million people worldwide in the 20th century and could kill 1\u00a0billion people around the world in the 21st century, a World Health Organization report warned.\n\nMany leading developed world causes of death can be postponed by diet and physical activity, but the accelerating incidence of disease with age still imposes limits on human longevity. The evolutionary cause of aging is, at best, only just beginning to be understood. It has been suggested that direct intervention in the aging process may now be the most effective intervention against major causes of death.\n\nSelye proposed a unified non-specific approach to many causes of death. He demonstrated that stress decreases adaptability of an organism and proposed to describe the adaptability as a special resource, adaptation energy. The animal dies when this resource is exhausted. Selye assumed that  the adaptability is a finite supply, presented at birth. Later on, Goldstone proposed the concept of a production or income of adaptation energy which may be stored (up to a limit), as a capital reserve of adaptation. In recent works,  adaptation energy is considered as an internal coordinate on the \"dominant path\" in the model of adaptation. It is demonstrated that oscillations of well-being appear when the reserve of adaptability is almost exhausted.\n\nIn 2012, suicide overtook car crashes for leading causes of human injury deaths in the U.S., followed by poisoning, falls and murder. Causes of death are different in different parts of the world. In high-income and middle income countries nearly half up to more than two thirds of all people live beyond the age of 70 and predominantly die of chronic diseases. In low-income countries, where less than one in five of all people reach the age of 70, and more than a third of all deaths are among children under 15, people predominantly die of infectious diseases.\n\nAutopsy \n\nAn autopsy, also known as a postmortem examination or an obduction, is a medical procedure that consists of a thorough examination of a human corpse to determine the cause and manner of a person's death and to evaluate any disease or injury that may be present. It is usually performed by a specialized medical doctor called a pathologist.\n\nAutopsies are either performed for legal or medical purposes. A forensic autopsy is carried out when the cause of death may be a criminal matter, while a clinical or academic autopsy is performed to find the medical cause of death and is used in cases of unknown or uncertain death, or for research purposes. Autopsies can be further classified into cases where external examination suffices, and those where the body is dissected and an internal examination is conducted. Permission from next of kin may be required for internal autopsy in some cases. Once an internal autopsy is complete the body is generally reconstituted by sewing it back together. Autopsy is important in a medical environment and may shed light on mistakes and help improve practices.\n\nA necropsy, which is not always a medical procedure, was a term previously used to describe an unregulated postmortem examination . In modern times, this term is more commonly associated with the corpses of animals.\n\nSenescence \n\nSenescence refers to a scenario when a living being is able to survive all calamities, but eventually dies due to causes relating to old age. Animal and plant cells normally reproduce and function during the whole period of natural existence, but the aging process derives from deterioration of cellular activity and ruination of regular functioning. Aptitude of cells for gradual deterioration and mortality means that cells are naturally sentenced to stable and long-term loss of living capacities, even despite continuing metabolic reactions and viability. In the United Kingdom, for example, nine out of ten of all the deaths that occur on a daily basis relates to senescence, while around the world it accounts for two-thirds of 150,000 deaths that take place daily (Hayflick & Moody, 2003).\n\nAlmost all animals who survive external hazards to their biological functioning eventually die from biological aging, known in life sciences as \"senescence\". Some organisms experience negligible senescence, even exhibiting biological immortality.  These include the jellyfish Turritopsis dohrnii, the hydra, and the planarian. Unnatural causes of death include suicide and predation. From all causes, roughly 150,000 people die around the world each day. Of these, two thirds die directly or indirectly due to senescence, but in industrialized countries \u2013 such as the United States, the United Kingdom, and Germany \u2013 the rate approaches 90% (i.e., nearly nine out of ten of all deaths are related to senescence).\n\nPhysiological death is now seen as a process, more than an event: conditions once considered indicative of death are now reversible. Where in the process a dividing line is drawn between life and death depends on factors beyond the presence or absence of vital signs. In general, clinical death is neither necessary nor sufficient for a determination of legal death. A patient with working heart and lungs determined to be brain dead can be pronounced legally dead without clinical death occurring.\n\nCryonics \n\nCryonics (from Greek \u03ba\u03c1\u03cd\u03bf\u03c2 'kryos-' meaning 'icy cold') is the low-temperature preservation of animals and humans who cannot be sustained by contemporary medicine, with the hope that healing and resuscitation may be possible in the future.\n\nCryopreservation of people or large animals is not reversible with current technology. The stated rationale for cryonics is that people who are considered dead by current legal or medical definitions may not necessarily be dead according to the more stringent information-theoretic definition of death.\n\nSome scientific literature is claimed to support the feasibility of cryonics. Medical science and cryobiologists generally regards cryonics with skepticism.\n\nReperfusion \n\"One of medicine's new frontiers: treating the dead\", recognizes that cells that have been without oxygen for more than five minutes die, not from lack of oxygen, but rather when their oxygen supply is resumed. Therefore, practitioners of this approach, e.g., at the Resuscitation Science institute at the University of Pennsylvania, \"aim to reduce oxygen uptake, slow metabolism and adjust the blood chemistry for gradual and safe reperfusion.\"\n\nLife extension \n\nLife extension refers to an increase in maximum or average lifespan, especially in humans, by slowing down or reversing the processes of aging through anti-aging measures. Despite the fact that aging is by far the most common cause of death worldwide, it is socially mostly ignored as such and seen as \"necessary\" and \"inevitable\" anyway, which is why little money is spent on research into anti-aging therapies, a phenomenon known as the pro-aging trance.\n\nAverage lifespan is determined by vulnerability to accidents and age or lifestyle-related afflictions such as cancer, or cardiovascular disease. Extension of average lifespan can be achieved by good diet, exercise and avoidance of hazards such as smoking. Maximum lifespan is also determined by the rate of aging for a species inherent in its genes. Currently, the only widely recognized method of extending maximum lifespan is calorie restriction. Theoretically, extension of maximum lifespan can be achieved by reducing the rate of aging damage, by periodic replacement of damaged tissues, or by molecular repair or rejuvenation of deteriorated cells and tissues.\n\nA United States poll found that religious people and irreligious people, as well as men and women and people of different economic classes have similar rates of support for life extension, while Africans and Hispanics have higher rates of support than white people. 38 percent of the polled said they would desire to have their aging process cured.\n\nResearchers of life extension are a subclass of biogerontologists known as \"biomedical gerontologists\". They try to understand the nature of aging and they develop treatments to reverse aging processes or to at least slow them down, for the improvement of health and the maintenance of youthful vigor at every stage of life. Those who take advantage of life extension findings and seek to apply them upon themselves are called \"life extensionists\" or \"longevists\". The primary life extension strategy currently is to apply available anti-aging methods in the hope of living long enough to benefit from a complete cure to aging once it is developed.\n\nLocation \n\nBefore about 1930, most people in Western countries died in their own homes, surrounded by family, and comforted by clergy, neighbors, and doctors making house calls. By the mid-20th century, half of all Americans died in a hospital. By the start of the 21st century, only about 20\u201325% of people in developed countries died outside of a medical institution. The shift away from dying at home towards dying in a professional medical environment has been termed the \"Invisible Death\". This shift occurred gradually over the years, until most deaths now occur outside the home.\n\nPsychology \n\nDeath studies is a field within psychology.\n\nMany people are afraid of dying. Discussing, thinking, or planning their own deaths causes them discomfort.  This fear may cause them to put off financial planning, preparing a will and testament, or requesting help from a hospice organization.\n\nDifferent people have different responses to the idea of their own deaths.\n\nPhilosopher Galen Strawson writes that the death that many people wish for is an instant, painless, unexperienced annihilation.  In this unlikely scenario, the person dies without realizing it and without being able to fear it.  One moment the person is walking, eating, or sleeping, and the next moment, the person is dead.  Strawson reasons that this type of death would not take anything away from the person, as he believes that a person cannot have a legitimate claim to ownership in the future.\n\nSociety and culture \n\nIn society, the nature of death and humanity's awareness of its own mortality has for millennia been a concern of the world's religious traditions and of philosophical inquiry. This includes belief in resurrection or an afterlife (associated with Abrahamic religions), reincarnation or rebirth (associated with Dharmic religions), or that consciousness permanently ceases to exist, known as eternal oblivion (associated with Secular humanism).\n\nCommemoration ceremonies after death may include various mourning, funeral practices and ceremonies of honouring the deceased. The physical remains of a person, commonly known as a corpse or body, are usually interred whole or cremated, though among the world's cultures there are a variety of other methods of mortuary disposal. In the English language, blessings directed towards a dead person include rest in peace (originally the Latin requiescat in pace), or its initialism RIP.\n\nDeath is the center of many traditions and organizations; customs relating to death are a feature of every culture around the world. Much of this revolves around the care of the dead, as well as the afterlife and the disposal of bodies upon the onset of death. The disposal of human corpses does, in general, begin with the last offices before significant time has passed, and ritualistic ceremonies often occur, most commonly interment or cremation. This is not a unified practice; in Tibet, for instance, the body is given a sky burial and left on a mountain top. Proper preparation for death and techniques and ceremonies for producing the ability to transfer one's spiritual attainments into another body (reincarnation) are subjects of detailed study in Tibet. Mummification or embalming is also prevalent in some cultures, to retard the rate of decay.\n\nLegal aspects of death are also part of many cultures, particularly the settlement of the deceased estate and the issues of inheritance and in some countries, inheritance taxation.\n\nCapital punishment is also a culturally divisive aspect of death. In most jurisdictions where capital punishment is carried out today, the death penalty is reserved for premeditated murder, espionage, treason, or as part of military justice. In some countries, sexual crimes, such as adultery and sodomy, carry the death penalty, as do religious crimes such as apostasy, the formal renunciation of one's religion. In many retentionist countries, drug trafficking is also a capital offense. In China, human trafficking and serious cases of corruption are also punished by the death penalty. In militaries around the world courts-martial have imposed death sentences for offenses such as cowardice, desertion, insubordination, and mutiny.\n\nDeath in warfare and in suicide attack also have cultural links, and the ideas of dulce et decorum est pro patria mori, mutiny punishable by death, grieving relatives of dead soldiers and death notification are embedded in many cultures. Recently in the western world, with the increase in terrorism following the September 11 attacks, but also further back in time with suicide bombings, kamikaze missions in World War II and suicide missions in a host of other conflicts in history, death for a cause by way of suicide attack, and martyrdom have had significant cultural impacts.\n\nSuicide in general, and particularly euthanasia, are also points of cultural debate. Both acts are understood very differently in different cultures. In Japan, for example, ending a life with honor by seppuku was considered a desirable death, whereas according to traditional Christian and Islamic cultures, suicide is viewed as a sin. Death is personified in many cultures, with such symbolic representations as the Grim Reaper, Azrael, the Hindu god Yama and Father Time.\n\nIn Brazil, a human death is counted officially when it is registered by existing family members at a cart\u00f3rio, a government-authorized registry. Before being able to file for an official death, the deceased must have been registered for an official birth at the cart\u00f3rio. Though a Public Registry Law guarantees all Brazilian citizens the right to register deaths, regardless of their financial means, of their family members (often children), the Brazilian government has not taken away the burden, the hidden costs and fees, of filing for a death. For many impoverished families, the indirect costs and burden of filing for a death lead to a more appealing, unofficial, local, cultural burial, which in turn raises the debate about inaccurate mortality rates.\n\nTalking about death and witnessing it is a difficult issue with most cultures. Western societies may like to treat the dead with the utmost material respect, with an official embalmer and associated rites. Eastern societies (like India) may be more open to accepting it as a fait accompli, with a funeral procession of the dead body ending in an open-air burning-to-ashes of the same.\n\nConsciousness \n\nMuch interest and debate surround the question of what happens to one's consciousness as one's body dies. The belief in the permanent loss of consciousness after death is often called eternal oblivion. Belief that the stream of consciousness is preserved after physical death is described by the term afterlife. Neither are likely to ever be confirmed without the ponderer having to actually die.\n\nIn biology \n\nAfter death, the remains of a former organism become part of the biogeochemical cycle, during which animals may be consumed by a predator or a scavenger. Organic material may then be further decomposed by detritivores, organisms which recycle detritus, returning it to the environment for reuse in the food chain, where these chemicals may eventually end up being consumed and assimilated into the cells of an organism. Examples of detritivores include earthworms, woodlice and dung beetles.\n\nMicroorganisms also play a vital role, raising the temperature of the decomposing matter as they break it down into yet simpler molecules. Not all materials need to be fully decomposed. Coal, a fossil fuel formed over vast tracts of time in swamp ecosystems, is one example.\n\nNatural selection \n\nContemporary evolutionary theory sees death as an important part of the process of natural selection. It is considered that organisms less adapted to their environment are more likely to die having produced fewer offspring, thereby reducing their contribution to the gene pool. Their genes are thus eventually bred out of a population, leading at worst to extinction and, more positively, making the process possible, referred to as speciation. Frequency of reproduction plays an equally important role in determining species survival: an organism that dies young but leaves numerous offspring displays, according to Darwinian criteria, much greater fitness than a long-lived organism leaving only one.\n\nExtinction \n\nExtinction is the cessation of existence of a species or group of taxa, reducing biodiversity. The moment of extinction is generally considered to be the death of the last individual of that species (although the capacity to breed and recover may have been lost before this point). Because a species' potential range may be very large, determining this moment is difficult, and is usually done retrospectively. This difficulty leads to phenomena such as Lazarus taxa, where species presumed extinct abruptly \"reappear\" (typically in the fossil record) after a period of apparent absence. New species arise through the process of speciation, an aspect of evolution. New varieties of organisms arise and thrive when they are able to find and exploit an ecological niche \u2013 and species become extinct when they are no longer able to survive in changing conditions or against superior competition.\n\nEvolution of aging and mortality \n\nInquiry into the evolution of aging aims to explain why so many living things and the vast majority of animals weaken and die with age (exceptions include Hydra and the already cited jellyfish Turritopsis dohrnii, which research shows to be biologically immortal). The evolutionary origin of senescence remains one of the fundamental puzzles of biology. Gerontology specializes in the science of human aging processes.\n\nOrganisms showing only asexual reproduction (e.g. bacteria, some protists, like the euglenoids and many amoebozoans) and unicellular organisms with sexual reproduction (colonial or not, like the volvocine algae Pandorina and Chlamydomonas) are \"immortal\" at some extent, dying only due to external hazards, like being eaten or meeting with a fatal accident. In multicellular organisms (and also in multinucleate ciliates), with a Weismannist development, that is, with a division of labor between mortal somatic (body) cells and \"immortal\" germ (reproductive) cells, death becomes an essential part of life, at least for the somatic line.\n\nThe Volvox algae are among the simplest organisms to exhibit that division of labor between two completely different cell types, and as a consequence include death of somatic line as a regular, genetically regulated part of its life history.\n\nReligious views\n\nBuddhism \n\nIn Buddhist doctrine and practice, death plays an important role. Awareness of death was what motivated Prince Siddhartha to strive to find the \"deathless\" and finally to attain enlightenment. In Buddhist doctrine, death functions as a reminder of the value of having been born as a human being. Being reborn as a human being is considered the only state in which one can attain enlightenment. Therefore, death helps remind oneself that one should not take life for granted. The belief in rebirth among Buddhists does not necessarily remove death anxiety, since all existence in the cycle of rebirth is considered filled with suffering, and being reborn many times does not necessarily mean that one progresses.\n\nDeath is part of several key Buddhist tenets, such as the Four Noble Truths and dependent origination.\n\nChristianity \nWhile there are different sects of Christianity with different branches of belief; the overarching ideology on death grows from the knowledge of afterlife. Meaning after death the individual will undergo a separation from mortality to immortality; their soul leaves the body entering a realm of spirits. Following this separation of body and spirit (i.e. death)resurrection will occur. Representing the same transformation Jesus Christ embodied after his body was placed in the tomb for three days. Like Him, each person's body will be resurrected reuniting the spirit and body in a perfect form. This process allows the individuals soul to withstand death and transform into life after death.\n\nHinduism\n\nIn Hindu texts, death is described as the individual eternal spiritual jiva-atma (soul or conscious self) exiting the current temporary material body. The soul exits this body when the body can no longer sustain the conscious self (life), which may be due to mental or physical reasons, or more accurately, the inability to act on one's kama (material desires). During conception, the soul enters a compatible new body based on the remaining merits and demerits of one's karma (good/bad material activities based on dharma) and the state of one's mind (impressions or last thoughts) at the time of death.\n\nUsually the process of reincarnation (soul's transmigration) makes one forget all memories of one's previous life. Because nothing really dies and the temporary material body is always changing, both in this life and the next, death simply means forgetfulness of one's previous experiences (previous material identity).\n\nMaterial existence is described as being full of miseries arising from birth, disease, old age, death, mind, weather, etc. To conquer samsara (the cycle of death and rebirth) and become eligible for one of the different types of moksha (liberation), one has to first conquer kama (material desires) and become self-realized. The human form of life is most suitable for this spiritual journey, especially with the help of sadhu (self-realized saintly persons), sastra (revealed spiritual scriptures), and guru (self-realized spiritual masters), given all three are in agreement.\n\nIslam\n\nJudaism \n\nThere are a variety of beliefs about the afterlife within Judaism, but none of them contradict the preference of life over death.  This is partially because death puts a cessation to the possibility of fulfilling any commandments.\n\nLanguage around death \n\nThe word death comes from Old English d\u0113a\u00fe, which in turn comes from Proto-Germanic *dau\u00feuz (reconstructed by etymological analysis). This comes from the Proto-Indo-European stem *dheu- meaning the \"process, act, condition of dying\".\n\nThe concept and symptoms of death, and varying degrees of delicacy used in discussion in public forums, have generated numerous scientific, legal, and socially acceptable terms or euphemisms for death.  When a person has died, it is also said they have passed away, passed on, expired, or are gone, among numerous other socially accepted, religiously specific, slang, and irreverent terms.\n\nAs a formal reference to a dead person, it has become common practice to use the participle form of \"decease\", as in the deceased; another noun form is decedent.\n\nBereft of life, the dead person is then a corpse, cadaver, a body, a set of remains, and when all flesh has rotted away, a skeleton. The terms carrion and carcass can also be used, though these more often connote the remains of non-human animals.  The ashes left after a cremation are sometimes referred to by the neologism cremains.\n\nSee also \n\n Casualty (person)\n Day of Judgment\n Day of the Dead\n Deathbed\n Death drive\n Death row\n Death trajectory\n Dying\n Dying declaration\n End-of-life care\n Eschatology\n Faked death\n Kar\u014dshi\n Last rites\n List of deaths by year\n List of expressions related to death\n Memento mori\n Near-death experience\n Origin-of-death myth\n Spiritual death\n Survivalism (life after death)\n Taboo on the dead\n Thanatology\n Yama\n\nReferences\n\nBibliography\n\nFurther reading \n \n \n \n \n  Interviews with people dying in hospices, and portraits of them before, and shortly after, death.\n \n  How the medical profession categorized causes of death.\n  A biologist explains life and death in different kinds of organisms, in relation to evolution.\n\nExternal links \n\n \n \n \n \"Death\" (video; 10:18) by Timothy Ferris, producer of the Voyager Golden Record for NASA. 2021\n\n \nSenescence",
  "Ethics": "Ethics or moral philosophy is a branch of philosophy that \"involves systematizing, defending, and recommending concepts of right and wrong behavior\". The field of ethics, along with aesthetics, concerns matters of value; these fields comprise the branch of philosophy called axiology.\n\nEthics seeks to resolve questions of human morality by defining concepts such as good and evil, right and wrong, virtue and vice, justice and crime. As a field of intellectual inquiry, moral philosophy is related to the fields of moral psychology, descriptive ethics, and value theory.\n\nThree major areas of study within ethics recognized today are:\n Meta-ethics, concerning the theoretical meaning and reference of moral propositions, and how their truth values (if any) can be determined;\n Normative ethics, concerning the practical means of determining a moral course of action;\n Applied ethics, concerning what a person is obligated (or permitted) to do in a specific situation or a particular domain of action.\n\nHistory\n\nDefining ethics\nThe English word ethics is derived from the Ancient Greek word \u0113thik\u00f3s (), meaning \"relating to one's character\", which itself comes from the root word \u00eathos () meaning \"character, moral nature\". This word was transferred into Latin as ethica and then into French as \u00e9thique, from which it was transferred into English.\n\nRushworth Kidder states that \"standard definitions of ethics have typically included such phrases as 'the science of the ideal human character' or 'the science of moral duty'. Richard William Paul and Linda Elder define ethics as \"a set of concepts and principles that guide us in determining what behavior helps or harms sentient creatures\". The Cambridge Dictionary of Philosophy states that the word \"ethics\" is \"commonly used interchangeably with 'morality'\u00a0... and sometimes it is used more narrowly to mean the moral principles of a particular tradition, group or individual.\" Paul and Elder state that most people confuse ethics with behaving in accordance with social conventions, religious beliefs, the law, and do not treat ethics as a stand-alone concept.\n\nThe word ethics in English refers to several things. It can refer to philosophical ethics or moral philosophy\u2014a project that attempts to use reason to answer various kinds of ethical questions. As the English moral philosopher Bernard Williams writes, attempting to explain moral philosophy: \"What makes an inquiry a philosophical one is reflective generality and a style of argument that claims to be rationally persuasive.\" Williams describes the content of this area of inquiry as addressing the very broad question, \"how one should live\". Ethics can also refer to a common human ability to think about ethical problems that is not particular to philosophy. As bioethicist Larry Churchill has written: \"Ethics, understood as the capacity to think critically about moral values and direct our actions in terms of such values, is a generic human capacity.\" Ethics can also be used to describe a particular person's own idiosyncratic principles or habits. For example: \"Joe has strange ethics.\" Ethics is a normative science.\n\nMeta-ethics\n\nMeta-ethics is the branch of philosophical ethics that asks how we understand, know about, and what we mean when we talk about what is right and what is wrong. An ethical question pertaining to a particular practical situation\u2014such as, \"Should I eat this particular piece of chocolate cake?\"\u2014cannot be a meta-ethical question (rather, this is an applied ethical question). A meta-ethical question is abstract and relates to a wide range of more specific practical questions. For example, \"Is it ever possible to have a secure knowledge of what is right and wrong?\" is a meta-ethical question.\n\nMeta-ethics has always accompanied philosophical ethics. For example, Aristotle implies that less precise knowledge is possible in ethics than in other spheres of inquiry, and he regards ethical knowledge as depending upon habit and acculturation in a way that makes it distinctive from other kinds of knowledge. Meta-ethics is also important in G.E. Moore's Principia Ethica from 1903. In it he first wrote about what he called the naturalistic fallacy. Moore was seen to reject naturalism in ethics, in his open-question argument. This made thinkers look again at second order questions about ethics. Earlier, the Scottish philosopher David Hume had put forward a similar view on the difference between facts and values.\n\nStudies of how we know in ethics divide into cognitivism and non-cognitivism; these, respectively, take descriptive and non-descriptive approaches to moral goodness or value. Non-cognitivism is the view that when we judge something as morally right or wrong, this is neither true nor false. We may, for example, be only expressing our emotional feelings about these things. Cognitivism can then be seen as the claim that when we talk about right and wrong, we are talking about matters of fact.\n\nThe ontology of ethics is about value-bearing things or properties, that is, the kind of things or stuff referred to by ethical propositions. Non-descriptivists and non-cognitivists believe that ethics does not need a specific ontology since ethical propositions do not refer. This is known as an anti-realist position. Realists, on the other hand, must explain what kind of entities, properties or states are relevant for ethics, how they have value, and why they guide and motivate our actions.\n\nMoral skepticism\n\nMoral skepticism (or moral scepticism) is a class of metaethical theories in which all members entail that no one has any moral knowledge. Many moral skeptics also make the stronger, modal claim that moral knowledge is impossible. Moral skepticism is particularly against moral realism which holds the view that there are knowable and objective moral truths.\n\nSome proponents of moral skepticism include Pyrrho, Aenesidemus, Sextus Empiricus, David Hume, Max Stirner, Friedrich Nietzsche, and J.L. Mackie.\n\nMoral skepticism is divided into three sub-classes:\n\n Moral error theory (or moral nihilism).\n Epistemological moral skepticism.\n Non-cognitivism.\n\nAll of these three theories share the same conclusions, which are as follows:\n\n(a) we are never justified in believing that moral claims (claims of the form \"state of affairs x is good,\" \"action y is morally obligatory,\" etc.) are true and, even more so\n(b) we never know that any moral claim is true.\n\nHowever, each method arrives at (a) and (b) by different routes.\n\nMoral error theory holds that we do not know that any moral claim is true because\n(i) all moral claims are false,\n(ii) we have reason to believe that all moral claims are false, and\n(iii) since we are not justified in believing any claim we have reason to deny, we are not justified in believing any moral claims.\n\nEpistemological moral skepticism is a subclass of theory, the members of which include Pyrrhonian moral skepticism and dogmatic moral skepticism. All members of epistemological moral skepticism share two things: first, they acknowledge that we are unjustified in believing any moral claim, and second, they are agnostic on whether (i) is true (i.e. on whether all moral claims are false).\nPyrrhonian moral skepticism holds that the reason we are unjustified in believing any moral claim is that it is irrational for us to believe either that any moral claim is true or that any moral claim is false. Thus, in addition to being agnostic on whether (i) is true, Pyrrhonian moral skepticism denies (ii).\nDogmatic moral skepticism, on the other hand, affirms (ii) and cites (ii)'s truth as the reason we are unjustified in believing any moral claim.\n\nNoncognitivism holds that we can never know that any moral claim is true because moral claims are incapable of being true or false (they are not truth-apt). Instead, moral claims are imperatives (e.g. \"Don't steal babies!\"), expressions of emotion (e.g. \"stealing babies: Boo!\"), or expressions of \"pro-attitudes\" (\"I do not believe that babies should be stolen.\")\n\nNormative ethics\n\nNormative ethics is the study of ethical action. It is the branch of ethics that investigates the set of questions that arise when considering how one ought to act, morally speaking. Normative ethics is distinct from meta-ethics because normative ethics examines standards for the rightness and wrongness of actions, while meta-ethics studies the meaning of moral language and the metaphysics of moral facts. Normative ethics is also distinct from descriptive ethics, as the latter is an empirical investigation of people's moral beliefs. To put it another way, descriptive ethics would be concerned with determining what proportion of people believe that killing is always wrong, while normative ethics is concerned with whether it is correct to hold such a belief. Hence, normative ethics is sometimes called prescriptive rather than descriptive. However, on certain versions of the meta-ethical view called moral realism, moral facts are both descriptive and prescriptive at the same time.\n\nTraditionally, normative ethics (also known as moral theory) was the study of what makes actions right and wrong. These theories offered an overarching moral principle one could appeal to in resolving difficult moral decisions.\n\nAt the turn of the 20th century, moral theories became more complex and were no longer concerned solely with rightness and wrongness, but were interested in many different kinds of moral status. During the middle of the century, the study of normative ethics declined as meta-ethics grew in prominence. This focus on meta-ethics was in part caused by an intense linguistic focus in analytic philosophy and by the popularity of logical positivism.\n\nVirtue ethics\n\nVirtue ethics describes the character of a moral agent as a driving force for ethical behavior, and it is used to describe the ethics of early Greek philosophers such as Socrates and Aristotle, and ancient Indian philosophers such as Valluvar. Socrates (469\u2013399 BC) was one of the first Greek philosophers to encourage both scholars and the common citizen to turn their attention from the outside world to the condition of humankind. In this view, knowledge bearing on human life was placed highest, while all other knowledge was secondary. Self-knowledge was considered necessary for success and inherently an essential good. A self-aware person will act completely within his capabilities to his pinnacle, while an ignorant person will flounder and encounter difficulty. To Socrates, a person must become aware of every fact (and its context) relevant to his existence, if he wishes to attain self-knowledge. He posited that people will naturally do what is good if they know what is right. Evil or bad actions are the results of ignorance. If a criminal was truly aware of the intellectual and spiritual consequences of his or her actions, he or she would neither commit nor even consider committing those actions. Any person who knows what is truly right will automatically do it, according to Socrates. While he correlated knowledge with virtue, he similarly equated virtue with joy. The truly wise man will know what is right, do what is good, and therefore be happy.\n\nAristotle (384\u2013323\u00a0BC) posited an ethical system that may be termed \"virtuous\". In Aristotle's view, when a person acts in accordance with virtue this person will do good and be content. Unhappiness and frustration are caused by doing wrong, leading to failed goals and a poor life. Therefore, it is imperative for people to act in accordance with virtue, which is only attainable by the practice of the virtues in order to be content and complete. Happiness was held to be the ultimate goal. All other things, such as civic life or wealth, were only made worthwhile and of benefit when employed in the practice of the virtues. The practice of the virtues is the surest path to happiness. Aristotle asserted that the soul of man had three natures: body (physical/metabolism), animal (emotional/appetite), and rational (mental/conceptual). Physical nature can be assuaged through exercise and care; emotional nature through indulgence of instinct and urges; and mental nature through human reason and developed potential. Rational development was considered the most important, as essential to philosophical self-awareness, and as uniquely human. Moderation was encouraged, with the extremes seen as degraded and immoral. For example, courage is the moderate virtue between the extremes of cowardice and recklessness. Man should not simply live, but live well with conduct governed by virtue. This is regarded as difficult, as virtue denotes doing the right thing, in the right way, at the right time, for the right reason.\n\nValluvar (before 5th century CE) keeps virtue, or a\u1e5fam (dharma) as he calls it, as the cornerstone throughout the writing of the Kural literature. While religious scriptures generally consider a\u1e5fam as divine in nature, Valluvar describes it as a way of life rather than any spiritual observance, a way of harmonious living that leads to universal happiness. Contrary to what other contemporary works say, Valluvar holds that a\u1e5fam is common for all, irrespective of whether the person is a bearer of palanquin or the rider in it. Valluvar considered justice as a facet of a\u1e5fam. While ancient Greek philosophers such as Plato, Aristotle, and their descendants opined that justice cannot be defined and that it was a divine mystery, Valluvar positively suggested that a divine origin is not required to define the concept of justice. In the words of V. R. Nedunchezhiyan, justice according to Valluvar \"dwells in the minds of those who have knowledge of the standard of right and wrong; so too deceit dwells in the minds which breed fraud.\"\n\nStoicism\n\nThe Stoic philosopher Epictetus posited that the greatest good was contentment and serenity. Peace of mind, or apatheia, was of the highest value; self-mastery over one's desires and emotions leads to spiritual peace. The \"unconquerable will\" is central to this philosophy. The individual's will should be independent and inviolate. Allowing a person to disturb the mental equilibrium is, in essence, offering yourself in slavery. If a person is free to anger you at will, you have no control over your internal world, and therefore no freedom. Freedom from material attachments is also necessary. If a thing breaks, the person should not be upset, but realize it was a thing that could break. Similarly, if someone should die, those close to them should hold to their serenity because the loved one was made of flesh and blood destined to death. Stoic philosophy says to accept things that cannot be changed, resigning oneself to the existence and enduring in a rational fashion. Death is not feared. People do not \"lose\" their life, but instead \"return\", for they are returning to God (who initially gave what the person is as a person). Epictetus said difficult problems in life should not be avoided, but rather embraced. They are spiritual exercises needed for the health of the spirit, just as physical exercise is required for the health of the body. He also stated that sex and sexual desire are to be avoided as the greatest threat to the integrity and equilibrium of a man's mind. Abstinence is highly desirable. Epictetus said remaining abstinent in the face of temptation was a victory for which a man could be proud.\n\nContemporary virtue ethics\nModern virtue ethics was popularized during the late 20th century in large part due to a revival of Aristotelianism, and as a response to G.E.M. Anscombe's \"Modern Moral Philosophy\". Anscombe argues that consequentialist and deontological ethics are only feasible as universal theories if the two schools ground themselves in divine law. As a deeply devoted Christian herself, Anscombe proposed that either those who do not give ethical credence to notions of divine law take up virtue ethics, which does not necessitate universal laws as agents themselves are investigated for virtue or vice and held up to \"universal standards\", or that those who wish to be utilitarian or consequentialist ground their theories in religious conviction. Alasdair MacIntyre, who wrote the book After Virtue, was a key contributor and proponent of modern virtue ethics, although some claim that MacIntyre supports a relativistic account of virtue based on cultural norms, not objective standards. Martha Nussbaum, a contemporary virtue ethicist, objects to MacIntyre's relativism, among that of others, and responds to relativist objections to form an objective account in her work \"Non-Relative Virtues: An Aristotelian Approach\". However, Nussbaum's accusation of relativism appears to be a misreading. In Whose Justice, Whose Rationality?, MacIntyre's ambition of taking a rational path beyond relativism was quite clear when he stated \"rival claims made by different traditions [\u2026] are to be evaluated [\u2026] without relativism\" (p.\u00a0354) because indeed \"rational debate between and rational choice among rival traditions is possible\u201d (p.\u00a0352). Complete Conduct Principles for the 21st Century blended the Eastern virtue ethics and the Western virtue ethics, with some modifications to suit the 21st Century, and formed a part of contemporary virtue ethics.\nMortimer J. Adler described Aristotle's Nicomachean Ethics as a \"unique book in the Western tradition of moral philosophy, the only ethics that is sound, practical, and undogmatic.\"\n\nOne major trend in contemporary virtue ethics is the Modern Stoicism movement.\n\nIntuitive ethics\n\nEthical intuitionism (also called moral intuitionism) is a family of views in moral epistemology (and, on some definitions, metaphysics).  At minimum, ethical intuitionism is the thesis that our intuitive awareness of value, or intuitive knowledge of evaluative facts, forms the foundation of our ethical knowledge.\n\nThe view is at its core a foundationalism about moral knowledge: it is the view that some moral truths can be known non-inferentially (i.e., known without one needing to infer them from other truths one believes).  Such an epistemological view implies that there are moral beliefs with propositional contents; so it implies cognitivism. As such, ethical intuitionism is to be contrasted with coherentist approaches to moral epistemology, such as those that depend on reflective equilibrium.\n\nThroughout the philosophical literature, the term \"ethical intuitionism\" is frequently used with significant variation in its sense. This article's focus on foundationalism reflects the core commitments of contemporary self-identified ethical intuitionists.\n\nSufficiently broadly defined, ethical intuitionism can be taken to encompass cognitivist forms of moral sense theory. It is usually furthermore taken as essential to ethical intuitionism that there be self-evident or a priori moral knowledge; this counts against considering moral sense theory to be a species of intuitionism. (see the Rational intuition versus moral sense section of this article for further discussion).\n\nEthical intuitionism was first clearly shown in use by the philosopher Francis Hutcheson. Later ethical intuitionists of influence and note include Henry Sidgwick, G.E. Moore, Harold Arthur Prichard, C.S. Lewis and, most influentially, Robert Audi.\n\nObjections to ethical intuitionism include whether or not there are objective moral values- an assumption which the ethical system is based upon- the question of why many disagree over ethics if they are absolute, and whether Occam's razor cancels such a theory out entirely.\n\nHedonism\n\nHedonism posits that the principal ethic is maximizing pleasure and minimizing pain. There are several schools of Hedonist thought ranging from those advocating the indulgence of even momentary desires to those teaching a pursuit of spiritual bliss. In their consideration of consequences, they range from those advocating self-gratification regardless of the pain and expense to others, to those stating that the most ethical pursuit maximizes pleasure and happiness for the most people.\n\nCyrenaic hedonism\nFounded by Aristippus of Cyrene, Cyrenaics supported immediate gratification or pleasure. \"Eat, drink and be merry, for tomorrow we die.\" Even fleeting desires should be indulged, for fear the opportunity should be forever lost. There was little to no concern with the future, the present dominating in the pursuit of immediate pleasure. Cyrenaic hedonism encouraged the pursuit of enjoyment and indulgence without hesitation, believing pleasure to be the only good.\n\nEpicureanism\n\nEpicurean ethics is a hedonist form of virtue ethics. Epicurus \"...presented a sustained argument that pleasure, correctly understood, will coincide with virtue.\" He rejected the extremism of the Cyrenaics, believing some pleasures and indulgences to be detrimental to human beings. Epicureans observed that indiscriminate indulgence sometimes resulted in negative consequences. Some experiences were therefore rejected out of hand, and some unpleasant experiences endured in the present to ensure a better life in the future. To Epicurus, the summum bonum, or greatest good, was prudence, exercised through moderation and caution. Excessive indulgence can be destructive to pleasure and can even lead to pain. For example, eating one food too often makes a person lose a taste for it. Eating too much food at once leads to discomfort and ill-health. Pain and fear were to be avoided. Living was essentially good, barring pain and illness. Death was not to be feared. Fear was considered the source of most unhappiness. Conquering the fear of death would naturally lead to a happier life. Epicurus reasoned if there were an afterlife and immortality, the fear of death was irrational. If there was no life after death, then the person would not be alive to suffer, fear, or worry; he would be non-existent in death. It is irrational to fret over circumstances that do not exist, such as one's state of death in the absence of an afterlife.\n\nState consequentialism\n\nState consequentialism, also known as Mohist consequentialism, is an ethical theory that evaluates the moral worth of an action based on how much it contributes to the basic goods of a state. The Stanford Encyclopedia of Philosophy describes Mohist consequentialism, dating back to the 5th century BC, as \"a remarkably sophisticated version based on a plurality of intrinsic goods taken as constitutive of human welfare\". Unlike utilitarianism, which views pleasure as a moral good, \"the basic goods in Mohist consequentialist thinking are\u00a0\u2026 order, material wealth, and increase in population\". During Mozi's era, war and famines were common, and population growth was seen as a moral necessity for a harmonious society. The \"material wealth\" of Mohist consequentialism refers to basic needs like shelter and clothing, and the \"order\" of Mohist consequentialism refers to Mozi's stance against warfare and violence, which he viewed as pointless and a threat to social stability.\n\nStanford sinologist David Shepherd Nivison, in The Cambridge History of Ancient China, writes that the moral goods of Mohism \"are interrelated: more basic wealth, then more reproduction; more people, then more production and wealth\u00a0\u2026 if people have plenty, they would be good, filial, kind, and so on unproblematically.\" The Mohists believed that morality is based on \"promoting the benefit of all under heaven and eliminating harm to all under heaven\". In contrast to Bentham's views, state consequentialism is not utilitarian because it is not hedonistic or individualistic. The importance of outcomes that are good for the community outweighs the importance of individual pleasure and pain.\n\nConsequentialism\n\nConsequentialism refers to moral theories that hold the consequences of a particular action form the basis for any valid moral judgment about that action (or create a structure for judgment, see rule consequentialism). Thus, from a consequentialist standpoint, morally right action is one that produces a good outcome, or consequence. This view is often expressed as the aphorism \"The ends justify the means\".\n\nThe term \"consequentialism\" was coined by G.E.M. Anscombe in her essay \"Modern Moral Philosophy\" in 1958, to describe what she saw as the central error of certain moral theories, such as those propounded by Mill and Sidgwick. Since then, the term has become common in English-language ethical theory.\n\nThe defining feature of consequentialist moral theories is the weight given to the consequences in evaluating the rightness and wrongness of actions. In consequentialist theories, the consequences of an action or rule generally outweigh other considerations. Apart from this basic outline, there is little else that can be unequivocally said about consequentialism as such. However, there are some questions that many consequentialist theories address:\n What sort of consequences count as good consequences?\n Who is the primary beneficiary of moral action?\n How are the consequences judged and who judges them?\n\nOne way to divide various consequentialisms is by the many types of consequences that are taken to matter most, that is, which consequences count as good states of affairs. According to utilitarianism, a good action is one that results in an increase and positive effect, and the best action is one that results in that effect for the greatest number. Closely related is eudaimonic consequentialism, according to which a full, flourishing life, which may or may not be the same as enjoying a great deal of pleasure, is the ultimate aim. Similarly, one might adopt an aesthetic consequentialism, in which the ultimate aim is to produce beauty. However, one might fix on non-psychological goods as the relevant effect. Thus, one might pursue an increase in material equality or political liberty instead of something like the more ephemeral \"pleasure\". Other theories adopt a package of several goods, all to be promoted equally.  Whether a particular consequentialist theory focuses on a single good or many, conflicts and tensions between different good states of affairs are to be expected and must be adjudicated.\n\nUtilitarianism\n\nUtilitarianism is an ethical theory that argues the proper course of action is one that maximizes a positive effect, such as \"happiness\", \"welfare\", or the ability to live according to personal preferences. Jeremy Bentham and John Stuart Mill are influential proponents of this school of thought.  In A Fragment on Government Bentham says 'it is the greatest happiness of the greatest number that is the measure of right and wrong' and describes this as a fundamental axiom. In An Introduction to the Principles of Morals and Legislation he talks of 'the principle of utility' but later prefers \"the greatest happiness principle\".\n\nUtilitarianism is the paradigmatic example of a consequentialist moral theory. This form of utilitarianism holds that the morally correct action is the one that produces the best outcome for all people affected by the action. John Stuart Mill, in his exposition of utilitarianism, proposed a hierarchy of pleasures, meaning that the pursuit of certain kinds of pleasure is more highly valued than the pursuit of other pleasures. Other noteworthy proponents of utilitarianism are neuroscientist Sam Harris, author of The Moral Landscape, and moral philosopher Peter Singer, author of, amongst other works, Practical Ethics.\n\nThe major division within utilitarianism is between act utilitarianism and rule utilitarianism. In act utilitarianism, the principle of utility applies directly to each alternative act in a situation of choice. The right act is the one that brings about the best results (or the least bad results). In rule utilitarianism, the principle of utility determines the validity of rules of conduct (moral principles). A rule like promise-keeping is established by looking at the consequences of a world in which people break promises at will and a world in which promises are binding. Right and wrong are the following or breaking of rules that are sanctioned by their utilitarian value. A proposed \"middle ground\" between these two types is Two-level utilitarianism, where rules are applied in ordinary circumstances, but with an allowance to choose actions outside of such rules when unusual situations call for it.\n\nDeontology\n\nDeontological ethics or deontology (from Greek , deon, \"obligation, duty\"; and , -logia) is an approach to ethics that determines goodness or rightness from examining acts, or the rules and duties that the person doing the act strove to fulfill.  This is in contrast to consequentialism, in which rightness is based on the consequences of an act, and not the act by itself. Under deontology, an act may be considered right even if it produces a bad consequence, if it follows the rule or moral law.  According to the deontological view, people have a duty to act in ways that are deemed inherently good (\"truth-telling\" for example), or follow an objectively obligatory rule (as in rule utilitarianism).\n\nKantianism\n\nImmanuel Kant's theory of ethics is considered deontological for several different reasons. First, Kant argues that to act in the morally right way, people must act from duty (Pflicht). Second, Kant argued that it was not the consequences of actions that make them right or wrong but the motives of the person who carries out the action.\n\nKant's argument that to act in the morally right way one must act purely from duty begins with an argument that the highest good must be both good in itself and good without qualification. Something is \"good in itself\" when it is intrinsically good, and \"good without qualification\", when the addition of that thing never makes a situation ethically worse. Kant then argues that those things that are usually thought to be good, such as intelligence, perseverance and pleasure, fail to be either intrinsically good or good without qualification. Pleasure, for example, appears not to be good without qualification, because when people take pleasure in watching someone suffer, this seems to make the situation ethically worse. He concludes that there is only one thing that is truly good:\nKant then argues that the consequences of an act of willing cannot be used to determine that the person has a good will; good consequences could arise by accident from an action that was motivated by a desire to cause harm to an innocent person, and bad consequences could arise from an action that was well-motivated. Instead, he claims, a person has goodwill when he 'acts out of respect for the moral law'. People 'act out of respect for the moral law' when they act in some way because they have a duty to do so. So, the only thing that is truly good in itself is goodwill, and goodwill is only good when the willer chooses to do something because it is that person's duty, i.e. out of \"respect\" for the law. He defines respect as \"the concept of a worth which thwarts my self-love\".\n\nKant's three significant formulations of the categorical imperative are:\n Act only according to that maxim by which you can also will that it would become a universal law.\n Act in such a way that you always treat humanity, whether in your own person or in the person of any other, never simply as a means, but always at the same time as an end.\n Every rational being must so act as if he were through his maxim always a legislating member in a universal kingdom of ends.\n\nKant argued that the only absolutely good thing is a good will, and so the single determining factor of whether an action is morally right is the will, or motive of the person doing it. If they are acting on a bad maxim, e.g. \"I will lie\", then their action is wrong, even if some good consequences come of it.\nIn his essay, On a Supposed Right to Lie Because of Philanthropic Concerns, arguing against the position of \nBenjamin Constant, Des r\u00e9actions politiques, Kant states that \"Hence a lie defined merely as an intentionally untruthful declaration to another man does not require the additional condition that it must do harm to another, as jurists require in their definition (mendacium est falsiloquium in praeiudicium alterius). For a lie always harms another; if not some human being, then it nevertheless does harm to humanity in general, inasmuch as it vitiates the very source of right [Rechtsquelle] ... All practical principles of right must contain rigorous truth ... This is because such exceptions would destroy the universality on account of which alone they bear the name of principles.\"\n\nDivine command theory\n\nAlthough not all deontologists are religious, some belief in the 'divine command theory', which is actually a cluster of related theories which essentially state that an action is right if God has decreed that it is right.  According to Ralph Cudworth, an English philosopher, William of Ockham, Ren\u00e9 Descartes, and eighteenth-century Calvinists all accepted various versions of this moral theory, as they all held that moral obligations arise from God's commands. The Divine Command Theory is a form of deontology because, according to it, the rightness of any action depends upon that action being performed because it is a duty, not because of any good consequences arising from that action. If God commands people not to work on Sabbath, then people act rightly if they do not work on Sabbath because God has commanded that they do not do so. If they do not work on Sabbath because they are lazy, then their action is not truly speaking \"right\", even though the actual physical action performed is the same. If God commands not to covet a neighbor's goods, this theory holds that it would be immoral to do so, even if coveting provides the beneficial outcome of a drive to succeed or do well.\n\nOne thing that clearly distinguishes Kantian deontologism from divine command deontology is that Kantianism maintains that man, as a rational being, makes the moral law universal, whereas divine command maintains that God makes the moral law universal.\n\nDiscourse ethics\n\nGerman philosopher J\u00fcrgen Habermas has proposed a theory of discourse ethics that he claims is a descendant of Kantian ethics. He proposes that action should be based on communication between those involved, in which their interests and intentions are discussed so they can be understood by all. Rejecting any form of coercion or manipulation, Habermas believes that agreement between the parties is crucial for a moral decision to be reached. Like Kantian ethics, discourse ethics is a cognitive ethical theory, in that it supposes that truth and falsity can be attributed to ethical propositions. It also formulates a rule by which ethical actions can be determined and proposes that ethical actions should be universalizable, in a similar way to Kant's ethics.\n\nHabermas argues that his ethical theory is an improvement on Kant's ethics. He rejects the dualistic framework of Kant's ethics. Kant distinguished between the phenomena world, which can be sensed and experienced by humans, and the noumena, or spiritual world, which is inaccessible to humans. This dichotomy was necessary for Kant because it could explain the autonomy of a human agent: although a human is bound in the phenomenal world, their actions are free in the noumenal world. For Habermas, morality arises from discourse, which is made necessary by their rationality and needs, rather than their freedom.\n\nPragmatic ethics\n\nAssociated with the pragmatists, Charles Sanders Peirce, William James, and especially John Dewey, pragmatic ethics holds that moral correctness evolves similarly to scientific knowledge: socially over the course of many lifetimes. Thus, we should prioritize social reform over attempts to account for consequences, individual virtue or duty (although these may be worthwhile attempts, if social reform is provided for).\n\nEthics of care\n\nCare ethics contrasts with more well-known ethical models, such as consequentialist theories (e.g. utilitarianism) and deontological theories (e.g., Kantian ethics) in that it seeks to incorporate traditionally feminized virtues and values that\u2014proponents of care ethics contend\u2014are absent in such traditional models of ethics. These values include the importance of empathetic relationships and compassion.\n\nCare-focused feminism is a branch of feminist thought, informed primarily by ethics of care as developed by Carol Gilligan and Nel Noddings. This body of theory is critical of how caring is socially assigned to women, and consequently devalued. They write, \"Care-focused feminists regard women's capacity for care as a human strength,\" that should be taught to and expected of men as well as women.  Noddings proposes that ethical caring has the potential to be a more concrete evaluative model of moral dilemma than an ethic of justice.  Noddings\u2019 care-focused feminism requires practical application of relational ethics, predicated on an ethic of care.\n\nFeminist matrixial ethics\n\nThe 'metafeminist' theory of  the matrixial gaze and the matrixial time-space, coined and developed by artist, philosopher and psychoanalyst Bracha L. Ettinger since 1985, articulates a revolutionary philosophical approach that, in \"daring to approach\", to use Griselda Pollock's description of Ettinger's ethical turn, \"the prenatal with the pre-maternal encounter\", violence toward women at war, and the Shoah, has philosophically established the rights of each female subject over her own reproductive body, and offered a language to relate to human experiences which escape the phallic domain. The matrixial sphere is a psychic and symbolic dimension that the 'phallic' language and regulations cannot control. In Ettinger's model, the relations between self and other are of neither assimilation nor rejection but 'coemergence'. In her conversation with Emmanuel Levinas, 1991, Ettinger prooses that the source of human Ethics is feminine-maternal and feminine-pre-maternal matrixial encounter-event. Sexuality and maternality coexist and are not in contradiction (the contradiction established by Sigmund Freud and Jacques Lacan), and the feminine is not an absolute alterity (the alterity established by Jacques Lacan and Emmanuel Levinas). With the 'originary response-ability', 'wit(h)nessing', 'borderlinking', 'communicaring', 'com-passion', 'seduction into life' and other processes invested by affects that occur in the Ettingerian matrixial time-space, the feminine is presented as the source of humanized Ethics in all genders. Compassion and Seduction into life occurs earlier than the primary seduction which passes through  enigmatic signals from the maternal sexuality according to Jean Laplanche, since it is active in 'coemergence' in 'withnessing' for any born subject, earlier to its birth. Ettinger suggests to Emanuel Levinas in their conversations in 1991, that the feminine understood via the matrixial perspective is the heart and the source of Ethics. At the beginning of life, an originary 'fascinance' felt by the infant is related to the passage from response-ability to responsibility, from com-passion to compassion, and from wit(h)nessing to witnessing operated and transmitted by the m/Other. The 'differentiation in jointness' that is at the heart of the matrixial borderspace has deep implications in the relational field\u00a0and for the ethics of care. The matrixial theory that proposes new ways to rethink sexual difference through the fluidity of boundaries informs aesthetics and ethics of compassion, carrying and non-abandonment in 'subjectivity as encounter-event'. It has become significant in Psychoanalysis and in transgender studies.\n\nRole ethics\n\nRole ethics is an ethical theory based on family roles. Unlike virtue ethics, role ethics is not individualistic. Morality is derived from a person's relationship with their community. Confucian ethics is an example of role ethics though this is not straightforwardly uncontested. Confucian roles center around the concept of filial piety or xiao, a respect for family members. According to Roger T. Ames and Henry Rosemont, \"Confucian normativity is defined by living one's family roles to maximum effect.\" Morality is determined through a person's fulfillment of a role, such as that of a parent or a child. Confucian roles are not rational, and originate through the xin, or human emotions.\n\nAnarchist ethics\n\nAnarchist ethics is an ethical theory based on the studies of anarchist thinkers. The biggest contributor to the anarchist ethics is the Russian zoologist, geographer, economist, and political activist Peter Kropotkin.\n\nStarting from the premise that the goal of ethical philosophy should be to help humans adapt and thrive in evolutionary terms, Kropotkin's ethical framework uses biology and anthropology as a basis \u2013 in order to scientifically establish what will best enable a given social order to thrive biologically and socially \u2013 and advocates certain behavioural practices to enhance humanity's capacity for freedom and well-being, namely practices which emphasise solidarity, equality, and justice.\n\nKropotkin argues that ethics itself is evolutionary, and is inherited as a sort of a social instinct through cultural history, and by so, he rejects any religious and transcendental explanation of morality. The origin of ethical feeling in both animals and humans can be found, he claims, in the natural fact of \"sociality\" (mutualistic symbiosis), which humans can then combine with the instinct for justice (i.e. equality) and then with the practice of reason to construct a non-supernatural and anarchistic system of ethics. Kropotkin suggests that the principle of equality at the core of anarchism is the same as the Golden rule: This principle of treating others as one wishes to be treated oneself, what is it but the very same principle as equality, the fundamental principle of anarchism? And how can any one manage to believe himself an anarchist unless he practices it? We do not wish to be ruled. And by this very fact, do we not declare that we ourselves wish to rule nobody? We do not wish to be deceived, we wish always to be told nothing but the truth. And by this very fact, do we not declare that we ourselves do not wish to deceive anybody, that we promise to always tell the truth, nothing but the truth, the whole truth? We do not wish to have the fruits of our labor stolen from us. And by that very fact, do we not declare that we respect the fruits of others' labor? By what right indeed can we demand that we should be treated in one fashion, reserving it to ourselves to treat others in a fashion entirely different? Our sense of equality revolts at such an idea.\n\nPostmodern ethics\n\nThe 20th century saw a remarkable expansion and evolution of critical theory, following on earlier Marxist Theory efforts to locate individuals within larger structural frameworks of ideology and action.\n\nAntihumanists such as Louis Althusser, Michel Foucault and structuralists such as Roland Barthes challenged the possibilities of individual agency and the coherence of the notion of the 'individual' itself. This was on the basis that personal identity was, in the most part, a social construction. As critical theory developed in the later 20th century, post-structuralism sought to problematize human relationships to knowledge and 'objective' reality. Jacques Derrida argued that access to meaning and the 'real' was always deferred, and sought to demonstrate via recourse to the linguistic realm that \"there is no outside-text/non-text\" (\"il n'y a pas de hors-texte\" is often mistranslated as \"there is nothing outside the text\"); at the same time, Jean Baudrillard theorised that signs and symbols or simulacra mask reality (and eventually the absence of reality itself), particularly in the consumer world.\n\nPost-structuralism and postmodernism argue that ethics must study the complex and relational conditions of actions.  A simple alignment of ideas of right and particular acts is not possible.  There will always be an ethical remainder that cannot be taken into account or often even recognized.  Such theorists find narrative (or, following Nietzsche and Foucault, genealogy) to be a helpful tool for understanding ethics because narrative is always about particular lived experiences in all their complexity rather than the assignment of an idea or norm to separate and individual actions.\n\nZygmunt Bauman says postmodernity is best described as modernity without illusion, the illusion being the belief that humanity can be repaired by some ethic principle.  Postmodernity can be seen in this light as accepting the messy nature of humanity as unchangeable. In this postmodern world, the means to act collectively and globally to solve large-scale problems have been all but discredited, dismantled or lost. Problems can be handled only locally and each on its own. All problem-handling means building a mini-order at the expense of order elsewhere, and at the cost of rising global disorder as well as depleting the shrinking supplies of resources which make ordering possible.  He considers Emmanuel Levinas's ethics as postmodern. Unlike the modern ethical philosophy which leaves the Other on the outside of the self as an ambivalent presence, Levinas's philosophy readmits her as a neighbor and as a crucial character in the process through which the moral self comes into its own.\n\nDavid Couzens Hoy states that Emmanuel Levinas's writings on the face of the Other and Derrida's meditations on the relevance of death to ethics are signs of the \"ethical turn\" in Continental philosophy that occurred in the 1980s and 1990s. Hoy describes post-critique ethics as the \"obligations that present themselves as necessarily to be fulfilled but are neither forced on one or are enforceable\".\n\nHoy's post-critique model uses the term ethical resistance. Examples of this would be an individual's resistance to consumerism in a retreat to a simpler but perhaps harder lifestyle, or an individual's resistance to a terminal illness. Hoy describes Levinas's account as \"not the attempt to use power against itself, or to mobilize sectors of the population to exert their political power; the ethical resistance is instead the resistance of the powerless\".\n\nHoy concludes that\n\nApplied ethics\n\nApplied ethics is a discipline of philosophy that attempts to apply ethical theory to real-life situations.  The discipline has many specialized fields, such as engineering ethics, bioethics, geoethics, public service ethics and business ethics.\n\nSpecific questions\nApplied ethics is used in some aspects of determining public policy, as well as by individuals facing difficult decisions. The sort of questions addressed by applied ethics include: \"Is getting an abortion immoral?\"; \"Is euthanasia immoral?\"; \"Is affirmative action right or wrong?\"; \"What are human rights, and how do we determine them?\"; \"Do animals have rights as well?\"; and \"Do individuals have the right of self-determination?\"\n\nA more specific question could be: \"If someone else can make better out of his/her life than I can, is it then moral to sacrifice myself for them if needed?\" Without these questions, there is no clear fulcrum on which to balance law, politics, and the practice of arbitration\u2014in fact, no common assumptions of all participants\u2014so the ability to formulate the questions are prior to rights balancing. But not all questions studied in applied ethics concern public policy. For example, making ethical judgments regarding questions such as, \"Is lying always wrong?\" and, \"If not, when is it permissible?\" is prior to any etiquette.\n\nPeople, in general, are more comfortable with dichotomies (two opposites).  However, in ethics, the issues are most often multifaceted and the best-proposed actions address many different areas concurrently. In ethical decisions, the answer is almost never a \"yes or no\" or a \"right or wrong\" statement. Many buttons are pushed so that the overall condition is improved and not to the benefit of any particular faction.\n\nAnd it has not only been shown that people consider the character of the moral agent (i.e. a principle implied in virtue ethics), the deed of the action (i.e. a principle implied in deontology), and the consequences of the action (i.e. a principle implied in utilitarianism) when formulating moral judgments, but moreover that the effect of each of these three components depends on the value of each component.\n\nParticular fields of application\n\nBioethics\n\nBioethics is the study of controversial ethics brought about by advances in biology and medicine. Bioethicists are concerned with the ethical questions that arise in the relationships among life sciences, biotechnology, medicine, politics, law, and philosophy. It also includes the study of the more commonplace questions of values (\"the ethics of the ordinary\") that arise in primary care and other branches of medicine.\n\nBioethics also needs to address emerging biotechnologies that affect basic biology and future humans. These developments include cloning, gene therapy, human genetic engineering, astroethics and life in space, and manipulation of basic biology through altered DNA, RNA and proteins, e.g. \"three parent baby, where baby is born from genetically modified embryos, would have DNA from a mother, a father and from a female donor. Correspondingly, new bioethics also need to address life at its core. For example, biotic ethics value organic gene/protein life itself and seek to propagate it. With such life-centered principles, ethics may secure a cosmological future for life.\n\nBusiness ethics\n\nBusiness ethics (also corporate ethics) is a form of applied ethics or professional ethics that examines ethical principles and moral or ethical problems that arise in a business environment, including fields like medical ethics. Business ethics represents the practices that any individual or group exhibits within an organization that can negatively or positively affect the businesses core values. It applies to all aspects of business conduct and is relevant to the conduct of individuals and entire organizations.\n\nBusiness ethics has both normative and descriptive dimensions. As a corporate practice and a career specialization, the field is primarily normative. Academics attempting to understand business behavior employ descriptive methods. The range and quantity of business ethical issues reflect the interaction of profit-maximizing behavior with non-economic concerns. Interest in business ethics accelerated dramatically during the 1980s and 1990s, both within major corporations and within academia. For example, today most major corporations promote their commitment to non-economic values under headings such as ethics codes and social responsibility charters. Adam Smith said, \"People of the same trade seldom meet together, even for merriment and diversion, but the conversation ends in a conspiracy against the public, or in some contrivance to raise prices.\" Governments use laws and regulations to point business behavior in what they perceive to be beneficial directions. Ethics implicitly regulates areas and details of behavior that lie beyond governmental control. The emergence of large corporations with limited relationships and sensitivity to the communities in which they operate accelerated the development of formal ethics regimes. Business ethics also relates to unethical activities of interorganizational relationships, such as strategic alliances, buyer-supplier relationships, or joint ventures. Such unethical practices include, for instance, opportunistic behaviors, contract violations, and deceitful practices. Some corporations have tried to burnish their ethical image by creating whistle-blower protections, such as anonymity. In the case of Citi, they call this the Ethics Hotline, though it is unclear whether firms such as Citi take offences reported to these hotlines seriously or not.\n\nMachine ethics\n\nIn Moral Machines: Teaching Robots Right from Wrong, Wendell Wallach and Colin Allen conclude that issues in machine ethics will likely drive advancement in understanding of human ethics by forcing us to address gaps in modern normative theory and by providing a platform for experimental investigation. The effort to actually program a machine or artificial agent to behave as though instilled with a sense of ethics requires new specificity in our normative theories, especially regarding aspects customarily considered common-sense. For example, machines, unlike humans, can support a wide selection of learning algorithms, and controversy has arisen over the relative ethical merits of these options. This may reopen classic debates of normative ethics framed in new (highly technical) terms.\n\nMilitary ethics\n\nMilitary ethics are concerned with questions regarding the application of force and the ethos of the soldier and are often understood as applied professional ethics. Just war theory is generally seen to set the background terms of military ethics. However individual countries and traditions have different fields of attention.\n\nMilitary ethics involves multiple subareas, including the following among others:\n what, if any, should be the laws of war.\n justification for the initiation of military force.\n decisions about who may be targeted in warfare.\n decisions on choice of weaponry, and what collateral effects such weaponry may have.\n standards for handling military prisoners.\n methods of dealing with violations of the laws of war.\n\nPolitical ethics\n\nPolitical ethics (also known as political morality or public ethics) is the practice of making moral judgements about political action and political agents.\n\nPublic sector ethics\n\nPublic sector ethics is a set of principles that guide public officials in their service to their constituents, including their decision-making on behalf of their constituents.  Fundamental to the concept of public sector ethics is the notion that decisions and actions are based on what best serves the public's interests, as opposed to the official's personal interests (including financial interests) or self-serving political interests.\n\nPublication ethics\nPublication ethics is the set of principles that guide the writing and publishing process for all professional publications. To follow these principles, authors must verify that the publication does not contain plagiarism or publication bias. As a way to avoid misconduct in research these principles can also apply to experiments that are referenced or analyzed in publications by ensuring the data is recorded honestly and accurately.\n\nPlagiarism is the failure to give credit to another author's work or ideas, when it is used in the publication. It is the obligation of the editor of the journal to ensure the article does not contain any plagiarism before it is published. If a publication that has already been published is proven to contain plagiarism, the editor of the journal can retract the article. Another critical publication ethics issue pertains to citation plagiarism when researchers copy and paste citation entries from other published works without reading the original source.\n\nPublication bias occurs when the publication is one-sided or \"prejudiced against results\". In best practice, an author should try to include information from all parties involved, or affected by the topic. If an author is prejudiced against certain results, than it can \"lead to erroneous conclusions being drawn\".\n\nMisconduct in research can occur when an experimenter falsifies results. Falsely recorded information occurs when the researcher \"fakes\" information or data, which was not used when conducting the actual experiment. By faking the data, the researcher can alter the results from the experiment to better fit the hypothesis they originally predicted. When conducting medical research, it is important to honor the healthcare rights of a patient by protecting their anonymity in the publication.\nRespect for autonomy is the principle that decision-making should allow individuals to be autonomous; they should be able to make decisions that apply to their own lives. This means that individuals should have control of their lives.\nJustice is the principle that decision-makers must focus on actions that are fair to those affected. Ethical decisions need to be consistent with the ethical theory. There are cases where the management has made decisions that seem to be unfair to the employees, shareholders, and other stakeholders (Solomon, 1992, pp49). Such decisions are unethical.\n\nRelational ethics\nRelational ethics are related to an ethics of care. They are used in qualitative research, especially ethnography and autoethnography. Researchers who employ relational ethics value and respect the connection between themselves and the people they study, and \"...between researchers and the communities in which they live and work.\" (Ellis, 2007, p.\u00a04). Relational ethics also help researchers understand difficult issues such as conducting research on intimate others that have died and developing friendships with their participants. Relational ethics in close personal relationships form a central concept of contextual therapy.\n\nEthics of nanotechnologies\n\nEthics of nanotechnology is the study of the ethical issues emerging from advances in nanotechnology.\n\nEthics of quantification\n\nEthics of quantification is the study of the ethical issues associated to different forms of visible or invisible forms of quantification.\n\nAnimal ethics\n\nAnimal ethics is a term used in academia to describe human-animal relationships and how animals ought to be treated. The subject matter includes animal rights, animal welfare, animal law, speciesism, animal cognition, wildlife conservation, the moral status of nonhuman animals, the concept of nonhuman personhood, human exceptionalism, the history of animal use, and theories of justice.\n\nEthics of technology\n\nEthics of technology is a sub-field of ethics addressing the ethical questions specific to the Technology Age. Some prominent works of philosopher Hans Jonas are devoted to ethics of technology. The subject has also been explored, following the work of Mario Bunge, under the term technoethics.\n\nMoral psychology\n\nMoral psychology is a field of study that began as an issue in philosophy and that is now properly considered part of the discipline of psychology.  Some use the term \"moral psychology\" relatively narrowly to refer to the study of moral development. However, others tend to use the term more broadly to include any topics at the intersection of ethics and psychology (and philosophy of mind). Such topics are ones that involve the mind and are relevant to moral issues. Some of the main topics of the field are moral responsibility, moral development, moral character (especially as related to virtue ethics), altruism, psychological egoism, moral luck, and moral disagreement.\n\nEvolutionary ethics\n\nEvolutionary ethics concerns approaches to ethics (morality) based on the role of evolution in shaping human psychology and behavior. Such approaches may be based in scientific fields such as evolutionary psychology or sociobiology, with a focus on understanding and explaining observed ethical preferences and choices.\n\nDescriptive ethics\n\nDescriptive ethics is on the less philosophical end of the spectrum since it seeks to gather particular information about how people live and draw general conclusions based on observed patterns. Abstract and theoretical questions that are more clearly philosophical\u2014such as, \"Is ethical knowledge possible?\"\u2014are not central to descriptive ethics. Descriptive ethics offers a value-free approach to ethics, which defines it as a social science rather than a humanity.  Its examination of ethics does not start with a preconceived theory but rather investigates observations of actual choices made by moral agents in practice. Some philosophers rely on descriptive ethics and choices made and unchallenged by a society or culture to derive categories, which typically vary by context. This can lead to situational ethics and situated ethics. These philosophers often view aesthetics, etiquette, and arbitration as more fundamental, percolating \"bottom up\" to imply the existence of, rather than explicitly prescribe, theories of value or of conduct. The study of descriptive ethics may include examinations of the following:\n Ethical codes applied by various groups. Some consider aesthetics itself the basis of ethics\u2014and a personal moral core developed through art and storytelling as very influential in one's later ethical choices.\n Informal theories of etiquette that tend to be less rigorous and more situational. Some consider etiquette a simple negative ethics, i.e., where can one evade an uncomfortable truth without doing wrong? One notable advocate of this view is Judith Martin (\"Miss Manners\"). According to this view, ethics is more a summary of common sense social decisions.\n Practices in arbitration and law, e.g., the claim that ethics itself is a matter of balancing \"right versus right\", i.e., putting priorities on two things that are both right, but that must be traded off carefully in each situation.\n Observed choices made by ordinary people, without expert aid or advice, who vote, buy, and decide what is worth valuing. This is a major concern of sociology, political science, and economics.\n\nSee also\n\n Morality\n Integrity\n Applied ethics\n Axiological ethics\n Contemporary ethics\n Corporate social responsibility\n Declaration of Geneva\n Declaration of Helsinki\n Deductive reasoning\n Dharma\n Effective altruism\n Environmental ethics\n Ethical movement\n Ethics in religion\n Ethics paper\n Feminist ethics\n Internalism and externalism\n Humanism\n Index of ethics articles\u2014alphabetical list of ethics-related articles\n Neuroethics\n Outline of ethics\u2014list of ethics-related articles, arranged by sub-topic\n Practical philosophy\n Science of morality\n Secular ethics\n Sexual ethics\n Theory of justification\n Trail ethics\n\nNotes\n\nReferences\n Hoy, D. (2005). Critical Resistance from Poststructuralism to Postcritique. Massachusetts Institute of Technology, Cambridge, Massachusetts.\n Lyon, D. (1999).  Postmodernity (2nd ed.). Open University Press, Buckingham.\n Singer, P. (2000). Writings on an Ethical Life. Harper Collins Publishers, London.\n\nFurther reading\n \nAristotle, Nicomachean Ethics\n Azurmendi, J. 1998: \"The violence and the search for new values\" in Euskal Herria krisian, (Elkar, 1999), pp.\u00a011\u2013116. \n Blackburn, S. (2001). Being good: A short introduction to ethics. Oxford: Oxford University Press.\nCools, Guy & Gielen, Pascal. The Ethics of Art. Valiz: Amsterdam, 2014.Jadranka Skorin-Kapov, The Intertwining of Aesthetics and Ethics: Exceeding of Expectations, Ecstasy, Sublimity. Lexington Books, 2016. De Finance, Joseph, An Ethical Inquiry, Rome, Editrice Pontificia Universit\u00e0 Gregoriana, 1991.\n De La Torre, Miguel A., \"Doing Christian Ethics from the Margins\", Orbis Books, 2004.\n Derrida, J. 1995, The Gift of Death, translated by David Wills, University of Chicago Press, Chicago.\nD'Urance, Michel, Jalons pour une \u00e9thique rebelle, Al\u00e9th\u00e9ia, Paris, 2005.Fagothey, Austin, Right and Reason, Tan Books & Publishers, Rockford, Illinois, 2000.\nEhrlich, Paul R. (May 2016), Conference on population, environment, ethics: where we stand now (video, 93 min), University of Lausanne\nEncyclopedia of Ethics. Lawrence C. Becker and Charlotte B. Becker, editors. Second edition in three volumes. New York: Routledge, 2002. A scholarly encyclopedia with over 500 signed, peer-reviewed articles, mostly on topics and figures of, or of special interest in, Western philosophy.\nJohn Paul II, Encyclical Letter Veritatis Splendor, August 6, 1993.\nLafollette, Hugh [ed.]: Ethics in Practice: An Anthology. Wiley Blackwell, 4th edition, Oxford 2014. \nLondon Philosophy Study Guide  offers many suggestions on what to read, depending on the student's familiarity with the subject:  Ethics \nLevinas, E.  1969, Totality and infinity, an essay on exteriority, translated by Alphonso Lingis, Duquesne University Press, Pittsburgh.\nNagel, Thomas, \"Types of Intuition: Thomas Nagel on human rights and moral knowledge\", London Review of Books, vol. 43, no. 11 (3 June 2021), pp. 3, 5\u20136, 8. Deontology, consequentialism, utilitarianism.\nNewton, John Ph.D. Complete Conduct Principles for the 21st Century, 2000. ., Butchvarov, Panayot. Skepticism in Ethics (1989).\n Solomon, R.C., Morality and the Good Life: An Introduction to Ethics Through Classical Sources, New York: McGraw-Hill Book Company, 1984.\nVendemiati, Aldo, In the First Person, An Outline of General Ethics, Rome, Urbaniana University Press, 2004.\n An entire issue of Pacific Island Studies devoted to studying \"Constructing Moral Communities\" in Pacific islands, 2002, vol. 25: Link\n\nExternal links\n\n \n \n \n \n \n An Introduction to Ethics  by Paul Newall, aimed at beginners.\n Ethics, 2d ed., 1973. by William Frankena\n Ethics Bites , Open University podcast series podcast exploring ethical dilemmas in everyday life.\n National Reference Center for Bioethics Literature World's largest library for ethical issues in medicine and biomedical research\n Ethics  entry in Encyclop\u00e6dia Britannica by Peter Singer\n The Philosophy of Ethics on Philosophy Archive\n Kirby Laing Institute for Christian Ethics Resources, events, and research on a range of ethical subjects from a Christian perspective.\n Basic principle of ethics summary talk\n International Association for Geoethics (IAGETH)\n International Association for Promoting Geoethics (IAPG)\n Markkula Center for Applied Ethics at Santa Clara University Resources for analyzing real-world ethical issues and tools to address them.\n \n\n \nAxiology\nPhilosophy of life\nPhilosophy of mind\nPsychoanalysis\nSocial philosophy\nMain topic articles",
  "Entertainment": "Entertainment is a form of activity that holds the attention and interest of an audience or gives pleasure and delight. It can be an idea or a task, but is more likely to be one of the activities or events that have developed over thousands of years specifically for the purpose of keeping an audience's attention.\n\nAlthough people's attention is held by different things because individuals have different preferences, most forms of entertainment are recognisable and familiar. Storytelling, music, drama, dance, and different kinds of performance exist in all cultures, were supported in royal courts, developed into sophisticated forms and over time became available to all citizens. The process has been accelerated in modern times by an entertainment industry that records and sells entertainment products. Entertainment evolves and can be adapted to suit any scale, ranging from an individual who chooses a private entertainment from a now enormous array of pre-recorded products; to a banquet adapted for two; to any size or type of party, with appropriate music and dance; to performances intended for thousands; and even for a global audience.\n\nThe experience of being entertained has come to be strongly associated with amusement, so that one common understanding of the idea is fun and laughter, although many entertainments have a serious purpose. This may be the case in the various forms of ceremony, celebration, religious festival, or satire for example. Hence, there is the possibility that what appears as entertainment may also be a means of achieving insight or intellectual growth.\n\nAn important aspect of entertainment is the audience, which turns a private recreation or leisure activity into entertainment. The audience may have a passive role, as in the case of persons watching a play, opera, television show, or film; or the audience role may be active, as in the case of games, where the participant/audience roles may be routinely reversed. Entertainment can be public or private, involving formal, scripted performance, as in the case of theatre or concerts; or unscripted and spontaneous, as in the case of children's games. Most forms of entertainment have persisted over many centuries, evolving due to changes in culture, technology, and fashion for example with stage magic. Films and video games, for example, although they use newer media, continue to tell stories, present drama, and play music. Festivals devoted to music, film, or dance allow audiences to be entertained over a number of consecutive days.\n\nSome entertainment, such as public executions, are now illegal in most countries. Activities such as fencing or archery, once used in hunting or war, have become spectator sports. In the same way, other activities, such as cooking, have developed into performances among professionals, staged as global competitions and then broadcast for entertainment. What is entertainment for one group or individual may be regarded as work or an act of cruelty by another.\n\nThe familiar forms of entertainment have the capacity to cross over different media and have demonstrated a seemingly unlimited potential for creative remix. This has ensured the continuity and longevity of many themes, images, and structures.\n\nEtymology \n\nThe Oxford English Dictionary gives Latin and French origins for the word \"entertain\", including inter (among) + tenir (to hold) as derivations, giving translations of \"to hold mutually\" or \"to hold intertwined\" and \"to engage, keep occupied, the attention thoughts or time (of a person)\". It also provides words like \"merry-making\", \"pleasure\", \"delight\", as well as \"to receive as a guest and show hospitality to\". It cites a 1490 usage by William Caxton.\n\nPsychology and philosophy \n\nEntertainment can be distinguished from other activities such as education and marketing even though they have learned how to use the appeal of entertainment to achieve their different goals. Sometimes entertainment can be a mixture for both. The importance and impact of entertainment is recognised by scholars and its increasing sophistication has influenced practices in other fields such as museology.\n\nPsychologists say the function of media entertainment is \"the attainment of gratification\". No other results or measurable benefit are usually expected from it (except perhaps the final score in a sporting entertainment). This is in contrast to education (which is designed with the purpose of developing understanding or helping people to learn) and marketing (which aims to encourage people to purchase commercial products). However, the distinctions become blurred when education seeks to be more \"entertaining\" and entertainment or marketing seek to be more \"educational\". Such mixtures are often known by the neologisms \"edutainment\" or \"infotainment\". The psychology of entertainment as well as of learning has been applied to all these fields. Some education-entertainment is a serious attempt to combine the best features of the two. Some people are entertained by others' pain or the idea of their unhappiness (schadenfreude).\n\nAn entertainment might go beyond gratification and produce some insight in its audience. Entertainment may skilfully consider universal philosophical questions such as: \"What does it mean to be human?\"; \"What is the right thing to do?\"; or \"How do I know what I know?\". \"The meaning of life\", for example, is the subject in a wide range of entertainment forms, including film, music and literature. Questions such as these drive many narratives and dramas, whether they are presented in the form of a story, film, play, poem, book, dance, comic, or game. Dramatic examples include Shakespeare's influential play Hamlet, whose hero articulates these concerns in poetry; and films, such as The Matrix, which explores the nature of knowledge and was released worldwide. Novels give great scope for investigating these themes while they entertain their readers. An example of a creative work that considers philosophical questions so entertainingly that it has been presented in a very wide range of forms is The Hitchhiker's Guide to the Galaxy. Originally a radio comedy, this story became so popular that it has also appeared as a novel, film, television series, stage show, comic, audiobook, LP record, adventure game and online game, its ideas became popular references (see Phrases from The Hitchhiker's Guide to the Galaxy) and has been translated into many languages. Its themes encompass the meaning of life, as well as \"the ethics of entertainment, artificial intelligence, multiple worlds, God, and philosophical method\".\n\nHistory \n\nThe \"ancient craft of communicating events and experiences, using words, images, sounds and gestures\" by telling a story is not only the means by which people passed on their cultural values and traditions and history from one generation to another, it has been an important part of most forms of entertainment ever since the earliest times. Stories are still told in the early forms, for example, around a fire while camping, or when listening to the stories of another culture as a tourist. \"The earliest storytelling sequences we possess, now of course, committed to writing, were undoubtedly originally a speaking from mouth to ear and their force as entertainment derived from the very same elements we today enjoy in films and novels.\" Storytelling is an activity that has evolved and developed \"toward variety\". Many entertainments, including storytelling but especially music and drama, remain familiar but have developed into a wide variety of form to suit a very wide range of personal preferences and cultural expression. Many types are blended or supported by other forms. For example, drama, stories and banqueting (or dining) are commonly enhanced by music; sport and games are incorporated into other activities to increase appeal. Some may have evolved from serious or necessary activities (such as running and jumping) into competition and then become entertainment. It is said, for example, that pole vaulting \"may have originated in the Netherlands, where people used long poles to vault over wide canals rather than wear out their clogs walking miles to the nearest bridge. Others maintain that pole vaulting was used in warfare to vault over fortress walls during battle.\" The equipment for such sports has become increasingly sophisticated. Vaulting poles, for example, were originally made from woods such as ash, hickory or hazel; in the 19th century bamboo was used and in the 21st century poles can be made of carbon fibre. Other activities, such as walking on stilts, are still seen in circus performances in the 21st century. Gladiatorial combats, also known as \"gladiatorial games\", popular during Roman times, provide a good example of an activity that is a combination of sport, punishment, and entertainment.\n\nChanges to what is regarded as entertainment can occur in response to cultural or historical shifts. Hunting wild animals, for example, was introduced into the Roman Empire from Carthage and became a popular public entertainment and spectacle, supporting an international trade in wild animals.\n\nEntertainment also evolved into different forms and expressions as a result of social upheavals such as wars and revolutions. During the Chinese Cultural Revolution, for example, Revolutionary opera was sanctioned by the Communist party and World War I, the Great Depression and the Russian revolution all affected entertainment.\n\nRelatively minor changes to the form and venue of an entertainment continue to come and go as they are affected by the period, fashion, culture, technology, and economics. For example, a story told in dramatic form can be presented in an open-air theatre, a music hall, a movie theatre, a multiplex, or as technological possibilities advanced, via a personal electronic device such as a tablet computer. Entertainment is provided for mass audiences in purpose-built structures such as a theatre, auditorium, or stadium. One of the most famous venues in the Western world, the Colosseum, \"dedicated AD\u00a080 with a hundred days of games, held fifty thousand spectators,\" and in it audiences \"enjoyed blood sport with the trappings of stage shows\". Spectacles, competitions, races, and sports were once presented in this purpose-built arena as public entertainment. New stadia continue to be built to suit the ever more sophisticated requirements of global audiences.\n\nCourt entertainment \n\nImperial and royal courts have provided training grounds and support for professional entertainers, with different cultures using palaces, castles and forts in different ways. In the Maya city states, for example, \"spectacles often took place in large plazas in front of palaces; the crowds gathered either there or in designated places from which they could watch at a distance.\" Court entertainments also crossed cultures. For example, the durbar was introduced to India by the Mughals, and passed onto the British Empire, which then followed Indian tradition: \"institutions, titles, customs, ceremonies by which a Maharaja or Nawab were installed\u00a0... the exchange of official presents\u00a0... the order of precedence\", for example, were \"all inherited from\u00a0... the Emperors of Delhi\". In Korea, the \"court entertainment dance\" was \"originally performed in the palace for entertainment at court banquets.\"\n\nCourt entertainment often moved from being associated with the court to more general use among commoners. This was the case with \"masked dance-dramas\" in Korea, which \"originated in conjunction with village shaman rituals and eventually became largely an entertainment form for commoners\". Nautch dancers in the Mughal Empire performed in Indian courts and palaces. Another evolution, similar to that from courtly entertainment to common practice, was the transition from religious ritual to secular entertainment, such as happened during the Goryeo dynasty with the Narye festival. Originally \"solely religious or ritualistic, a secular component was added at the conclusion\". Former courtly entertainments, such as jousting, often also survived in children's games.\n\nIn some courts, such as those during the Byzantine Empire, the genders were segregated among the upper classes, so that \"at least before the period of the Komnenoi\" (1081\u20131185) men were separated from women at ceremonies where there was entertainment such as receptions and banquets.\n\nCourt ceremonies, palace banquets and the spectacles associated with them, have been used not only to entertain but also to demonstrate wealth and power. Such events reinforce the relationship between ruler and ruled; between those with power and those without, serving to \"dramatise the differences between ordinary families and that of the ruler\". This is the case as much as for traditional courts as it is for contemporary ceremonials, such as the Hong Kong handover ceremony in 1997, at which an array of entertainments (including a banquet, a parade, fireworks, a festival performance and an art spectacle) were put to the service of highlighting a change in political power. Court entertainments were typically performed for royalty and courtiers as well as \"for the pleasure of local and visiting dignitaries\". Royal courts, such as the Korean one, also supported traditional dances. In Sudan, musical instruments such as the so-called \"slit\" or \"talking\" drums, once \"part of the court orchestra of a powerful chief\", had multiple purposes: they were used to make music; \"speak\" at ceremonies; mark community events; send long-distance messages; and call men to hunt or war.\n\nCourtly entertainments also demonstrate the complex relationship between entertainer and spectator: individuals may be either an entertainer or part of the audience, or they may swap roles even during the course of one entertainment. In the court at the Palace of Versailles, \"thousands of courtiers, including men and women who inhabited its apartments, acted as both performers and spectators in daily rituals that reinforced the status hierarchy\".\n\nLike court entertainment, royal occasions such as coronations and weddings provided opportunities to entertain both the aristocracy and the people. For example, the splendid 1595 Accession Day celebrations of Queen Elizabeth I offered tournaments and jousting and other events performed \"not only before the assembled court, in all their finery, but also before thousands of Londoners eager for a good day's entertainment. Entry for the day's events at the Tiltyard in Whitehall was set at 12d\".\n\nPublic punishment \n\nAlthough most forms of entertainment have evolved and continued over time, some once-popular forms are no longer as acceptable. For example, during earlier centuries in Europe, watching or participating in the punishment of criminals or social outcasts was an accepted and popular form of entertainment. Many forms of public humiliation also offered local entertainment in the past. Even capital punishment such as hanging and beheading, offered to the public as a warning, were also regarded partly as entertainment. Capital punishments that lasted longer, such as stoning and drawing and quartering, afforded a greater public spectacle. \"A hanging was a carnival that diverted not merely the unemployed but the unemployable. Good bourgeois or curious aristocrats who could afford it watched it from a carriage or rented a room.\" Public punishment as entertainment lasted until the 19th century by which time \"the awesome event of a public hanging aroused the[ir] loathing of writers and philosophers\". Both Dickens and Thackeray wrote about a hanging in Newgate Prison in 1840, and \"taught an even wider public that executions are obscene entertainments\".\n\nChildren \n\nChildren's entertainment is centred on play and is significant for their growth. It often mimics adult activities, such as watching performances (9); prepares them for adult responsibilities, such as child rearing or social interaction (1,2,3,4,8); or develops skills such as motor skills (5), needed for sports and music (6,7). In the modern day, it often involves sedentary engagement with advanced technology (9,10).\n\nEntertainment is also provided to children or taught to them by adults and many activities that appeal to them such as puppets, clowns, pantomimes and cartoons are also enjoyed by adults.\n\nChildren have always played games. It is accepted that as well as being entertaining, playing games helps children's development. One of the most famous visual accounts of children's games is a painting by Pieter Bruegel the Elder called Children's Games, painted in 1560. It depicts children playing a range of games that presumably were typical of the time. Many of these games, such as marbles, hide-and-seek, blowing soap bubbles and piggyback riding continue to be played.\n\nMost forms of entertainment can be or are modified to suit children's needs and interests. During the 20th century, starting with the often criticised but nonetheless important work of G. Stanley Hall, who \"promoted the link between the study of development and the 'new' laboratory psychology\", and especially with the work of Jean Piaget, who \"saw cognitive development as being analogous to biological development\", it became understood that the psychological development of children occurs in stages and that their capacities differ from adults. Hence, stories and activities, whether in books, film, or video games were developed specifically for child audiences. Countries have responded to the special needs of children and the rise of digital entertainment by developing systems such as television content rating systems, to guide the public and the entertainment industry.\n\nIn the 21st century, as with adult products, much entertainment is available for children on the internet for private use. This constitutes a significant change from earlier times. The amount of time expended by children indoors on screen-based entertainment and the \"remarkable collapse of children's engagement with nature\" has drawn criticism for its negative effects on imagination, adult cognition and psychological well-being.\n\nForms\n\nBanquets \nBanquets have been a venue for amusement, entertainment or pleasure since ancient times, continuing until the 21st century, when they are still being used for many of their original purposes to impress visitors, especially important ones (4, 6, 9); to show hospitality (2, 4, 8); as an occasion to showcase supporting entertainments such as music or dancing, or both (2, 3). They were an integral part of court entertainments (3, 4) and helped entertainers develop their skills (2, 3). They are also important components of celebrations such as coronations (9), weddings (7), birthdays (10) civic or political achievements (5), military engagements or victories (6) as well as religious obligations (1). In modern times, banquets are commercially available, for example, in restaurants (10) and combined with a performance in dinner theatres. Cooking by professional chefs has also become a form of entertainment as part of global competitions such as the Bocuse d'Or.\n\nMusic \n\nMusic is a supporting component of many kinds of entertainment and most kinds of performance. For example, it is used to enhance storytelling, it is indispensable in dance (1, 4) and opera, and is usually incorporated into dramatic film or theatre productions.\n\nMusic is also a universal and popular type of entertainment on its own, constituting an entire performance such as when concerts are given (2, 4, 5, 6, 7, 8, 9). Depending on the rhythm, instrument, performance and style, music is divided into many genres, such as classical, jazz, folk, (4, 5, 8), rock, pop music (6, 9) or traditional (1, 3). Since the 20th century, performed music, once available only to those who could pay for the performers, has been available cheaply to individuals by the entertainment industry, which broadcasts it or pre-records it for sale.\n\nThe wide variety of musical performances, whether or not they are artificially amplified (6, 7, 9, 10), all provide entertainment irrespective of whether the performance is from soloists (6), choral (2) or orchestral groups (5, 8), or ensemble (3). Live performances use specialised venues, which might be small or large; indoors or outdoors; free or expensive. The audiences have different expectations of the performers as well as of their own role in the performance. For example, some audiences expect to listen silently and are entertained by the excellence of the music, its rendition or its interpretation (5, 8). Other audiences of live performances are entertained by the ambience and the chance to participate (7, 9). Even more listeners are entertained by pre-recorded music and listen privately (10).\n\nThe instruments used in musical entertainment are either solely the human voice (2, 6) or solely instrumental (1, 3) or some combination of the two (4, 5, 7, 8). Whether the performance is given by vocalists or instrumentalists, the performers may be soloists or part of a small or large group, in turn entertaining an audience that might be individual (10), passing by (3), small (1, 2) or large (6, 7, 8, 9). Singing is generally accompanied by instruments although some forms, notably a cappella and overtone singing, are unaccompanied. Modern concerts often use various special effects and other theatrics to accompany performances of singing and dancing (7).\n\nGames \n\nGames are played for entertainment\u2014sometimes purely for recreation, sometimes for achievement or reward as well. They can be played alone, in teams, or online; by amateurs or by professionals. The players may have an audience of non-players, such as when people are entertained by watching a chess championship. On the other hand, players in a game may constitute their own audience as they take their turn to play. Often, part of the entertainment for children playing a game is deciding who is part of their audience and who is a player.\n\nEquipment varies with the game. Board games, such as Go, Monopoly or backgammon need a board and markers. One of the oldest known board games is Senet, a game played in Ancient Egypt, enjoyed by the pharaoh Tutankhamun. Card games, such as whist, poker and Bridge have long been played as evening entertainment among friends. For these games, all that is needed is a deck of playing cards. Other games, such as bingo, played with numerous strangers, have been organised to involve the participation of non-players via gambling. Many are geared for children, and can be played outdoors, including hopscotch, hide and seek, or Blind man's bluff. The list of ball games is quite extensive. It includes, for example, croquet, lawn bowling and paintball as well as many sports using various forms of balls. The options cater to a wide range of skill and fitness levels. Physical games can develop agility and competence in motor skills. Number games such as Sudoku and puzzle games like the Rubik's cube can develop mental prowess.\n\nVideo games are played using a controller to create results on a screen. They can also be played online with participants joining in remotely. In the second half of the 20th century and in the 21st century the number of such games increased enormously, providing a wide variety of entertainment to players around the world. Video games are popular across the world.\n\nLiterature \n\nReading has been a source of entertainment for a very long time, especially when other forms, such as performance entertainments, were (or are) either unavailable or too costly. Even when the primary purpose of the writing is to inform or instruct, reading is well known for its capacity to distract from everyday worries. Both stories and information have been passed on through the tradition of orality and oral traditions survive in the form of performance poetry for example. However, they have drastically declined. \"Once literacy had arrived in strength, there was no return to the oral prerogative.\" The advent of printing, the reduction in costs of books and an increasing literacy all served to enhance the mass appeal of reading. Furthermore, as fonts were standardised and texts became clearer, \"reading ceased being a painful process of decipherment and became an act of pure pleasure\". By the 16th century in Europe, the appeal of reading for entertainment was well established.\n\nAmong literature's many genres are some designed, in whole or in part, purely for entertainment. Limericks, for example, use verse in a strict, predictable rhyme and rhythm to create humour and to amuse an audience of listeners or readers. Interactive books such as \"choose your own adventure\" can make literary entertainment more participatory.\n\nComics and cartoons are literary genres that use drawings or graphics, usually in combination with text, to convey an entertaining narrative. Many contemporary comics have elements of fantasy and are produced by companies that are part of the entertainment industry. Others have unique authors who offer a more personal, philosophical view of the world and the problems people face. Comics about superheroes such as Superman are of the first type. Examples of the second sort include the individual work over 50 years of Charles M. Schulz who produced a popular comic called Peanuts about the relationships among a cast of child characters; and Michael Leunig who entertains by producing whimsical cartoons that also incorporate social criticism. The Japanese Manga style differs from the western approach in that it encompasses a wide range of genres and themes for a readership of all ages. Caricature uses a kind of graphic entertainment for purposes ranging from merely putting a smile on the viewer's face, to raising social awareness, to highlighting the moral characteristics of a person being caricatured.\n\nComedy \n\nComedy is both a genre of entertainment and a component of it, providing laughter and amusement, whether the comedy is the sole purpose or used as a form of contrast in an otherwise serious piece. It is a valued contributor to many forms of entertainment, including in literature, theatre, opera, film and games. In royal courts, such as in the Byzantine court, and presumably, also in its wealthy households, \"mimes were the focus of orchestrated humour, expected or obliged to make fun of all at court, not even excepting the emperor and members of the imperial family. This highly structured role of jester consisted of verbal humour, including teasing, jests, insult, ridicule, and obscenity and non-verbal humour such as slapstick and horseplay in the presence of an audience.\" In medieval times, all comic types the buffoon, jester, hunchback, dwarf, jokester, were all \"considered to be essentially of one comic type: the fool\", who while not necessarily funny, represented \"the shortcomings of the individual\".\n\nShakespeare wrote seventeen comedies that incorporate many techniques still used by performers and writers of comedy\u2014such as jokes, puns, parody, wit, observational humor, or the unexpected effect of irony. One-liner jokes and satire are also used to comedic effect in literature. In farce, the comedy is a primary purpose.\n\nThe meaning of the word \"comedy\" and the audience's expectations of it have changed over time and vary according to culture. Simple physical comedy such as slapstick is entertaining to a broad range of people of all ages. However, as cultures become more sophisticated, national nuances appear in the style and references so that what is amusing in one culture may be unintelligible in another.\n\nPerformance \n\nLive performances before an audience constitute a major form of entertainment, especially before the invention of audio and video recording. Performance takes a wide range of forms, including theatre, music and drama. In the 16th and 17th centuries, European royal courts presented masques that were complex theatrical entertainments involving dancing, singing and acting. Opera is a similarly demanding performance style that remains popular. It also encompass all three forms, demanding a high level of musical and dramatic skill, collaboration and like the masque, production expertise as well.\n\nAudiences generally show their appreciation of an entertaining performance with applause. However, all performers run the risk of failing to hold their audience's attention and thus, failing to entertain. Audience dissatisfaction is often brutally honest and direct.\n\nStorytelling \n\nStorytelling is an ancient form of entertainment that has influenced almost all other forms. It is \"not only entertainment, it is also thinking through human conflicts and contradictions\". Hence, although stories may be delivered directly to a small listening audience, they are also presented as entertainment and used as a component of any piece that relies on a narrative, such as film, drama, ballet, and opera. Written stories have been enhanced by illustrations, often to a very high artistic standard, for example, on illuminated manuscripts and on ancient scrolls such as Japanese ones. Stories remain a common way of entertaining a group that is on a journey. Showing how stories are used to pass the time and entertain an audience of travellers, Chaucer used pilgrims in his literary work The Canterbury Tales in the 14th century, as did Wu Cheng'en in the 16th century in Journey to the West. Even though journeys can now be completed much faster, stories are still told to passengers en route in cars and aeroplanes either orally or delivered by some form of technology.\n\nThe power of stories to entertain is evident in one of the most famous ones\u2014Scheherazade\u2014a story in the Persian professional storytelling tradition, of a woman who saves her own life by telling stories. The connections between the different types of entertainment are shown by the way that stories like this inspire a retelling in another medium, such as music, film or games. For example, composers Rimsky-Korsakov, Ravel and Szymanowski have each been inspired by the Scheherazade story and turned it into an orchestral work; director Pasolini made a film adaptation; and there is an innovative video game based on the tale. Stories may be told wordlessly, in music, dance or puppetry for example, such as in the Javanese tradition of wayang, in which the performance is accompanied by a gamelan orchestra or the similarly traditional Punch and Judy show.\n\nEpic narratives, poems, sagas and allegories from all cultures tell such gripping tales that they have inspired countless other stories in all forms of entertainment. Examples include the Hindu Ramayana and Mahabharata; Homer's Odyssey and Iliad; the first Arabic novel Hayy ibn Yaqdhan; the Persian epic Shahnameh; the Sagas of Icelanders and the celebrated Tale of the Genji. Collections of stories, such as Grimms' Fairy Tales or those by Hans Christian Andersen, have been similarly influential. Originally published in the early 19th century, this collection of folk stories significantly influence modern popular culture, which subsequently used its themes, images, symbols, and structural elements to create new entertainment forms.\n\nSome of the most powerful and long-lasting stories are the foundation stories, also called origin or creation myths such as the Dreamtime myths of the Australian aborigines, the Mesopotamian Epic of Gilgamesh, or the Hawaiian stories of the origin of the world. These too are developed into books, films, music and games in a way that increases their longevity and enhances their entertainment value.\n\nTheatre \n\nTheatre performances, typically dramatic or musical, are presented on a stage for an audience and have a history that goes back to Hellenistic times when \"leading musicians and actors\" performed widely at \"poetical competitions\", for example at \"Delphi, Delos, Ephesus\". Aristotle and his teacher Plato both wrote on the theory and purpose of theatre. Aristotle posed questions such as \"What is the function of the arts in shaping character? Should a member of the ruling class merely watch performances or be a participant and perform? What kind of entertainment should be provided for those who do not belong to the elite?\" The \"Ptolemys in Egypt, the Seleucids in Pergamum\" also had a strong theatrical tradition and later, wealthy patrons in Rome staged \"far more lavish productions\".\n\nExpectations about the performance and their engagement with it have changed over time (1). For example, in England during the 18th century, \"the prejudice against actresses had faded\" and in Europe generally, going to the theatre, once a socially dubious activity, became \"a more respectable middle-class pastime\" in the late 19th and early 20th centuries, when the variety of popular entertainments increased. Operetta and music halls became available, and new drama theatres such as the Moscow Art Theatre and the Suvorin Theatre in Russia opened. At the same time, commercial newspapers \"began to carry theatre columns and reviews\" that helped make theatre \"a legitimate subject of intellectual debate\" in general discussions about art and culture. Audiences began to gather to \"appreciate creative achievement, to marvel at, and be entertained by, the prominent 'stars'.\" Vaudeville and music halls, popular at this time in the United States, England, Canada, Australia and New Zealand, were themselves eventually superseded.\n\nPlays, musicals, monologues, pantomimes, and performance poetry are part of the very long history of theatre, which is also the venue for the type of performance known as stand-up comedy. In the 20th century, radio and television, often broadcast live, extended the theatrical tradition that continued to exist alongside the new forms.\n\nThe stage and the spaces set out in front of it for an audience create a theatre. All types of stage are used with all types of seating for the audience, including the impromptu or improvised (2, 3, 6); the temporary (2); the elaborate (9); or the traditional and permanent (5, 7). They are erected indoors (3, 5, 9) or outdoors (2, 4, 6). The skill of managing, organising and preparing the stage for a performance is known as stagecraft (10). The audience's experience of the entertainment is affected by their expectations, the stagecraft, the type of stage, and the type and standard of seating provided.\n\nCinema and film \n\nFilms are a major form of entertainment, although not all films have entertainment as their primary purpose: documentary film, for example, aims to create a record or inform, although the two purposes often work together. The medium was a global business from the beginning: \"The Lumi\u00e8re brothers were the first to send cameramen throughout the world, instructing them to film everything which could be of interest for the public.\" In 1908, Path\u00e9 launched and distributed newsreels and by World War I, films were meeting an enormous need for mass entertainment. \"In the first decade of the [20th] century cinematic programmes combined, at random, fictions and newsfilms.\" The Americans first \"contrived a way of producing an illusion of motion through successive images,\" but \"the French were able to transform a scientific principle into a commercially lucrative spectacle\". Film therefore became a part of the entertainment industry from its early days. Increasingly sophisticated techniques have been used in the film medium to delight and entertain audiences. Animation, for example, which involves the display of rapid movement in an art work, is one of these techniques that particularly appeals to younger audiences. The advent of computer-generated imagery (CGI) in the 21st century made it \"possible to do spectacle\" more cheaply and \"on a scale never dreamed of\" by Cecil B. DeMille. From the 1930s to 1950s, movies and radio were the \"only mass entertainment\" but by the second decade of the 21st century, technological changes, economic decisions, risk aversion and globalisation reduced both the quality and range of films being produced. Sophisticated visual effects and CGI techniques, for example, rather than humans, were used not only to create realistic images of people, landscapes and events (both real and fantastic) but also to animate non-living items such as Lego normally used as entertainment as a game in physical form. Creators of The Lego Movie \"wanted the audience to believe they were looking at actual Lego bricks on a tabletop that were shot with a real camera, not what we actually did, which was create vast environments with digital bricks inside the computer.\" The convergence of computers and film has allowed entertainment to be presented in a new way and the technology has also allowed for those with the personal resources to screen films in a home theatre, recreating in a private venue the quality and experience of a public theatre. This is similar to the way that the nobility in earlier times could stage private musical performances or the use of domestic theatres in large homes to perform private plays in earlier centuries.\n\nFilms also re-imagine entertainment from other forms, turning stories, books and plays, for example, into new entertainments. The Story of Film, a documentary about the history of film, gives a survey of global achievements and innovations in the medium, as well as changes in the conception of film-making. It demonstrates that while some films, particularly those in the Hollywood tradition that combines \"realism and melodramatic romanticism\", are intended as a form of escapism, others require a deeper engagement or more thoughtful response from their audiences. For example, the award-winning Senegalese film Xala takes government corruption as its theme. Charlie Chaplin's film The Great Dictator was a brave and innovative parody, also on a political theme. Stories that are thousands of years old, such as Noah, have been re-interpreted in film, applying familiar literary devices such as allegory and personification with new techniques such as CGI to explore big themes such as \"human folly\", good and evil, courage and despair, love, faith, and death themes that have been a main-stay of entertainment across all its forms.\n\nAs in other media, excellence and achievement in films is recognised through a range of awards, including ones from the American Academy of Motion Picture Arts and Sciences, the British Academy of Film and Television Arts, the Cannes International Film Festival in France and the Asia Pacific Screen Awards.\n\nDance \n\nThe many forms of dance provide entertainment for all age groups and cultures. Dance can be serious in tone, such as when it is used to express a culture's history or important stories; it may be provocative; or it may put in the service of comedy. Since it combines many forms of entertainment music, movement, storytelling, theatre it provides a good example of the various ways that these forms can be combined to create entertainment for different purposes and audiences.\n\nDance is \"a form of cultural representation\" that involves not just dancers, but \"choreographers, audience members, patrons and impresarios\u00a0... coming from all over the globe and from vastly varied time periods.\" Whether from Africa, Asia or Europe, dance is constantly negotiating the realms of political, social, spiritual and artistic influence.\" Even though dance traditions may be limited to one cultural group, they all develop. For example, in Africa, there are \"Dahomean dances, Hausa dances, Masai dances and so forth.\" Ballet is an example of a highly developed Western form of dance that moved to the theatres from the French court during the time of Louis XIV, the dancers becoming professional theatrical performers. Some dances, such as the quadrille, a square dance that \"emerged during the Napoleonic years in France\" and other country dances were once popular at social gatherings like balls, but are now rarely performed. On the other hand, many folk dances (such as Scottish Highland dancing and Irish dancing), have evolved into competitions, which by adding to their audiences, has increased their entertainment value. \"Irish dance theatre, which sometimes features traditional Irish steps and music, has developed into a major dance form with an international reputation.\"\n\nSince dance is often \"associated with the female body and women's experiences\", female dancers, who dance to entertain, have in some cases been regarded as distinct from \"decent\" women because they \"use their bodies to make a living instead of hiding them as much as possible\". Society's attitudes to female dancers depend on the culture, its history and the entertainment industry itself. For example, while some cultures regard any dancing by women as \"the most shameful form of entertainment\", other cultures have established venues such as strip clubs where deliberately erotic or sexually provocative dances such as striptease are performed in public by professional women dancers for mostly male audiences.\n\nVarious political regimes have sought to control or ban dancing or specific types of dancing, sometimes because of disapproval of the music or clothes associated with it. Nationalism, authoritarianism and racism have played a part in banning dances or dancing. For example, during the Nazi regime, American dances such as swing, regarded as \"completely un-German\", had \"become a public offense and needed to be banned\". Similarly, in Shanghai, China, in the 1930s, \"dancing and nightclubs had come to symbolise the excess that plagued Chinese society\" and officials wondered if \"other forms of entertainment such as brothels\" should also be banned. Banning had the effect of making \"the dance craze\" even greater. In Ireland, the Public Dance Hall Act of 1935 \"banned but did not stop dancing at the crossroads and other popular dance forms such as house and barn dances.\" In the US, various dances were once banned, either because like burlesque, they were suggestive, or because, like the Twist, they were associated with African Americans. \"African American dancers were typically banned from performing in minstrel shows until after the Civil War.\"\n\nDances can be performed solo (1, 4); in pairs, (2, 3); in groups, (5, 6, 7); or by massed performers (10). They might be improvised (4, 8) or highly choreographed (1, 2, 5, 10); spontaneous for personal entertainment, (such as when children begin dancing for themselves); a private audience, (4); a paying audience (2); a world audience (10); or an audience interested in a particular dance genre (3, 5). They might be a part of a celebration, such as a wedding or New Year (6, 8); or a cultural ritual with a specific purpose, such as a dance by warriors like a haka (7). Some dances, such as traditional dance in 1 and ballet in 2, need a very high level of skill and training; others, such as the can-can, require a very high level of energy and physical fitness. Entertaining the audience is a normal part of dance but its physicality often also produces joy for the dancers themselves (9).\n\nAnimals \nAnimals have been used for the purposes of entertainment for millennia. They have been hunted for entertainment (as opposed to hunted for food); displayed while they hunt for prey; watched when they compete with each other; and watched while they perform a trained routine for human amusement. The Romans, for example, were entertained both by competitions involving wild animals and acts performed by trained animals. They watched as \"lions and bears danced to the music of pipes and cymbals; horses were trained to kneel, bow, dance and prance\u00a0... acrobats turning handsprings over wild lions and vaulting over wild leopards.\" There were \"violent confrontations with wild beasts\" and \"performances over time became more brutal and bloodier\".\n\nAnimals that perform trained routines or \"acts\" for human entertainment include fleas in flea circuses, dolphins in dolphinaria, and monkeys doing tricks for an audience on behalf of the player of a street organ. Animals kept in zoos in ancient times were often kept there for later use in the arena as entertainment or for their entertainment value as exotica.\n\nMany contests between animals are now regarded as sports for example, horse racing is regarded as both a sport and an important source of entertainment. Its economic impact means that it is also considered a global industry, one in which horses are carefully transported around the world to compete in races. In Australia, the horse race run on Melbourne Cup Day is a public holiday and the public regards the race as an important annual event. Like horse racing, camel racing requires human riders, while greyhound racing does not. People find it entertaining to watch animals race competitively, whether they are trained, like horses, camels or dogs, or untrained, like cockroaches.\n\nThe use of animals for entertainment is sometimes controversial, especially the hunting of wild animals. Some contests between animals, once popular entertainment for the public, have become illegal because of the cruelty involved. Among these are blood sports such as bear-baiting, dog fighting and cockfighting. Other contests involving animals remain controversial and have both supporters and detractors. For example, the conflict between opponents of pigeon shooting who view it as \"a cruel and moronic exercise in marksmanship, and proponents, who view it as entertainment\" has been tested in a court of law. Fox hunting, which involves the use of horses as well as hounds, and bullfighting, which has a strong theatrical component, are two entertainments that have a long and significant cultural history. They both involve animals and are variously regarded as sport, entertainment or cultural tradition. Among the organisations set up to advocate for the rights of animals are some whose concerns include the use of animals for entertainment. However, \"in many cases of animal advocacy groups versus organisations accused of animal abuse, both sides have cultural claims.\"\n\nCircus \n\nA circus, described as \"one of the most brazen of entertainment forms\", is a special type of theatrical performance, involving a variety of physical skills such as acrobatics and juggling and sometimes performing animals. Usually thought of as a travelling show performed in a big top, circus was first performed in permanent venues. Philip Astley is regarded as the founder of the modern circus in the second half of the 18th century and Jules L\u00e9otard is the French performer credited with developing the art of the trapeze, considered synonymous with circuses. Astley brought together performances that were generally familiar in traditional British fairs \"at least since the beginning of the 17th century\": \"tumbling, rope-dancing, juggling, animal tricks and so on\". It has been claimed that \"there is no direct link between the Roman circus and the circus of modern times.\u00a0... Between the demise of the Roman 'circus' and the foundation of Astley's Amphitheatre in London some 1300 years later, the nearest thing to a circus ring was the rough circle formed by the curious onlookers who gathered around the itinerant tumbler or juggler on a village green.\"\n\nMagic \n\nThe form of entertainment known as stage magic or conjuring and recognisable as performance, is based on traditions and texts of magical rites and dogmas that have been a part of most cultural traditions since ancient times. (References to magic, for example, can be found in the Bible, in Hermeticism, in Zoroastrianism, in the Kabbalistic tradition, in mysticism and in the sources of Freemasonry.)\n\nStage magic is performed for an audience in a variety of media and locations: on stage, on television, in the street, and live at parties or events. It is often combined with other forms of entertainment, such as comedy or music and showmanship is often an essential part of magic performances. Performance magic relies on deception, psychological manipulation, sleight of hand and other forms of trickery to give an audience the illusion that a performer can achieve the impossible. Audiences amazed at the stunt performances and escape acts of Harry Houdini, for example, regarded him as a magician.\n\nFantasy magicians have held an important place in literature for centuries, offering entertainment to millions of readers. Famous wizards such as Merlin in the Arthurian legends have been written about since the 5th and 6th centuries, while in the 21st century, the young wizard Harry Potter became a global entertainment phenomenon when the book series about him sold about 450 million copies (as at June 2011), making it the best-selling book series in history.\n\nStreet performance \n\nStreet entertainment, street performance, or \"busking\" are forms of performance that have been meeting the public's need for entertainment for centuries. It was \"an integral aspect of London's life\", for example, when the city in the early 19th century was \"filled with spectacle and diversion\". Minstrels or troubadours are part of the tradition. The art and practice of busking is still celebrated at annual busking festivals.\n\nThere are three basic forms of contemporary street performance. The first form is the \"circle show\". It tends to gather a crowd, usually has a distinct beginning and end, and is done in conjunction with street theatre, puppeteering, magicians, comedians, acrobats, jugglers and sometimes musicians. This type has the potential to be the most lucrative for the performer because there are likely to be more donations from larger audiences if they are entertained by the act. Good buskers control the crowd so patrons do not obstruct foot traffic. The second form, the walk-by act, has no distinct beginning or end. Typically, the busker provides an entertaining ambience, often with an unusual instrument, and the audience may not stop to watch or form a crowd. Sometimes a walk-by act spontaneously turns into a circle show. The third form, caf\u00e9 busking, is performed mostly in restaurants, pubs, bars and caf\u00e9s. This type of act occasionally uses public transport as a venue.\n\nParades \n\nParades are held for a range of purposes, often more than one. Whether their mood is sombre or festive, being public events that are designed to attract attention and activities that necessarily divert normal traffic, parades have a clear entertainment value to their audiences. Cavalcades and the modern variant, the motorcade, are examples of public processions. Some people watching the parade or procession may have made a special effort to attend, while others become part of the audience by happenstance. Whatever their mood or primary purpose, parades attract and entertain people who watch them pass by. Occasionally, a parade takes place in an improvised theatre space (such as the Trooping the Colour in 8) and tickets are sold to the physical audience while the global audience participates via broadcast.\n\nOne of the earliest forms of parade were \"triumphs\" grand and sensational displays of foreign treasures and spoils, given by triumphant Roman generals to celebrate their victories. They presented conquered peoples and nations that exalted the prestige of the victor. \"In the summer of 46\u00a0BCE Julius Caesar chose to celebrate four triumphs held on different days extending for about one month.\" In Europe from the Middle Ages to the Baroque the Royal Entry celebrated the formal visit of the monarch to the city with a parade through elaborately decorated streets, passing various shows and displays. The annual Lord Mayor's Show in London is an example of a civic parade that has survived since medieval times.\n\nMany religious festivals (especially those that incorporate processions, such as Holy Week processions or the Indian festival of Holi) have some entertainment appeal in addition to their serious purpose. Sometimes, religious rituals have been adapted or evolved into secular entertainments, or like the Festa del Redentore in Venice, have managed to grow in popularity while holding both secular and sacred purposes in balance. However, pilgrimages, such as the Roman Catholic pilgrimage of the Way of St. James, the Muslim Hajj and the Hindu Kumbh Mela, which may appear to the outsider as an entertaining parade or procession, are not intended as entertainment: they are instead about an individual's spiritual journey. Hence, the relationship between spectator and participant, unlike entertainments proper, is different. The manner in which the Kumbh Mela, for example, \"is divorced from its cultural context and repackaged for Western consumption renders the presence of voyeurs deeply problematic.\"\n\nParades generally impress and delight often by including unusual, colourful costumes (7, 10). Sometimes they also commemorate (5, 8) or celebrate (1, 4, 6, 8, 9). Sometimes they have a serious purpose, such as when the context is military (1, 2, 5), when the intention is sometimes to intimidate; or religious, when the audience might participate or have a role to play (6, 7, 10). Even if a parade uses new technology and is some distance away (9), it is likely to have a strong appeal, draw the attention of onlookers and entertain them.\n\nFireworks \n\nFireworks are a part of many public entertainments and have retained an enduring popularity since they became a \"crowning feature of elaborate celebrations\" in the 17th century. First used in China, classical antiquity and Europe for military purposes, fireworks were most popular in the 18th century and high prices were paid for pyrotechnists, especially the skilled Italian ones, who were summoned to other countries to organise displays. Fire and water were important aspects of court spectacles because the displays \"inspired by means of fire, sudden noise, smoke and general magnificence the sentiments thought fitting for the subject to entertain of his sovereign: awe fear and a vicarious sense of glory in his might. Birthdays, name-days, weddings and anniversaries provided the occasion for celebration.\" One of the most famous courtly uses of fireworks was one used to celebrate the end of the War of the Austrian Succession and while the fireworks themselves caused a fire, the accompanying Music for the Royal Fireworks written by Handel has been popular ever since. Aside from their contribution to entertainments related to military successes, courtly displays and personal celebrations, fireworks are also used as part of religious ceremony. For example, during the Indian Dashavatara Kala of Gomantaka \"the temple deity is taken around in a procession with a lot of singing, dancing and display of fireworks\".\n\nThe \"fire, sudden noise and smoke\" of fireworks is still a significant part of public celebration and entertainment. For example, fireworks were one of the primary forms of display chosen to celebrate the turn of the millennium around the world. As the clock struck midnight and 1999 became 2000, firework displays and open-air parties greeted the New Year as the time zones changed over to the next century. Fireworks, carefully planned and choreographed, were let off against the backdrop of many of the world's most famous buildings, including the Sydney Harbour Bridge, the Pyramids of Giza in Egypt, the Acropolis in Athens, Red Square in Moscow, Vatican City in Rome, the Brandenburg Gate in Berlin, the Eiffel Tower in Paris, and Elizabeth Tower in London.\n\nSport \n\nSporting competitions have always provided entertainment for crowds. To distinguish the players from the audience, the latter are often known as spectators. Developments in stadium and auditorium design, as well as in recording and broadcast technology, have allowed off-site spectators to watch sport, with the result that the size of the audience has grown ever larger and spectator sport has become increasingly popular. Two of the most popular sports with global appeal are association football and cricket. Their ultimate international competitions, the FIFA World Cup and the Cricket World Cup, are broadcast around the world. Beyond the very large numbers involved in playing these sports, they are notable for being a major source of entertainment for many millions of non-players worldwide. A comparable multi-stage, long-form sport with global appeal is the Tour de France, unusual in that it takes place outside of special stadia, being run instead in the countryside.\n\nAside from sports that have worldwide appeal and competitions, such as the Olympic Games, the entertainment value of a sport depends on the culture and country where people play it. For example, in the United States, baseball and basketball games are popular forms of entertainment; in Bhutan, the national sport is archery; in New Zealand, it is rugby union; in Iran, it is freestyle wrestling. Japan's unique sumo wrestling contains ritual elements that derive from its long history. In some cases, such as the international running group Hash House Harriers, participants create a blend of sport and entertainment for themselves, largely independent of spectator involvement, where the social component is more important than the competitive.\n\nThe evolution of an activity into a sport and then an entertainment is also affected by the local climate and conditions. For example, the modern sport of surfing is associated with Hawaii and that of snow skiing probably evolved in Scandinavia. While these sports and the entertainment they offer to spectators have spread around the world, people in the two originating countries remain well known for their prowess. Sometimes the climate offers a chance to adapt another sport such as in the case of ice hockey\u2014an important entertainment in Canada.\n\nFairs, expositions, shopping \n\nFairs and exhibitions have existed since ancient and medieval times, displaying wealth, innovations and objects for trade and offering specific entertainments as well as being places of entertainment in themselves. Whether in a medieval market or a small shop, \"shopping always offered forms of exhilaration that took one away from the everyday\". However, in the modern world, \"merchandising has become entertainment: spinning signs, flashing signs, thumping music\u00a0... video screens, interactive computer kiosks, day care .. caf\u00e9s\".\n\nBy the 19th century, \"expos\" that encouraged arts, manufactures and commerce had become international. They were not only hugely popular but affected international ideas. For example, the 1878 Paris Exposition facilitated international cooperation about ideas, innovations and standards. From London 1851 to Paris 1900, \"in excess of 200 million visitors had entered the turnstiles in London, Paris, Vienna, Philadelphia, Chicago and a myriad of smaller shows around the world.\" Since World War II \"well over 500 million visits have been recorded through world expo turnstiles\". As a form of spectacle and entertainment, expositions influenced \"everything from architecture, to patterns of globalisation, to fundamental matters of human identity\" and in the process established the close relationship between \"fairs, the rise of department stores and art museums\", the modern world of mass consumption and the entertainment industry.\n\nSafety \nSome entertainments, such as at large festivals (whether religious or secular), concerts, clubs, parties and celebrations, involve big crowds. From earliest times, crowds at an entertainment have associated hazards and dangers, especially when combined with the recreational consumption of intoxicants such as alcohol. The Ancient Greeks had Dionysian Mysteries, for example, and the Romans had Saturnalia. The consequence of excess and crowds can produce breaches of social norms of behaviour, sometimes causing injury or even death, such as for example, at the Altamont Free Concert, an outdoor rock festival. The list of serious incidents at nightclubs includes those caused by stampede; overcrowding; terrorism, such as the 2002 Bali bombings that targeted a nightclub; and especially fire. Investigations, such as that carried out in the US after The Station nightclub fire often demonstrate that lessons learned \"regarding fire safety in nightclubs\" from earlier events such as the Cocoanut Grove fire do \"not necessarily result in lasting effective change\". Efforts to prevent such incidents include appointing special officers, such as the medieval Lord of Misrule or, in modern times, security officers who control access; and also ongoing improvement of relevant standards such as those for building safety. The tourism industry now regards safety and security at entertainment venues as an important management task.\n\nIndustry \n\nEntertainment is big business, especially in the United States, but ubiquitous in all cultures.\nAlthough kings, rulers and powerful people have always been able to pay for entertainment to be provided for them and in many cases have paid for public entertainment, people generally have made their own entertainment or when possible, attended a live performance. Technological developments in the 20th century, especially in the area of mass media, meant that entertainment could be produced independently of the audience, packaged and sold on a commercial basis by an entertainment industry. Sometimes referred to as show business, the industry relies on business models to produce, market, broadcast or otherwise distribute many of its traditional forms, including performances of all types. The industry became so sophisticated that its economics became a separate area of academic study.\n\nThe film industry is a part of the entertainment industry. Components of it include the Hollywood and Bollywood film industries, as well as the cinema of the United Kingdom and all the cinemas of Europe, including France, Germany, Spain, Italy and others. The sex industry is another component of the entertainment industry, applying the same forms and media (for example, film, books, dance and other performances) to the development, marketing and sale of sex products on a commercial basis.\n\nAmusement parks entertain paying guests with rides, such as roller coasters, ridable miniature railways, water rides, and dark rides, as well as other events and associated attractions. The parks are built on a large area subdivided into themed areas named \"lands\". Sometimes the whole amusement park is based on one theme, such as the various SeaWorld parks that focus on the theme of sea life.\n\nOne of the consequences of the development of the entertainment industry has been the creation of new types of employment. While jobs such as writer, musician and composer exist as they always have, people doing this work are likely to be employed by a company rather than a patron as they once would have been. New jobs have appeared, such as gaffer or special effects supervisor in the film industry, and attendants in an amusement park.\n\nPrestigious awards are given by the industry for excellence in the various types of entertainment. For example, there are awards for Music, Games (including video games), Comics, Comedy, Theatre, Television, Film, Dance and Magic. Sporting awards are made for the results and skill, rather than for the entertainment value.\n\nArchitecture\n\nArchitecture for entertainment \nPurpose-built structures as venues for entertainment that accommodate audiences have produced many famous and innovative buildings, among the most recognisable of which are theatre structures. For the ancient Greeks, \"the architectural importance of the theatre is a reflection of their importance to the community, made apparent in their monumentality, in the effort put into their design, and in the care put into their detail.\" The Romans subsequently developed the stadium in an oval form known as a circus. In modern times, some of the grandest buildings for entertainment have brought fame to their cities as well as their designers. The Sydney Opera House, for example, is a World Heritage Site and The O\u2082 in London is an entertainment precinct that contains an indoor arena, a music club, a cinema and exhibition space. The Bayreuth Festspielhaus in Germany is a theatre designed and built for performances of one specific musical composition.\n\nTwo of the chief architectural concerns for the design of venues for mass audiences are speed of egress and safety. The speed at which the venue empty is important both for amenity and safety, because large crowds take a long time to disperse from a badly designed venue, which creates a safety risk. The Hillsborough disaster is an example of how poor aspects of building design can contribute to audience deaths. Sightlines and acoustics are also important design considerations in most theatrical venues.\n\nIn the 21st century, entertainment venues, especially stadia, are \"likely to figure among the leading architectural genres\". However, they require \"a whole new approach\" to design, because they need to be \"sophisticated entertainment centres, multi-experience venues, capable of being enjoyed in many diverse ways\". Hence, architects now have to design \"with two distinct functions in mind, as sports and entertainment centres playing host to live audiences, and as sports and entertainment studios serving the viewing and listening requirements of the remote audience\".\n\nArchitecture as entertainment \n\nArchitects who push the boundaries of design or construction sometimes create buildings that are entertaining because they exceed the expectations of the public and the client and are aesthetically outstanding. Buildings such as Guggenheim Museum Bilbao, designed by Frank Gehry, are of this type, becoming a tourist attraction as well as a significant international museum. Other apparently usable buildings are really follies, deliberately constructed for a decorative purpose and never intended to be practical.\n\nOn the other hand, sometimes architecture is entertainment, while pretending to be functional. The tourism industry, for example, creates or renovates buildings as \"attractions\" that have either never been used or can never be used for their ostensible purpose. They are instead re-purposed to entertain visitors often by simulating cultural experiences. Buildings, history and sacred spaces are thus made into commodities for purchase. Such intentional tourist attractions divorce buildings from the past so that \"the difference between historical authenticity and contemporary entertainment venues/theme parks becomes hard to define\". Examples include \"the preservation of the Alc\u00e1zar of Toledo, with its grim Civil War History, the conversion of slave dungeons into tourist attractions in Ghana, [such as, for example, Cape Coast Castle] and the presentation of indigenous culture in Libya\". The specially constructed buildings in amusement parks represent the park's theme and are usually neither authentic nor completely functional.\n\nEffects of developments in electronic media\n\nGlobalisation \nBy the second half of the 20th century, developments in electronic media made possible the delivery of entertainment products to mass audiences across the globe. The technology enabled people to see, hear and participate in all the familiar forms stories, theatre, music, dance wherever they live. The rapid development of entertainment technology was assisted by improvements in data storage devices such as cassette tapes or compact discs, along with increasing miniaturisation. Computerisation and the development of barcodes also made ticketing easier, faster and global.\n\nObsolescence \n\nIn the 1940s, radio was the electronic medium for family entertainment and information. In the 1950s, it was television that was the new medium and it rapidly became global, bringing visual entertainment, first in black and white, then in colour, to the world. By the 1970s, games could be played electronically, then hand-held devices provided mobile entertainment, and by the last decade of the 20th century, via networked play. In combination with products from the entertainment industry, all the traditional forms of entertainment became available personally. People could not only select an entertainment product such as a piece of music, film or game, they could choose the time and place to use it. The \"proliferation of portable media players and the emphasis on the computer as a site for film consumption\" together have significantly changed how audiences encounter films. One of the most notable consequences of the rise of electronic entertainment has been the rapid obsolescence of the various recording and storage methods. As an example of speed of change driven by electronic media, over the course of one generation, television as a medium for receiving standardised entertainment products went from unknown, to novel, to ubiquitous and finally to superseded. One estimate was that by 2011 over 30 percent of households in the US would own a Wii console, \"about the same percentage that owned a television in 1953\". Some expected that halfway through the second decade of the 21st century, online entertainment would have completely replaced television\u2014which didn't happen. The so-called \"digital revolution\" has produced an increasingly transnational marketplace that has caused difficulties for governments, business, industries, and individuals, as they all try to keep up. Even the sports stadium of the future will increasingly compete with television viewing \"...in terms of comfort, safety and the constant flow of audio-visual information and entertainment available.\" Other flow on effects of the shift are likely to include those on public architecture such as hospitals and nursing homes, where television, regarded as an essential entertainment service for patients and residents, will need to be replaced by access to the internet. At the same time, the ongoing need for entertainers as \"professional engagers\" shows the continuity of traditional entertainment.\n\nConvergence \nBy the second decade of the 21st century, analogue recording was being replaced by digital recording and all forms of electronic entertainment began to converge. For example, convergence is challenging standard practices in the film industry: whereas \"success or failure used to be determined by the first weekend of its run. Today,\u00a0... a series of exhibition 'windows', such as DVD, pay-per-view, and fibre-optic video-on-demand are used to maximise profits.\" Part of the industry's adjustment is its release of new commercial product directly via video hosting services. Media convergence is said to be more than technological: the convergence is cultural as well. It is also \"the result of a deliberate effort to protect the interests of business entities, policy institutions and other groups\". Globalisation and cultural imperialism are two of the cultural consequences of convergence. Others include fandom and interactive storytelling as well as the way that single franchises are distributed through and affect a range of delivery methods. The \"greater diversity in the ways that signals may be received and packaged for the viewer, via terrestrial, satellite or cable television, and of course, via the Internet\" also affects entertainment venues, such as sports stadia, which now need to be designed so that both live and remote audiences can interact in increasingly sophisticated ways for example, audiences can \"watch highlights, call up statistics\", \"order tickets and merchandise\" and generally \"tap into the stadium's resources at any time of the day or night\".\n\nThe introduction of television altered the availability, cost, variety and quality of entertainment products for the public and the convergence of online entertainment is having a similar effect. For example, the possibility and popularity of user-generated content, as distinct from commercial product, creates a \"networked audience model [that] makes programming obsolete\". Individuals and corporations use video hosting services to broadcast content that is equally accepted by the public as legitimate entertainment.\n\nWhile technology increases demand for entertainment products and offers increased speed of delivery, the forms that make up the content are in themselves, relatively stable. Storytelling, music, theatre, dance and games are recognisably the same as in earlier centuries.\n\nSee also \n Entertainment law\n Family entertainment centre\n List of entertainer occupations\n Outline of entertainment\n Performing arts\n Performing arts education\n\nReferences\n\nExternal links \n\n \nConcepts in aesthetics\nArticles containing video clips\nMain topic articles\nGood articles\nPerforming arts",
  "Energy": "In physics, energy is the quantitative property that must be transferred to a body or physical system to perform work on the body, or to heat it. Energy is a conserved quantity; the law of conservation of energy states that energy can be converted in form, but not created or destroyed. The unit of measurement in the International System of Units (SI) of energy is the joule, which is the energy transferred to an object by the work of moving it a distance of one metre against a force of one newton.\n\nCommon forms of energy include the kinetic energy of a moving object, the potential energy stored by an object's position in a force field (gravitational, electric or magnetic), the elastic energy stored by stretching solid objects, the chemical energy released when a fuel burns, the radiant energy carried by light, and the thermal energy due to an object's temperature.\n\nMass and energy are closely related. Due to mass\u2013energy equivalence, any object that has mass when stationary (called rest mass) also has an equivalent amount of energy whose form is called rest energy, and any additional energy (of any form) acquired by the object above that rest energy will increase the object's total mass just as it increases its total energy. For example, after heating an object, its increase in energy could in principle be measured as a small increase in mass, with a sensitive enough scale.\n\nLiving organisms require energy to stay alive, such as the energy humans get from food and oxygen. Human civilization requires energy to function, which it gets from energy resources such as fossil fuels, nuclear fuel, or renewable energy. The processes of Earth's climate and ecosystem are driven by the radiant energy Earth receives from the Sun and the geothermal energy contained within the earth.\n\nForms\n\nThe total energy of a system can be subdivided and classified into potential energy, kinetic energy, or combinations of the two in various ways. Kinetic energy is determined by the movement of an object \u2013 or the composite motion of the components of an object \u2013 and potential energy reflects the potential of an object to have motion, and generally is a function of the position of an object within a field or may be stored in the field itself.\n\nWhile these two categories are sufficient to describe all forms of energy, it is often convenient to refer to particular combinations of potential and kinetic energy as its own form. For example, the sum of translational and rotational kinetic and potential energy within a system is referred to as mechanical energy, whereas nuclear energy refers to the combined potentials within an atomic nucleus from either the nuclear force or the weak force, among other examples.\n\nHistory\n\nThe word energy derives from the , which possibly appears for the first time in the work of Aristotle in the 4th century BC. In contrast to the modern definition, energeia was a qualitative philosophical concept, broad enough to include ideas such as happiness and pleasure.\n\nIn the late 17th century, Gottfried Leibniz proposed the idea of the , or living force, which defined as the product of the mass of an object and its velocity squared; he believed that total vis viva was conserved. To account for slowing due to friction, Leibniz theorized that thermal energy consisted of the motions of the constituent parts of matter, although it would be more than a century until this was generally accepted. The modern analog of this property, kinetic energy, differs from vis viva only by a factor of two.  Writing in the early 18th century, \u00c9milie du Ch\u00e2telet proposed the concept of conservation of energy in the marginalia of her French language translation of Newton's Principia Mathematica, which represented the first formulation of a conserved measurable quantity that was distinct from momentum, and which would later be called \"energy\".  \n\nIn 1807, Thomas Young was possibly the first to use the term \"energy\" instead of vis viva, in its modern sense. Gustave-Gaspard Coriolis described \"kinetic energy\" in 1829 in its modern sense, and in 1853, William Rankine coined the term \"potential energy\". The law of conservation of energy was also first postulated in the early 19th century, and applies to any isolated system. It was argued for some years whether heat was a physical substance, dubbed the caloric, or merely a physical quantity, such as momentum. In 1845 James Prescott Joule discovered the link between mechanical work and the generation of heat.\n\nThese developments led to the theory of conservation of energy, formalized largely by William Thomson (Lord Kelvin) as the field of thermodynamics. Thermodynamics aided the rapid development of explanations of chemical processes by Rudolf Clausius, Josiah Willard Gibbs, and Walther Nernst. It also led to a mathematical formulation of the concept of entropy by Clausius and to the introduction of laws of radiant energy by Jo\u017eef Stefan. According to Noether's theorem, the conservation of energy is a consequence of the fact that the laws of physics do not change over time. Thus, since 1918, theorists have understood that the law of conservation of energy is the direct mathematical consequence of the translational symmetry of the quantity conjugate to energy, namely time.\n\nUnits of measure\n\nIn 1843, James Prescott Joule independently discovered the mechanical equivalent in a series of experiments. The most famous of them used the \"Joule apparatus\": a descending weight, attached to a string, caused rotation of a paddle immersed in water, practically insulated from heat transfer. It showed that the gravitational potential energy lost by the weight in descending was equal to the internal energy gained by the water through friction with the paddle.\n\nIn the International System of Units (SI), the unit of energy is the joule, named after Joule. It is a derived unit. It is equal to the energy expended (or work done) in applying a force of one newton through a distance of one metre. However energy is also expressed in many other units not part of the SI, such as ergs, calories, British Thermal Units, kilowatt-hours and kilocalories, which require a conversion factor when expressed in SI units.\n\nThe SI unit of energy rate (energy per unit time) is the watt, which is a joule per second.  Thus, one joule is one watt-second, and 3600 joules equal one watt-hour.  The CGS energy unit is the erg and the imperial and US customary unit is the foot pound. Other energy units such as the electronvolt, food calorie or thermodynamic kcal (based on the temperature change of water in a heating process), and BTU are used in specific areas of science and commerce.\n\nScientific use\n\nClassical mechanics\n\nIn classical mechanics, energy is a conceptually and mathematically useful property, as it is a conserved quantity. Several formulations of mechanics have been developed using energy as a core concept.\n\nWork, a function of energy, is force times distance.\n\n \n\nThis says that the work () is equal to the line integral of the force F along a path C; for details see the mechanical work article. Work and thus energy is frame dependent. For example, consider a ball being hit by a bat. In the center-of-mass reference frame, the bat does no work on the ball. But, in the reference frame of the person swinging the bat, considerable work is done on the ball.\n\nThe total energy of a system is sometimes called the Hamiltonian, after William Rowan Hamilton. The classical equations of motion can be written in terms of the Hamiltonian, even for highly complex or abstract systems. These classical equations have remarkably direct analogs in nonrelativistic quantum mechanics.\n\nAnother energy-related concept is called the Lagrangian, after Joseph-Louis Lagrange. This formalism is as fundamental as the Hamiltonian, and both can be used to derive the equations of motion or be derived from them. It was invented in the context of classical mechanics, but is generally useful in modern physics. The Lagrangian is defined as the kinetic energy minus the potential energy. Usually, the Lagrange formalism is mathematically more convenient than the Hamiltonian for non-conservative systems (such as systems with friction).\n\nNoether's theorem (1918) states that any differentiable symmetry of the action of a physical system has a corresponding conservation law. Noether's theorem has become a fundamental tool of modern theoretical physics and the calculus of variations. A generalisation of the seminal formulations on constants of motion in Lagrangian and Hamiltonian mechanics (1788 and 1833, respectively), it does not apply to systems that cannot be modeled with a Lagrangian; for example, dissipative systems with continuous symmetries need not have a corresponding conservation law.\n\nChemistry\nIn the context of chemistry, energy is an attribute of a substance as a consequence of its atomic, molecular, or aggregate structure. Since a chemical transformation is accompanied by a change in one or more of these kinds of structure, it is usually accompanied by a decrease, and sometimes an increase, of the total energy of the substances involved. Some energy may be transferred between the surroundings and the reactants in the form of heat or light; thus the products of a reaction have sometimes more but usually less energy than the reactants. A reaction is said to be exothermic or exergonic if the final state is lower on the energy scale than the initial state; in the less common case of endothermic reactions the situation is the reverse. Chemical reactions are usually not possible unless the reactants surmount an energy barrier known as the activation energy. The speed of a chemical reaction (at a given temperature\u00a0T) is related to the activation energy\u00a0E by the Boltzmann's population factor\u00a0e\u2212E/kT; that is, the probability of a molecule to have energy greater than or equal to\u00a0E at a given temperature\u00a0T. This exponential dependence of a reaction rate on temperature is known as the Arrhenius equation. The activation energy necessary for a chemical reaction can be provided in the form of thermal energy.\n\nBiology\n\nIn biology, energy is an attribute of all biological systems, from the biosphere to the smallest living organism. Within an organism it is responsible for growth and development of a biological cell or organelle of a biological organism. Energy used in respiration is mostly stored in molecular oxygen and can be unlocked by reactions with molecules of substances such as carbohydrates (including sugars), lipids, and proteins stored by cells. In human terms, the human equivalent (H-e) (Human energy conversion) indicates, for a given amount of energy expenditure, the relative quantity of energy needed for human metabolism, using as a standard an average human energy expenditure of 12,500\u00a0kJ per day and a basal metabolic rate of 80 watts. For example, if our bodies run (on average) at 80 watts, then a light bulb running at 100 watts is running at 1.25 human equivalents (100 \u00f7 80) i.e. 1.25 H-e. For a difficult task of only a few seconds' duration, a person can put out thousands of watts, many times the 746 watts in one official horsepower. For tasks lasting a few minutes, a fit human can generate perhaps 1,000 watts. For an activity that must be sustained for an hour, output drops to around 300; for an activity kept up all day, 150 watts is about the maximum. The human equivalent assists understanding of energy flows in physical and biological systems by expressing energy units in human terms: it provides a \"feel\" for the use of a given amount of energy.\n\nSunlight's radiant energy is also captured by plants as chemical potential energy in photosynthesis, when carbon dioxide and water (two low-energy compounds) are converted into carbohydrates, lipids, proteins and high-energy compounds like oxygen and ATP. Carbohydrates, lipids, and proteins can release the energy of oxygen, which is utilized by living organisms as an electron acceptor. Release of the energy stored during photosynthesis as heat or light may be triggered suddenly by a spark in a forest fire, or it may be made available more slowly for animal or human metabolism when organic molecules are ingested and catabolism is triggered by enzyme action.\n\nAll living creatures rely on an external source of energy to be able to grow and reproduce \u2013 radiant energy from the Sun in the case of green plants and chemical energy (in some form) in the case of animals. The daily 1500\u20132000\u00a0Calories (6\u20138\u00a0MJ) recommended for a human adult are taken as a combination of oxygen and food molecules, the latter mostly carbohydrates and fats, of which glucose (C6H12O6) and stearin (C57H110O6) are convenient examples. The food molecules are oxidized to carbon dioxide and water in the mitochondria\nC6H12O6 + 6O2 -> 6CO2 + 6H2O\nC57H110O6 + (81 1/2) O2 -> 57CO2 + 55H2O\nand some of the energy is used to convert ADP into ATP:\n\nThe rest of the chemical energy of O2 and the carbohydrate or fat are converted into heat: the ATP is used as a sort of \"energy currency\", and some of the chemical energy it contains is used for other metabolism when ATP reacts with OH groups and eventually splits into ADP and phosphate (at each stage of a metabolic pathway, some chemical energy is converted into heat). Only a tiny fraction of the original chemical energy is used for work:\ngain in kinetic energy of a sprinter during a 100\u00a0m race: 4\u00a0kJ\ngain in gravitational potential energy of a 150\u00a0kg weight lifted through 2\u00a0metres: 3\u00a0kJ\nDaily food intake of a normal adult: 6\u20138\u00a0MJ\n\nIt would appear that living organisms are remarkably inefficient (in the physical sense) in their use of the energy they receive (chemical or radiant energy); most machines manage higher efficiencies. In growing organisms the energy that is converted to heat serves a vital purpose, as it allows the organism tissue to be highly ordered with regard to the molecules it is built from. The second law of thermodynamics states that energy (and matter) tends to become more evenly spread out across the universe: to concentrate energy (or matter) in one specific place, it is necessary to spread out a greater amount of energy (as heat) across the remainder of the universe (\"the surroundings\"). Simpler organisms can achieve higher energy efficiencies than more complex ones, but the complex organisms can occupy ecological niches that are not available to their simpler brethren. The conversion of a portion of the chemical energy to heat at each step in a metabolic pathway is the physical reason behind the pyramid of biomass observed in ecology. As an example, to take just the first step in the food chain: of the estimated 124.7\u00a0Pg/a of carbon that is fixed by photosynthesis, 64.3\u00a0Pg/a (52%) are used for the metabolism of green plants, i.e. reconverted into carbon dioxide and heat.\n\nEarth sciences\nIn geology, continental drift, mountain ranges, volcanoes, and earthquakes are phenomena that can be explained in terms of energy transformations in the Earth's interior, while meteorological phenomena like wind, rain, hail, snow, lightning, tornadoes and hurricanes are all a result of energy transformations in our atmosphere brought about by solar energy.\n\nSunlight is the main input to Earth's energy budget which accounts for its temperature and climate stability.  Sunlight may be stored as gravitational potential energy after it strikes the Earth, as (for example when) water evaporates from oceans and is deposited upon mountains (where, after being released at a hydroelectric dam, it can be used to drive turbines or generators to produce electricity). Sunlight also drives most weather phenomena, save a few exceptions, like those generated by volcanic events for example. An example of a solar-mediated weather event is a hurricane, which occurs when large unstable areas of warm ocean, heated over months, suddenly give up some of their thermal energy to power a few days of violent air movement.\n\nIn a slower process, radioactive decay of atoms in the core of the Earth releases heat. This thermal energy drives plate tectonics and may lift mountains, via orogenesis. This slow lifting represents a kind of gravitational potential energy storage of the thermal energy, which may later be transformed into active kinetic energy during landslides, after a triggering event. Earthquakes also release stored elastic potential energy in rocks, a store that has been produced ultimately from the same radioactive heat sources. Thus, according to present understanding, familiar events such as landslides and earthquakes release energy that has been stored as potential energy in the Earth's gravitational field or elastic strain (mechanical potential energy) in rocks. Prior to this, they represent release of energy that has been stored in heavy atoms since the collapse of long-destroyed supernova stars (which created these atoms).\n\nCosmology\nIn cosmology and astronomy the phenomena of stars, nova, supernova, quasars and gamma-ray bursts are the universe's highest-output energy transformations of matter. All stellar phenomena (including solar activity) are driven by various kinds of energy transformations. Energy in such transformations is either from gravitational collapse of matter (usually molecular hydrogen) into various classes of astronomical objects (stars, black holes, etc.), or from nuclear fusion (of lighter elements, primarily hydrogen). The nuclear fusion of hydrogen in the Sun also releases another store of potential energy which was created at the time of the Big Bang. At that time, according to theory, space expanded and the universe cooled too rapidly for hydrogen to completely fuse into heavier elements. This meant that hydrogen represents a store of potential energy that can be released by fusion. Such a fusion process is triggered by heat and pressure generated from gravitational collapse of hydrogen clouds when they produce stars, and some of the fusion energy is then transformed into sunlight.\n\nQuantum mechanics\n\nIn quantum mechanics, energy is defined in terms of the energy operator\n(Hamiltonian) as a time derivative of the wave function. The Schr\u00f6dinger equation equates the energy operator to the full energy of a particle or a system. Its results can be considered as a definition of measurement of energy in quantum mechanics. The Schr\u00f6dinger equation describes the space- and time-dependence of a slowly changing (non-relativistic) wave function of quantum systems. The solution of this equation for a bound system is discrete (a set of permitted states, each characterized by an energy level) which results in the concept of quanta. In the solution of the Schr\u00f6dinger equation for any oscillator (vibrator) and for electromagnetic waves in a vacuum, the resulting energy states are related to the frequency by Planck's relation:  (where  is Planck's constant and  the frequency). In the case of an electromagnetic wave these energy states are called quanta of light or photons.\n\nRelativity\nWhen calculating kinetic energy (work to accelerate a massive body from zero speed to some finite speed) relativistically \u2013 using Lorentz transformations instead of Newtonian mechanics \u2013 Einstein discovered an unexpected by-product of these calculations to be an energy term which does not vanish at zero speed. He called it rest energy: energy which every massive body must possess even when being at rest. The amount of energy is directly proportional to the mass of the body:\n\nwhere\nm0 is the rest mass of the body,\nc is the speed of light in vacuum,\n is the rest energy.\n\nFor example, consider electron\u2013positron annihilation, in which the rest energy of these two individual particles (equivalent to their rest mass) is converted to the radiant energy of the photons produced in the process. In this system the matter and antimatter (electrons and positrons) are destroyed and changed to non-matter (the photons). However, the total mass and total energy do not change during this interaction. The photons each have no rest mass but nonetheless have radiant energy which exhibits the same inertia as did the two original particles.  This is a reversible process \u2013 the inverse process is called pair creation \u2013 in which the rest mass of particles is created from the radiant energy of two (or more) annihilating photons.\n\nIn general relativity, the stress\u2013energy tensor serves as the source term for the gravitational field, in rough analogy to the way mass serves as the source term in the non-relativistic Newtonian approximation.\n\nEnergy and mass are manifestations of one and the same underlying physical property of a system.  This property is responsible for the inertia and strength of gravitational interaction of the system (\"mass manifestations\"), and is also responsible for the potential ability of the system to perform work or heating (\"energy manifestations\"), subject to the limitations of other physical laws.\n\nIn classical physics, energy is a scalar quantity, the canonical conjugate to time. In special relativity energy is also a scalar (although not a Lorentz scalar but a time component of the energy\u2013momentum 4-vector). In other words, energy is invariant with respect to rotations of space, but not invariant with respect to rotations of spacetime (= boosts).\n\nTransformation\n\nEnergy may be transformed between different forms at various efficiencies. Items that transform between these forms are called transducers. Examples of transducers include a battery (from chemical energy to electric energy), a dam (from gravitational potential energy to kinetic energy of moving water (and the blades of a turbine) and ultimately to electric energy through an electric generator), and a heat engine (from heat to work).\n\nExamples of energy transformation include generating electric energy from heat energy via a steam turbine, or lifting an object against gravity using electrical energy driving a crane motor. Lifting against gravity performs mechanical work on the object and stores gravitational potential energy in the object. If the object falls to the ground, gravity does mechanical work on the object which transforms the potential energy in the gravitational field to the kinetic energy released as heat on impact with the ground. Our Sun transforms nuclear potential energy to other forms of energy; its total mass does not decrease due to that itself (since it still contains the same total energy even in different forms) but its mass does decrease when the energy escapes out to its surroundings, largely as radiant energy.\n\nThere are strict limits to how efficiently heat can be converted into work in a cyclic process, e.g. in a heat engine, as described by Carnot's theorem and the second law of thermodynamics. However, some energy transformations can be quite efficient. The direction of transformations in energy (what kind of energy is transformed to what other kind) is often determined by entropy (equal energy spread among all available degrees of freedom) considerations. In practice all energy transformations are permitted on a small scale, but certain larger transformations are not permitted because it is statistically unlikely that energy or matter will randomly move into more concentrated forms or smaller spaces.\n\nEnergy transformations in the universe over time are characterized by various kinds of potential energy, that has been available since the Big Bang, being \"released\" (transformed to more active types of energy such as kinetic or radiant energy) when a triggering mechanism is available. Familiar examples of such processes include nucleosynthesis, a process ultimately using the gravitational potential energy released from the gravitational collapse of supernovae to \"store\" energy in the creation of heavy isotopes (such as uranium and thorium), and nuclear decay, a process in which energy is released that was originally stored in these heavy elements, before they were incorporated into the solar system and the Earth. This energy is triggered and released in nuclear fission bombs or in civil nuclear power generation. Similarly, in the case of a chemical explosion, chemical potential energy is transformed to kinetic and thermal energy in a very short time.\n\nYet another example is that of a pendulum. At its highest points the kinetic energy is zero and the gravitational potential energy is at its maximum. At its lowest point the kinetic energy is at its maximum and is equal to the decrease in potential energy. If one (unrealistically) assumes that there is no friction or other losses, the conversion of energy between these processes would be perfect, and the pendulum would continue swinging forever.\n\nEnergy is also transferred from potential energy () to kinetic energy () and then back to potential energy constantly. This is referred to as conservation of energy. In this isolated system, energy cannot be created or destroyed; therefore, the initial energy and the final energy will be equal to each other. This can be demonstrated by the following:\n\nThe equation can then be simplified further since  (mass times acceleration due to gravity times the height) and  (half\u00a0mass times velocity squared). Then the total amount of energy can be found by adding .\n\nConservation of energy and mass in transformation\nEnergy gives rise to weight when it is trapped in a system with zero momentum, where it can be weighed. It is also equivalent to mass, and this mass is always associated with it. Mass is also equivalent to a certain amount of energy, and likewise always appears associated with it, as described in mass-energy equivalence. The formula E\u00a0=\u00a0mc\u00b2, derived by Albert Einstein (1905) quantifies the relationship between relativistic mass and energy within the concept of special relativity. In different theoretical frameworks, similar formulas were derived by J.J. Thomson (1881), Henri Poincar\u00e9 (1900), Friedrich Hasen\u00f6hrl (1904) and others (see Mass-energy equivalence#History for further information).\n\nPart of the rest energy (equivalent to rest mass) of matter may be converted to other forms of energy (still exhibiting mass), but neither energy nor mass can be destroyed; rather, both remain constant during any process. However, since  is extremely large relative to ordinary human scales, the conversion of an everyday amount of rest mass (for example, 1\u00a0kg) from rest energy to other forms of energy (such as kinetic energy, thermal energy, or the radiant energy carried by light and other radiation) can liberate tremendous amounts of energy (~ joules = 21 megatons of TNT), as can be seen in nuclear reactors and nuclear weapons. Conversely, the mass equivalent of an everyday amount energy is minuscule, which is why a loss of energy (loss of mass) from most systems is difficult to measure on a weighing scale, unless the energy loss is very large. Examples of large transformations between rest energy (of matter) and other forms of energy (e.g., kinetic energy into particles with rest mass) are found in nuclear physics and particle physics. Often, however, the complete conversion of matter (such as atoms) to non-matter (such as photons) is forbidden by conservation laws.\n\nReversible and non-reversible transformations\nThermodynamics divides energy transformation into two kinds: reversible processes and irreversible processes. An irreversible process is one in which energy is dissipated (spread) into empty energy states available in a volume, from which it cannot be recovered into more concentrated forms (fewer quantum states), without degradation of even more energy. A reversible process is one in which this sort of dissipation does not happen. For example, conversion of energy from one type of potential field to another is reversible, as in the pendulum system described above. In processes where heat is generated, quantum states of lower energy, present as possible excitations in fields between atoms, act as a reservoir for part of the energy, from which it cannot be recovered, in order to be converted with 100% efficiency into other forms of energy. In this case, the energy must partly stay as thermal energy and cannot be completely recovered as usable energy, except at the price of an increase in some other kind of heat-like increase in disorder in quantum states, in the universe (such as an expansion of matter, or a randomization in a crystal).\n\nAs the universe evolves with time, more and more of its energy becomes trapped in irreversible states (i.e., as heat or as other kinds of increases in disorder). This has led to the hypothesis of the inevitable thermodynamic heat death of the universe. In this heat death the energy of the universe does not change, but the fraction of energy which is available to do work through a heat engine, or be transformed to other usable forms of energy (through the use of generators attached to heat engines), continues to decrease.\n\nConservation of energy\n\nThe fact that energy can be neither created nor destroyed is called the law of conservation of energy.  In the form of the first law of thermodynamics, this states that a closed system's energy is constant unless energy is transferred in or out as work or heat, and that no energy is lost in transfer. The total inflow of energy into a system must equal the total outflow of energy from the system, plus the change in the energy contained within the system. Whenever one measures (or calculates) the total energy of a system of particles whose interactions do not depend explicitly on time, it is found that the total energy of the system always remains constant.\n\nWhile heat can always be fully converted into work in a reversible isothermal expansion of an ideal gas, for cyclic processes of practical interest in heat engines the second law of thermodynamics states that the system doing work always loses some energy as waste heat. This creates a limit to the amount of heat energy that can do work in a cyclic process, a limit called the available energy. Mechanical and other forms of energy can be transformed in the other direction into thermal energy without such limitations. The total energy of a system can be calculated by adding up all forms of energy in the system.\n\nRichard Feynman said during a 1961 lecture:\n\nMost kinds of energy (with gravitational energy being a notable exception) are subject to strict local conservation laws as well. In this case, energy can only be exchanged between adjacent regions of space, and all observers agree as to the volumetric density of energy in any given space. There is also a global law of conservation of energy, stating that the total energy of the universe cannot change; this is a corollary of the local law, but not vice versa.\n\nThis law is a fundamental principle of physics. As shown rigorously by Noether's theorem, the conservation of energy is a mathematical consequence of translational symmetry of time, a property of most phenomena below the cosmic scale that makes them independent of their locations on the time coordinate. Put differently, yesterday, today, and tomorrow are physically indistinguishable. This is because energy is the quantity which is canonical conjugate to time. This mathematical entanglement of energy and time also results in the uncertainty principle \u2013 it is impossible to define the exact amount of energy during any definite time interval (though this is practically significant only for very short time intervals). The uncertainty principle should not be confused with energy conservation \u2013 rather it provides mathematical limits to which energy can in principle be defined and measured.\n\nEach of the basic forces of nature is associated with a different type of potential energy, and all types of potential energy (like all other types of energy) appear as system mass, whenever present. For example, a compressed spring will be slightly more massive than before it was compressed. Likewise, whenever energy is transferred between systems by any mechanism, an associated mass is transferred with it.\n\nIn quantum mechanics energy is expressed using the Hamiltonian operator. On any time scales, the uncertainty in the energy is by\n\n \n\nwhich is similar in form to the Heisenberg Uncertainty Principle (but not really mathematically equivalent thereto, since H and t are not dynamically conjugate variables, neither in classical nor in quantum mechanics).\n\nIn particle physics, this inequality permits a qualitative understanding of virtual particles, which carry momentum. The exchange of virtual particles with real particles is responsible for the creation of all known fundamental forces (more accurately known as fundamental interactions). Virtual photons are also responsible for the electrostatic interaction between electric charges (which results in Coulomb's law), for spontaneous radiative decay of excited atomic and nuclear states, for the Casimir force, for the Van der Waals force and some other observable phenomena.\n\nEnergy transfer\n\nClosed systems\nEnergy transfer can be considered for the special case of systems which are closed to transfers of matter. The portion of the energy which is transferred by conservative forces over a distance is measured as the work the source system does on the receiving system. The portion of the energy which does not do work during the transfer is called heat. Energy can be transferred between systems in a variety of ways. Examples include the transmission of electromagnetic energy via photons, physical collisions which transfer kinetic energy, and the conductive transfer of thermal energy.\n\nEnergy is strictly conserved and is also locally conserved wherever it can be defined. In thermodynamics, for closed systems, the process of energy transfer is described by the first law:\n\nwhere  is the amount of energy transferred, \u00a0 represents the work done on or by the system, and  represents the heat flow into or out of the system. As a simplification, the heat term, , can sometimes be ignored, especially for fast processes involving gases, which are poor conductors of heat, or when the thermal efficiency of the transfer is high. For such adiabatic processes,\n\nThis simplified equation is the one used to define the joule, for example.\n\nOpen systems\nBeyond the constraints of closed systems, open systems can gain or lose energy in association with matter transfer (this process is illustrated by injection of an air-fuel mixture into a car engine, a system which gains in energy thereby, without addition of either work or heat). Denoting this energy by , one may write\n\nThermodynamics\n\nInternal energy\nInternal energy is the sum of all microscopic forms of energy of a system. It is the energy needed to create the system. It is related to the potential energy, e.g., molecular structure, crystal structure, and other geometric aspects, as well as the motion of the particles, in form of kinetic energy. Thermodynamics is chiefly concerned with changes in internal energy and not its absolute value, which is impossible to determine with thermodynamics alone.\n\nFirst law of thermodynamics\nThe first law of thermodynamics asserts that the total energy of a system and its surroundings (but not necessarily thermodynamic free energy) is always conserved and that heat flow is a form of energy transfer. For homogeneous systems, with a well-defined temperature and pressure, a commonly used corollary of the first law is that, for a system subject only to pressure forces and heat transfer (e.g., a cylinder-full of gas) without chemical changes, the differential change in the internal energy of the system (with a gain in energy signified by a positive quantity) is given as\n\n,\n\nwhere the first term on the right is the heat transferred into the system, expressed in terms of temperature T and entropy S (in which entropy increases and its change dS is positive when heat is added to the system), and the last term on the right hand side is identified as work done on the system, where pressure is P and volume V (the negative sign results since compression of the system requires work to be done on it and so the volume change, dV, is negative when work is done on the system).\n\nThis equation is highly specific, ignoring all chemical, electrical, nuclear, and gravitational forces, effects such as advection of any form of energy other than heat and PV-work. The general formulation of the first law (i.e., conservation of energy) is valid even in situations in which the system is not homogeneous. For these cases the change in internal energy of a closed system is expressed in a general form by\n\nwhere  is the heat supplied to the system and  is the work applied to the system.\n\nEquipartition of energy\nThe energy of a mechanical harmonic oscillator (a mass on a spring) is alternately kinetic and potential energy. At two points in the oscillation cycle it is entirely kinetic, and at two points it is entirely potential. Over a whole cycle, or over many cycles, average energy is equally split between kinetic and potential. This is an example of the equipartition principle: the total energy of a system with many degrees of freedom is equally split among all available degrees of freedom, on average.\n\nThis principle is vitally important to understanding the behavior of a quantity closely related to energy, called entropy. Entropy is a measure of evenness of a distribution of energy between parts of a system. When an isolated system is given more degrees of freedom (i.e., given new available energy states that are the same as existing states), then total energy spreads over all available degrees equally without distinction between \"new\" and \"old\" degrees. This mathematical result is part of the second law of thermodynamics. The second law of thermodynamics is simple only for systems which are near or in a physical equilibrium state. For non-equilibrium systems, the laws governing the systems' behavior are still debatable. One of the guiding principles for these systems is the principle of maximum entropy production. It states that nonequilibrium systems behave in such a way as to maximize their entropy production.\n\nSee also\n\n Combustion\n Index of energy articles\n Index of wave articles\n Orders of magnitude (energy)\n Power station\n Transfer energy\n\nNotes\n\nReferences\n\nFurther reading\n\n \n The Biosphere (A Scientific American Book), San Francisco, W.H. Freeman and Co., 1970, . This book, originally a 1970 Scientific American issue, covers virtually every major concern and concept since debated regarding materials and energy resources, population trends, and environmental degradation.\n \n Energy and Power (A Scientific American Book), San Francisco, W.H. Freeman and Co., 1971, .\n \n Santos, Gildo M. \"Energy in Brazil: a historical overview,\" The Journal of Energy History (2018), online\n\nJournals\n  The Journal of Energy History / Revue d'histoire de l'\u00e9nergie (JEHRHE), 2018\u2013\n\nExternal links\n\n \n Differences between Heat and Thermal energy  \u2013 BioCab\n\n \nMain topic articles\nNature\nUniverse\nScalar physical quantities",
  "Food": "Food is any substance consumed to provide nutritional support for an organism. Food is usually of plant, animal, or fungal origin, and contains essential nutrients, such as carbohydrates, fats, proteins, vitamins, or minerals. The substance is ingested by an organism and assimilated by the organism's cells to provide energy, maintain life, or stimulate growth. Different species of animals have different feeding behaviours that satisfy the needs of their unique metabolisms, often evolved to fill a specific ecological niche within specific geographical contexts. \n\nOmnivorous humans are highly adaptable and have adapted to obtain food in many different ecosystems. Historically, humans secured food through two main methods: hunting and gathering and agriculture. As agricultural technologies increased, humans settled into agriculture lifestyles with diets shaped by the agriculture opportunities in their geography. Geographic and cultural differences has led to creation of numerous cuisines and culinary arts, including a wide array of ingredients, herbs, spices, techniques, and dishes. As cultures have mixed through forces like international trade and globalization, ingredients have become more widely available beyond their geographic and cultural origins, creating a cosmopolitan exchange of different food traditions and practices.\n\nToday, the majority of the food energy required by the ever-increasing population of the world is supplied by the industrial food industry, which produces food with intensive agriculture and distributes it through complex food processing and food distribution systems. This system of conventional agriculture relies heavily on fossil fuels, which means that the food and agricultural system is one of the major contributors to climate change, accountable for as much as 37% of total greenhouse gas emissions. Addressing the carbon intensity of the food system and food waste are important mitigation measures in the global response to climate change.\n\nThe food system has significant impacts on a wide range of other social and political issues including: sustainability, biological diversity, economics, population growth, water supply, and access to food. The right to food is a human right derived from the International Covenant on Economic, Social and Cultural Rights (ICESCR), recognizing the \"right to an adequate standard of living, including adequate food\", as well as the \"fundamental right to be free from hunger\". Because of these fundamental rights, food security is often a priority international policy activity; for example Sustainable Development Goal 2 \"Zero hunger\" is meant to eliminate hunger by 2030. Food safety and food security are monitored by international agencies like the International Association for Food Protection, World Resources Institute, World Food Programme, Food and Agriculture Organization, and International Food Information Council, and are often subject to national regulation by institutions, like the Food and Drug Administration in the United States.\n\nDefinition and classification \n\nFood is any substance consumed to provide nutritional support for an organism. It can be raw, processed or formulated and is consumed orally by animals for growth, health or pleasure. Food is mainly composed of water, lipids, proteins and carbohydrates. Minerals (e.g salts) and organic substances (e.g vitamins) can also be found in food. Plants, algae and some microorganisms use photosynthesis to make their own food molecules. Water is found in many foods and has been defined as a food by itself. Food provides energy and nutrition to the organism. Water and fiber have low energy densities, or calories, while fat is the most energy dense component.  \n\nHuman food can be classified in various ways, either by related content or by how the food is processed. The number and composition of food groups can vary. Most systems include four basic groups that describe their origin and relative nutritional function: Vegetables and Fruit, Cereals and Bread, Dairy, and Meat. Studies that look into diet quality often group food into whole grains/cereals, refined grains/cereals, vegetables, fruits, nuts, legumes, eggs, dairy products, fish, red meat, processed meat, and sugar-sweetened beverages. The Food and Agriculture Organization and World Health Organization use a system with nineteen food classifications: cereals, roots, pulses and nuts, milk, eggs, fish and shellfish, meat, insects, vegetables, fruits, fats and oils, sweets and sugars, spices and condiments, beverages, foods for nutritional uses, food additives, composite dishes and savoury snacks.\n\nFood sources \nIn a given ecosystem, food forms a web of interlocking chains with primary producers at the bottom and apex predators at the top. Other aspects of the web include detrovores (that eat detritis) and decomposers (that break down dead organisms).  Primary producers include algae, plants, bacteria and protists that acquire their energy from sunlight. Primary consumers are the herbivores that consume the pants and secondary consumers are the carnivores that consume those herbivores. Some organisms, including most mammals and birds, diets consist of both animals and plants and they are considered omnivores. The chain ends in the apex predator, the animal that has no known predators in its ecosystem. Humans are often considered apex predators.\n\nHumans are omnivores finding sustenance in vegetables, fruits, cooked meat, milk, eggs, mushrooms and seaweed. Cereal grain is a staple food that provides more food energy worldwide than any other type of crop. Corn (maize), wheat, and rice  account for 87% of all grain production worldwide. Most of the grain that is produced worldwide is fed to livestock. We also use fungi and ambient bacteria in the preparation of fermented and pickled foods like leavened bread, alcoholic drinks, cheese, pickles, kombucha, and yogurt. Another example is blue-green algae such as Spirulina. Inorganic substances such as salt, baking soda and cream of tartar are used to preserve or chemically alter an ingredient.\n\nPlants\n\nMany plants and plant parts are eaten as food and around 2,000 plant species are cultivated for food. Many of these plant species have several distinct cultivars.\n\nSeeds of plants are a good source of food for animals, including humans, because they contain the nutrients necessary for the plant's initial growth, including many healthful fats, such as omega fats. In fact, the majority of food consumed by human beings are seed-based foods. Edible seeds include cereals (corn, wheat, rice, et cetera), legumes (beans, peas, lentils, et cetera), and nuts. Oilseeds are often pressed to produce rich oils - sunflower, flaxseed, rapeseed (including canola oil), sesame, etc.\n\nSeeds are typically high in unsaturated fats and, in moderation, are considered a health food. However, not all seeds are edible for humans. Large seeds, such as those from a lemon, pose a choking hazard, while seeds from cherries and apples  contain cyanide which could be poisonous only if consumed in large volumes. Birds are also well-known for feeding on seeds (for more information, see birdseed). \n\nFruits are the ripened ovaries of plants, including the seeds within. Many plants and animals have coevolved such that the fruits of the former are an attractive food source to the latter, because animals that eat the fruits may excrete the seeds some distance away. Animals that eat fruits are known as frugivores. One such coevolutionary relationship involves primates, who are primarily frugivorous. Fruits, therefore, make up a significant part of the diets of most cultures. Some botanical fruits, such as tomatoes, pumpkins, and eggplants, are eaten as vegetables. (For more information, see list of fruits.)\n\nVegetables are a second type of plant matter that is commonly eaten as food. These include root vegetables (potatoes and carrots), bulbs (onion family), leaf vegetables (spinach and lettuce), stem vegetables (bamboo shoots and asparagus), and inflorescence vegetables (globe artichokes and broccoli and other vegetables such as cabbage or cauliflower).\n\nAnimals\n\nAnimals are used as food either directly or indirectly by the products they produce. Meat is an example of a direct product taken from an animal, which comes from muscle systems or from organs (offal).\n\nFood products produced by animals include milk produced by mammary glands, which in many cultures is drunk or processed into dairy products (cheese, butter, etc.). In addition, birds and other animals lay eggs, which are often eaten, and bees produce honey, a reduced nectar from flowers, which is a popular sweetener in many cultures. Some cultures consume blood, sometimes in the form of blood sausage, as a thickener for sauces, or in a cured, salted form for times of food scarcity, and others use blood in stews such as jugged hare.\n\nSome cultures and people do not consume meat or animal food products for cultural, dietary, health, ethical, or ideological reasons. Vegetarians choose to forgo food from animal sources to varying degrees. Vegans do not consume any foods that are or contain ingredients from an animal source.\n\nClassifications and types of food \n\n Broad classifications are covered below. For regional types, see Cuisine.\n\nAdulterated food \n\nAdulteration is a legal term meaning that a food product fails to meet the legal standards. One form of adulteration is an addition of another substance to a food item in order to increase the quantity of the food item in raw form or prepared form, which may result in the loss of actual quality of food item. These substances may be either available food items or non-food items. Among meat and meat products some of the items used to adulterate are water or ice, carcasses, or carcasses of animals other than the animal meant to be consumed.\n\nCamping food \n\nCamping food includes ingredients used to prepare food suitable for backcountry camping and backpacking. The foods differ substantially from the ingredients found in a typical home kitchen. The primary differences relate to campers' and backpackers' special needs for foods that have appropriate cooking time, perishability, weight, and nutritional content.\n\nTo address these needs, camping food is often made up of either freeze-dried, precooked or dehydrated ingredients. Many campers use a combination of these foods.\n\nFreeze-drying requires the use of heavy machinery and is not something that most campers are able to do on their own. Freeze-dried ingredients are often considered superior to dehydrated ingredients however because they rehydrate at camp faster and retain more flavor than their dehydrated counterparts. Freeze-dried ingredients take so little time to rehydrate that they can often be eaten without cooking them first and have a texture similar to a crunchy chip.\n\nDehydration can reduce the weight of the food by sixty to ninety percent by removing water through evaporation. Some foods dehydrate well, such as onions, peppers, and tomatoes. Dehydration often produces a more compact, albeit slightly heavier, result than freeze-drying.\n\nSurplus precooked military Meals, Meals, Ready-to-Eat (MREs) are sometimes used by campers. These meals contain pre-cooked foods in retort pouches. A retort pouch is a plastic and metal foil laminate pouch that is used as an alternative to traditional industrial canning methods.\n\nDiet food \n\nDiet food or dietetic food refers to any food or beverage whose recipe is altered to reduce fat, carbohydrates, abhor/adhore sugar in order to make it part of a weight loss program or diet. Such foods are usually intended to assist in weight loss or a change in body type, although bodybuilding supplements are designed to aid in gaining weight or muscle.\n\nThe process of making a diet version of a food usually requires finding an acceptable low-food-energy substitute for some high-food-energy ingredient. This can be as simple as replacing some or all of the food's sugar with a sugar substitute as is common with diet soft drinks such as Coca-Cola (for example Diet Coke). In some snacks, the food may be baked instead of fried thus reducing the food energy. In other cases, low-fat ingredients may be used as replacements.\n\nIn whole grain foods, the higher fiber content effectively displaces some of the starch components of the flour. Since certain fibers have no food energy, this results in a modest energy reduction. Another technique relies on the intentional addition of other reduced-food-energy ingredients, such as resistant starch or dietary fiber, to replace part of the flour and achieve a more significant energy reduction.\n\nFinger food \n\nFinger food is food meant to be eaten directly using the hands, in contrast to food eaten with a knife and fork, spoon, chopsticks, or other utensils.  In some cultures, food is almost always eaten with the hands; for example, Ethiopian cuisine is eaten by rolling various dishes up in injera bread.  Foods considered street foods are frequently, though not exclusively, finger foods.\n\nIn the western world, finger foods are often either appetizers (hors d'\u0153uvres) or entree/main course items. Examples of these are miniature meat pies, sausage rolls, sausages on sticks, cheese and olives on sticks, chicken drumsticks or wings, spring rolls, miniature quiches, samosas, sandwiches, Merenda or other such based foods, such as pitas or items in buns, bhajjis, potato wedges, vol au vents, several other such small items and risotto balls (arancini). Other well-known foods that are generally eaten with the hands include hamburgers, pizza, chips, hot dogs, fruit and bread.\n\nIn Greater China, foods like pancakes or flatbreads (bing \u997c) and street foods such as chuan (\u4e32, also pronounced chuan) are often eaten with the hands.\n\nFresh food \n\nFresh food is food which has not been preserved and has not spoiled yet. For vegetables and fruits, this means that they have been recently harvested and treated properly postharvest; for meat, it has recently been slaughtered and butchered; for fish, it has been recently caught or harvested and kept cold.\n\nDairy products are fresh and will spoil quickly. Thus, fresh cheese is cheese which has not been dried or salted for aging. Soured cream may be considered \"fresh\" (cr\u00e8me fra\u00eeche).\n\nFresh food has not been dried, smoked, salted, frozen, canned, pickled, or otherwise preserved.\n\nFrozen food \n\nFreezing food preserves it from the time it is prepared to the time it is eaten. Since early times, farmers, fishermen, and trappers have preserved grains and produce in unheated buildings during the winter season. Freezing food slows down decomposition by turning residual moisture into ice, inhibiting the growth of most bacterial species. In the food commodity industry, there are two processes: mechanical and cryogenic (or flash freezing). The kinetics of the freezing is important to preserve food quality and texture. Quicker freezing generates smaller ice crystals and maintains cellular structure. Cryogenic freezing is the quickest freezing technology available utilizing the extremely low temperature of liquid nitrogen  .\n\nPreserving food in domestic kitchens during modern times is achieved using household freezers. Accepted advice to householders was to freeze food on the day of purchase. An initiative by a supermarket group in 2012 (backed by the UK's Waste & Resources Action Programme) promotes the freezing of food \"as soon as possible up to the product's 'use by' date\". The Food Standards Agency was reported as supporting the change, providing the food had been stored correctly up to that time.\n\nFunctional food \n\nA functional food is a food given an additional function (often one related to health-promotion or disease prevention) by adding new ingredients or more of existing ingredients. The term may also apply to traits purposely bred into existing edible plants, such as purple or gold potatoes having enriched anthocyanin or carotenoid contents, respectively. Functional foods may be \"designed to have physiological benefits and/or reduce the risk of chronic disease beyond basic nutritional functions, and may be similar in appearance to conventional food and consumed as part of a regular diet\".\n\nThe term was first used in Japan in the 1980s where there is a government approval process for functional foods called Foods for Specified Health Use (FOSHU).\n\nHealth food \n\nHealth food is food marketed to provide human health effects beyond a normal healthy diet required for human nutrition. Foods marketed as health foods may be part of one or more categories, such as natural foods, organic foods, whole foods,  vegetarian foods or dietary supplements. These products may be sold in health food stores or in the health food or organic sections of grocery stores.\n\nHealthy food \n\nA healthy diet is a diet that helps to maintain or improve overall health. A healthy diet provides the body with essential nutrition: fluid, macronutrients, micronutrients, and adequate calories.\n\nFor people who are healthy, a healthy diet is not complicated and contains mostly fruits, vegetables, and whole grains, and includes little to no processed food and sweetened beverages.  The requirements for a healthy diet can be met from a variety of plant-based and animal-based foods, although a non-animal source of vitamin B12 is needed for those following a vegan diet.  Various nutrition guides are published by medical and governmental institutions to educate individuals on what they should be eating to be healthy. Nutrition facts labels are also mandatory in some countries to allow consumers to choose between foods based on the components relevant to health.\n\nA healthy lifestyle includes getting exercise every day along with eating a healthy diet. A healthy lifestyle may lower disease risks, such as obesity, heart disease, type 2 diabetes, hypertension and cancer.\n\nThere are specialized healthy diets, called medical nutrition therapy, for people with various diseases or conditions.  There are also prescientific ideas about such specialized diets, as in dietary therapy in traditional Chinese medicine.\n\nThe World Health Organization (WHO) makes the following 5 recommendations with respect to both populations and individuals:\n Maintain a healthy weight by eating roughly the same number of calories that your body is using.\n Limit intake of fats. Not more than 30% of the total calories should come from fats. Prefer unsaturated fats to saturated fats. Avoid trans fats.\n Eat at least 400 grams of fruits and vegetables per day (potatoes, sweet potatoes, cassava and other starchy roots do not count). A healthy diet also contains legumes (e.g. lentils, beans), whole grains and nuts.\n Limit the intake of simple sugars to less than 10% of calorie (below 5% of calories or 25 grams may be even better)\n Limit salt / sodium from all sources and ensure that salt is iodized. Less than 5 grams of salt per day can reduce the risk of cardiovascular disease.\n\nLive food \n\nLive food is living food for carnivorous or omnivorous animals kept in captivity; in other words, small animals such as insects or mice fed to larger carnivorous or omnivorous species kept either in a zoo or as a pet.\n\nLive food is commonly used as feed for a variety of species of exotic pets and zoo animals, ranging from alligators to various snakes, frogs and lizards, but also including other, non-reptile, non-amphibian carnivores and omnivores (for instance, skunks, which are omnivorous mammals, can technically be fed a limited amount of live food, though this is not a common practice). Common live food ranges from crickets (used as an inexpensive form of feed for carnivorous and omnivorous reptiles such as bearded dragons and commonly available in pet stores for this reason), waxworms, mealworms and to a lesser extent cockroaches and locusts, to small birds and mammals such as mice or chickens.\n\nMedical food \n\nMedical foods are foods that are specially formulated and intended for the dietary management of a disease that has distinctive nutritional needs that cannot be met by normal diet alone. In the United States they were defined in the Food and Drug Administration's 1988 Orphan Drug Act Amendments and are subject to the general food and safety labeling requirements of the Federal Food, Drug, and Cosmetic Act. In Europe the European Food Safety Authority established definitions for \"foods for special medical purposes\" (FSMPs) in 2015.\n\nMedical foods, called \"food for special medical purposes\" in Europe, are distinct from the broader category of foods for special dietary use, from traditional foods that bear a health claim, and from dietary supplements. In order to be considered a medical food the product must, at a minimum:\n be a food for oral ingestion or tube feeding (nasogastric tube)\n be labeled for the dietary management of a specific medical disorder, disease or condition for which there are distinctive nutritional requirements, and\n be intended to be used under medical supervision.\n\nMedical foods can be classified into the following categories:\n Nutritionally complete formulas\n Nutritionally incomplete formulas\n Formulas for metabolic disorders\n Oral rehydration products\n\nNatural foods \n\nNatural foods and \"all-natural foods\" are widely used terms in food labeling and marketing with a variety of definitions, most of which are vague. The term is often assumed to imply foods that are not processed and whose ingredients are all natural products (in the chemist's sense of that term), thus conveying an appeal to nature. But the lack of standards in most jurisdictions means that the term assures nothing. In some countries, the term \"natural\" is defined and enforced. In others, such as the United States, it is not enforced.\n\n\u201cNatural foods\u201d are often assumed to be foods that are not processed, or do not contain any food additives, or do not contain particular additives such as hormones, antibiotics, sweeteners, food colors, or flavorings that were not originally in the food. In fact, many people (63%) when surveyed showed a preference for products labeled \"natural\" compared to the unmarked counterparts, based on the common belief (86% of polled consumers) that the term \"natural\" indicated that the food does not contain any artificial ingredients. The terms are variously used and misused on labels and in advertisements.\n\nThe international Food and Agriculture Organization\u2019s Codex Alimentarius does not recognize the term \u201cnatural\u201d but does have a standard for organic foods.\n\nNegative-calorie food \n\nA negative-calorie food is food that supposedly requires more food energy to be digested than the food provides. Its thermic effect or specific dynamic action\u00a0\u2013 the caloric \"cost\" of digesting the food\u00a0\u2013 would be greater than its food energy content. Despite its recurring popularity in dieting guides, there is no scientific evidence supporting the idea that any food is calorically negative. While some chilled beverages are calorically negative, the effect is minimal and drinking large amounts of water can be dangerous.\n\nOrganic food \n\nOrganic food is food produced by methods that comply with the standards of organic farming. Standards vary worldwide, but organic farming in general features practices that strive to cycle resources, promote ecological balance, and conserve biodiversity. Organizations regulating organic products may restrict the use of certain pesticides and fertilizers in farming. In general, organic foods are also usually not processed using irradiation, industrial solvents or synthetic food additives.\n\nCurrently, the European Union, the United States, Canada, Mexico, Japan, and many other countries require producers to obtain special certification in order to market food as organic within their borders. In the context of these regulations, organic food is produced in a way that complies with organic standards set by regional organizations, national governments, and international organizations. Although the produce of kitchen gardens may be organic, selling food with an organic label is regulated by governmental food safety authorities, such as the US Department of Agriculture (USDA) or European Commission (EC).\n\nFertilizing and the use of pesticides in conventional farming has caused, and is causing, enormous damage worldwide to local ecosystems, biodiversity, groundwater and drinking water supplies, and sometimes farmer health and fertility. These environmental, economic and health issues are intended to be minimized or avoided in organic farming. From a consumers perspective, there is not sufficient evidence in scientific and medical literature to support claims that organic food is safer or healthier to eat than conventionally grown food. While there may be some differences in the nutrient and antinutrient contents of organically- and conventionally-produced food, the variable nature of food production and handling makes it difficult to generalize results. Claims that organic food tastes better are generally not supported by tests.\n\nPeasant foods \n\nPeasant foods are dishes specific to a particular culture, made from accessible and inexpensive ingredients, and usually prepared and seasoned to make them more palatable. They often form a significant part of the diets of people who live in poverty, or have a lower income compared to the average for their society or country.\n\nPeasant foods have been described as being the diet of peasants, that is, tenant or poorer farmers and their farm workers, and by extension, of other cash-poor people. They may use ingredients, such as offal and less-tender cuts of meat, which are not as marketable as a cash crop. Characteristic recipes often consist of hearty one-dish meals, in which chunks of meat and various vegetables are eaten in a savory broth, with bread or other staple food. Sausages are also amenable to varied readily available ingredients, and they themselves tend to contain offal and grains.\n\nPeasant foods often involve skilled preparation by knowledgeable cooks using inventiveness and skills passed down from earlier generations. Such dishes are often prized as ethnic foods by other cultures and by descendants of the native culture who still desire these traditional dishes.\n\nPrison food \n\nPrison food is the term for meals served to prisoners while incarcerated in correctional institutions. While some prisons prepare their own food, many use staff from on-site catering companies. Many prisons today support the requirements of specific religions, as well as vegetarianism. It is said that prison food of many developed countries is adequate to maintain health and dieting.\n\nSeasonal food \n\n\"Seasonal\" here refers to the times of the year when the harvest or the flavor of a given type of food is at its peak. This is usually the time when the item is harvested, with some exceptions; an example being sweet potatoes which are best eaten quite a while after harvest. It also appeals to people who prefer a low carbon diet that reduces the greenhouse gas emissions resulting from food consumption (Food miles).\n\nShelf-stable food \n\nShelf-stable food (sometimes ambient food) is food of a type that can be safely stored at room temperature in a sealed container. This includes foods that would normally be stored refrigerated but which have been processed so that they can be safely stored at room or ambient temperature for a usefully long shelf life.\n\nVarious food preservation and packaging techniques are used to extend a food's shelf life.  Decreasing the amount of available water in a product, increasing its acidity, or irradiating or otherwise sterilizing the food and then sealing it in an air-tight container are all ways of depriving bacteria of suitable conditions in which to thrive. All of these approaches can all extend a food's shelf life without unacceptably changing its taste or texture.\n\nFor some foods, alternative ingredients can be used. Common oils and fats become rancid relatively quickly if not refrigerated; replacing them with hydrogenated oils delays the onset of rancidity, increasing shelf life. This is a common approach in industrial food production, but recent concerns about health hazards associated with trans fats have led to their strict control in several jurisdictions. Even where trans fats are not prohibited, in many places there are new labeling laws (or rules), which require information to be printed on packages, or to be published elsewhere, about the amount of trans fat contained in certain products.\n\nSpace food \n\nSpace food is a type of food product created and processed for consumption by astronauts in outer space. The food has specific requirements of providing balanced nutrition for individuals working in space while being easy and safe to store, prepare and consume in the machinery-filled weightless environments of crewed spacecraft.\n\nIn recent years, space food has been used by various nations engaging in space programs as a way to share and show off their cultural identity and facilitate intercultural communication. Although astronauts consume a wide variety of foods and beverages in space, the initial idea from The Man in Space Committee of the Space Science Board in 1963 was to supply astronauts with a formula diet that would supply all the needed vitamins and nutrients.\n\nTraditional food \n\nTraditional foods are foods and dishes that are passed through generations or which have been consumed many generations. Traditional foods and dishes are traditional in nature, and may have a historic precedent in a national dish, regional cuisine or local cuisine. Traditional foods and beverages may be produced as homemade, by restaurants and small manufacturers, and by large food processing plant facilities.\n\nSome traditional foods have geographical indications and traditional specialities in the European Union designations per European Union schemes of geographical indications and traditional specialties: Protected designation of origin (PDO), Protected geographical indication (PGI) and Traditional specialities guaranteed (TSG). These standards serve to promote and protect names of quality agricultural products and foodstuffs.\n\nThis article also includes information about traditional beverages.\n\nWhole food \n\nWhole foods are plant foods that are unprocessed and unrefined, or processed and refined as little as possible, before being consumed. Examples of whole foods include whole grains, tubers, legumes, fruits, vegetables.\n\nThere is some confusion over the usage of the term surrounding the inclusion of certain foods, in particular animal foods. The modern usage of the term whole foods diet is now widely synonymous with \"whole foods plant-based diet\" with animal products, oil and salt no longer constituting whole foods.\n\nThe earliest use of the term in the post-industrial age appears to be in 1946 in The Farmer, a quarterly magazine published and edited from his farm by F. Newman Turner, a writer and pioneering organic farmer. The magazine sponsored the establishment of the Producer-Consumer Whole Food Society Ltd, with Newman Turner as president and Derek Randal as vice-president. Whole food was defined as \"mature produce of field, orchard, or garden without subtraction, addition, or alteration grown from seed without chemical dressing, in fertile soil manured solely with animal and vegetable wastes, and composts therefrom, and ground, raw rock and without chemical manures, sprays, or insecticides,\" having intent to connect suppliers and the growing public demand for such food. Such diets are rich in whole and unrefined foods, like whole grains, dark green and yellow/orange-fleshed vegetables and fruits, legumes, nuts and seeds.\n\nTaste perception\n\nAnimals, specifically humans, have five different types of tastes: sweet, sour, salty, bitter, and umami. As animals have evolved, the tastes that provide the most energy (sugar and fats) are the most pleasant to eat while others, such as bitter, are not enjoyable. Water, while important for survival, has no taste. Fats, on the other hand, especially saturated fats, are thicker and rich and are thus considered more enjoyable to eat.\n\nSweet\n\nGenerally regarded as the most pleasant taste, sweetness is almost always caused by a type of simple sugar such as glucose or fructose, or disaccharides such as sucrose, a molecule combining glucose and fructose. Complex carbohydrates are long chains and thus do not have the sweet taste. Artificial sweeteners such as sucralose are used to mimic the sugar molecule, creating the sensation of sweet, without the calories. Other types of sugar include raw sugar, which is known for its amber color, as it is unprocessed. As sugar is vital for energy and survival, the taste of sugar is pleasant.\n\nThe stevia plant contains a compound known as steviol which, when extracted, has 300 times the sweetness of sugar while having minimal impact on blood sugar.\n\nSour\n\nSourness is caused by the taste of acids, such as vinegar in alcoholic beverages. Sour foods include citrus, specifically lemons, limes, and to a lesser degree oranges. Sour is evolutionarily significant as it is a sign for a food that may have gone rancid due to bacteria. Many foods, however, are slightly acidic, and help stimulate the taste buds and enhance flavor.\n\nSalty\n\nSaltiness is the taste of alkali metal ions such as sodium and potassium. It is found in almost every food in low to moderate proportions to enhance flavor, although to eat pure salt is regarded as highly unpleasant. There are many different types of salt, with each having a different degree of saltiness, including sea salt, fleur de sel, kosher salt, mined salt, and grey salt. Other than enhancing flavor, its significance is that the body needs and maintains a delicate electrolyte balance, which is the kidney's function. Salt may be iodized, meaning iodine has been added to it, a necessary nutrient that promotes thyroid function. Some canned foods, notably soups or packaged broths, tend to be high in salt as a means of preserving the food longer. Historically salt has long been used as a meat preservative as salt promotes water excretion. Similarly, dried foods also promote food safety.\n\nBitter\n\nBitterness is a sensation often considered unpleasant characterized by having a sharp, pungent taste. Unsweetened dark chocolate, caffeine, lemon rind, and some types of fruit are known to be bitter.\n\nUmami\n\nCuisine\n\nMany scholars claim that the rhetorical function of food is to represent the culture of a country, and that it can be used as a form of communication. According to Goode, Curtis and Theophano, food \"is the last aspect of an ethnic culture to be lost\".\n\nMany cultures have a recognizable cuisine, a specific set of cooking traditions using various spices or a combination of flavors unique to that culture, which evolves over time. Other differences include preferences (hot or cold, spicy, etc.) and practices, the study of which is known as gastronomy. Many cultures have diversified their foods by means of preparation, cooking methods, and manufacturing. This also includes a complex food trade which helps the cultures to economically survive by way of food, not just by consumption.\n\nSome popular types of ethnic foods include Italian, French, Japanese, Chinese, American, Cajun, Thai, African, Indian and Nepalese. Various cultures throughout the world study the dietary analysis of food habits. While evolutionarily speaking, as opposed to culturally, humans are omnivores, religion and social constructs such as morality, activism, or environmentalism will often affect which foods they will consume. Food is eaten and typically enjoyed through the sense of taste, the perception of flavor from eating and drinking. Certain tastes are more enjoyable than others, for evolutionary purposes.\n\nPresentation\n\nAesthetically pleasing and eye-appealing food presentations can encourage people to consume foods. A common saying is that people \"eat with their eyes\". Food presented in a clean and appetizing way will encourage a good flavor, even if unsatisfactory.\n\nTexture plays a crucial role in the enjoyment of eating foods. Contrasts in textures, such as something crunchy in an otherwise smooth dish, may increase the appeal of eating it. Common examples include adding granola to yogurt, adding croutons to a salad or soup, and toasting bread to enhance its crunchiness for a smooth topping, such as jam or butter.\n\nAnother universal phenomenon regarding food is the appeal of contrast in taste and presentation. For example, such opposite flavors as sweetness and saltiness tend to go well together, as in kettle corn and nuts.\n\nFood preparation\n\nWhile many foods can be eaten raw, many also undergo some form of preparation for reasons of safety, palatability, texture, or flavor. At the simplest level this may involve washing, cutting, trimming, or adding other foods or ingredients, such as spices. It may also involve mixing, heating or cooling, pressure cooking, fermentation, or combination with other food. In a home, most food preparation takes place in a kitchen. Some preparation is done to enhance the taste or aesthetic appeal; other preparation may help to preserve the food; others may be involved in cultural identity. A meal is made up of food which is prepared to be eaten at a specific time and place.\n\nAnimal preparation\nThe preparation of animal-based food usually involves slaughter, evisceration, hanging, portioning, and rendering. In developed countries, this is usually done outside the home in slaughterhouses, which are used to process animals en masse for meat production. Many countries regulate their slaughterhouses by law. For example, the United States has established the Humane Slaughter Act of 1958, which requires that an animal be stunned before killing. This act, like those in many countries, exempts slaughter in accordance with religious law, such as kosher, shechita, and dhab\u012b\u1e25ah halal. Strict interpretations of kashrut require the animal to be fully aware when its carotid artery is cut.\n\nOn the local level, a butcher may commonly break down larger animal meat into smaller manageable cuts, and pre-wrap them for commercial sale or wrap them to order in butcher paper. In addition, fish and seafood may be fabricated into smaller cuts by a fishmonger. However, fish butchery may be done onboard a fishing vessel and quick-frozen for the preservation of quality.\n\nRaw food preparation\n\nCertain cultures highlight animal and vegetable foods in a raw state. Salads consisting of raw vegetables or fruits are common in many cuisines. Sashimi in Japanese cuisine consists of raw sliced fish or other meat, and sushi often incorporates raw fish or seafood. Steak tartare and salmon tartare are dishes made from diced or ground raw beef or salmon, mixed with various ingredients and served with baguettes, brioche, or frites. In Italy, carpaccio is a dish of very thinly sliced raw beef, drizzled with a vinaigrette made with olive oil. The health food movement known as raw foodism promotes a mostly vegan diet of raw fruits, vegetables, and grains prepared in various ways, including juicing, food dehydration, sprouting, and other methods of preparation that do not heat the food above . An example of a raw meat dish is ceviche, a Latin American dish made with raw meat that is \"cooked\" from the highly acidic citric juice from lemons and limes along with other aromatics such as garlic.\n\nCooking\n\nThe term \"cooking\" encompasses a vast range of methods, tools, and combinations of ingredients to improve the flavor or digestibility of food. Cooking technique, known as culinary art, generally requires the selection, measurement, and combining of ingredients in an ordered procedure in an effort to achieve the desired result. Constraints on success include the variability of ingredients, ambient conditions, tools, and the skill of the individual cook. The diversity of cooking worldwide is a reflection of the myriad nutritional, aesthetic, agricultural, economic, cultural, and religious considerations that affect it.\n\nCooking requires applying heat to a food which usually, though not always, chemically changes the molecules, thus changing its flavor, texture, appearance, and nutritional properties. Cooking certain proteins, such as egg whites, meats, and fish, denatures the protein, causing it to firm. There is archaeological evidence of roasted foodstuffs at Homo erectus campsites dating from 420,000 years ago. Boiling as a means of cooking requires a container, and has been practiced at least since the 10th millennium BC with the introduction of pottery.\n\nCooking equipment\n\nThere are many different types of equipment used for cooking.\n\nOvens are mostly hollow devices that get very hot (up to ) and are used for baking or roasting and offer a dry-heat cooking method. Different cuisines will use different types of ovens. For example, Indian culture uses a tandoor oven, which is a cylindrical clay oven which operates at a single high temperature. Western kitchens use variable temperature convection ovens, conventional ovens, toaster ovens, or non-radiant heat ovens like the microwave oven. Classic Italian cuisine includes the use of a brick oven containing burning wood. Ovens may be wood-fired, coal-fired, gas, electric, or oil-fired.\n\nVarious types of cook-tops are used as well. They carry the same variations of fuel types as the ovens mentioned above. Cook-tops are used to heat vessels placed on top of the heat source, such as a saut\u00e9 pan, sauce pot, frying pan, or pressure cooker. These pieces of equipment can use either a moist or dry cooking method and include methods such as steaming, simmering, boiling, and poaching for moist methods, while the dry methods include saut\u00e9ing, pan frying, and deep-frying.\n\nIn addition, many cultures use grills for cooking. A grill operates with a radiant heat source from below, usually covered with a metal grid and sometimes a cover. An open-pit barbecue in the American south is one example along with the American style outdoor grill fueled by wood, liquid propane, or charcoal along with soaked wood chips for smoking. A Mexican style of barbecue is called barbacoa, which involves the cooking of meats such as whole sheep over an open fire. In Argentina, an asado (Spanish for \"grilled\") is prepared on a grill held over an open pit or fire made upon the ground, on which a whole animal or smaller cuts are grilled.\n\nRestaurants\n\nRestaurants employ chefs to prepare the food, and waiters to serve customers at the table. The term restaurant comes from an old term for a restorative meat broth; this broth (or bouillon) was served in elegant outlets in Paris from the mid 18th century. These refined \"restaurants\" were a marked change from the usual basic eateries such as inns and taverns, and some had developed from early Parisian caf\u00e9s, such as Caf\u00e9 Procope, by first serving bouillon, then adding other cooked food to their menus.\n\nCommercial eateries existed during the Roman period, with evidence of 150 \"thermopolia\", a form of fast food restaurant, found in Pompeii, and urban sales of prepared foods may have existed in China during the Song dynasty.\n\nIn 2005, the population of the United States spent $496 billion on out-of-home dining. Expenditures by type of out-of-home dining were as follows: 40% in full-service restaurants, 37.2% in limited service restaurants (fast food), 6.6% in schools or colleges, 5.4% in bars and vending machines, 4.7% in hotels and motels, 4.0% in recreational places, and 2.2% in others, which includes military bases.\n\nEconomy\n\n Food systems have complex economic and social value chains that effect many parts of the global economy.\n\nProduction\n\nMost food has always been obtained through agriculture. With increasing concern over both the methods and products of modern industrial agriculture, there has been a growing trend toward sustainable agricultural practices. This approach, partly fueled by consumer demand, encourages biodiversity, local self-reliance and organic farming methods. Major influences on food production include international organizations (e.g. the World Trade Organization and Common Agricultural Policy), national government policy (or law), and war.\n\nSeveral organisations have begun calling for a new kind of agriculture in which agroecosystems provide food but also support vital ecosystem services so that soil fertility and biodiversity are maintained rather than compromised. According to the International Water Management Institute and UNEP, well-managed agroecosystems not only provide food, fiber and animal products, they also provide services such as flood mitigation, groundwater recharge, erosion control and habitats for plants, birds, fish and other animals.\n\nFood manufacturing\n\nPackaged foods are manufactured outside the home for purchase. This can be as simple as a butcher preparing meat, or as complex as a modern international food industry. Early food processing techniques were limited by available food preservation, packaging, and transportation. This mainly involved salting, curing, curdling, drying, pickling, fermenting, and smoking. Food manufacturing arose during the industrial revolution in the 19th century. This development took advantage of new mass markets and emerging technology, such as milling, preservation, packaging and labeling, and transportation. It brought the advantages of pre-prepared time-saving food to the bulk of ordinary people who did not employ domestic servants.\n\nAt the start of the 21st century, a two-tier structure has arisen, with a few international food processing giants controlling a wide range of well-known food brands. There also exists a wide array of small local or national food processing companies. Advanced technologies have also come to change food manufacture. Computer-based control systems, sophisticated processing and packaging methods, and logistics and distribution advances can enhance product quality, improve food safety, and reduce costs.\n\nInternational food imports and exports\n\nThe World Bank reported that the European Union was the top food importer in 2005, followed at a distance by the US and Japan. Britain's need for food was especially well-illustrated in World War II.  Despite the implementation of food rationing, Britain remained dependent on food imports and the result was a long term engagement in the Battle of the Atlantic.\n\nFood is traded and marketed on a global basis. The variety and availability of food is no longer restricted by the diversity of locally grown food or the limitations of the local growing season. Between 1961 and 1999, there was a 400% increase in worldwide food exports. Some countries are now economically dependent on food exports, which in some cases account for over 80% of all exports.\n\nIn 1994, over 100 countries became signatories to the Uruguay Round of the General Agreement on Tariffs and Trade in a dramatic increase in trade liberalization. This included an agreement to reduce subsidies paid to farmers, underpinned by the WTO enforcement of agricultural subsidy, tariffs, import quotas, and settlement of trade disputes that cannot be bilaterally resolved. Where trade barriers are raised on the disputed grounds of public health and safety, the WTO refer the dispute to the Codex Alimentarius Commission, which was founded in 1962 by the United Nations Food and Agriculture Organization and the World Health Organization. Trade liberalization has greatly affected world food trade.\n\nMarketing and retailing\n\nFood marketing brings together the producer and the consumer. The marketing of even a single food product can be a complicated process involving many producers and companies. For example, fifty-six companies are involved in making one can of chicken noodle soup. These businesses include not only chicken and vegetable processors but also the companies that transport the ingredients and those who print labels and manufacture cans. The food marketing system is the largest direct and indirect non-government employer in the United States.\n\nIn the pre-modern era, the sale of surplus food took place once a week when farmers took their wares on market day into the local village marketplace. Here food was sold to grocers for sale in their local shops for purchase by local consumers. With the onset of industrialization and the development of the food processing industry, a wider range of food could be sold and distributed in distant locations. Typically early grocery shops would be counter-based shops, in which purchasers told the shop-keeper what they wanted, so that the shop-keeper could get it for them.\n\nIn the 20th century, supermarkets were born. Supermarkets brought with them a self service approach to shopping using shopping carts, and were able to offer quality food at lower cost through economies of scale and reduced staffing costs. In the latter part of the 20th century, this has been further revolutionized by the development of vast warehouse-sized, out-of-town supermarkets, selling a wide range of food from around the world.\n\nUnlike food processors, food retailing is a two-tier market in which a small number of very large companies control a large proportion of supermarkets. The supermarket giants wield great purchasing power over farmers and processors, and strong influence over consumers. Nevertheless, less than 10% of consumer spending on food goes to farmers, with larger percentages going to advertising, transportation, and intermediate corporations.\n\nPrices\n\nAs investment\n\nProblems\n\nBecause of its centrality to human life, problems related to access, quality and production of food effect every aspect of human life.\n\nNutrition and dietary problems \nBetween the extremes of optimal health and death from starvation or malnutrition, there is an array of disease states that can be caused or alleviated by changes in diet. Deficiencies, excesses, and imbalances in diet can produce negative impacts on health, which may lead to various health problems such as scurvy, obesity, or osteoporosis, diabetes, cardiovascular diseases as well as psychological and behavioral problems. The science of nutrition attempts to understand how and why specific dietary aspects influence health.\n\nNutrients in food are grouped into several categories. Macronutrients are fat, protein, and carbohydrates. Micronutrients are the minerals and vitamins. Additionally, food contains water and dietary fiber.\n\nAs previously discussed, the body is designed by natural selection to enjoy sweet and fattening foods for evolutionary diets, ideal for hunters and gatherers. Thus, sweet and fattening foods in nature are typically rare and are very pleasurable to eat. In modern times, with advanced technology, enjoyable foods are easily available to consumers. Unfortunately, this promotes obesity in adults and children alike.\n\nHunger and starvation \nFood deprivation leads to malnutrition and ultimately starvation. This is often connected with famine, which involves the absence of food in entire communities. This can have a devastating and widespread effect on human health and mortality. Rationing is sometimes used to distribute food in times of shortage, most notably during times of war.\n\nStarvation is a significant international problem. Approximately 815 million people are undernourished, and over 16,000 children die per day from hunger-related causes. Food deprivation is regarded as a deficit need in Maslow's hierarchy of needs and is measured using famine scales.\n\nFood waste\n\nPolicy\n\nLegal definition\nSome countries list a legal definition of food, often referring them with the word foodstuff. These countries list food as any item that is to be processed, partially processed, or unprocessed for consumption. The listing of items included as food includes any substance intended to be, or reasonably expected to be, ingested by humans. In addition to these foodstuffs, drink, chewing gum, water, or other items processed into said food items are part of the legal definition of food. Items not included in the legal definition of food include animal feed, live animals (unless being prepared for sale in a market), plants prior to harvesting, medicinal products, cosmetics, tobacco and tobacco products, narcotic or psychotropic substances, and residues and contaminants.\n\nRight to food\n\nFood security\n\nInternational aid\n\nFood aid can benefit people suffering from a shortage of food. It can be used to improve peoples' lives in the short term, so that a society can increase its standard of living to the point that food aid is no longer required. Conversely, badly managed food aid can create problems by disrupting local markets, depressing crop prices, and discouraging food production. Sometimes a cycle of food aid dependence can develop. Its provision, or threatened withdrawal, is sometimes used as a political tool to influence the policies of the destination country, a strategy known as food politics. Sometimes, food aid provisions will require certain types of food be purchased from certain sellers, and food aid can be misused to enhance the markets of donor countries. International efforts to distribute food to the neediest countries are often coordinated by the World Food Programme.\n\nSafety\n\nFoodborne illness, commonly called \"food poisoning\", is caused by bacteria, toxins, viruses, parasites, and prions. Roughly 7 million people die of food poisoning each year, with about 10 times as many suffering from a non-fatal version. The two most common factors leading to cases of bacterial foodborne illness are cross-contamination of ready-to-eat food from other uncooked foods and improper temperature control. Less commonly, acute adverse reactions can also occur if chemical contamination of food occurs, for example from improper storage, or use of non-food grade soaps and disinfectants. Food can also be adulterated by a very wide range of articles (known as \"foreign bodies\") during farming, manufacture, cooking, packaging, distribution, or sale. These foreign bodies can include pests or their droppings, hairs, cigarette butts, wood chips, and all manner of other contaminants. It is possible for certain types of food to become contaminated if stored or presented in an unsafe container, such as a ceramic pot with lead-based glaze.\n\nFood poisoning has been recognized as a disease since as early as Hippocrates. The sale of rancid, contaminated, or adulterated food was commonplace until the introduction of hygiene, refrigeration, and vermin controls in the 19th century. Discovery of techniques for killing bacteria using heat, and other microbiological studies by scientists such as Louis Pasteur, contributed to the modern sanitation standards that are ubiquitous in developed nations today. This was further underpinned by the work of Justus von Liebig, which led to the development of modern food storage and food preservation methods. In more recent years, a greater understanding of the causes of food-borne illnesses has led to the development of more systematic approaches such as the Hazard Analysis and Critical Control Points (HACCP), which can identify and eliminate many risks.\n\nRecommended measures for ensuring food safety include maintaining a clean preparation area with foods of different types kept separate, ensuring an adequate cooking temperature, and refrigerating foods promptly after cooking.\n\nFoods that spoil easily, such as meats, dairy, and seafood, must be prepared a certain way to avoid contaminating the people for whom they are prepared. As such, the rule of thumb is that cold foods (such as dairy products) should be kept cold and hot foods (such as soup) should be kept hot until storage. Cold meats, such as chicken, that are to be cooked should not be placed at room temperature for thawing, at the risk of dangerous bacterial growth, such as Salmonella or E. coli.\n\nAllergies\n\nSome people have allergies or sensitivities to foods that are not problematic to most people. This occurs when a person's immune system mistakes a certain food protein for a harmful foreign agent and attacks it. About 2% of adults and 8% of children have a food allergy. The amount of the food substance required to provoke a reaction in a particularly susceptible individual can be quite small. In some instances, traces of food in the air, too minute to be perceived through smell, have been known to provoke lethal reactions in extremely sensitive individuals. Common food allergens are gluten, corn, shellfish (mollusks), peanuts, and soy. Allergens frequently produce symptoms such as diarrhea, rashes, bloating, vomiting, and regurgitation. The digestive complaints usually develop within half an hour of ingesting the allergen.\n\nRarely, food allergies can lead to a medical emergency, such as anaphylactic shock, hypotension (low blood pressure), and loss of consciousness. An allergen associated with this type of reaction is peanut, although latex products can induce similar reactions. Initial treatment is with epinephrine (adrenaline), often carried by known patients in the form of an Epi-pen or Twinject.\n\nOther health issues\nHuman diet was estimated to cause perhaps around 35% of cancers in a human epidemiological analysis by Richard Doll and Richard Peto in 1981.  These cancer may be caused by carcinogens that are present in food naturally or as contaminants. Food contaminated with fungal growth may contain mycotoxins such as aflatoxins which may be found in contaminated corn and peanuts.  Other carcinogens identified in food include heterocyclic amines generated in meat when cooked at high temperature, polyaromatic hydrocarbons in charred meat and smoked fish, and nitrosamines generated from nitrites used as food preservatives in cured meat such as bacon.\n\nAnticarcinogens that may help prevent cancer can also be found in many food especially fruit and vegetables. Antioxidants are important groups of compounds that may help remove potentially harmful chemicals. It is however often difficult to identify the specific components in diet that serve to increase or decrease cancer risk since many food, such as beef steak and broccoli, contain low concentrations of both carcinogens and anticarcinogens.\nThere are many international certifications in the cooking field, such as Monde Selection, A.A. Certification, iTQi. They use high-quality evaluation methods to make the food safer.\n\nDiet\n\nCultural and religious diets\nMany cultures hold some food preferences and some food taboos. Dietary choices can also define cultures and play a role in religion. For example, only kosher foods are permitted by Judaism, halal foods by Islam, and in Hinduism beef is restricted. In addition, the dietary choices of different countries or regions have different characteristics. This is highly related to a culture's cuisine.\n\nDiet deficiencies\n\nDietary habits play a significant role in the health and mortality of all humans. Imbalances between the consumed fuels and expended energy results in either starvation or excessive reserves of adipose tissue, known as body fat. Poor intake of various vitamins and minerals can lead to diseases that can have far-reaching effects on health. For instance, 30% of the world's population either has, or is at risk for developing, iodine deficiency. It is estimated that at least 3 million children are blind due to vitamin A deficiency. Vitamin C deficiency results in scurvy. Calcium, Vitamin D, and phosphorus are inter-related; the consumption of each may affect the absorption of the others. Kwashiorkor and marasmus are childhood disorders caused by lack of dietary protein.\n\nMoral, ethical, and health-conscious diets\nMany individuals limit what foods they eat for reasons of morality or other habits. For instance, vegetarians choose to forgo food from animal sources to varying degrees. Others choose a healthier diet, avoiding sugars or animal fats and increasing consumption of dietary fiber and antioxidants. Obesity, a serious problem in the western world, leads to higher chances of developing heart disease, diabetes, cancer and many other diseases. More recently, dietary habits have been influenced by the concerns that some people have about possible impacts on health or the environment from genetically modified food. Further concerns about the impact of industrial farming (grains) on animal welfare, human health, and the environment are also having an effect on contemporary human dietary habits. This has led to the emergence of a movement with a preference for organic and local food.\n\nSee also\n\n Bulk foods\n Beverages\n Food and Bioprocess Technology\n Food engineering\n Food, Inc., a 2009 documentary\n Food science\n Future food technology\n Industrial crop\n List of foods\n Lists of prepared foods\n Optimal foraging theory\n Outline of cooking\n Outline of nutrition\n Right to food by country\n\nReferences\n\nSources\n\n Aguilera, Jose Miguel and David W. Stanley. Microstructural Principles of Food Processing and Engineering. Springer, 1999. .\n.\n Asado Argentina. About Asado Argentina. Retrieved from http://www.asadoargentina.com/about-asado-argentina/ on 2007-05-28.\n Campbell, Bernard Grant. Human Evolution: An Introduction to Man's Adaptations. Aldine Transaction: 1998. .\n Carpenter, Ruth Ann; Finley, Carrie E. Healthy Eating Every Day. Human Kinetics, 2005. .\n Davidson, Alan. The Oxford Companion to Food. 2nd ed. UK: Oxford University Press, 2006.\n Food and Agriculture Organization of the United Nations. The State of Food Insecurity in the World 2005. . Retrieved from http://www.fao.org/docrep/008/a0200e/a0200e00.htm on 2006-09-29.\n Hannaford, Steve. Oligopoly Watch: Top 20 world food companies. Retrieved from https://web.archive.org/web/20090918101335/http://www.oligopolywatch.com/2005/10/06.html on 2006-09-23.\n Howe, P. and S. Devereux. Famine Intensity and Magnitude Scales: A Proposal for an Instrumental Definition of Famine. 2004.\n Humphery, Kim. Shelf Life: Supermarkets and the Changing Cultures of Consumption. Cambridge University Press, 1998. .\n.\n Jango-Cohen, Judith. The History Of Food. Twenty-First Century Books, 2005. .\n Jurgens, Marshall H. Animal Feeding and Nutrition. Kendall Hunt, 2001. .\n.\n Kripke, Gawain. Food aid or hidden dumping?. Oxfam International, March 2005. Retrieved from https://web.archive.org/web/20060714133231/http://www.oxfam.org/en/policy/briefingpapers/bp71_food_aid_240305 on 2007-05-26.\n Lawrie, Stephen; R.A. Lawrie. Lawrie's Meat Science. Woodhead Publishing: 1998. .\n Magdoff, Fred; Foster, John Bellamy; and Buttel, Frederick H. Hungry for Profit: The Agribusiness Threat to Farmers, Food, and the Environment. September 2000. .\n Mason, John. Sustainable Agriculture. Landlinks Press: 2003. .\n Merson, Michael H.; Black, Robert E.; Mills, Anne J. International Public Health: Disease, Programs, Systems, and Policies. Jones and Bartlett Publishers, 2005.\n McGee, Harold. On Food and Cooking: The Science and Lore of the Kitchen. New York: Simon & Schuster, 2004. .\n Mead, Margaret. The Changing Significance of Food. In Carole Counihan and Penny Van Esterik (Ed.), Food and Culture: A Reader. UK: Routledge, 1997. .\n Messer, Ellen; Derose, Laurie Fields and Sara Millman. Who's Hungry? and How Do We Know?: Food Shortage, Poverty, and Deprivation. United Nations University Press, 1998. .\n National Institute of Health. Food poisoning. MedlinePlus Medical Encyclopedia F. 11 May 2006. Retrieved from https://web.archive.org/web/20060928222906/http://www.niaid.nih.gov/publications/pdf/foodallergy.pdf on 2006-09-29.\n Nicklas, Barbara J. Endurance Exercise and Adipose Tissue. CRC Press, 2002. .\n Parekh, Sarad R. The Gmo Handbook: Genetically Modified Animals, Microbes, and Plants in Biotechnology. Humana Press,2004. .\n Regmi, Anita (editor).Changing Structure of Global Food Consumption and Trade. Market and Trade Economics Division, Economic Research Service, USDA, 30 May 2001. stock #ERSWRS01-1.\n Schor, Juliet; Taylor, Betsy (editors). Sustainable Planet: Roadmaps for the Twenty-First Century. Beacon Press, 2003. .\n Shah, Anup. Food Dumping (Aid) Maintains Poverty. Causes of Poverty. Retrieved from http://www.globalissues.org/TradeRelated/Poverty/FoodDumping.asp on 2006-09-29.\n Simoons, Frederick J. Eat Not This Flesh: Food Avoidances from Prehistory to the Present. .\n Smith, Andrew (Editor). \u201cFood Marketing,\u201d in Oxford Encyclopedia of American Food and Drink, New York: Oxford University Press, 2007.\n.\n The Economic Research Service of the USDA. Global Food Markets: Briefing Rooms. Retrieved from https://web.archive.org/web/20170704104430/https://www.ers.usda.gov/topics/international-markets-trade/global-food-markets.aspx on 2006-09-29.\n United Kingdom Office of Public Sector Information. Food Safety Act 1990 (c. 16). Retrieved from http://www.opsi.gov.uk/acts/acts1990/Ukpga_19900016_en_2.htm#mdiv1 on 2006-11-08.\n.\n.\n United States Department of Agriculture, USDA Economic Research Service: The Economics of Food, Farming, Natural Resources, and Rural America. \"Briefing Rooms, Food CPI, Prices and Expenditures: Food Expenditure Tables\". Retrieved from http://www.ers.usda.gov/data-products/food-price-outlook.aspx on 2007-06-06.\n Van den Bossche, Peter. The Law and Policy of the bosanac Trade Organization: Text, Cases and Materials. UK: Cambridge University Press, 2005. .\n World Food Programme. Breaking out of the Poverty Trap: How We Use Food Aid. Retrieved from https://web.archive.org/web/20060928075506/http://www.wfp.org/food_aid/introduction/index.asp?section=12&sub_section=1 on 2006-09-29.\n World Health Organization. WHO Global Database on Child Growth and Malnutrition.  Retrieved from  on 2006-09-29.\n World Trade Organization. The Uruguay Round.  Retrieved from https://web.archive.org/web/20060822200650/http://www.wto.org/trade_resources/history/wto/urug_round.htm on 2006-09-29.\n.\n\nFurther reading\n Collingham, E.M. (2011).  The Taste of War: World War Two and the Battle for Food\n Katz, Solomon (2003). The Encyclopedia of Food and Culture, Scribner\n Nestle, Marion (2007). Food Politics: How the Food Industry Influences Nutrition and Health, University Presses of California, revised and expanded edition, \n Mobbs, Michael (2012). Sustainable Food Sydney: NewSouth Publishing,  \n  The Future of Food (2015).  A panel discussion at the 2015  Digital Life Design (DLD) Annual Conference. \"How can we grow and enjoy food, closer to home, further into the future? MIT Media Lab\u2019s Kevin Slavin hosts a conversation with food artist, educator, and entrepreneur Emilie Baltz, professor Caleb Harper from MIT Media Lab's CityFarm project, the Barbarian Group's Benjamin Palmer, and Andras Forgacs, the co-founder and CEO of Modern Meadow, who is growing 'victimless' meat in a lab. The discussion addresses issues of sustainable urban farming, ecosystems, technology, food supply chains and their broad environmental and humanitarian implications, and how these changes in food production may change what people may find delicious ... and the other way around.\"  Posted on the official YouTube Channel of DLD\n\nExternal links\n\n \n \n Food Timeline\n Wikibooks Cookbook\n Food, BBC Radio 4 discussion with Rebecca Spang, Ivan Day and Felipe Fernandez-Armesto (In Our Time, 27 December 2001)\n\n \nFood Watchlist Articles",
  "Internet": "The Internet (or internet) is the global system of interconnected computer networks that uses the Internet protocol suite (TCP/IP) to communicate between networks and devices. It is a network of networks that consists of private, public, academic, business, and government networks of local to global scope, linked by a broad array of electronic, wireless, and optical networking technologies. The Internet carries a vast range of information resources and services, such as the inter-linked hypertext documents and applications of the World Wide Web (WWW), electronic mail, telephony, and file sharing.\n\nThe origins of the Internet date back to the development of packet switching and research commissioned by the United States Department of Defense in the 1960s to enable time-sharing of computers. The primary precursor network, the ARPANET, initially served as a backbone for interconnection of regional academic and military networks in the 1970s. The funding of the National Science Foundation Network as a new backbone in the 1980s, as well as private funding for other commercial extensions, led to worldwide participation in the development of new networking technologies, and the merger of many networks. The linking of commercial networks and enterprises by the early 1990s marked the beginning of the transition to the modern Internet, and generated a sustained exponential growth as generations of institutional, personal, and mobile computers were connected to the network. Although the Internet was widely used by academia in the 1980s, commercialization incorporated its services and technologies into virtually every aspect of modern life.\n\nMost traditional communication media, including telephony, radio, television, paper mail and newspapers are reshaped, redefined, or even bypassed by the Internet, giving birth to new services such as email, Internet telephony, Internet television, online music, digital newspapers, and video streaming websites. Newspaper, book, and other print publishing are adapting to website technology, or are reshaped into blogging, web feeds and online news aggregators. The Internet has enabled and accelerated new forms of personal interactions through instant messaging, Internet forums, and social networking services. Online shopping has grown exponentially for major retailers, small businesses, and entrepreneurs, as it enables firms to extend their \"brick and mortar\" presence to serve a larger market or even sell goods and services entirely online. Business-to-business and financial services on the Internet affect supply chains across entire industries.\n\nThe Internet has no single centralized governance in either technological implementation or policies for access and usage; each constituent network sets its own policies. The overreaching definitions of the two principal name spaces in the Internet, the Internet Protocol address (IP address) space and the Domain Name System (DNS), are directed by a maintainer organization, the Internet Corporation for Assigned Names and Numbers (ICANN). The technical underpinning and standardization of the core protocols is an activity of the Internet Engineering Task Force (IETF), a non-profit organization of loosely affiliated international participants that anyone may associate with by contributing technical expertise. In November 2006, the Internet was included on USA Todays list of New Seven Wonders.\n\nTerminology \n\nThe word internetted was used as early as 1849, meaning interconnected or interwoven. The word Internet was used in 1974 as the shorthand form of Internetwork. Today, the term Internet most commonly refers to the global system of interconnected computer networks, though it may also refer to any group of smaller networks.\n\nWhen it came into common use, most publications treated the word Internet as a capitalized proper noun; this has become less common. This reflects the tendency in English to capitalize new terms and move to lowercase as they become familiar. The word is sometimes still capitalized to distinguish the global internet from smaller networks, though many publications, including the AP Stylebook since 2016, recommend the lowercase form in every case. In 2016, the Oxford English Dictionary found that, based on a study of around 2.5 billion printed and online sources, \"Internet\" was capitalized in 54% of cases.\n\nThe terms Internet and World Wide Web are often used interchangeably; it is common to speak of \"going on the Internet\" when using a web browser to view web pages. However, the World Wide Web or the Web is only one of a large number of Internet services, a collection of documents (web pages) and other web resources, linked by hyperlinks and URLs.\n\nHistory \n\nIn the 1960s, the Advanced Research Projects Agency (ARPA) of the United States Department of Defense funded research into time-sharing of computers. Research into packet switching, one of the fundamental Internet technologies, started in the work of Paul Baran in the early 1960s and, independently, Donald Davies in 1965. After the Symposium on Operating Systems Principles in 1967, packet switching from the proposed NPL network was incorporated into the design for the ARPANET and other resource sharing networks such as the Merit Network and CYCLADES, which were developed in the late 1960s and early 1970s.\n\nARPANET development began with two network nodes which were interconnected between the Network Measurement Center at the University of California, Los Angeles (UCLA) Henry Samueli School of Engineering and Applied Science directed by Leonard Kleinrock, and the NLS system at SRI International (SRI) by Douglas Engelbart in Menlo Park, California, on 29 October 1969. The third site was the Culler-Fried Interactive Mathematics Center at the University of California, Santa Barbara, followed by the University of Utah Graphics Department. In a sign of future growth, 15 sites were connected to the young ARPANET by the end of 1971. These early years were documented in the 1972 film Computer Networks: The Heralds of Resource Sharing.\n\nEarly international collaborations for the ARPANET were rare. Connections were made in 1973 to the Norwegian Seismic Array (NORSAR) via a satellite station in Tanum, Sweden, and to Peter Kirstein's research group at University College London which provided a gateway to British academic networks. The ARPA projects and international working groups led to the development of various protocols and standards by which multiple separate networks could become a single network or \"a network of networks\". In 1974, Vint Cerf and Bob Kahn used the term internet as a shorthand for internetwork in , and later RFCs repeated this use. Cerf and Kahn credit Louis Pouzin with important influences on TCP/IP design. Commercial PTT providers were concerned with developing X.25 public data networks.\n\nAccess to the ARPANET was expanded in 1981 when the National Science Foundation (NSF) funded the Computer Science Network (CSNET). In 1982, the Internet Protocol Suite (TCP/IP) was standardized, which permitted worldwide proliferation of interconnected networks. TCP/IP network access expanded again in 1986 when the National Science Foundation Network (NSFNet) provided access to supercomputer sites in the United States for researchers, first at speeds of 56 kbit/s and later at 1.5 Mbit/s and 45 Mbit/s. The NSFNet expanded into academic and research organizations in Europe, Australia, New Zealand and Japan in 1988\u201389. Although other network protocols such as UUCP had global reach well before this time, this marked the beginning of the Internet as an intercontinental network. Commercial Internet service providers (ISPs) emerged in 1989 in the United States and Australia. The ARPANET was decommissioned in 1990.\n\nSteady advances in semiconductor technology and optical networking created new economic opportunities for commercial involvement in the expansion of the network in its core and for delivering services to the public. In mid-1989, MCI Mail and Compuserve established connections to the Internet, delivering email and public access products to the half million users of the Internet. Just months later, on 1 January 1990, PSInet launched an alternate Internet backbone for commercial use; one of the networks that added to the core of the commercial Internet of later years. In March 1990, the first high-speed T1 (1.5 Mbit/s) link between the NSFNET and Europe was installed between Cornell University and CERN, allowing much more robust communications than were capable with satellites. Six months later Tim Berners-Lee would begin writing WorldWideWeb, the first web browser, after two years of lobbying CERN management. By Christmas 1990, Berners-Lee had built all the tools necessary for a working Web: the HyperText Transfer Protocol (HTTP) 0.9, the HyperText Markup Language (HTML), the first Web browser (which was also a HTML editor and could access Usenet newsgroups and FTP files), the first HTTP server software (later known as CERN httpd), the first web server, and the first Web pages that described the project itself. In 1991 the Commercial Internet eXchange was founded, allowing PSInet to communicate with the other commercial networks CERFnet and Alternet. Stanford Federal Credit Union was the first financial institution to offer online Internet banking services to all of its members in October 1994. In 1996, OP Financial Group, also a cooperative bank, became the second online bank in the world and the first in Europe. By 1995, the Internet was fully commercialized in the U.S. when the NSFNet was decommissioned, removing the last restrictions on use of the Internet to carry commercial traffic.\n\nAs technology advanced and commercial opportunities fueled reciprocal growth, the volume of Internet traffic started experiencing similar characteristics as that of the scaling of MOS transistors, exemplified by Moore's law, doubling every 18 months. This growth, formalized as Edholm's law, was catalyzed by advances in MOS technology, laser light wave systems, and noise performance.\n\nSince 1995, the Internet has tremendously impacted culture and commerce, including the rise of near instant communication by email, instant messaging, telephony (Voice over Internet Protocol or VoIP), two-way interactive video calls, and the World Wide Web with its discussion forums, blogs, social networking services, and online shopping sites. Increasing amounts of data are transmitted at higher and higher speeds over fiber optic networks operating at 1 Gbit/s, 10 Gbit/s, or more. The Internet continues to grow, driven by ever greater amounts of online information and knowledge, commerce, entertainment and social networking services. During the late 1990s, it was estimated that traffic on the public Internet grew by 100 percent per year, while the mean annual growth in the number of Internet users was thought to be between 20% and 50%. This growth is often attributed to the lack of central administration, which allows organic growth of the network, as well as the non-proprietary nature of the Internet protocols, which encourages vendor interoperability and prevents any one company from exerting too much control over the network. , the estimated total number of Internet users was 2.095\u00a0billion (30.2% of world population). It is estimated that in 1993 the Internet carried only 1% of the information flowing through two-way telecommunication. By 2000 this figure had grown to 51%, and by 2007 more than 97% of all telecommunicated information was carried over the Internet.\n\nGovernance \n\nThe Internet is a global network that comprises many voluntarily interconnected autonomous networks. It operates without a central governing body. The technical underpinning and standardization of the core protocols (IPv4 and IPv6) is an activity of the Internet Engineering Task Force (IETF), a non-profit organization of loosely affiliated international participants that anyone may associate with by contributing technical expertise. To maintain interoperability, the principal name spaces of the Internet are administered by the Internet Corporation for Assigned Names and Numbers (ICANN). ICANN is governed by an international board of directors drawn from across the Internet technical, business, academic, and other non-commercial communities. ICANN coordinates the assignment of unique identifiers for use on the Internet, including domain names, IP addresses, application port numbers in the transport protocols, and many other parameters. Globally unified name spaces are essential for maintaining the global reach of the Internet. This role of ICANN distinguishes it as perhaps the only central coordinating body for the global Internet.\n\nRegional Internet registries (RIRs) were established for five regions of the world. The African Network Information Center (AfriNIC) for Africa, the American Registry for Internet Numbers (ARIN) for North America, the Asia-Pacific Network Information Centre (APNIC) for Asia and the Pacific region, the Latin American and Caribbean Internet Addresses Registry (LACNIC) for Latin America and the Caribbean region, and the R\u00e9seaux IP Europ\u00e9ens \u2013 Network Coordination Centre (RIPE NCC) for Europe, the Middle East, and Central Asia were delegated to assign IP address blocks and other Internet parameters to local registries, such as Internet service providers, from a designated pool of addresses set aside for each region.\n\nThe National Telecommunications and Information Administration, an agency of the United States Department of Commerce, had final approval over changes to the DNS root zone until the IANA stewardship transition on 1 October 2016. The Internet Society (ISOC) was founded in 1992 with a mission to \"assure the open development, evolution and use of the Internet for the benefit of all people throughout the world\". Its members include individuals (anyone may join) as well as corporations, organizations, governments, and universities. Among other activities ISOC provides an administrative home for a number of less formally organized groups that are involved in developing and managing the Internet, including: the IETF, Internet Architecture Board (IAB), Internet Engineering Steering Group (IESG), Internet Research Task Force (IRTF), and Internet Research Steering Group (IRSG). On 16 November 2005, the United Nations-sponsored World Summit on the Information Society in Tunis established the Internet Governance Forum (IGF) to discuss Internet-related issues.\n\nInfrastructure \n\nThe communications infrastructure of the Internet consists of its hardware components and a system of software layers that control various aspects of the architecture. As with any computer network, the Internet physically consists of routers, media (such as cabling and radio links), repeaters, modems etc. However, as an example of internetworking, many of the network nodes are not necessarily internet equipment per se, the internet packets are carried by other full-fledged networking protocols with the Internet acting as a homogeneous networking standard, running across heterogeneous hardware, with the packets guided to their destinations by IP routers.\n\nService tiers \n\nInternet service providers (ISPs) establish the worldwide connectivity between individual networks at various levels of scope. End-users who only access the Internet when needed to perform a function or obtain information, represent the bottom of the routing hierarchy. At the top of the routing hierarchy are the tier 1 networks, large telecommunication companies that exchange traffic directly with each other via very high speed fibre optic cables and governed by peering agreements. Tier 2 and lower-level networks buy Internet transit from other providers to reach at least some parties on the global Internet, though they may also engage in peering. An ISP may use a single upstream provider for connectivity, or implement multihoming to achieve redundancy and load balancing. Internet exchange points are major traffic exchanges with physical connections to multiple ISPs. Large organizations, such as academic institutions, large enterprises, and governments, may perform the same function as ISPs, engaging in peering and purchasing transit on behalf of their internal networks. Research networks tend to interconnect with large subnetworks such as GEANT, GLORIAD, Internet2, and the UK's national research and education network, JANET.\n\nAccess \nCommon methods of Internet access by users include dial-up with a computer modem via telephone circuits, broadband over coaxial cable, fiber optics or copper wires, Wi-Fi, satellite, and cellular telephone technology (e.g. 3G, 4G). The Internet may often be accessed from computers in libraries and Internet cafes. Internet access points exist in many public places such as airport halls and coffee shops. Various terms are used, such as public Internet kiosk, public access terminal, and Web payphone. Many hotels also have public terminals that are usually fee-based. These terminals are widely accessed for various usages, such as ticket booking, bank deposit, or online payment. Wi-Fi provides wireless access to the Internet via local computer networks. Hotspots providing such access include Wi-Fi cafes, where users need to bring their own wireless devices such as a laptop or PDA. These services may be free to all, free to customers only, or fee-based.\n\nGrassroots efforts have led to wireless community networks. Commercial Wi-Fi services that cover large areas are available in many cities, such as New York, London, Vienna, Toronto, San Francisco, Philadelphia, Chicago and Pittsburgh, where the Internet can then be accessed from places such as a park bench. Experiments have also been conducted with proprietary mobile wireless networks like Ricochet, various high-speed data services over cellular networks, and fixed wireless services. Modern smartphones can also access the Internet through the cellular carrier network. For Web browsing, these devices provide applications such as Google Chrome, Safari, and Firefox and a wide variety of other Internet software may be installed from app-stores. Internet usage by mobile and tablet devices exceeded desktop worldwide for the first time in October 2016.\n\nMobile communication\n World Trends in Freedom of Expression and Media Development Global Report 2017/2018\nThe International Telecommunication Union (ITU) estimated that, by the end of 2017, 48% of individual users regularly connect to the Internet, up from 34% in 2012. Mobile Internet connectivity has played an important role in expanding access in recent years especially in Asia and the Pacific and in Africa. The number of unique mobile cellular subscriptions increased from 3.89\u00a0billion in 2012 to 4.83\u00a0billion in 2016, two-thirds of the world's population, with more than half of subscriptions located in Asia and the Pacific. The number of subscriptions is predicted to rise to 5.69\u00a0billion users in 2020. , almost 60% of the world's population had access to a 4G broadband cellular network, up from almost 50% in 2015 and 11% in 2012. The limits that users face on accessing information via mobile applications coincide with a broader process of fragmentation of the Internet. Fragmentation restricts access to media content and tends to affect poorest users the most.\n\nZero-rating, the practice of Internet service providers allowing users free connectivity to access specific content or applications without cost, has offered opportunities to surmount economic hurdles, but has also been accused by its critics as creating a two-tiered Internet. To address the issues with zero-rating, an alternative model has emerged in the concept of 'equal rating' and is being tested in experiments by Mozilla and Orange in Africa. Equal rating prevents prioritization of one type of content and zero-rates all content up to a specified data cap. A study published by Chatham House, 15 out of 19 countries researched in Latin America had some kind of hybrid or zero-rated product offered. Some countries in the region had a handful of plans to choose from (across all mobile network operators) while others, such as Colombia, offered as many as 30 pre-paid and 34 post-paid plans.\n\nA study of eight countries in the Global South found that zero-rated data plans exist in every country, although there is a great range in the frequency with which they are offered and actually used in each. The study looked at the top three to five carriers by market share in Bangladesh, Colombia, Ghana, India, Kenya, Nigeria, Peru and Philippines. Across the 181 plans examined, 13 per cent were offering zero-rated services. Another study, covering Ghana, Kenya, Nigeria and South Africa, found Facebook's Free Basics and Wikipedia Zero to be the most commonly zero-rated content.\n\nInternet Protocol Suite \n\nThe Internet standards describe a framework known as the Internet protocol suite (also called TCP/IP, based on the first two components.) This is a suite of protocols that are ordered into a set of four conceptional layers by the scope of their operation, originally documented in  and . At the top is the application layer, where communication is described in terms of the objects or data structures most appropriate for each application. For example, a web browser operates in a client\u2013server application model and exchanges information with the Hypertext Transfer Protocol (HTTP) and an application-germane data structure, such as the Hypertext Markup Language (HTML).\n\nBelow this top layer, the transport layer connects applications on different hosts with a logical channel through the network. It provides this service with a variety of possible characteristics, such as ordered, reliable delivery (TCP), and an unreliable datagram service (UDP).\n\nUnderlying these layers are the networking technologies that interconnect networks at their borders and exchange traffic across them. The Internet layer implements the Internet Protocol (IP) which enables computers to identify and locate each other by IP address, and route their traffic via intermediate (transit) networks. The internet protocol layer code is independent of the type of network that it is physically running over.\n\nAt the bottom of the architecture is the link layer, which connects nodes on the same physical link, and contains protocols that do not require routers for traversal to other links. The protocol suite does not explicitly specify hardware methods to transfer bits, or protocols to manage such hardware, but assumes that appropriate technology is available. Examples of that technology include Wi-Fi, Ethernet, and DSL.\n\nInternet protocol\n\nThe most prominent component of the Internet model is the Internet Protocol (IP). IP enables internetworking and, in essence, establishes the Internet itself. Two versions of the Internet Protocol exist, IPV4 and IPV6.\n\nIP Addresses\n\nFor locating individual computers on the network, the Internet provides IP addresses. IP addresses are used by the Internet infrastructure to direct internet packets to their destinations. They consist of fixed-length numbers, which are found within the packet. IP addresses are generally assigned to equipment either automatically via DHCP, or are configured.\n\nHowever, the network also supports other addressing systems. Users generally enter domain names (e.g. \"en.wikipedia.org\") instead of IP addresses because they are easier to remember, they are converted by the Domain Name System (DNS) into IP addresses which are more efficient for routing purposes.\n\nIPv4\nInternet Protocol version 4 (IPv4) defines an IP address as a 32-bit number. IPv4 is the initial version used on the first generation of the Internet and is still in dominant use. It was designed to address up to \u22484.3\u00a0billion (109) hosts. However, the explosive growth of the Internet has led to IPv4 address exhaustion, which entered its final stage in 2011, when the global IPv4 address allocation pool was exhausted.\n\nIPv6\nBecause of the growth of the Internet and the depletion of available IPv4 addresses, a new version of IP IPv6, was developed in the mid-1990s, which provides vastly larger addressing capabilities and more efficient routing of Internet traffic. IPv6 uses 128 bits for the IP address and was standardized in 1998. IPv6 deployment has been ongoing since the mid-2000s and is currently in growing deployment around the world, since Internet address registries (RIRs) began to urge all resource managers to plan rapid adoption and conversion.\n\nIPv6 is not directly interoperable by design with IPv4. In essence, it establishes a parallel version of the Internet not directly accessible with IPv4 software. Thus, translation facilities must exist for internetworking or nodes must have duplicate networking software for both networks. Essentially all modern computer operating systems support both versions of the Internet Protocol. Network infrastructure, however, has been lagging in this development. Aside from the complex array of physical connections that make up its infrastructure, the Internet is facilitated by bi- or multi-lateral commercial contracts, e.g., peering agreements, and by technical specifications or protocols that describe the exchange of data over the network. Indeed, the Internet is defined by its interconnections and routing policies.\n\nSubnetwork\n\nA subnetwork or subnet is a logical subdivision of an IP network. The practice of dividing a network into two or more networks is called subnetting.\n\nComputers that belong to a subnet are addressed with an identical most-significant bit-group in their IP addresses. This results in the logical division of an IP address into two fields, the network number or routing prefix and the rest field or host identifier. The rest field is an identifier for a specific host or network interface.\n\nThe routing prefix may be expressed in Classless Inter-Domain Routing (CIDR) notation written as the first address of a network, followed by a slash character (/), and ending with the bit-length of the prefix. For example,  is the prefix of the Internet Protocol version 4 network starting at the given address, having 24 bits allocated for the network prefix, and the remaining 8 bits reserved for host addressing. Addresses in the range  to  belong to this network. The IPv6 address specification  is a large address block with 296 addresses, having a 32-bit routing prefix.\n\nFor IPv4, a network may also be characterized by its subnet mask or netmask, which is the bitmask that when applied by a bitwise AND operation to any IP address in the network, yields the routing prefix. Subnet masks are also expressed in dot-decimal notation like an address. For example,  is the subnet mask for the prefix .\n\nTraffic is exchanged between subnetworks through routers when the routing prefixes of the source address and the destination address differ. A router serves as a logical or physical boundary between the subnets.\n\nThe benefits of subnetting an existing network vary with each deployment scenario. In the address allocation architecture of the Internet using CIDR and in large organizations, it is necessary to allocate address space efficiently. Subnetting may also enhance routing efficiency, or have advantages in network management when subnetworks are administratively controlled by different entities in a larger organization. Subnets may be arranged logically in a hierarchical architecture, partitioning an organization's network address space into a tree-like routing structure.\n\nRouting\nComputers and routers use routing tables in their operating system to direct IP packets to reach a node on a different subnetwork. Routing tables are maintained by manual configuration or automatically by routing protocols. End-nodes typically use a default route that points toward an ISP providing transit, while ISP routers use the Border Gateway Protocol to establish the most efficient routing across the complex connections of the global Internet. The default gateway is the node that serves as the forwarding host (router) to other networks when no other route specification matches the destination IP address of a packet.\n\nIETF\nWhile the hardware components in the Internet infrastructure can often be used to support other software systems, it is the design and the standardization process of the software that characterizes the Internet and provides the foundation for its scalability and success. The responsibility for the architectural design of the Internet software systems has been assumed by the Internet Engineering Task Force (IETF). The IETF conducts standard-setting work groups, open to any individual, about the various aspects of Internet architecture. The resulting contributions and standards are published as Request for Comments (RFC) documents on the IETF web site. The principal methods of networking that enable the Internet are contained in specially designated RFCs that constitute the Internet Standards. Other less rigorous documents are simply informative, experimental, or historical, or document the best current practices (BCP) when implementing Internet technologies.\n\nApplications and services \nThe Internet carries many applications and services, most prominently the World Wide Web, including social media, electronic mail, mobile applications, multiplayer online games, Internet telephony, file sharing, and streaming media services.\n\nMost servers that provide these services are today hosted in data centers, and content is often accessed through high-performance content delivery networks.\n\nWorld Wide Web \n\nThe World Wide Web is a global collection of documents, images, multimedia, applications, and other resources, logically interrelated by hyperlinks and referenced with Uniform Resource Identifiers (URIs), which provide a global system of named references. URIs symbolically identify services, web servers, databases, and the documents and resources that they can provide. Hypertext Transfer Protocol (HTTP) is the main access protocol of the World Wide Web. Web services also use HTTP for communication between software systems for information transfer, sharing and exchanging business data and logistic and is one of many languages or protocols that can be used for communication on the Internet.\n\nWorld Wide Web browser software, such as Microsoft's Internet Explorer/Edge, Mozilla Firefox, Opera, Apple's Safari, and Google Chrome, lets users navigate from one web page to another via the hyperlinks embedded in the documents. These documents may also contain any combination of computer data, including graphics, sounds, text, video, multimedia and interactive content that runs while the user is interacting with the page. Client-side software can include animations, games, office applications and scientific demonstrations. Through keyword-driven Internet research using search engines like Yahoo!, Bing and Google, users worldwide have easy, instant access to a vast and diverse amount of online information. Compared to printed media, books, encyclopedias and traditional libraries, the World Wide Web has enabled the decentralization of information on a large scale.\n\nThe Web has enabled individuals and organizations to publish ideas and information to a potentially large audience online at greatly reduced expense and time delay. Publishing a web page, a blog, or building a website involves little initial cost and many cost-free services are available. However, publishing and maintaining large, professional web sites with attractive, diverse and up-to-date information is still a difficult and expensive proposition. Many individuals and some companies and groups use web logs or blogs, which are largely used as easily updatable online diaries. Some commercial organizations encourage staff to communicate advice in their areas of specialization in the hope that visitors will be impressed by the expert knowledge and free information, and be attracted to the corporation as a result.\n\nAdvertising on popular web pages can be lucrative, and e-commerce, which is the sale of products and services directly via the Web, continues to grow. Online advertising is a form of marketing and advertising which uses the Internet to deliver promotional marketing messages to consumers. It includes email marketing, search engine marketing (SEM), social media marketing, many types of display advertising (including web banner advertising), and mobile advertising. In 2011, Internet advertising revenues in the United States surpassed those of cable television and nearly exceeded those of broadcast television. Many common online advertising practices are controversial and increasingly subject to regulation.\n\nWhen the Web developed in the 1990s, a typical web page was stored in completed form on a web server, formatted in HTML, complete for transmission to a web browser in response to a request. Over time, the process of creating and serving web pages has become dynamic, creating a flexible design, layout, and content. Websites are often created using content management software with, initially, very little content. Contributors to these systems, who may be paid staff, members of an organization or the public, fill underlying databases with content using editing pages designed for that purpose while casual visitors view and read this content in HTML form. There may or may not be editorial, approval and security systems built into the process of taking newly entered content and making it available to the target visitors.\n\nCommunication \nEmail is an important communications service available via the Internet. The concept of sending electronic text messages between parties, analogous to mailing letters or memos, predates the creation of the Internet. Pictures, documents, and other files are sent as email attachments. Email messages can be cc-ed to multiple email addresses.\n\nInternet telephony is a common communications service realized with the Internet. The name of the principle internetworking protocol, the Internet Protocol, lends its name to voice over Internet Protocol (VoIP). The idea began in the early 1990s with walkie-talkie-like voice applications for personal computers. VoIP systems now dominate many markets, and are as easy to use and as convenient as a traditional telephone. The benefit has been substantial cost savings over traditional telephone calls, especially over long distances. Cable, ADSL, and mobile data networks provide Internet access in customer premises and inexpensive VoIP network adapters provide the connection for traditional analog telephone sets. The voice quality of VoIP often exceeds that of traditional calls. Remaining problems for VoIP include the situation that emergency services may not be universally available, and that devices rely on a local power supply, while older traditional phones are powered from the local loop, and typically operate during a power failure.\n\nData transfer \nFile sharing is an example of transferring large amounts of data across the Internet. A computer file can be emailed to customers, colleagues and friends as an attachment. It can be uploaded to a website or File Transfer Protocol (FTP) server for easy download by others. It can be put into a \"shared location\" or onto a file server for instant use by colleagues. The load of bulk downloads to many users can be eased by the use of \"mirror\" servers or peer-to-peer networks. In any of these cases, access to the file may be controlled by user authentication, the transit of the file over the Internet may be obscured by encryption, and money may change hands for access to the file. The price can be paid by the remote charging of funds from, for example, a credit card whose details are also passed\u2014usually fully encrypted\u2014across the Internet. The origin and authenticity of the file received may be checked by digital signatures or by MD5 or other message digests. These simple features of the Internet, over a worldwide basis, are changing the production, sale, and distribution of anything that can be reduced to a computer file for transmission. This includes all manner of print publications, software products, news, music, film, video, photography, graphics and the other arts. This in turn has caused seismic shifts in each of the existing industries that previously controlled the production and distribution of these products.\n\nStreaming media is the real-time delivery of digital media for the immediate consumption or enjoyment by end users. Many radio and television broadcasters provide Internet feeds of their live audio and video productions. They may also allow time-shift viewing or listening such as Preview, Classic Clips and Listen Again features. These providers have been joined by a range of pure Internet \"broadcasters\" who never had on-air licenses. This means that an Internet-connected device, such as a computer or something more specific, can be used to access on-line media in much the same way as was previously possible only with a television or radio receiver. The range of available types of content is much wider, from specialized technical webcasts to on-demand popular multimedia services. Podcasting is a variation on this theme, where\u2014usually audio\u2014material is downloaded and played back on a computer or shifted to a portable media player to be listened to on the move. These techniques using simple equipment allow anybody, with little censorship or licensing control, to broadcast audio-visual material worldwide.\n\nDigital media streaming increases the demand for network bandwidth. For example, standard image quality needs 1 Mbit/s link speed for SD 480p, HD 720p quality requires 2.5 Mbit/s, and the top-of-the-line HDX quality needs 4.5 Mbit/s for 1080p.\n\nWebcams are a low-cost extension of this phenomenon. While some webcams can give full-frame-rate video, the picture either is usually small or updates slowly. Internet users can watch animals around an African waterhole, ships in the Panama Canal, traffic at a local roundabout or monitor their own premises, live and in real time. Video chat rooms and video conferencing are also popular with many uses being found for personal webcams, with and without two-way sound. YouTube was founded on 15 February 2005 and is now the leading website for free streaming video with more than two billion users. It uses an HTML5 based web player by default to stream and show video files. Registered users may upload an unlimited amount of video and build their own personal profile. YouTube claims that its users watch hundreds of millions, and upload hundreds of thousands of videos daily.\n\nSocial impact \nThe Internet has enabled new forms of social interaction, activities, and social associations. This phenomenon has given rise to the scholarly study of the sociology of the Internet.\n\nUsers \n\nFrom 2000 to 2009, the number of Internet users globally rose from 394\u00a0million to 1.858\u00a0billion. By 2010, 22 percent of the world's population had access to computers with 1\u00a0billion Google searches every day, 300\u00a0million Internet users reading blogs, and 2\u00a0billion videos viewed daily on YouTube. In 2014 the world's Internet users surpassed 3\u00a0billion or 43.6 percent of world population, but two-thirds of the users came from richest countries, with 78.0 percent of Europe countries population using the Internet, followed by 57.4 percent of the Americas. However, by 2018, Asia alone accounted for 51% of all Internet users, with 2.2\u00a0billion out of the 4.3\u00a0billion Internet users in the world coming from that region. The number of China's Internet users surpassed a major milestone in 2018, when the country's Internet regulatory authority, China Internet Network Information Centre, announced that China had 802\u00a0million Internet users. By 2019, China was the world's leading country in terms of Internet users, with more than 800\u00a0million users, followed closely by India, with some 700\u00a0million users, with the United States a distant third with 275\u00a0million users. However, in terms of penetration, China has a 38.4% penetration rate compared to India's 40% and the United States's 80%. As of 2020, it was estimated that 4.5\u00a0billion people use the Internet, more than half of the world's population.\n\nThe prevalent language for communication via the Internet has always been English. This may be a result of the origin of the Internet, as well as the language's role as a lingua franca and as a world language. Early computer systems were limited to the characters in the American Standard Code for Information Interchange (ASCII), a subset of the Latin alphabet.\n\nAfter English (27%), the most requested languages on the World Wide Web are Chinese (25%), Spanish (8%), Japanese (5%), Portuguese and German (4% each), Arabic, French and Russian (3% each), and Korean (2%). By region, 42% of the world's Internet users are based in Asia, 24% in Europe, 14% in North America, 10% in Latin America and the Caribbean taken together, 6% in Africa, 3% in the Middle East and 1% in Australia/Oceania. The Internet's technologies have developed enough in recent years, especially in the use of Unicode, that good facilities are available for development and communication in the world's widely used languages. However, some glitches such as mojibake (incorrect display of some languages' characters) still remain.\n\nIn an American study in 2005, the percentage of men using the Internet was very slightly ahead of the percentage of women, although this difference reversed in those under 30. Men logged on more often, spent more time online, and were more likely to be broadband users, whereas women tended to make more use of opportunities to communicate (such as email). Men were more likely to use the Internet to pay bills, participate in auctions, and for recreation such as downloading music and videos. Men and women were equally likely to use the Internet for shopping and banking.\nMore recent studies indicate that in 2008, women significantly outnumbered men on most social networking services, such as Facebook and Myspace, although the ratios varied with age. In addition, women watched more streaming content, whereas men downloaded more. In terms of blogs, men were more likely to blog in the first place; among those who blog, men were more likely to have a professional blog, whereas women were more likely to have a personal blog.\n\nSplitting by country, in 2012 Iceland, Norway, Sweden, the Netherlands, and Denmark had the highest Internet penetration by the number of users, with 93% or more of the population with access.\n\nSeveral neologisms exist that refer to Internet users: Netizen (as in \"citizen of the net\") refers to those actively involved in improving online communities, the Internet in general or surrounding political affairs and rights such as free speech, Internaut refers to operators or technically highly capable users of the Internet, digital citizen refers to a person using the Internet in order to engage in society, politics, and government participation.\n\nUsage \n\nThe Internet allows greater flexibility in working hours and location, especially with the spread of unmetered high-speed connections. The Internet can be accessed almost anywhere by numerous means, including through mobile Internet devices. Mobile phones, datacards, handheld game consoles and cellular routers allow users to connect to the Internet wirelessly. Within the limitations imposed by small screens and other limited facilities of such pocket-sized devices, the services of the Internet, including email and the web, may be available. Service providers may restrict the services offered and mobile data charges may be significantly higher than other access methods.\n\nEducational material at all levels from pre-school to post-doctoral is available from websites. Examples range from CBeebies, through school and high-school revision guides and virtual universities, to access to top-end scholarly literature through the likes of Google Scholar. For distance education, help with homework and other assignments, self-guided learning, whiling away spare time or just looking up more detail on an interesting fact, it has never been easier for people to access educational information at any level from anywhere. The Internet in general and the World Wide Web in particular are important enablers of both formal and informal education. Further, the Internet allows universities, in particular, researchers from the social and behavioral sciences, to conduct research remotely via virtual laboratories, with profound changes in reach and generalizability of findings as well as in communication between scientists and in the publication of results.\n\nThe low cost and nearly instantaneous sharing of ideas, knowledge, and skills have made collaborative work dramatically easier, with the help of collaborative software. Not only can a group cheaply communicate and share ideas but the wide reach of the Internet allows such groups more easily to form. An example of this is the free software movement, which has produced, among other things, Linux, Mozilla Firefox, and OpenOffice.org (later forked into LibreOffice). Internet chat, whether using an IRC chat room, an instant messaging system, or a social networking service, allows colleagues to stay in touch in a very convenient way while working at their computers during the day. Messages can be exchanged even more quickly and conveniently than via email. These systems may allow files to be exchanged, drawings and images to be shared, or voice and video contact between team members.\n\nContent management systems allow collaborating teams to work on shared sets of documents simultaneously without accidentally destroying each other's work. Business and project teams can share calendars as well as documents and other information. Such collaboration occurs in a wide variety of areas including scientific research, software development, conference planning, political activism and creative writing. Social and political collaboration is also becoming more widespread as both Internet access and computer literacy spread.\n\nThe Internet allows computer users to remotely access other computers and information stores easily from any access point. Access may be with computer security, i.e. authentication and encryption technologies, depending on the requirements. This is encouraging new ways of working from home, collaboration and information sharing in many industries. An accountant sitting at home can audit the books of a company based in another country, on a server situated in a third country that is remotely maintained by IT specialists in a fourth. These accounts could have been created by home-working bookkeepers, in other remote locations, based on information emailed to them from offices all over the world. Some of these things were possible before the widespread use of the Internet, but the cost of private leased lines would have made many of them infeasible in practice. An office worker away from their desk, perhaps on the other side of the world on a business trip or a holiday, can access their emails, access their data using cloud computing, or open a remote desktop session into their office PC using a secure virtual private network (VPN) connection on the Internet. This can give the worker complete access to all of their normal files and data, including email and other applications, while away from the office. It has been referred to among system administrators as the Virtual Private Nightmare, because it extends the secure perimeter of a corporate network into remote locations and its employees' homes.\n\nBy late 2010s Internet has been described as \"the main source of scientific information \"for the majority of the global North population\".\n\nSocial networking and entertainment \n\nMany people use the World Wide Web to access news, weather and sports reports, to plan and book vacations and to pursue their personal interests. People use chat, messaging and email to make and stay in touch with friends worldwide, sometimes in the same way as some previously had pen pals. Social networking services such as Facebook have created new ways to socialize and interact. Users of these sites are able to add a wide variety of information to pages, pursue common interests, and connect with others. It is also possible to find existing acquaintances, to allow communication among existing groups of people. Sites like LinkedIn foster commercial and business connections. YouTube and Flickr specialize in users' videos and photographs. Social networking services are also widely used by businesses and other organizations to promote their brands, to market to their customers and to encourage posts to \"go viral\". \"Black hat\" social media techniques are also employed by some organizations, such as spam accounts and astroturfing.\n\nA risk for both individuals and organizations writing posts (especially public posts) on social networking services, is that especially foolish or controversial posts occasionally lead to an unexpected and possibly large-scale backlash on social media from other Internet users. This is also a risk in relation to controversial offline behavior, if it is widely made known. The nature of this backlash can range widely from counter-arguments and public mockery, through insults and hate speech, to, in extreme cases, rape and death threats. The online disinhibition effect describes the tendency of many individuals to behave more stridently or offensively online than they would in person. A significant number of feminist women have been the target of various forms of harassment in response to posts they have made on social media, and Twitter in particular has been criticised in the past for not doing enough to aid victims of online abuse.\n\nFor organizations, such a backlash can cause overall brand damage, especially if reported by the media. However, this is not always the case, as any brand damage in the eyes of people with an opposing opinion to that presented by the organization could sometimes be outweighed by strengthening the brand in the eyes of others. Furthermore, if an organization or individual gives in to demands that others perceive as wrong-headed, that can then provoke a counter-backlash.\n\nSome websites, such as Reddit, have rules forbidding the posting of personal information of individuals (also known as doxxing), due to concerns about such postings leading to mobs of large numbers of Internet users directing harassment at the specific individuals thereby identified. In particular, the Reddit rule forbidding the posting of personal information is widely understood to imply that all identifying photos and names must be censored in Facebook screenshots posted to Reddit. However, the interpretation of this rule in relation to public Twitter posts is less clear, and in any case, like-minded people online have many other ways they can use to direct each other's attention to public social media posts they disagree with.\n\nChildren also face dangers online such as cyberbullying and approaches by sexual predators, who sometimes pose as children themselves. Children may also encounter material which they may find upsetting, or material that their parents consider to be not age-appropriate. Due to naivety, they may also post personal information about themselves online, which could put them or their families at risk unless warned not to do so. Many parents choose to enable Internet filtering or supervise their children's online activities in an attempt to protect their children from inappropriate material on the Internet. The most popular social networking services, such as Facebook and Twitter, commonly forbid users under the age of 13. However, these policies are typically trivial to circumvent by registering an account with a false birth date, and a significant number of children aged under 13 join such sites anyway. Social networking services for younger children, which claim to provide better levels of protection for children, also exist.\n\nThe Internet has been a major outlet for leisure activity since its inception, with entertaining social experiments such as MUDs and MOOs being conducted on university servers, and humor-related Usenet groups receiving much traffic. Many Internet forums have sections devoted to games and funny videos. The Internet pornography and online gambling industries have taken advantage of the World Wide Web. Although many governments have attempted to restrict both industries' use of the Internet, in general, this has failed to stop their widespread popularity.\n\nAnother area of leisure activity on the Internet is multiplayer gaming. This form of recreation creates communities, where people of all ages and origins enjoy the fast-paced world of multiplayer games. These range from MMORPG to first-person shooters, from role-playing video games to online gambling. While online gaming has been around since the 1970s, modern modes of online gaming began with subscription services such as GameSpy and MPlayer. Non-subscribers were limited to certain types of game play or certain games. Many people use the Internet to access and download music, movies and other works for their enjoyment and relaxation. Free and fee-based services exist for all of these activities, using centralized servers and distributed peer-to-peer technologies. Some of these sources exercise more care with respect to the original artists' copyrights than others.\n\nInternet usage has been correlated to users' loneliness. Lonely people tend to use the Internet as an outlet for their feelings and to share their stories with others, such as in the \"I am lonely will anyone speak to me\" thread.\n\nA 2017 book claimed that the Internet consolidates most aspects of human endeavor into singular arenas of which all of humanity are potential members and competitors, with fundamentally negative impacts on mental health as a result. While successes in each field of activity are pervasively visible and trumpeted, they are reserved for an extremely thin sliver of the world's most exceptional, leaving everyone else behind. Whereas, before the Internet, expectations of success in any field were supported by reasonable probabilities of achievement at the village, suburb, city or even state level, the same expectations in the Internet world are virtually certain to bring disappointment today: there is always someone else, somewhere on the planet, who can do better and take the now one-and-only top spot.\n\nCybersectarianism is a new organizational form which involves: \"highly dispersed small groups of practitioners that may remain largely anonymous within the larger social context and operate in relative secrecy, while still linked remotely to a larger network of believers who share a set of practices and texts, and often a common devotion to a particular leader. Overseas supporters provide funding and support; domestic practitioners distribute tracts, participate in acts of resistance, and share information on the internal situation with outsiders. Collectively, members and practitioners of such sects construct viable virtual communities of faith, exchanging personal testimonies and engaging in the collective study via email, on-line chat rooms, and web-based message boards.\" In particular, the British government has raised concerns about the prospect of young British Muslims being indoctrinated into Islamic extremism by material on the Internet, being persuaded to join terrorist groups such as the so-called \"Islamic State\", and then potentially committing acts of terrorism on returning to Britain after fighting in Syria or Iraq.\n\nCyberslacking can become a drain on corporate resources; the average UK employee spent 57 minutes a day surfing the Web while at work, according to a 2003 study by Peninsula Business Services. Internet addiction disorder is excessive computer use that interferes with daily life. Nicholas G. Carr believes that Internet use has other effects on individuals, for instance improving skills of scan-reading and interfering with the deep thinking that leads to true creativity.\n\nElectronic business \nElectronic business (e-business) encompasses business processes spanning the entire value chain: purchasing, supply chain management, marketing, sales, customer service, and business relationship. E-commerce seeks to add revenue streams using the Internet to build and enhance relationships with clients and partners. According to International Data Corporation, the size of worldwide e-commerce, when global business-to-business and -consumer transactions are combined, equate to $16\u00a0trillion for 2013. A report by Oxford Economics added those two together to estimate the total size of the digital economy at $20.4\u00a0trillion, equivalent to roughly 13.8% of global sales.\n\nWhile much has been written of the economic advantages of Internet-enabled commerce, there is also evidence that some aspects of the Internet such as maps and location-aware services may serve to reinforce economic inequality and the digital divide. Electronic commerce may be responsible for consolidation and the decline of mom-and-pop, brick and mortar businesses resulting in increases in income inequality.\n\nAuthor Andrew Keen, a long-time critic of the social transformations caused by the Internet, has focused on the economic effects of consolidation from Internet businesses. Keen cites a 2013 Institute for Local Self-Reliance report saying brick-and-mortar retailers employ 47 people for every $10\u00a0million in sales while Amazon employs only 14. Similarly, the 700-employee room rental start-up Airbnb was valued at $10\u00a0billion in 2014, about half as much as Hilton Worldwide, which employs 152,000 people. At that time, Uber employed 1,000 full-time employees and was valued at $18.2\u00a0billion, about the same valuation as Avis Rent a Car and The Hertz Corporation combined, which together employed almost 60,000 people.\n\nTelecommuting \nTelecommuting is the performance within a traditional worker and employer relationship when it is facilitated by tools such as groupware, virtual private networks, conference calling, videoconferencing, and VoIP so that work may be performed from any location, most conveniently the worker's home. It can be efficient and useful for companies as it allows workers to communicate over long distances, saving significant amounts of travel time and cost. As broadband Internet connections become commonplace, more workers have adequate bandwidth at home to use these tools to link their home to their corporate intranet and internal communication networks.\n\nCollaborative publishing \nWikis have also been used in the academic community for sharing and dissemination of information across institutional and international boundaries. In those settings, they have been found useful for collaboration on grant writing, strategic planning, departmental documentation, and committee work. The United States Patent and Trademark Office uses a wiki to allow the public to collaborate on finding prior art relevant to examination of pending patent applications. Queens, New York has used a wiki to allow citizens to collaborate on the design and planning of a local park. The English Wikipedia has the largest user base among wikis on the World Wide Web and ranks in the top 10 among all Web sites in terms of traffic.\n\nPolitics and political revolutions \n\nThe Internet has achieved new relevance as a political tool. The presidential campaign of Howard Dean in 2004 in the United States was notable for its success in soliciting donation via the Internet. Many political groups use the Internet to achieve a new method of organizing for carrying out their mission, having given rise to Internet activism, most notably practiced by rebels in the Arab Spring. The New York Times suggested that social media websites, such as Facebook and Twitter, helped people organize the political revolutions in Egypt, by helping activists organize protests, communicate grievances, and disseminate information.\n\nMany have understood the Internet as an extension of the Habermasian notion of the public sphere, observing how network communication technologies provide something like a global civic forum. However, incidents of politically motivated Internet censorship have now been recorded in many countries, including western democracies.\n\nPhilanthropy \nThe spread of low-cost Internet access in developing countries has opened up new possibilities for peer-to-peer charities, which allow individuals to contribute small amounts to charitable projects for other individuals. Websites, such as DonorsChoose and GlobalGiving, allow small-scale donors to direct funds to individual projects of their choice. A popular twist on Internet-based philanthropy is the use of peer-to-peer lending for charitable purposes. Kiva pioneered this concept in 2005, offering the first web-based service to publish individual loan profiles for funding. Kiva raises funds for local intermediary microfinance organizations that post stories and updates on behalf of the borrowers. Lenders can contribute as little as $25 to loans of their choice, and receive their money back as borrowers repay. Kiva falls short of being a pure peer-to-peer charity, in that loans are disbursed before being funded by lenders and borrowers do not communicate with lenders themselves.\n\nSecurity \n\nInternet resources, hardware, and software components are the target of criminal or malicious attempts to gain unauthorized control to cause interruptions, commit fraud, engage in blackmail or access private information.\n\nMalware\nMalware is malicious software used and distributed via the Internet. It includes computer viruses which are copied with the help of humans, computer worms which copy themselves automatically, software for denial of service attacks, ransomware, botnets, and spyware that reports on the activity and typing of users. Usually, these activities constitute cybercrime. Defense theorists have also speculated about the possibilities of hackers using cyber warfare using similar methods on a large scale.\n\nSurveillance \n\nThe vast majority of computer surveillance involves the monitoring of data and traffic on the Internet. In the United States for example, under the Communications Assistance For Law Enforcement Act, all phone calls and broadband Internet traffic (emails, web traffic, instant messaging, etc.) are required to be available for unimpeded real-time monitoring by Federal law enforcement agencies. Packet capture is the monitoring of data traffic on a computer network. Computers communicate over the Internet by breaking up messages (emails, images, videos, web pages, files, etc.) into small chunks called \"packets\", which are routed through a network of computers, until they reach their destination, where they are assembled back into a complete \"message\" again. Packet Capture Appliance intercepts these packets as they are traveling through the network, in order to examine their contents using other programs. A packet capture is an information gathering tool, but not an analysis tool. That is it gathers \"messages\" but it does not analyze them and figure out what they mean. Other programs are needed to perform traffic analysis and sift through intercepted data looking for important/useful information. Under the Communications Assistance For Law Enforcement Act all U.S. telecommunications providers are required to install packet sniffing technology to allow Federal law enforcement and intelligence agencies to intercept all of their customers' broadband Internet and VoIP traffic.\n\nThe large amount of data gathered from packet capturing requires surveillance software that filters and reports relevant information, such as the use of certain words or phrases, the access of certain types of web sites, or communicating via email or chat with certain parties. Agencies, such as the Information Awareness Office, NSA, GCHQ and the FBI, spend billions of dollars per year to develop, purchase, implement, and operate systems for interception and analysis of data. Similar systems are operated by Iranian secret police to identify and suppress dissidents. The required hardware and software was allegedly installed by German Siemens AG and Finnish Nokia.\n\nCensorship \n\nSome governments, such as those of Burma, Iran, North Korea, Mainland China, Saudi Arabia and the United Arab Emirates, restrict access to content on the Internet within their territories, especially to political and religious content, with domain name and keyword filters.\n\nIn Norway, Denmark, Finland, and Sweden, major Internet service providers have voluntarily agreed to restrict access to sites listed by authorities. While this list of forbidden resources is supposed to contain only known child pornography sites, the content of the list is secret. Many countries, including the United States, have enacted laws against the possession or distribution of certain material, such as child pornography, via the Internet, but do not mandate filter software. Many free or commercially available software programs, called content-control software are available to users to block offensive websites on individual computers or networks, in order to limit access by children to pornographic material or depiction of violence.\n\nPerformance \nAs the Internet is a heterogeneous network, the physical characteristics, including for example the data transfer rates of connections, vary widely. It exhibits emergent phenomena that depend on its large-scale organization.\n\nTraffic volume\n\nThe volume of Internet traffic is difficult to measure, because no single point of measurement exists in the multi-tiered, non-hierarchical topology. Traffic data may be estimated from the aggregate volume through the peering points of the Tier 1 network providers, but traffic that stays local in large provider networks may not be accounted for.\n\nOutages \nAn Internet blackout or outage can be caused by local signalling interruptions. Disruptions of submarine communications cables may cause blackouts or slowdowns to large areas, such as in the 2008 submarine cable disruption. Less-developed countries are more vulnerable due to a small number of high-capacity links. Land cables are also vulnerable, as in 2011 when a woman digging for scrap metal severed most connectivity for the nation of Armenia. Internet blackouts affecting almost entire countries can be achieved by governments as a form of Internet censorship, as in the blockage of the Internet in Egypt, whereby approximately 93% of networks were without access in 2011 in an attempt to stop mobilization for anti-government protests.\n\nEnergy use \nEstimates of the Internet's electricity usage have been the subject of controversy, according to a 2014 peer-reviewed research paper that found claims differing by a factor of 20,000 published in the literature during the preceding decade, ranging from 0.0064 kilowatt hours per gigabyte transferred (kWh/GB) to 136 kWh/GB. The researchers attributed these discrepancies mainly to the year of reference (i.e. whether efficiency gains over time had been taken into account) and to whether \"end devices such as personal computers and servers are included\" in the analysis.\n\nIn 2011, academic researchers estimated the overall energy used by the Internet to be between 170 and 307 GW, less than two percent of the energy used by humanity. This estimate included the energy needed to build, operate, and periodically replace the estimated 750\u00a0million laptops, a billion smart phones and 100\u00a0million servers worldwide as well as the energy that routers, cell towers, optical switches, Wi-Fi transmitters and cloud storage devices use when transmitting Internet traffic. According to a non-peer reviewed study published in 2018 by The Shift Project (a French think tank funded by corporate sponsors), nearly 4% of global CO2 emissions could be attributed to global data transfer and the necessary infrastructure. The study also said that online video streaming alone accounted for 60% of this data transfer and therefore contributed to over 300\u00a0million tons of CO2 emission per year, and argued for new \"digital sobriety\" regulations restricting the use and size of video files.\n\nSee also \n\n Crowdfunding\n Crowdsourcing\n Darknet\n Deep web\n Freenet\n Internet industry jargon\n Index of Internet-related articles\n Internet metaphors\n Internet video\n \"Internets\"\n Open Systems Interconnection\n Outline of the Internet\n\nNotes\n\nReferences\n\nSources\n\nFurther reading \n First Monday, a peer-reviewed journal on the Internet by the University Library of the University of Illinois at Chicago, \n The Internet Explained, Vincent Zegna & Mike Pepper, Sonet Digital, November 2005, pp.\u00a01\u20137.\n\nExternal links \n\n The Internet Society\n  Living Internet, Internet history and related information, including information from many creators of the Internet\n\n \n1969 establishments in the United States\nAmerican inventions\nComputer-related introductions in 1969\nComputer-related introductions in 1989\nCultural globalization\nDigital technology\nMass media technology\nNew media\nPromotion and marketing communications\nPublic services\nTelegraphy\nTransport systems\nVirtual reality\nMain topic articles",
  "Life": "Life is a characteristic that distinguishes physical entities that have biological processes, such as signaling and self-sustaining processes, from those that do not, either because such functions have ceased (they have died) or because they never had such functions and are classified as inanimate. Various forms of life exist, such as plants, animals, fungi, protists, archaea, and bacteria. Biology is the science that studies life.\n\nThere is currently no consensus regarding the definition of life. One popular definition is that organisms are open systems that maintain homeostasis, are composed of cells, have a life cycle, undergo metabolism, can grow, adapt to their environment, respond to stimuli, reproduce and evolve. Other definitions sometimes include non-cellular life forms such as viruses and viroids.\n\nAbiogenesis is the natural process of life arising from non-living matter, such as simple organic compounds. The prevailing scientific hypothesis is that the transition from non-living to living entities was not a single event, but a gradual process of increasing complexity. Life on Earth first appeared as early as 4.28 billion years ago, soon after ocean formation 4.41 billion years ago, and not long after the formation of Earth 4.54 billion years ago. The earliest known life forms are bacteria. Life on Earth is probably descended from an RNA world, although RNA-based life may not have been the first life to have existed. Metal-Binding Proteins that allowed biological electron transfer may have evolved from minerals. The classic 1952 Miller\u2013Urey experiment and similar research demonstrated that most amino acids, the chemical constituents of the proteins used in all living organisms, can be synthesized from inorganic compounds under conditions intended to replicate those of the early Earth. Complex organic molecules occur in the Solar System and in interstellar space, and these molecules may have provided starting material for the development of life on Earth.\n\nSince its primordial beginnings, life on Earth has changed its environment on a geologic time scale, but it has also adapted to survive in most ecosystems and conditions. Some microorganisms, called extremophiles, thrive in physically or geochemically extreme environments that are detrimental to most other life on Earth. The cell is considered the structural and functional unit of life. There are two kinds of cells, prokaryotic and eukaryotic, both of which consist of cytoplasm enclosed within a membrane and contain many biomolecules such as proteins and nucleic acids. Cells reproduce through a process of cell division, in which the parent cell divides into two or more daughter cells.\n\nIn the past, there have been many attempts to define what is meant by \"life\" through obsolete concepts such as Odic force, hylomorphism, spontaneous generation and vitalism, that have now been disproved by biological discoveries. Aristotle is considered to be the first person to classify organisms. Later, Carl Linnaeus introduced his system of binomial nomenclature for the classification of species. Eventually new groups and categories of life were discovered, such as cells and microorganisms, forcing significant revisions of the structure of relationships between living organisms. Though currently only known on Earth, life need not be restricted to it, and many scientists speculate in the existence of extraterrestrial life. Artificial life is a computer simulation or human-made reconstruction of any aspect of life, which is often used to examine systems related to natural life.\n\nDeath is the permanent termination of all biological processes which sustain an organism, and as such, is the end of its life. Extinction is the term describing the dying-out of a group or taxon, usually a species. Fossils are the preserved remains or traces of organisms.\n\nDefinitions\nThe definition of life has long been a challenge for scientists and philosophers. This is partially because life is a process, not a substance. This is complicated by a lack of knowledge of the characteristics of living entities, if any, that may have developed outside of Earth. Philosophical definitions of life have also been put forward, with similar difficulties on how to distinguish living things from the non-living. Legal definitions of life have also been described and debated, though these generally focus on the decision to declare a human dead, and the legal ramifications of this decision. As many as 123 definitions of life have been compiled. One definition seems to be favored by NASA: \"a self-sustaining chemical system capable of Darwinian evolution\". More simply, life is, \"matter that can reproduce itself and evolve as survival dictates\".\n\nBiology\n\nSince there is no unequivocal definition of life, most current definitions in biology are descriptive. Life is considered a characteristic of something that preserves, furthers or reinforces its existence in the given environment. This characteristic exhibits all or most of the following traits:\n Homeostasis: regulation of the internal environment to maintain a constant state; for example, sweating to reduce temperature\n Organization: being structurally composed of one or more cells\u00a0\u2013 the basic units of life\n Metabolism: transformation of energy by converting chemicals and energy into cellular components (anabolism) and decomposing organic matter (catabolism). Living things require energy to maintain internal organization (homeostasis) and to produce the other phenomena associated with life.\n Growth: maintenance of a higher rate of anabolism than catabolism. A growing organism increases in size in all of its parts, rather than simply accumulating matter.\n Adaptation: the ability to change over time in response to the environment. This ability is fundamental to the process of evolution and is determined by the organism's heredity, diet, and external factors.\n Response to stimuli: a response can take many forms, from the contraction of a unicellular organism to external chemicals, to complex reactions involving all the senses of multicellular organisms. A response is often expressed by motion; for example, the leaves of a plant turning toward the sun (phototropism), and chemotaxis.\n Reproduction: the ability to produce new individual organisms, either asexually from a single parent organism or sexually from two parent organisms.\n\nThese complex processes, called physiological functions, have underlying physical and chemical bases, as well as signaling and control mechanisms that are essential to maintaining life.\n\nAlternative definitions\n\nFrom a physics perspective, living beings are thermodynamic systems with an organized molecular structure that can reproduce itself and evolve as survival dictates. Thermodynamically, life has been described as an open system which makes use of gradients in its surroundings to create imperfect copies of itself. Another way of putting this is to define life as \"a self-sustained chemical system capable of undergoing Darwinian evolution\", a definition adopted by a NASA committee attempting to define life for the purposes of exobiology, based on a suggestion by Carl Sagan. A major strength of this definition is that it distinguishes life by the evolutionary process rather than its chemical composition.\n\nOthers take a systemic viewpoint that does not necessarily depend on molecular chemistry. One systemic definition of life is that living things are self-organizing and autopoietic (self-producing). Variations of this definition include Stuart Kauffman's definition as an autonomous agent or a multi-agent system capable of reproducing itself or themselves, and of completing at least one thermodynamic work cycle. This definition is extended by the apparition of novel functions over time.\n\nViruses\n\nWhether or not viruses should be considered as alive is controversial. They are most often considered as just gene coding replicators rather than forms of life. They have been described as \"organisms at the edge of life\" because they possess genes, evolve by natural selection, and replicate by making multiple copies of themselves through self-assembly. However, viruses do not metabolize and they require a host cell to make new products. Virus self-assembly within host cells has implications for the study of the origin of life, as it may support the hypothesis that life could have started as self-assembling organic molecules.\n\nBiophysics\n\nTo reflect the minimum phenomena required, other biological definitions of life have been proposed, with many of these being based upon chemical systems. Biophysicists have commented that living things function on negative entropy. In other words, living processes can be viewed as a delay of the spontaneous diffusion or dispersion of the internal energy of biological molecules towards more potential microstates. In more detail, according to physicists such as John Bernal, Erwin Schr\u00f6dinger, Eugene Wigner, and John Avery, life is a member of the class of phenomena that are open or continuous systems able to decrease their internal entropy at the expense of substances or free energy taken in from the environment and subsequently rejected in a degraded form. The emergence and increasing popularity of biomimetics or biomimicry (the design and production of materials, structures, and systems that are modeled on biological entities and processes) will likely redefine the boundary between natural and artificial life.\n\nLiving systems theories\nLiving systems are open self-organizing living things that interact with their environment. These systems are maintained by flows of information, energy, and matter.\n\nBudisa, Kubyshkin and Schmidt defined cellular life as an organizational unit resting on four pillars/cornerstones: (i) energy, (ii) metabolism, (iii) information and (iv) form. This system is able to regulate and control metabolism and energy supply and contains at least one subsystem that functions as an information carrier (genetic information). Cells as self-sustaining units are parts of different populations that are involved in the unidirectional and irreversible open-ended process known as evolution.\n\nSome scientists have proposed in the last few decades that a general living systems theory is required to explain the nature of life. Such a general theory would arise out of the ecological and biological sciences and attempt to map general principles for how all living systems work. Instead of examining phenomena by attempting to break things down into components, a general living systems theory explores phenomena in terms of dynamic patterns of the relationships of organisms with their environment.\n\nGaia hypothesis\n\nThe idea that Earth is alive is found in philosophy and religion, but the first scientific discussion of it was by the Scottish scientist James Hutton. In 1785, he stated that Earth was a superorganism and that its proper study should be physiology. Hutton is considered the father of geology, but his idea of a living Earth was forgotten in the intense reductionism of the 19th century. The Gaia hypothesis, proposed in the 1960s by scientist James Lovelock, suggests that life on Earth functions as a single organism that defines and maintains environmental conditions necessary for its survival. This hypothesis served as one of the foundations of the modern Earth system science.\n\nNonfractionability\nRobert Rosen devoted a large part of his career, from 1958 onwards, to developing a comprehensive theory of life as a self-organizing complex system, \"closed to efficient causation\" He defined a system component as \"a unit of organization; a part with a function, i.e., a definite relation between part and whole.\" He identified the \"nonfractionability of components in an organism\" as the fundamental difference between living systems and \"biological machines.\" He summarized his views in his book Life Itself. Similar ideas may be found in the book Living Systems by James Grier Miller.\n\nLife as a property of ecosystems\nA systems view of life treats environmental fluxes and biological fluxes together as a \"reciprocity of influence,\" and a reciprocal relation with environment is arguably as important for understanding life as it is for understanding ecosystems. As Harold J. Morowitz (1992) explains it, life is a property of an ecological system rather than a single organism or species. He argues that an ecosystemic definition of life is preferable to a strictly biochemical or physical one. Robert Ulanowicz (2009) highlights mutualism as the key to understand the systemic, order-generating behavior of life and ecosystems.\n\nComplex systems biology\n\nComplex systems biology (CSB) is a field of science that studies the emergence of complexity in functional organisms from the viewpoint of dynamic systems theory. The latter is also often called systems biology and aims to understand the most fundamental aspects of life. A closely related approach to CSB and systems biology called relational biology is concerned mainly with understanding life processes in terms of the most important relations, and categories of such relations among the essential functional components of organisms; for multicellular organisms, this has been defined as \"categorical biology\", or a model representation of organisms as a category theory of biological relations, as well as an algebraic topology of the functional organization of living organisms in terms of their dynamic, complex networks of metabolic, genetic, and epigenetic processes and signaling pathways. Alternative but closely related approaches focus on the interdependence of constraints, where constraints can be either molecular, such as enzymes, or macroscopic, such as the geometry of a bone or of the vascular system.\n\nDarwinian dynamic\n\nIt has also been argued that the evolution of order in living systems and certain physical systems obeys a common fundamental principle termed the Darwinian dynamic. The Darwinian dynamic was formulated by first considering how macroscopic order is generated in a simple non-biological system far from thermodynamic equilibrium, and then extending consideration to short, replicating RNA molecules. The underlying order-generating process was concluded to be basically similar for both types of systems.\n\nOperator theory\nAnother systemic definition called the operator theory proposes that \"life is a general term for the presence of the typical closures found in organisms; the typical closures are a membrane and an autocatalytic set in the cell\" and that an organism is any system with an organisation that complies with an operator type that is at least as complex as the cell. Life can also be modeled as a network of inferior negative feedbacks of regulatory mechanisms subordinated to a superior positive feedback formed by the potential of expansion and reproduction.\n\nHistory of study\n\nMaterialism\n\nSome of the earliest theories of life were materialist, holding that all that exists is matter, and that life is merely a complex form or arrangement of matter. Empedocles (430 BC) argued that everything in the universe is made up of a combination of four eternal \"elements\" or \"roots of all\": earth, water, air, and fire. All change is explained by the arrangement and rearrangement of these four elements. The various forms of life are caused by an appropriate mixture of elements.\n\nDemocritus (460 BC) thought that the essential characteristic of life is having a soul (psyche). Like other ancient writers, he was attempting to explain what makes something a living thing. His explanation was that fiery atoms make a soul in exactly the same way atoms and void account for any other thing. He elaborates on fire because of the apparent connection between life and heat, and because fire moves.\n\nThe mechanistic materialism that originated in ancient Greece was revived and revised by the French philosopher Ren\u00e9 Descartes (1596\u20131650), who held that animals and humans were assemblages of parts that together functioned as a machine. This idea was developed further by Julien Offray de La Mettrie (1709\u20131750) in his book L'Homme Machine.\n\nIn the 19th century, the advances in cell theory in biological science encouraged this view. The evolutionary theory of Charles Darwin (1859) is a mechanistic explanation for the origin of species by means of natural selection.\n\nAt the beginning of the 20th century St\u00e9phane Leduc (1853\u20131939) promoted the idea that biological processes could be understood in terms of physics and chemistry, and that their growth resembled that of inorganic crystals immersed in solutions of sodium silicate. His ideas, set out in his book La biologie synth\u00e9tique was widely dismissed during his lifetime, but has incurred a resurgence of interest in the work of Russell, Barge and colleagues.\n\nHylomorphism\n\nHylomorphism is a theory first expressed by the Greek philosopher Aristotle (322 BC). The application of hylomorphism to biology was important to Aristotle, and biology is extensively covered in his extant writings. In this view, everything in the material universe has both matter and form, and the form of a living thing is its soul (Greek psyche, Latin anima). There are three kinds of souls: the vegetative soul of plants, which causes them to grow and decay and nourish themselves, but does not cause motion and sensation; the animal soul, which causes animals to move and feel; and the rational soul, which is the source of consciousness and reasoning, which (Aristotle believed) is found only in man. Each higher soul has all of the attributes of the lower ones. Aristotle believed that while matter can exist without form, form cannot exist without matter, and that therefore the soul cannot exist without the body.\n\nThis account is consistent with teleological explanations of life, which account for phenomena in terms of purpose or goal-directedness. Thus, the whiteness of the polar bear's coat is explained by its purpose of camouflage. The direction of causality (from the future to the past) is in contradiction with the scientific evidence for natural selection, which explains the consequence in terms of a prior cause. Biological features are explained not by looking at future optimal results, but by looking at the past evolutionary history of a species, which led to the natural selection of the features in question.\n\nSpontaneous generation \n\nSpontaneous generation was the belief that living organisms can form without descent from similar organisms. Typically, the idea was that certain forms such as fleas could arise from inanimate matter such as dust or the supposed seasonal generation of mice and insects from mud or garbage.\n\nThe theory of spontaneous generation was proposed by Aristotle, who compiled and expanded the work of prior natural philosophers and the various ancient explanations of the appearance of organisms; it was considered the best explanation for two millennia. It was decisively dispelled by the experiments of Louis Pasteur in 1859, who expanded upon the investigations of predecessors such as Francesco Redi. Disproof of the traditional ideas of spontaneous generation is no longer controversial among biologists.\n\nVitalism\n\nVitalism is the belief that the life-principle is non-material. This originated with Georg Ernst Stahl (17th century), and remained popular until the middle of the 19th century. It appealed to philosophers such as Henri Bergson, Friedrich Nietzsche, and Wilhelm Dilthey, anatomists like Xavier Bichat, and chemists like Justus von Liebig. Vitalism included the idea that there was a fundamental difference between organic and inorganic material, and the belief that organic material can only be derived from living things. This was disproved in 1828, when Friedrich W\u00f6hler prepared urea from inorganic materials. This W\u00f6hler synthesis is considered the starting point of modern organic chemistry. It is of historical significance because for the first time an organic compound was produced in inorganic reactions.\n\nDuring the 1850s, Hermann von Helmholtz, anticipated by Julius Robert von Mayer, demonstrated that no energy is lost in muscle movement, suggesting that there were no \"vital forces\" necessary to move a muscle. These results led to the abandonment of scientific interest in vitalistic theories, especially after Buchner's demonstration that alcoholic fermentation could occur in cell-free extracts of yeast.\nNonetheless, the belief still exists in pseudoscientific theories such as homeopathy, which interprets diseases and sickness as caused by disturbances in a hypothetical vital force or life force.\n\nOrigin\n\nThe age of Earth is about 4.54 billion years. Evidence suggests that life on Earth has existed for at least 3.5\u00a0billion years, with the oldest physical traces of life dating back 3.7 billion years; however, some hypotheses, such as Late Heavy Bombardment, suggest that life on Earth may have started even earlier, as early as 4.1\u20134.4 billion years ago, and the chemistry leading to life may have begun shortly after the Big Bang, 13.8 billion years ago, during an epoch when the universe was only 10\u201317 million years old.\n\nMore than 99% of all species of life forms, amounting to over five billion species, that ever lived on Earth are estimated to be extinct.\n\nAlthough the number of Earth's catalogued species of lifeforms is between 1.2 million and 2 million, the total number of species in the planet is uncertain. Estimates range from 8 million to 100 million, with a more narrow range between 10 and 14 million, but it may be as high as 1 trillion (with only one-thousandth of one percent of the species described) according to studies realized in May 2016. The total number of related DNA base pairs on Earth is estimated at 5.0 x 1037 and weighs 50 billion tonnes. In comparison, the total mass of the biosphere has been estimated to be as much as 4 TtC (trillion tons of carbon). In July 2016, scientists reported identifying a set of 355 genes from the Last Universal Common Ancestor (LUCA) of all organisms living on Earth.\n\nAll known life forms share fundamental molecular mechanisms, reflecting their common descent; based on these observations, hypotheses on the origin of life attempt to find a mechanism explaining the formation of a universal common ancestor, from simple organic molecules via pre-cellular life to protocells and metabolism. Models have been divided into \"genes-first\" and \"metabolism-first\" categories, but a recent trend is the emergence of hybrid models that combine both categories.\n\nThere is no current scientific consensus as to how life originated. However, most accepted scientific models build on the Miller\u2013Urey experiment and the work of Sidney Fox, which show that conditions on the primitive Earth favored chemical reactions that synthesize amino acids and other organic compounds from inorganic precursors, and phospholipids spontaneously form lipid bilayers, the basic structure of a cell membrane.\n\nLiving organisms synthesize proteins, which are polymers of amino acids using instructions encoded by deoxyribonucleic acid (DNA). Protein synthesis entails intermediary ribonucleic acid (RNA) polymers. One possibility for how life began is that genes originated first, followed by proteins; the alternative being that proteins came first and then genes.\n\nHowever, because genes and proteins are both required to produce the other, the problem of considering which came first is like that of the chicken or the egg. Most scientists have adopted the hypothesis that because of this, it is unlikely that genes and proteins arose independently.\n\nTherefore, a possibility, first suggested by Francis Crick, is that the first life was based on RNA, which has the DNA-like properties of information storage and the catalytic properties of some proteins. This is called the RNA world hypothesis, and it is supported by the observation that many of the most critical components of cells (those that evolve the slowest) are composed mostly or entirely of RNA. Also, many critical cofactors (ATP, Acetyl-CoA, NADH, etc.) are either nucleotides or substances clearly related to them. The catalytic properties of RNA had not yet been demonstrated when the hypothesis was first proposed, but they were confirmed by Thomas Cech in 1986.\n\nOne issue with the RNA world hypothesis is that synthesis of RNA from simple inorganic precursors is more difficult than for other organic molecules. One reason for this is that RNA precursors are very stable and react with each other very slowly under ambient conditions, and it has also been proposed that living organisms consisted of other molecules before RNA. However, the successful synthesis of certain RNA molecules under the conditions that existed prior to life on Earth has been achieved by adding alternative precursors in a specified order with the precursor phosphate present throughout the reaction. This study makes the RNA world hypothesis more plausible.\n\nGeological findings in 2013 showed that reactive phosphorus species (like phosphite) were in abundance in the ocean before 3.5 Ga, and that Schreibersite easily reacts with aqueous glycerol to generate phosphite and glycerol 3-phosphate. It is hypothesized that Schreibersite-containing meteorites from the Late Heavy Bombardment could have provided early reduced phosphorus, which could react with prebiotic organic molecules to form phosphorylated biomolecules, like RNA.\n\nIn 2009, experiments demonstrated Darwinian evolution of a two-component system of RNA enzymes (ribozymes) in vitro. The work was performed in the laboratory of Gerald Joyce, who stated \"This is the first example, outside of biology, of evolutionary adaptation in a molecular genetic system.\"\n\nPrebiotic compounds may have originated extraterrestrially. NASA findings in 2011, based on studies with meteorites found on Earth, suggest DNA and RNA components (adenine, guanine and related organic molecules) may be formed in outer space.\n\nIn March 2015, NASA scientists reported that, for the first time, complex DNA and RNA organic compounds of life, including uracil, cytosine and thymine, have been formed in the laboratory under outer space conditions, using starting chemicals, such as pyrimidine, found in meteorites. Pyrimidine, like polycyclic aromatic hydrocarbons (PAHs), the most carbon-rich chemical found in the universe, may have been formed in red giants or in interstellar dust and gas clouds, according to the scientists.\n\nAccording to the panspermia hypothesis, microscopic life\u2014distributed by meteoroids, asteroids and other small Solar System bodies\u2014may exist throughout the universe.\n\nEnvironmental conditions\n\nThe diversity of life on Earth is a result of the dynamic interplay between genetic opportunity, metabolic capability, environmental challenges, and symbiosis. For most of its existence, Earth's habitable environment has been dominated by microorganisms and subjected to their metabolism and evolution. As a consequence of these microbial activities, the physical-chemical environment on Earth has been changing on a geologic time scale, thereby affecting the path of evolution of subsequent life. For example, the release of molecular oxygen by cyanobacteria as a by-product of photosynthesis induced global changes in the Earth's environment. Because oxygen was toxic to most life on Earth at the time, this posed novel evolutionary challenges, and ultimately resulted in the formation of Earth's major animal and plant species. This interplay between organisms and their environment is an inherent feature of living systems.\n\nBiosphere\n\nThe biosphere is the global sum of all ecosystems. It can also be termed as the zone of life on Earth, a closed system (apart from solar and cosmic radiation and heat from the interior of the Earth), and largely self-regulating. By the most general biophysiological definition, the biosphere is the global ecological system integrating all living beings and their relationships, including their interaction with the elements of the lithosphere, geosphere, hydrosphere, and atmosphere.\n\nLife forms live in every part of the Earth's biosphere, including soil, hot springs, inside rocks at least  deep underground, the deepest parts of the ocean, and at least  high in the atmosphere. Under certain test conditions, life forms have been observed to thrive in the near-weightlessness of space and to survive in the vacuum of outer space. Life forms appear to thrive in the Mariana Trench, the deepest spot in the Earth's oceans. Other researchers reported related studies that life forms thrive inside rocks up to  below the sea floor under  of ocean off the coast of the northwestern United States, as well as  beneath the seabed off Japan. In August 2014, scientists confirmed the existence of life forms living  below the ice of Antarctica. According to one researcher, \"You can find microbes everywhere\u2014they're extremely adaptable to conditions, and survive wherever they are.\"\n\nThe biosphere is postulated to have evolved, beginning with a process of biopoesis (life created naturally from non-living matter, such as simple organic compounds) or biogenesis (life created from living matter), at least some 3.5 billion years ago. The earliest evidence for life on Earth includes biogenic graphite found in 3.7 billion-year-old metasedimentary rocks from Western Greenland and microbial mat fossils found in 3.48 billion-year-old sandstone from Western Australia. More recently, in 2015, \"remains of biotic life\" were found in 4.1 billion-year-old rocks in Western Australia. In 2017, putative fossilized microorganisms (or microfossils) were announced to have been discovered in hydrothermal vent precipitates in the Nuvvuagittuq Belt of Quebec, Canada that were as old as 4.28 billion years, the oldest record of life on earth, suggesting \"an almost instantaneous emergence of life\" after ocean formation 4.4 billion years ago, and not long after the formation of the Earth 4.54 billion years ago. According to biologist Stephen Blair Hedges, \"If life arose relatively quickly on Earth\u00a0... then it could be common in the universe.\"\n\nIn a general sense, biospheres are any closed, self-regulating systems containing ecosystems. This includes artificial biospheres such as Biosphere 2 and BIOS-3, and potentially ones on other planets or moons.\n\nRange of tolerance\n\nThe inert components of an ecosystem are the physical and chemical factors necessary for life\u2014energy (sunlight or chemical energy), water, heat, atmosphere, gravity, nutrients, and ultraviolet solar radiation protection. In most ecosystems, the conditions vary during the day and from one season to the next. To live in most ecosystems, then, organisms must be able to survive a range of conditions, called the \"range of tolerance.\" Outside that are the \"zones of physiological stress,\" where the survival and reproduction are possible but not optimal. Beyond these zones are the \"zones of intolerance,\" where survival and reproduction of that organism is unlikely or impossible. Organisms that have a wide range of tolerance are more widely distributed than organisms with a narrow range of tolerance.\n\nExtremophiles\n\nTo survive, selected microorganisms can assume forms that enable them to withstand freezing, complete desiccation, starvation, high levels of radiation exposure, and other physical or chemical challenges. These microorganisms may survive exposure to such conditions for weeks, months, years, or even centuries. Extremophiles are microbial life forms that thrive outside the ranges where life is commonly found. They excel at exploiting uncommon sources of energy. While all organisms are composed of nearly identical molecules, evolution has enabled such microbes to cope with this wide range of physical and chemical conditions. Characterization of the structure and metabolic diversity of microbial communities in such extreme environments is ongoing.\n\nMicrobial life forms thrive even in the Mariana Trench, the deepest spot in the Earth's oceans. Microbes also thrive inside rocks up to  below the sea floor under  of ocean. Expeditions of the International Ocean Discovery Program found unicellular life in 120\u00b0C sediment that is 1.2 km below seafloor in the Nankai Trough subduction zone.\n\nInvestigation of the tenacity and versatility of life on Earth, as well as an understanding of the molecular systems that some organisms utilize to survive such extremes, is important for the search for life beyond Earth. For example, lichen could survive for a month in a simulated Martian environment.\n\nChemical elements\nAll life forms require certain core chemical elements needed for biochemical functioning. These include carbon, hydrogen, nitrogen, oxygen, phosphorus, and sulfur\u2014the elemental macronutrients for all organisms\u2014often represented by the acronym CHNOPS. Together these make up nucleic acids, proteins and lipids, the bulk of living matter. Five of these six elements comprise the chemical components of DNA, the exception being sulfur. The latter is a component of the amino acids cysteine and methionine. The most biologically abundant of these elements is carbon, which has the desirable attribute of forming multiple, stable covalent bonds. This allows carbon-based (organic) molecules to form an immense variety of chemical arrangements. Alternative hypothetical types of biochemistry have been proposed that eliminate one or more of these elements, swap out an element for one not on the list, or change required chiralities or other chemical properties.\n\nDNA\n\nDeoxyribonucleic acid is a molecule that carries most of the genetic instructions used in the growth, development, functioning and reproduction of all known living organisms and many viruses. DNA and RNA are nucleic acids; alongside proteins and complex carbohydrates, they are one of the three major types of macromolecule that are essential for all known forms of life. Most DNA molecules consist of two biopolymer strands coiled around each other to form a double helix. The two DNA strands are known as polynucleotides since they are composed of simpler units called nucleotides. Each nucleotide is composed of a nitrogen-containing nucleobase\u2014either cytosine (C), guanine (G), adenine (A), or thymine (T)\u2014as well as a sugar called deoxyribose and a phosphate group. The nucleotides are joined to one another in a chain by covalent bonds between the sugar of one nucleotide and the phosphate of the next, resulting in an alternating sugar-phosphate backbone. According to base pairing rules (A with T, and C with G), hydrogen bonds bind the nitrogenous bases of the two separate polynucleotide strands to make double-stranded DNA. The total amount of related DNA base pairs on Earth is estimated at 5.0 x 1037, and weighs 50 billion tonnes. In comparison, the total mass of the biosphere has been estimated to be as much as 4 TtC (trillion tons of carbon).\n\nDNA stores biological information. The DNA backbone is resistant to cleavage, and both strands of the double-stranded structure store the same biological information. Biological information is replicated as the two strands are separated. A significant portion of DNA (more than 98% for humans) is non-coding, meaning that these sections do not serve as patterns for protein sequences.\n\nThe two strands of DNA run in opposite directions to each other and are therefore anti-parallel. Attached to each sugar is one of four types of nucleobases (informally, bases). It is the sequence of these four nucleobases along the backbone that encodes biological information. Under the genetic code, RNA strands are translated to specify the sequence of amino acids within proteins. These RNA strands are initially created using DNA strands as a template in a process called transcription.\n\nWithin cells, DNA is organized into long structures called chromosomes. During cell division these chromosomes are duplicated in the process of DNA replication, providing each cell its own complete set of chromosomes. Eukaryotic organisms (animals, plants, fungi, and protists) store most of their DNA inside the cell nucleus and some of their DNA in organelles, such as mitochondria or chloroplasts. In contrast, prokaryotes (bacteria and archaea) store their DNA only in the cytoplasm. Within the chromosomes, chromatin proteins such as histones compact and organize DNA. These compact structures guide the interactions between DNA and other proteins, helping control which parts of the DNA are transcribed.\n\nDNA was first isolated by Friedrich Miescher in 1869. Its molecular structure was identified by James Watson and Francis Crick in 1953, whose model-building efforts were guided by X-ray diffraction data acquired by Rosalind Franklin.\n\nClassification\n\nAntiquity\nThe first known attempt to classify organisms was conducted by the Greek philosopher Aristotle (384\u2013322 BC), who classified all living organisms known at that time as either a plant or an animal, based mainly on their ability to move. He also distinguished animals with blood from animals without blood (or at least without red blood), which can be compared with the concepts of vertebrates and invertebrates respectively, and divided the blooded animals into five groups: viviparous quadrupeds (mammals), oviparous quadrupeds (reptiles and amphibians), birds, fishes and whales. The bloodless animals were also divided into five groups: cephalopods, crustaceans, insects (which included the spiders, scorpions, and centipedes, in addition to what we define as insects today), shelled animals (such as most molluscs and echinoderms), and \"zoophytes\" (animals that resemble plants). Though Aristotle's work in zoology was not without errors, it was the grandest biological synthesis of the time and remained the ultimate authority for many centuries after his death.\n\nLinnaean \nThe exploration of the Americas revealed large numbers of new plants and animals that needed descriptions and classification. In the latter part of the 16th century and the beginning of the 17th, careful study of animals commenced and was gradually extended until it formed a sufficient body of knowledge to serve as an anatomical basis for classification.\n\nIn the late 1740s, Carl Linnaeus introduced his system of binomial nomenclature for the classification of species. Linnaeus attempted to improve the composition and reduce the length of the previously used many-worded names by abolishing unnecessary rhetoric, introducing new descriptive terms and precisely defining their meaning. The Linnaean classification has eight levels: domains, kingdoms, phyla, class, order, family, genus, and species.\n\nThe fungi were originally treated as plants. For a short period Linnaeus had classified them in the taxon Vermes in Animalia, but later placed them back in Plantae. Copeland classified the Fungi in his Protoctista, thus partially avoiding the problem but acknowledging their special status. The problem was eventually solved by Whittaker, when he gave them their own kingdom in his five-kingdom system. Evolutionary history shows that the fungi are more closely related to animals than to plants.\n\nAs new discoveries enabled detailed study of cells and microorganisms, new groups of life were revealed, and the fields of cell biology and microbiology were created. These new organisms were originally described separately in protozoa as animals and protophyta/thallophyta as plants, but were united by Haeckel in the kingdom Protista; later, the prokaryotes were split off in the kingdom Monera, which would eventually be divided into two separate groups, the Bacteria and the Archaea. This led to the six-kingdom system and eventually to the current three-domain system, which is based on evolutionary relationships. However, the classification of eukaryotes, especially of protists, is still controversial.\n\nAs microbiology, molecular biology and virology developed, non-cellular reproducing agents were discovered, such as viruses and viroids. Whether these are considered alive has been a matter of debate; viruses lack characteristics of life such as cell membranes, metabolism and the ability to grow or respond to their environments. Viruses can still be classed into \"species\" based on their biology and genetics, but many aspects of such a classification remain controversial.\n\nIn May 2016, scientists reported that 1 trillion species are estimated to be on Earth currently with only one-thousandth of one percent described.\n\nThe original Linnaean system has been modified over time as follows:\n\nCladistic\nIn the 1960s cladistics emerged: a system arranging taxa based on clades in an evolutionary or phylogenetic tree.\n\nCells\n\nCells are the basic unit of structure in every living thing, and all cells arise from pre-existing cells by division. Cell theory was formulated by Henri Dutrochet, Theodor Schwann, Rudolf Virchow and others during the early nineteenth century, and subsequently became widely accepted. The activity of an organism depends on the total activity of its cells, with energy flow occurring within and between them.  Cells contain hereditary information that is carried forward as a genetic code during cell division.\n\nThere are two primary types of cells. Prokaryotes lack a nucleus and other membrane-bound organelles, although they have circular DNA and ribosomes. Bacteria and Archaea are two domains of prokaryotes. The other primary type of cells are the eukaryotes, which have distinct nuclei bound by a nuclear membrane and membrane-bound organelles, including mitochondria, chloroplasts, lysosomes, rough and smooth endoplasmic reticulum, and vacuoles. In addition, they possess organized chromosomes that store genetic material. All species of large complex organisms are eukaryotes, including animals, plants and fungi, though most species of eukaryote are protist microorganisms. The conventional model is that eukaryotes evolved from prokaryotes, with the main organelles of the eukaryotes forming through endosymbiosis between bacteria and the progenitor eukaryotic cell.\n\nThe molecular mechanisms of cell biology are based on proteins. Most of these are synthesized by the ribosomes through an enzyme-catalyzed process called protein biosynthesis. A sequence of amino acids is assembled and joined together based upon gene expression of the cell's nucleic acid. In eukaryotic cells, these proteins may then be transported and processed through the Golgi apparatus in preparation for dispatch to their destination.\n\nCells reproduce through a process of cell division in which the parent cell divides into two or more daughter cells. For prokaryotes, cell division occurs through a process of fission in which the DNA is replicated, then the two copies are attached to parts of the cell membrane. In eukaryotes, a more complex process of mitosis is followed. However, the end result is the same; the resulting cell copies are identical to each other and to the original cell (except for mutations), and both are capable of further division following an interphase period.\n\nMulticellular organisms may have first evolved through the formation of colonies of identical cells. These cells can form group organisms through cell adhesion. The individual members of a colony are capable of surviving on their own, whereas the members of a true multi-cellular organism have developed specializations, making them dependent on the remainder of the organism for survival. Such organisms are formed clonally or from a single germ cell that is capable of forming the various specialized cells that form the adult organism. This specialization allows multicellular organisms to exploit resources more efficiently than single cells. In January 2016, scientists reported that, about 800 million years ago, a minor genetic change in a single molecule, called GK-PID, may have allowed organisms to go from a single cell organism to one of many cells.\n\nCells have evolved methods to perceive and respond to their microenvironment, thereby enhancing their adaptability. Cell signaling coordinates cellular activities, and hence governs the basic functions of multicellular organisms. Signaling between cells can occur through direct cell contact using juxtacrine signalling, or indirectly through the exchange of agents as in the endocrine system. In more complex organisms, coordination of activities can occur through a dedicated nervous system.\n\nExtraterrestrial\n\nThough life is confirmed only on Earth, many think that extraterrestrial life is not only plausible, but probable or inevitable. Other planets and moons in the Solar System and other planetary systems are being examined for evidence of having once supported simple life, and projects such as SETI are trying to detect radio transmissions from possible alien civilizations. Other locations within the Solar System that may host microbial life include the subsurface of Mars, the upper atmosphere of Venus, and subsurface oceans on some of the moons of the giant planets.\nBeyond the Solar System, the region around another main-sequence star that could support Earth-like life on an Earth-like planet is known as the habitable zone. The inner and outer radii of this zone vary with the luminosity of the star, as does the time interval during which the zone survives. Stars more massive than the Sun have a larger habitable zone, but remain on the Sun-like \"main sequence\" of stellar evolution for a shorter time interval. Small red dwarfs have the opposite problem, with a smaller habitable zone that is subject to higher levels of magnetic activity and the effects of tidal locking from close orbits. Hence, stars in the intermediate mass range such as the Sun may have a greater likelihood for Earth-like life to develop. The location of the star within a galaxy may also affect the likelihood of life forming. Stars in regions with a greater abundance of heavier elements that can form planets, in combination with a low rate of potentially habitat-damaging supernova events, are predicted to have a higher probability of hosting planets with complex life. The variables of the Drake equation are used to discuss the conditions in planetary systems where civilization is most likely to exist. Use of the equation to predict the amount of extraterrestrial life, however, is difficult; because many of the variables are unknown, the equation functions as more of a mirror to what its user already thinks. As a result, the number of civilizations in the galaxy can be estimated as low as 9.1 x 10\u221213, suggesting a minimum value of 1, or as high as 15.6 million (0.156 x 109); for the calculations, see Drake equation.\n\nA \"Confidence of Life Detection\" scale (CoLD) for reporting evidence of life beyond Earth has been proposed.\n\nArtificial\n\nArtificial life is the simulation of any aspect of life, as through computers, robotics, or biochemistry. The study of artificial life imitates traditional biology by recreating some aspects of biological phenomena. Scientists study the logic of living systems by creating artificial environments\u2014seeking to understand the complex information processing that defines such systems.  While life is, by definition, alive, artificial life is generally referred to as data confined to a digital environment and existence.\n\nSynthetic biology is a new area of biotechnology that combines science and biological engineering. The common goal is the design and construction of new biological functions and systems not found in nature. Synthetic biology includes the broad redefinition and expansion of biotechnology, with the ultimate goals of being able to design and build engineered biological systems that process information, manipulate chemicals, fabricate materials and structures, produce energy, provide food, and maintain and enhance human health and the environment.\n\nDeath\n\nDeath is the termination of all vital functions or life processes in an organism or cell. It can occur as a result of an accident, violence, medical conditions, biological interaction, malnutrition, poisoning, senescence, or suicide. After death, the remains of an organism re-enter the biogeochemical cycle. Organisms may be consumed by a predator or a scavenger and leftover organic material may then be further decomposed by detritivores, organisms that recycle detritus, returning it to the environment for reuse in the food chain.\n\nOne of the challenges in defining death is in distinguishing it from life. Death would seem to refer to either the moment life ends, or when the state that follows life begins. However, determining when death has occurred is difficult, as cessation of life functions is often not simultaneous across organ systems. Such determination therefore requires drawing conceptual lines between life and death. This is problematic, however, because there is little consensus over how to define life. The nature of death has for millennia been a central concern of the world's religious traditions and of philosophical inquiry. Many religions maintain faith in either a kind of afterlife or reincarnation for the soul, or resurrection of the body at a later date.\n\nExtinction\n\nExtinction is the process by which a group of taxa or species dies out, reducing biodiversity. The moment of extinction is generally considered the death of the last individual of that species. Because a species' potential range may be very large, determining this moment is difficult, and is usually done retrospectively after a period of apparent absence. Species become extinct when they are no longer able to survive in changing habitat or against superior competition. In Earth's history, over 99% of all the species that have ever lived are extinct; however, mass extinctions may have accelerated evolution by providing opportunities for new groups of organisms to diversify.\n\nFossils\n\nFossils are the preserved remains or traces of animals, plants, and other organisms from the remote past. The totality of fossils, both discovered and undiscovered, and their placement in fossil-containing rock formations and sedimentary layers (strata) is known as the fossil record. A preserved specimen is called a fossil if it is older than the arbitrary date of 10,000 years ago. Hence, fossils range in age from the youngest at the start of the Holocene Epoch to the oldest from the Archaean Eon, up to 3.4 billion years old.\n\nSee also\n\n Biology, the study of life\n Astrobiology\n Biosignature\n Evolutionary history of life\n Lists of organisms by population\n Phylogenetics\n Viable system theory\n Central dogma of molecular biology\n Epigenetics \n Synthetic biology\n Hypothetical types of biochemistry \n Carbon-based life\n\nNotes\n\nReferences\n\nFurther reading\n\nExternal links\n\n Life (Systema Naturae 2000)\n Vitae (BioLib)\n Biota (Taxonomicon)\n Wikispecies\u00a0\u2013 a free directory of life\n Resources for life in the Solar System and in galaxy, and the potential scope of life in the cosmological future\n \"The Adjacent Possible: A Talk with Stuart Kauffman\"\n Stanford Encyclopedia of Philosophy entry\n The Kingdoms of Life\n\n \nMain topic articles",
  "Metaphysics": "Metaphysics is the branch of philosophy that studies the fundamental nature of reality, the first principles of being, identity and change, space and time, causality, necessity, and possibility. It includes questions about the nature of consciousness and the relationship between mind and matter, between substance and attribute, and between potentiality and actuality. The word \"metaphysics\" comes from two Greek words that, together, literally mean \"after or behind or among [the study of] the natural\". It has been suggested that the term might have been coined by a first century CE editor who assembled various small selections of Aristotle's works into the treatise we now know by the name Metaphysics (\u03bc\u03b5\u03c4\u1f70 \u03c4\u1f70 \u03c6\u03c5\u03c3\u03b9\u03ba\u03ac, meta ta physika,  'after the Physics\u2009', another of Aristotle's works).\n\nMetaphysics studies questions related to what it is for something to exist and what types of existence there are. Metaphysics seeks to answer, in an abstract and fully general manner, the questions:\n What ?\n What is it ?\n\nTopics of metaphysical investigation include existence, objects and their properties, space and time, cause and effect, and possibility. Metaphysics is considered one of the four main branches of philosophy, along with epistemology, logic, and ethics.\n\nEpistemological foundation\n\nMetaphysical study is conducted using deduction from that which is known a priori. Like foundational mathematics (which is sometimes considered a special case of metaphysics applied to the existence of number), it tries to give a coherent account of the structure of the world, capable of explaining our everyday and scientific perception of the world, and being free from contradictions.  In mathematics, there are many different ways to define numbers; similarly, in metaphysics, there are many different ways to define objects, properties, concepts, and other entities that are claimed to make up the world.   While metaphysics may, as a special case, study the entities postulated by fundamental science such as atoms and superstrings, its core topic is the set of categories such as object, property and causality which those scientific theories assume.   For example: claiming that \"electrons have charge\" is a scientific theory; while exploring what it means for electrons to be (or at least, to be perceived as)  \"objects\", charge to be a \"property\", and for both to exist in a topological entity called \"space\" is the task of metaphysics.\n\nThere are two broad stances about what is \"the world\" studied by metaphysics. According to metaphysical realism, the objects studied by metaphysics exist independently of any observer so that the subject is the most fundamental of all sciences. Metaphysical anti-realism, on the other hand, assumes that the objects studied by metaphysics exist inside the mind of an observer, so the subject becomes a form of introspection and conceptual analysis. This position is of more recent origin. Some philosophers, notably Kant, discuss both of these \"worlds\" and what can be inferred about each one. Some, such as the logical positivists, and many scientists, reject the metaphysical realism as meaningless and unverifiable. Others reply that this criticism also applies to any type of knowledge, including hard science, which claims to describe anything other than the contents of human perception, and thus that the world of perception is the objective world in some sense.  Metaphysics itself usually assumes that some stance has been taken on these questions and that it may proceed independently of the choice\u2014the question of which stance to take belongs instead to another branch of philosophy, epistemology.\n\nCentral questions\n\nOntology (being)\n\nOntology is the branch of philosophy that studies concepts such as existence, being, becoming, and reality. It includes the questions of how entities are grouped into basic categories and which of these entities exist on the most fundamental level. Ontology is sometimes referred to as the science of being. It has been characterized as general metaphysics in contrast to special metaphysics, which is concerned with more particular aspects of being. Ontologists often try to determine what the categories or highest kinds are and how they form a system of categories that provides an encompassing classification of all entities. Commonly proposed categories include substances, properties, relations, states of affairs and events. These categories are characterized by fundamental ontological concepts, like particularity and universality, abstractness and concreteness or possibility and necessity. Of special interest is the concept of ontological dependence, which determines whether the entities of a category exist on the most fundamental level. Disagreements within ontology are often about whether entities belonging to a certain category exist and, if so, how they are related to other entities.\n\nIdentity and change\n\nIdentity is a fundamental metaphysical concern. Metaphysicians investigating identity are tasked with the question of what, exactly, it means for something to be identical to itself, or \u2013 more controversially \u2013 to something else. Issues of identity arise in the context of time: what does it mean for something to be itself across two moments in time? How do we account for this? Another question of identity arises when we ask what our criteria ought to be for determining identity, and how the reality of identity interfaces with linguistic expressions.\n\nThe metaphysical positions one takes on identity have far-reaching implications on issues such as the Mind\u2013body problem, personal identity, ethics, and law.\n\nA few ancient Greeks took extreme positions on the nature of change. Parmenides denied change altogether, while Heraclitus argued that change was ubiquitous: \"No man ever steps in the same river twice.\"\n\nIdentity, sometimes called numerical identity, is the relation that a thing bears to itself, and which no thing bears to anything other than itself (cf. sameness).\n\nA modern philosopher who made a lasting impact on the philosophy of identity was Leibniz, whose Law of the Indiscernibility of Identicals is still widely accepted today. It states that if some object x is identical to some object y, then any property that x has, y will have as well.\n\nPut formally, it states\n\nHowever, it does seem that objects can change over time. If one were to look at a tree one day, and the tree later lost a leaf, it would seem that one could still be looking at that same tree. Two rival theories to account for the relationship between change and identity are perdurantism, which treats the tree as a series of tree-stages, and endurantism, which maintains that the organism\u2014the same tree\u2014is present at every stage in its history.\n\nBy appealing to intrinsic and extrinsic properties, endurantism finds a way to harmonize identity with change. Endurantists believe that objects persist by being strictly numerically identical over time. However, if  Leibniz's Law of the Indiscernibility of Identicals is utilized to define numerical identity here, it seems that objects must be completely unchanged in order to persist. Discriminating between intrinsic properties and extrinsic properties, endurantists state that numerical identity means that, if some object x is identical to some object y, then any intrinsic property that x has, y will have as well. Thus, if an object persists, intrinsic properties of it are unchanged, but extrinsic properties can change over time. Besides the object itself, environments and other objects can change over time; properties that relate to other objects would change even if this object does not change.\n\nPerdurantism can harmonize identity with change in another way. In four-dimensionalism, a version of perdurantism, what persists is a four-dimensional object which does not change although three-dimensional slices of the object may differ.\n\nSpace and time\n\nObjects appear to us in space and time, while abstract entities such as classes, properties, and relations do not.  How do space and time serve this function as a ground for objects?  Are space and time entities themselves, of some form?  Must they exist prior to objects?  How exactly can they be defined?  How is time related to change; must there always be something changing in order for time to exist?\n\nCausality\n\nClassical philosophy recognized a number of causes, including teleological future causes. In special relativity and quantum field theory the notions of space, time and causality become tangled together, with temporal orders of causations becoming dependent on who is observing them. The laws of physics are symmetrical in time, so could equally well be used to describe time as running backwards. Why then do we perceive it as flowing in one direction, the arrow of time, and as containing causation flowing in the same direction?\n\nFor that matter, can an effect precede its cause? This was the title of a 1954 paper by Michael Dummett, which sparked a discussion that continues today.  Earlier, in 1947, C. S. Lewis had argued that one can meaningfully pray concerning the outcome of, e.g., a medical test while recognizing that the outcome is determined by past events: \"My free act contributes to the cosmic shape.\"   Likewise, some interpretations of quantum mechanics, dating to 1945, involve backward-in-time causal influences.\n\nCausality is linked by many philosophers to the concept of counterfactuals. To say that A caused B means that if A had not happened then B would not have happened. This view was advanced by David Lewis in his 1973 paper \"Causation\". His subsequent papers further develop his theory of causation.\n\nCausality is usually required as a foundation for philosophy of science if science aims to understand causes and effects and make predictions about them.\n\nNecessity and possibility\n\nMetaphysicians investigate questions about the ways the world could have been. David Lewis, in On the Plurality of Worlds, endorsed a view called concrete modal realism, according to which facts about how things could have been are made true by other concrete worlds in which things are different. Other philosophers, including Gottfried Leibniz, have dealt with the idea of possible worlds as well. A necessary fact is true across all possible worlds. A possible fact is true in some possible world, even if not in the actual world. For example, it is possible that cats could have had two tails, or that any particular apple could have not existed. By contrast, certain propositions seem necessarily true, such as analytic propositions, e.g., \"All bachelors are unmarried.\" The view that any analytic truth is necessary is not universally held among philosophers. A less controversial view is that self-identity is necessary, as it seems fundamentally incoherent to claim that any x is not identical to itself; this is known as the law of identity, a putative \"first principle\". Similarly, Aristotle describes the principle of non-contradiction:\nIt is impossible that the same quality should both belong and not belong to the same thing\u00a0... This is the most certain of all principles\u00a0... Wherefore they who demonstrate refer to this as an ultimate opinion. For it is by nature the source of all the other axioms.\n\nPeripheral questions\n\nMetaphysical cosmology and cosmogony\n\nMetaphysical cosmology is the branch of metaphysics that deals with the world as the totality of all phenomena in space and time. Historically, it formed a major part of the subject alongside Ontology, though its role is more peripheral in contemporary philosophy. It has had a broad scope, and in many cases was founded in religion. The ancient Greeks drew no distinction between this use and their model for the cosmos. However, in modern times it addresses questions about the Universe which are beyond the scope of the physical sciences. It is distinguished from religious cosmology in that it approaches these questions using philosophical methods (e.g. dialectics).\n\nCosmogony deals specifically with the origin of the universe.  Modern metaphysical cosmology and cosmogony try to address questions such as:\n What is the origin of the Universe? What is its first cause? Is its existence necessary? (see monism, pantheism, emanationism and creationism)\n What are the ultimate material components of the Universe? (see mechanism, dynamism, hylomorphism, atomism)\n What is the ultimate reason for the existence of the Universe? Does the cosmos have a purpose? (see teleology)\n\nMind and matter\n\nAccounting for the existence of mind in a world largely composed of matter is a metaphysical problem which is so large and important as to have become a specialized subject of study in its own right, philosophy of mind.\n\nSubstance dualism is a classical theory in which mind and body are essentially different, with the mind having some of the attributes traditionally assigned to the soul, and which creates an immediate conceptual puzzle about how the two interact. This form of substance dualism differs from the dualism of some eastern philosophical traditions (like Ny\u0101ya), which also posit a soul; for the soul, under their view, is ontologically distinct from the mind. Idealism postulates that material objects do not exist unless perceived and only as perceptions.  Adherents of panpsychism, a kind of property dualism, hold that everything has a mental aspect, but not that everything exists in a mind.  Neutral monism postulates that existence consists of a single substance that in itself is neither mental nor physical, but is capable of mental and physical aspects or attributesthus it implies a dual-aspect theory.   For the last century, the dominant theories have been science-inspired including materialistic monism, type identity theory, token identity theory, functionalism, reductive physicalism, nonreductive physicalism, eliminative materialism, anomalous monism, property dualism, epiphenomenalism and emergence.\n\nDeterminism and free will\n\nDeterminism is the philosophical proposition that every event, including human cognition, decision and action, is causally determined by an unbroken chain of prior occurrences. It holds that nothing happens that has not already been determined. The principal consequence of the deterministic claim is that it poses a challenge to the existence of free will.\n\nThe problem of free will is the problem of whether rational agents exercise control over their own actions and decisions. Addressing this problem requires understanding the relation between freedom and causation, and determining whether the laws of nature are causally deterministic. Some philosophers, known as incompatibilists, view determinism and free will as mutually exclusive. If they believe in determinism, they will therefore believe free will to be an illusion, a position known as Hard Determinism. Proponents range from Baruch Spinoza to Ted Honderich. Henri Bergson defended free will in his dissertation Time and Free Will from 1889.\n\nOthers, labeled compatibilists (or \"soft determinists\"), believe that the two ideas can be reconciled coherently. Adherents of this view include Thomas Hobbes and many modern philosophers such as John Martin Fischer, Gary Watson, Harry Frankfurt, and the like.\n\nIncompatibilists who accept free will but reject determinism are called libertarians, a term not to be confused with the political sense. Robert Kane and Alvin Plantinga are modern defenders of this theory.\n\nNatural and social kinds\nThe earliest type of classification of social construction traces back to Plato in his dialogue Phaedrus where he claims that the biological classification system seems to carve nature at the joints. In contrast, later philosophers such as Michel Foucault and Jorge Luis Borges have challenged the capacity of natural and social classification. In his essay The Analytical Language of John Wilkins, Borges makes us imagine a certain encyclopedia where the animals are divided into (a) those that belong to the emperor; (b) embalmed ones; (c) those that are trained;... and so forth, in order to bring forward the ambiguity of natural and social kinds. According to metaphysics author Alyssa Ney: \"the reason all this is interesting is that there seems to be a metaphysical difference between the Borgesian system and Plato's\". The difference is not obvious but one classification attempts to carve entities up according to objective distinction while the other does not. According to Quine this notion is closely related to the notion of similarity.\n\nNumber\n\nThere are different ways to set up the notion of number in metaphysics theories.  Platonist theories postulate number as a fundamental category itself.  Others consider it to be a property of an entity called a \"group\" comprising other entities; or to be a relation held between several groups of entities, such as \"the number four is the set of all sets of four things\".  Many of the debates around universals are applied to the study of number, and are of particular importance due to its status as a foundation for the philosophy of mathematics and for mathematics itself.\n\nApplied metaphysics\nAlthough metaphysics as a philosophical enterprise is highly hypothetical, it also has practical application in most other branches of philosophy, science, and now also information technology. Such areas generally assume some basic ontology (such as a system of objects, properties, classes, and space-time) as well as other metaphysical stances on topics such as causality and agency, then build their own particular theories upon these.\n\nIn science, for example, some theories are based on the ontological assumption of objects with properties (such as electrons having charge) while others may reject objects completely (such as quantum field theories, where spread-out \"electronness\" becomes property of space-time rather than an object).\n\n\"Social\" branches of philosophy such as philosophy of morality, aesthetics and philosophy of religion (which in turn give rise to practical subjects such as ethics, politics, law, and art) all require metaphysical foundations, which may be considered as branches or applications of metaphysics.  For example, they may postulate the existence of basic entities such as value, beauty, and God.   Then they use these postulates to make their own arguments about consequences resulting from them.  When philosophers in these subjects make their foundations they are doing applied metaphysics, and may draw upon its core topics and methods to guide them, including ontology and other core and peripheral topics.  As in science, the foundations chosen will in turn depend on the underlying ontology used, so philosophers in these subjects may have to dig right down to the ontological layer of metaphysics to find what is possible for their theories.  For example, a contradiction obtained in a theory of God or Beauty might be due to an assumption that it is an object rather than some other kind of ontological entity.\n\nRelation to other disciplines\n\nScience\nPrior to the modern history of science, scientific questions were addressed as a part of natural philosophy. Originally, the term \"science\" () simply meant \"knowledge\". The scientific method, however, transformed natural philosophy into an empirical activity deriving from experiment, unlike the rest of philosophy. By the end of the 18th century, it had begun to be called \"science\" to distinguish it from other branches of philosophy. Science and philosophy have been considered separated disciplines ever since. Thereafter, metaphysics denoted philosophical enquiry of a non-empirical character into the nature of existence.\n\nMetaphysics continues asking \"why\" where science leaves off. For example, any theory of fundamental physics is based on some set of axioms, which may postulate the existence of entities such as atoms, particles, forces, charges, mass, or fields. Stating such postulates is considered to be the \"end\" of a science theory. Metaphysics takes these postulates and explores what they mean as human concepts. For example, do all theories of physics require the existence of space and time, objects, and properties? Or can they be expressed using only objects, or only properties? Do the objects have to retain their identity over time or can they change? If they change, then are they still the same object? Can theories be reformulated by converting properties or predicates (such as \"red\") into entities (such as redness or redness fields) or processes ('there is some redding happening over there' appears in some human languages in place of the use of properties). Is the distinction between objects and properties fundamental to the physical world or to our perception of it?\n\nMuch recent work has been devoted to analyzing the role of metaphysics in scientific theorizing. Alexandre Koyr\u00e9 led this movement, declaring in his book Metaphysics and Measurement, \"It is not by following experiment, but by outstripping experiment, that the scientific mind makes progress.\" That metaphysical propositions can influence scientific theorizing is John Watkins' most lasting contribution to philosophy. Since 1957 \"he showed the ways in which some un-testable and hence, according to Popperian ideas, non-empirical propositions can nevertheless be influential in the development of properly testable and hence scientific theories. These profound results in applied elementary logic...represented an important corrective to positivist teachings about the meaninglessness of metaphysics and of normative claims\". Imre Lakatos maintained that all scientific theories have a metaphysical \"hard core\" essential for the generation of hypotheses and theoretical assumptions. Thus, according to Lakatos, \"scientific changes are connected with vast cataclysmic metaphysical revolutions.\"\n\nAn example from biology of Lakatos' thesis: David Hull has argued that changes in the ontological status of the species concept have been central in the development of biological thought from Aristotle through Cuvier, Lamarck, and Darwin. Darwin's ignorance of metaphysics made it more difficult for him to respond to his critics because he could not readily grasp the ways in which their underlying metaphysical views differed from his own.\n\nIn physics, new metaphysical ideas have arisen in connection with quantum mechanics, where subatomic particles arguably do not have the same sort of individuality as the particulars with which philosophy has traditionally been concerned. Also, adherence to a deterministic metaphysics in the face of the challenge posed by the quantum-mechanical uncertainty principle led physicists such as Albert Einstein to propose alternative theories that retained determinism. A.N. Whitehead is famous for creating a process philosophy metaphysics inspired by electromagnetism and special relativity.\n\nIn chemistry, Gilbert Newton Lewis addressed the nature of motion, arguing that an electron should not be said to move when it has none of the properties of motion.\n\nKatherine Hawley notes that the metaphysics even of a widely accepted scientific theory may be challenged if it can be argued that the metaphysical presuppositions of the theory make no contribution to its predictive success.\n\nTheology \nThere is a relationship between theological doctrines and philosophical reflection in the philosophy of a religion (such as Christian philosophy), philosophical reflections are strictly rational. On this way of seeing the two disciplines, if at least one of the premises of an argument is derived from revelation, the argument falls in the domain of theology; otherwise it falls into philosophy's domain.\n\nRejections of metaphysics\nMeta-metaphysics is the branch of philosophy that is concerned with the foundations of metaphysics. A number of individuals have suggested that much or all of metaphysics should be rejected, a meta-metaphysical position known as metaphysical deflationism or ontological deflationism.\n\nIn the 16th century, Francis Bacon rejected scholastic metaphysics, and argued strongly for what is now called empiricism, being seen later as the father of modern empirical science. In the 18th century, David Hume took a strong position, arguing that all genuine knowledge involves either mathematics or matters of fact and that metaphysics, which goes beyond these, is worthless. He concludes his Enquiry Concerning Human Understanding (1748) with the statement:\n\nIf we take in our hand any volume [book]; of divinity or school metaphysics, for instance; let us ask, Does it contain any abstract reasoning concerning quantity or number? No. Does it contain any experimental reasoning concerning matter of fact and existence? No. Commit it then to the flames: for it can contain nothing but sophistry and illusion.\n\nThirty-three years after Hume's Enquiry appeared, Immanuel Kant published his Critique of Pure Reason. Although he followed Hume in rejecting much of previous metaphysics, he argued that there was still room for some synthetic a priori knowledge, concerned with matters of fact yet obtainable independent of experience. These included fundamental structures of space, time, and causality. He also argued for the freedom of the will and the existence of \"things in themselves\", the ultimate (but unknowable) objects of experience.\n\nWittgenstein introduced the concept that metaphysics could be influenced by theories of aesthetics, via logic, vis. a world composed of \"atomical facts\".\n\nIn the 1930s, A.J. Ayer and Rudolf Carnap endorsed Hume's position; Carnap quoted the passage above. They argued that metaphysical statements are neither true nor false but meaningless since, according to their verifiability theory of meaning, a statement is meaningful only if there can be empirical evidence for or against it. Thus, while Ayer rejected the monism of Spinoza, he avoided a commitment to pluralism, the contrary position, by holding both views to be without meaning. Carnap took a similar line with the controversy over the reality of the external world. While the logical positivism movement is now considered dead (with Ayer, a major proponent, admitting in a 1979 TV interview that \"nearly all of it was false\"),  it has continued to influence philosophy development.\n\nArguing against such rejections, the Scholastic philosopher Edward Feser held that Hume's critique of metaphysics, and specifically Hume's fork, is \"notoriously self-refuting\". Feser argues that Hume's fork itself is not a conceptual truth and is not empirically testable.\n\nSome living philosophers, such as Amie Thomasson, have argued that many metaphysical questions can be dissolved just by looking at the way we use words; others, such as Ted Sider, have argued that metaphysical questions are substantive, and that we can make progress toward answering them by comparing theories according to a range of theoretical virtues inspired by the sciences, such as simplicity and explanatory power.\n\nEtymology\nThe word \"metaphysics\" derives from the Greek words \u03bc\u03b5\u03c4\u03ac (met\u00e1, \"after\") and \u03c6\u03c5\u03c3\u03b9\u03ba\u03ac (physik\u00e1, \"physics\"). It was first used as the title for several of Aristotle's works, because they were usually anthologized after the works on physics in complete editions. The prefix meta- (\"after\") indicates that these works come \"after\" the chapters on physics. However, Aristotle himself did not call the subject of these books metaphysics: he referred to it as \"first philosophy\" (; ). The editor of Aristotle's works, Andronicus of Rhodes, is thought to have placed the books on first philosophy right after another work, Physics, and called them  (t\u00e0 met\u00e0 t\u00e0 physik\u00e0 bibl\u00eda) or \"the books [that come] after the [books on] physics\".\n\nHowever, once the name was given, the commentators sought to find other reasons for its appropriateness. For instance, Thomas Aquinas understood it to refer to the chronological or pedagogical order among our philosophical studies, so that the \"metaphysical sciences\" would mean \"those that we study after having mastered the sciences that deal with the physical world\".\n\nThe term was misread by other medieval commentators, who thought it meant \"the science of what is beyond the physical\".  Following this tradition, the prefix meta- has more recently been prefixed to the names of sciences to designate higher sciences dealing with ulterior and more fundamental problems: hence metamathematics, metaphysiology, etc.\n\nA person who creates or develops metaphysical theories is called a metaphysician.\n\nCommon parlance also uses the word \"metaphysics\" for a different referent from that of the present article, namely for beliefs in arbitrary non-physical or magical entities. For example, \"Metaphysical healing\" to refer to healing by means of remedies that are magical rather than scientific.   This usage stemmed from the various historical schools of speculative metaphysics which operated by postulating all manner of physical, mental and spiritual entities as bases for particular metaphysical systems. Metaphysics as a subject does not preclude beliefs in such magical entities but neither does it promote them. Rather, it is the subject which provides the vocabulary and logic with which such beliefs might be analyzed and studied, for example to search for inconsistencies both within themselves and with other accepted systems such as Science.\n\nHistory and schools of metaphysics\n\nPre-history\nCognitive archeology such as analysis of cave paintings and other pre-historic art and customs suggests that a form of perennial philosophy or Shamanic metaphysics may stretch back to the birth of behavioral modernity, all around the world.   Similar beliefs are found in present-day \"stone age\" cultures such as Australian aboriginals.  Perennial philosophy postulates the existence of a spirit or concept world alongside the day-to-day world, and interactions between these worlds during dreaming and ritual, or on special days or at special places.  It has been argued that perennial philosophy formed the basis for Platonism, with Plato articulating, rather than creating, much older widespread beliefs.\n\nBronze Age\nBronze Age cultures such as ancient Mesopotamia and ancient Egypt (along with similarly structured but chronologically later cultures such as Mayans and Aztecs) developed belief systems based on mythology, anthropomorphic gods, mind\u2013body dualism, and a spirit world, to explain causes and cosmology.  These cultures appear to have been interested in astronomy and may have associated or identified the stars with some of these entities.  In ancient Egypt, the ontological distinction between order (maat) and chaos (Isfet) seems to have been important.\n\nPre-Socratic Greece\n\nThe first named Greek philosopher, according to Aristotle, is Thales of Miletus, early 6th century BCE. He made use of purely physical explanations to explain the phenomena of the world rather than the mythological and divine explanations of tradition.  He is thought to have posited water as the single underlying principle  (or arche in later Aristotelian terminology) of the material world.  His fellow, but younger Miletians,  Anaximander and Anaximenes, also posited monistic underlying principles, namely apeiron (the indefinite or boundless) and air respectively.\n\nAnother school was the Eleatics, in southern Italy. The group was founded in the early fifth century BCE by Parmenides, and included Zeno of Elea and Melissus of Samos. Methodologically, the Eleatics were broadly rationalist, and took logical standards of clarity and necessity to be the criteria of truth. Parmenides' chief doctrine was that reality is a single unchanging and universal Being. Zeno used reductio ad absurdum, to demonstrate the illusory nature of change and time in his paradoxes.\n\nHeraclitus of Ephesus, in contrast, made change central, teaching that \"all things flow\". His philosophy, expressed in brief aphorisms, is quite cryptic. For instance, he also taught the unity of opposites.\n\nDemocritus and his teacher Leucippus, are known for formulating an atomic theory for the cosmos. They are considered forerunners of the scientific method.\n\nClassical China\n\nMetaphysics in Chinese philosophy can be traced back to the earliest Chinese philosophical concepts from the Zhou Dynasty such as Tian (Heaven) and Yin and Yang. The fourth century BCE saw a turn towards cosmogony with the rise of Taoism (in the Daodejing and Zhuangzi) and sees the natural world as dynamic and constantly changing processes which spontaneously arise from a single immanent metaphysical source or principle (Tao). Another philosophical school which arose around this time was the School of Naturalists which saw the ultimate metaphysical principle as the Taiji, the \"supreme polarity\" composed of the forces of Yin and Yang which were always in a state of change seeking balance. Another concern of Chinese metaphysics, especially Taoism, is the relationship and nature of Being and non-Being (you \u6709 and wu \u7121). The Taoists held that the ultimate, the Tao, was also non-being or no-presence. Other important concepts were those of spontaneous generation or natural vitality (Ziran) and \"correlative resonance\" (Ganying).\n\nAfter the fall of the Han Dynasty (220 CE), China saw the rise of the Neo-Taoist Xuanxue school. This school was very influential in developing the concepts of later Chinese metaphysics. Buddhist philosophy entered China (c. 1st century) and was influenced by the native Chinese metaphysical concepts to develop new theories. The native Tiantai and Huayen schools of philosophy maintained and reinterpreted the Indian theories of shunyata (emptiness, kong \u7a7a) and Buddha-nature (Fo xing \u4f5b\u6027) into the theory of interpenetration of phenomena. Neo-Confucians like Zhang Zai under the influence of other schools developed the concepts of \"principle\" (li) and vital energy (qi).\n\nClassical Greece\nSocrates and Plato\nSocrates is known for his dialectic or questioning approach to philosophy rather than a positive metaphysical doctrine.\n\nHis pupil, Plato is famous for his theory of forms (which he places in the mouth of Socrates in his dialogues). Platonic realism (also considered a form of idealism) is considered to be a solution to the problem of universals; i.e., what particular objects have in common is that they share a specific Form which is universal to all others of their respective kind.\n\nThe theory has a number of other aspects:\n Epistemological: knowledge of the Forms is more certain than mere sensory data.\n Ethical: The Form of the Good sets an objective standard for morality.\n Time and Change: The world of the Forms is eternal and unchanging. Time and change belong only to the lower sensory world. \"Time is a moving image of Eternity\".\n Abstract objects and mathematics: Numbers, geometrical figures, etc., exist mind-independently in the World of Forms.\n\nPlatonism developed into Neoplatonism, a philosophy with a monotheistic and mystical flavour that survived well into the early Christian era.\n\nAristotle\nPlato's pupil Aristotle wrote widely on almost every subject, including metaphysics. His solution to the problem of universals contrasts with Plato's. Whereas Platonic Forms are existentially apparent in the visible world, Aristotelian essences dwell in particulars.\n\nPotentiality and Actuality are principles of a dichotomy which Aristotle used throughout his philosophical works to analyze motion, causality and other issues.\n\nThe Aristotelian theory of change and causality stretches to four causes: the material, formal, efficient and final. The efficient cause corresponds to what is now known as a cause simplicity. Final causes are explicitly teleological, a concept now regarded as controversial in science. The Matter/Form dichotomy was to become highly influential in later philosophy as the substance/essence distinction.\n\nThe opening arguments in Aristotle's Metaphysics, Book I,  revolve around the senses, knowledge, experience, theory, and wisdom.  The first main focus in the Metaphysics is attempting to determine how intellect \"advances from sensation through memory, experience, and art, to theoretical knowledge\".  Aristotle claims that eyesight provides us with the capability to recognize and remember experiences, while sound allows us to learn.\n\nClassical IndiaMore on Indian philosophy: Hindu philosophyS\u0101\u1e43khyaS\u0101\u1e43khya is an ancient system of Indian philosophy based on a dualism involving the ultimate principles of consciousness and matter. It is described as the rationalist school of Indian philosophy. It is most related to the Yoga school of Hinduism, and its method was most influential on the development of Early Buddhism.\n\nThe S\u0101mkhya is an enumerationist philosophy whose epistemology accepts three of six pramanas (proofs) as the only reliable means of gaining knowledge. These include pratyak\u1e63a (perception), anum\u0101\u1e47a (inference) and \u015babda (\u0101ptavacana, word/testimony of reliable sources). Eliott Deutsche (2000), in Philosophy of Religion : Indian Philosophy Vol 4 (Editor: Roy Perrett), Routledge, , pp.\u00a0245\u2013248;\n John A. Grimes, A Concise Dictionary of Indian Philosophy: Sanskrit Terms Defined in English, State University of New York Press, , p. 238\n\nSamkhya is strongly dualist. S\u0101mkhya philosophy regards the universe as consisting of two realities; puru\u1e63a (consciousness) and prak\u1e5bti (matter). Jiva (a living being) is that state in which puru\u1e63a is bonded to prak\u1e5bti in some form. This fusion, state the Samkhya scholars, led to the emergence of buddhi (\"spiritual awareness\") and aha\u1e45k\u0101ra (ego consciousness). The universe is described by this school as one created by purusa-prak\u1e5bti entities infused with various permutations and combinations of variously enumerated elements, senses, feelings, activity and mind. During the state of imbalance, one of more constituents overwhelm the others, creating a form of bondage, particularly of the mind. The end of this imbalance, bondage is called liberation, or moksha, by the Samkhya school.\n\nThe existence of God or supreme being is not directly asserted, nor considered relevant by the Samkhya philosophers. S\u0101\u1e43khya denies the final cause of Ishvara (God). While the Samkhya school considers the Vedas as a reliable source of knowledge, it is an atheistic philosophy according to Paul Deussen and other scholars.Lloyd Pflueger, Person Purity and Power in Yogasutra, in Theory and Practice of Yoga (Editor: Knut Jacobsen), Motilal Banarsidass, , pp.\u00a038\u201339 A key difference between Samkhya and Yoga schools, state scholars,Mike Burley (2012), Classical Samkhya and Yoga \u2013 An Indian Metaphysics of Experience, Routledge, , pp. 39, 41 is that Yoga school accepts a \"personal, yet essentially inactive, deity\" or \"personal god\".\n\nSamkhya is known for its theory of gu\u1e47as (qualities, innate tendencies). Gu\u1e47a, it states, are of three types: sattva being good, compassionate, illuminating, positive, and constructive; rajas is one of activity, chaotic, passion, impulsive, potentially good or bad; and tamas being the quality of darkness, ignorance, destructive, lethargic, negative. Everything, all life forms and human beings, state Samkhya scholars, have these three gu\u1e47as, but in different proportions. The interplay of these gu\u1e47as defines the character of someone or something, of nature and determines the progress of life.T Bernard (1999), Hindu Philosophy, Motilal Banarsidass, , pp. 74\u201376 The Samkhya theory of gu\u1e47as was widely discussed, developed and refined by various schools of Indian philosophies, including Buddhism. Samkhya's philosophical treatises also influenced the development of various theories of Hindu ethics.\n\nVed\u0101nta\nRealization of the nature of Self-identity is the principal object of the Vedanta system of Indian metaphysics. In the Upanishads, self-consciousness is not the first-person indexical self-awareness or the self-awareness which is self-reference without identification, and also not the self-consciousness which as a kind of desire is satisfied by another self-consciousness. It is Self-realisation; the realisation of the Self consisting of consciousness that leads all else.\n\nThe word self-consciousness in the Upanishads means the knowledge about the existence and nature of manusya, human being. It means the consciousness of our own real being, the primary reality. Self-consciousness means self-knowledge, the knowledge of Prajna i.e. of Prana which is attained by a Brahman. According to the Upanishads the Atman or Paramatman is phenomenally unknowable; it is the object of realisation. The Atman is unknowable in its essential nature; it is unknowable in its essential nature because it is the eternal subject who knows about everything including itself. The Atman is the knower and also the known.\n\nMetaphysicians regard the Self either to be distinct from the Absolute or entirely identical with the Absolute. They have given form to three schools of thought \u2013 a) the Dualistic school, b) the Quasi-dualistic school and c) the Monistic school, as the result of their varying mystical experiences. Prakrti and Atman, when treated as two separate and distinct aspects form the basis of the Dualism of the Shvetashvatara Upanishad. Quasi-dualism is reflected in the Vaishnavite-monotheism of Ramanuja and the absolute Monism, in the teachings of Adi Shankara.\n\nSelf-consciousness is the Fourth state of consciousness or Turiya, the first three being Vaisvanara, Taijasa and Prajna. These are the four states of individual consciousness.\n\nThere are three distinct stages leading to Self-realisation. The First stage is in mystically apprehending the glory of the Self within us as though we were distinct from it. The Second stage is in identifying the \"I-within\" with the Self, that we are in essential nature entirely identical with the pure Self. The Third stage is in realising that the Atman is Brahman, that there is no difference between the Self and the Absolute. The Fourth stage is in realising \"I am the Absolute\" \u2013 Aham Brahman Asmi. The Fifth stage is in realising that Brahman is the \"All\" that exists, as also that which does not exist.\n\nBuddhist metaphysics\nIn Buddhist philosophy there are various metaphysical traditions that have proposed different questions about the nature of reality based on the teachings of the Buddha in the early Buddhist texts. The Buddha of the early texts does not focus on metaphysical questions but on ethical and spiritual training and in some cases, he dismisses certain metaphysical questions as unhelpful and indeterminate Avyakta, which he recommends should be set aside. The development of systematic metaphysics arose after the Buddha's death with the rise of the Abhidharma traditions. The Buddhist Abhidharma schools developed their analysis of reality based on the concept of dharmas which are the ultimate physical and mental events that makeup experience and their relations to each other. Noa Ronkin has called their approach \"phenomenological\".\n\nLater philosophical traditions include the Madhyamika school of Nagarjuna, which further developed the theory of the emptiness (shunyata) of all phenomena or dharmas which rejects any kind of substance. This has been interpreted as a form of anti-foundationalism and anti-realism which sees reality as having no ultimate essence or ground. The Yogacara school meanwhile promoted a theory called \"awareness only\" (vijnapti-matra) which has been interpreted as a form of Idealism or Phenomenology and denies the split between awareness itself and the objects of awareness.\n\nIslamic metaphysics\n\nMajor ideas in Sufi metaphysics have surrounded the concept of we\u1e25dah (\u0648\u062d\u062f\u0629) meaning \"unity\", or in Arabic \u062a\u0648\u062d\u064a\u062f tawhid. wa\u1e25dat al-wuj\u016bd literally means the \"Unity of Existence\" or \"Unity of Being.\" The phrase has been translated \"pantheism.\" Wujud (i.e. existence or presence) here refers to Allah's wujud (compare tawhid). On the other hand, wa\u1e25dat ash-shuh\u016bd, meaning \"Apparentism\" or \"Monotheism of Witness\", holds that God and his creation are entirely separate.\n\nScholasticism and the Middle Ages\n\nBetween about 1100 and 1500, philosophy as a discipline took place as part of the Catholic church's teaching system, known as scholasticism. Scholastic philosophy took place within an established framework blending Christian theology with Aristotelian teachings. Although fundamental orthodoxies were not commonly challenged, there were nonetheless deep metaphysical disagreements, particularly over the problem of universals, which engaged Duns Scotus and Pierre Abelard. William of Ockham is remembered for his principle of ontological parsimony.\n\nContinental rationalism\n\nIn the early modern period (17th and 18th centuries), the system-building scope of philosophy is often linked to the rationalist method of philosophy, that is the technique of deducing the nature of the world by pure reason. The scholastic concepts of substance and accident were employed.\n Leibniz proposed in his Monadology a plurality of non-interacting substances.\n Descartes is famous for his dualism of material and mental substances.\n Spinoza believed reality was a single substance of God-or-nature.\n\nWolff\nChristian Wolff had theoretical philosophy divided into an ontology or philosophia prima as a general metaphysics, which arises as a preliminary to the distinction of the three \"special metaphysics\" on the soul, world and God: rational psychology, rational cosmology and rational theology. The three disciplines are called empirical and rational because they are independent of revelation. This scheme, which is the counterpart of religious tripartition in creature, creation, and Creator, is best known to philosophical students by Kant's treatment of it in the Critique of Pure Reason. In the \"Preface\" of the 2nd edition of Kant's book, Wolff is defined \"the greatest of all dogmatic philosophers.\"\n\nBritish empiricism\n\nBritish empiricism marked something of a reaction to rationalist and system-building metaphysics, or speculative metaphysics as it was pejoratively termed. The skeptic David Hume famously declared that most metaphysics should be consigned to the flames (see below). Hume was notorious among his contemporaries as one of the first philosophers to openly doubt religion, but is better known now for his critique of causality. John Stuart Mill, Thomas Reid and John Locke were less skeptical, embracing a more cautious style of metaphysics based on realism, common sense and science. Other philosophers, notably George Berkeley were led from empiricism to idealistic metaphysics.\n\nKant\nImmanuel Kant attempted a grand synthesis and revision of the trends already mentioned: scholastic philosophy, systematic metaphysics, and skeptical empiricism, not to forget the burgeoning science of his day. As did the systems builders, he had an overarching framework in which all questions were to be addressed. Like Hume, who famously woke him from his 'dogmatic slumbers', he was suspicious of metaphysical speculation, and also places much emphasis on the limitations of the human mind.\nKant described his shift in metaphysics away from making claims about an objective noumenal world, towards exploring the subjective phenomenal world, as a Copernican Revolution, by analogy to (though opposite in direction to) Copernicus' shift from man (the subject) to the sun (an object) at the center of the universe.\n\nKant saw rationalist philosophers as aiming for a kind of metaphysical knowledge he defined as the synthetic apriori\u2014that is knowledge that does not come from the senses (it is a priori) but is nonetheless about reality (synthetic). Inasmuch as it is about reality, it differs from abstract mathematical propositions (which he terms analytical apriori), and being apriori it is distinct from empirical, scientific knowledge (which he terms synthetic aposteriori). The only synthetic apriori knowledge we can have is of how our minds organise the data of the senses; that organising framework is space and time, which for Kant have no mind-independent existence, but nonetheless operate uniformly in all humans. Apriori knowledge of space and time is all that remains of metaphysics as traditionally conceived. There is a reality beyond sensory data or phenomena, which he calls the realm of noumena; however, we cannot know it as it is in itself, but only as it appears to us. He allows himself to speculate that the origins of phenomenal God, morality, and free will might exist in the noumenal realm, but these possibilities have to be set against its basic unknowability for humans. Although he saw himself as having disposed of metaphysics, in a sense, he has generally been regarded in retrospect as having a metaphysics of his own, and as beginning the modern analytical conception of the subject.\n\nLate modern philosophy\n\nNineteenth century philosophy was overwhelmingly influenced by Kant and his successors. Schopenhauer, Schelling, Fichte and Hegel all purveyed their own panoramic versions of German Idealism, Kant's own caution about metaphysical speculation, and refutation of idealism, having fallen by the wayside. The idealistic impulse continued into the early twentieth century with British idealists such as F. H. Bradley and J. M. E. McTaggart.  Followers of Karl Marx took Hegel's dialectic view of history and re-fashioned it as materialism.\n\nEarly analytic philosophy and positivism\nDuring the period when idealism was dominant in philosophy, science had been making great advances. The arrival of a new generation of scientifically minded philosophers led to a sharp decline in the popularity of idealism during the 1920s.\n\nAnalytic philosophy was spearheaded by Bertrand Russell and G. E. Moore. Russell and William James tried to compromise between idealism and materialism with the theory of neutral monism.\n\nThe early to mid-twentieth-century philosophy saw a trend to reject metaphysical questions as meaningless. The driving force behind this tendency was the philosophy of logical positivism as espoused by the Vienna Circle, which argued that the meaning of a statement was its prediction of observable results of an experiment, and thus that there is no need to postulate the existence of any objects other than these perceptual observations.\n\nAt around the same time, the American pragmatists were steering a middle course between materialism and idealism.\nSystem-building metaphysics, with a fresh inspiration from science, was revived by A. N. Whitehead and Charles Hartshorne.\n\nContinental philosophy\nThe forces that shaped analytic philosophy\u2014the break with idealism, and the influence of science\u2014were much less significant outside the English speaking world, although there was a shared turn toward language. Continental philosophy continued in a trajectory from post Kantianism.\n\nThe phenomenology of Husserl and others was intended as a collaborative project for the investigation of the features and structure of consciousness common to all humans, in line with Kant's basing his synthetic apriori on the uniform operation of consciousness. It was officially neutral with regards to ontology, but was nonetheless to spawn a number of metaphysical systems. Brentano's concept of intentionality would become widely influential, including on analytic philosophy.\n\nHeidegger, author of Being and Time, saw himself as re-focusing on Being-qua-being, introducing the novel concept of Dasein in the process. Classing himself an existentialist, Sartre wrote an extensive study of Being and Nothingness.\n\nThe speculative realism movement marks a return to full blooded realism.\n\nProcess metaphysics\n\nThere are two fundamental aspects of everyday experience: change and persistence. Until recently, the Western philosophical tradition has arguably championed substance and persistence, with some notable exceptions, however. According to process thinkers, novelty, flux and accident do matter, and sometimes they constitute the ultimate reality.\n\nIn a broad sense, process metaphysics is as old as Western philosophy, with figures such as Heraclitus, Plotinus, Duns Scotus, Leibniz, David Hume, Georg Wilhelm Friedrich Hegel, Friedrich Wilhelm Joseph von Schelling, Gustav Theodor Fechner, Friedrich Adolf Trendelenburg, Charles Renouvier, Karl Marx, Ernst Mach, Friedrich Wilhelm Nietzsche, \u00c9mile Boutroux, Henri Bergson, Samuel Alexander and Nicolas Berdyaev. It seemingly remains an open question whether major \"Continental\" figures such as the late Martin Heidegger, Maurice Merleau-Ponty, Gilles Deleuze, Michel Foucault, or Jacques Derrida should be included.\n\nIn a strict sense, process metaphysics may be limited to the works of a few philosophers: G. W. F. Hegel, Charles Sanders Peirce, William James, Henri Bergson, A. N. Whitehead, and John Dewey. From a European perspective, there was a very significant and early Whiteheadian influence on the works of outstanding scholars such as \u00c9mile Meyerson (1859\u20131933), Louis Couturat (1868\u20131914), Jean Wahl (1888\u20131974), Robin George Collingwood (1889\u20131943), Philippe Devaux (1902\u20131979), Hans Jonas (1903\u20131993), Dorothy M. Emmett (1904\u20132000), Maurice Merleau Ponty (1908\u20131961), Enzo Paci (1911\u20131976), Charlie Dunbar Broad (1887\u20131971), Wolfe Mays (1912\u20132005), Ilya Prigogine (1917\u20132003), Jules Vuillemin (1920\u20132001), Jean Ladri\u00e8re (1921\u20132007), Gilles Deleuze (1925\u20131995), Wolfhart Pannenberg (1928\u20132014), and Reiner Wiehl (1929\u20132010).\n\nContemporary analytic philosophy\nWhile early analytic philosophy tended to reject metaphysical theorizing, under the influence of logical positivism, it was revived in the second half of the twentieth century. Philosophers such as David K. Lewis and David Armstrong developed elaborate theories on a range of topics such as universals, causation, possibility and necessity and abstract objects. However, the focus of analytic philosophy generally is away from the construction of all-encompassing systems and toward close analysis of individual ideas.\n\nAmong the developments that led to the revival of metaphysical theorizing were Quine's attack on the analytic\u2013synthetic distinction, which was generally taken to undermine Carnap's distinction between existence questions internal to a framework and those external to it.\n\nThe philosophy of fiction, the problem of empty names, and the debate over existence's status as a property have all come of relative obscurity into the limelight, while perennial issues such as free will, possible worlds, and the philosophy of time have had new life breathed into them.Van Inwagen, Peter, and Dean Zimmerman (eds.) (1998), Metaphysics: The Big Questions.\n\nThe analytic view is of metaphysics as studying phenomenal human concepts rather than making claims about the noumenal world, so its style often blurs into philosophy of language and introspective psychology.   Compared to system-building, it can seem very dry, stylistically similar to computer programming, mathematics or even accountancy (as a common stated goal is to \"account for\" entities in the world).\n\nSee also\n Computational metaphysics\n Feminist metaphysics\n Fundamental question of metaphysics\n Metaphysical grounding\n Metaphilosophy\n Meta-ontology\n Meta-epistemology\n Metasemantics\n Meta-ethics\n Metacognition\n Metaphysical fiction novels\n Metaphysics of presence\n Philosophical logic\n Philosophical realism\n Philosophical theology\n Philosophy of science\n\nNotes\n\nReferences\n\nBibliography\n \n Butchvarov, Panayot (1979). Being Qua Being: A Theory of Identity, Existence and Predication. Bloomington and London: Indiana University Press.\n Chalmers, David, David Manley and Ryan Wasserman, eds. (2009). Metametaphysics: New Essays on the Foundations of Ontology. Oxford University Press.\n Crane, T and Farkas, K (2004). Metaphysics: A Guide and Anthology, Oxford University Press, .\n Gale, Richard M. (2002). The Blackwell Guide to Metaphysics. Oxford: Blackwell.\n Gay, Peter. (1966). The Enlightenment: An Interpretation (2 vols.). New York: W.W. Norton & Company.\n Harris, E. E. (1965). The Foundations of Metaphysics in Science. London: George Allen and Unwin.\n Harris, E. E. (2000). The Restitution of Metaphysics. New York: Humanity Books.\n Heisenberg, Werner (1958), \"Atomic Physics and Causal Law,\" from The Physicist's Conception of Nature.\n Koons, Robert C. and Pickavance, Timothy H. (2015), Metaphysics: The Fundamentals. Wiley-Blackwell.\n Le Poidevin R. & al. eds. (2009). The Routledge Companion to Metaphysics. New York: Routledge.\n Loux, M. J. (2006). Metaphysics: A Contemporary Introduction (3rd ed.). London: Routledge.\n Lowe, E. J. (2002). A Survey of Metaphysics. Oxford: Oxford University Press.\n Tuomas E. Tahko (2015). An Introduction to Metametaphysics. Cambridge: Cambridge University Press.\n\nFurther reading\n Benovsky, Jiri (2016), Meta-metaphysics: On Metaphysical Equivalence, Primitiveness, and Theory Choice. Springer.\n Bliss, Ricki and J. T. M. Miller, eds. (forthcoming). The Routledge Handbook of Metametaphysics. Routledge.\n Kim, Jaegwon and Ernest Sosa, eds. (1999). Metaphysics: An Anthology. Blackwell Philosophy Anthologies.\n Kim, Jaegwon and Ernest Sosa, eds. (2000). A Companion to Metaphysics. Malden Massachusetts. Blackwell.\n Neil A. Manson, Robert W. Barnard, eds. (2014). The Bloomsbury Companion to Metaphysics. Bloomsbury.\n Raven, Michael J. (2020). The Routledge Handbook of Metaphysical Grounding''. Routledge.\n\nExternal links\n\n \n \n \n Metaphysics at Encyclop\u00e6dia Britannica\n The London Philosophy Study Guide  offers many suggestions on what to read, depending on the student's familiarity with the subject: Logic & Metaphysics .",
  "Mass media": "Mass media refers to a diverse array of media technologies that reach a large audience via mass communication. The technologies through which this communication takes place include a variety of outlets.\n\nBroadcast media transmit information electronically via media such as films, radio, recorded music, or television. Digital media comprises both Internet and mobile mass communication. Internet media comprise such services as email, social media sites, websites, and Internet-based radio and television. Many other mass media outlets have an additional presence on the web, by such means as linking to or running TV ads online, or distributing QR codes in outdoor or print media to direct mobile users to a website. In this way, they can use the easy accessibility and outreach capabilities the Internet affords, as thereby easily broadcast information throughout many different regions of the world simultaneously and cost-efficiently. Outdoor media transmit information via such media as AR advertising; billboards; blimps; flying billboards (signs in tow of airplanes); placards or kiosks placed inside and outside buses, commercial buildings, shops, sports stadiums, subway cars, or trains; signs; or skywriting. Print media transmit information via physical objects, such as books, comics, magazines, newspapers, or pamphlets. Event organising and public speaking can also be considered forms of mass media.\n\nThe organisations that control these technologies, such as movie studios, publishing companies, and radio and television stations, are also known as the mass media.\n\nIssues with definition \n\nIn the late 20th century, mass media could be classified into eight mass media industries: books, the Internet, magazines, movies, newspapers, radio, recordings and television. The explosion of digital communication technology in the late 20th and early 21st centuries made prominent the question: what forms of media should be classified as \"mass media\"? For example, it is controversial whether to include mobile phones, computer games (such as MMORPGs) and video games in the definition. In the early 2000s, a classification called the \"seven mass media\" came into use. In order of introduction, they are:\n\n Print (books, pamphlets, newspapers, magazines, posters, etc.) from the late 15th century\n Recordings (gramophone records, magnetic tapes, cassettes, cartridges, CDs and DVDs) from the late 19th century\n Cinema from about 1900\n Radio from about 1910\n Television from about 1950\n Internet from about 1990\n Mobile phones from about 2000\n\nEach mass medium has its own content types, creative artists, technicians and business models. For example, the Internet includes blogs, podcasts, web sites and various other technologies built atop the general distribution network. The sixth and seventh media, Internet and mobile phones, are often referred to collectively as digital media; and the fourth and fifth, radio and TV, as broadcast media. Some argue that video games have developed into a distinct mass form of media.\n\nWhile a telephone is a two-way communication device, mass media communicates to a large group. In addition, the telephone has transformed into a cell phone which is equipped with Internet access. A question arises whether this makes cell phones a mass medium or simply a device used to access a mass medium (the Internet). There is currently a system by which marketers and advertisers are able to tap into satellites, and broadcast commercials and advertisements directly to cell phones, unsolicited by the phone's user. This transmission of mass advertising to millions of people is another form of mass communication.\n\nVideo games may also be evolving into a mass medium. Video games (for example, massively multiplayer online role-playing games (MMORPGs), such as RuneScape) provide a common gaming experience to millions of users across the globe and convey the same messages and ideologies to all their users. Users sometimes share the experience with one another by playing online. Excluding the Internet, however, it is questionable whether players of video games are sharing a common experience when they play the game individually. It is possible to discuss in great detail the events of a video game with a friend one has never played with, because the experience is identical to each. The question, then, is whether this is a form of mass communication.\n\nCharacteristics \n\nFive characteristics of mass communication have been identified by sociologist John Thompson of Cambridge University:\n \"[C]omprises both technical and institutional methods of production and distribution\" \u2013 This is evident throughout the history of mass media, from print to the Internet, each suitable for commercial utility\n Involves the \"commodification of symbolic forms\" \u2013 as the production of materials relies on its ability to manufacture and sell large quantities of the work; as radio stations rely on their time sold to advertisements, so too newspapers rely on their space for the same reasons\n \"[S]eparate contexts between the production and reception of information\"\n Its \"reach to those 'far removed' in time and space, in comparison to the producers\"\n \"[I]nformation distribution\" \u2013 a \"one to many\" form of communication, whereby products are mass-produced and disseminated to a great quantity of audiences\n\nMass vs. mainstream and alternative \n\nThe term \"mass media\" is sometimes erroneously used as a synonym for \"mainstream media\". Mainstream media are distinguished from alternative media by their content and point of view. Alternative media are also \"mass media\" outlets in the sense that they use technology capable of reaching many people, even if the audience is often smaller than the mainstream.\n\nIn common usage, the term \"mass\" denotes not that a given number of individuals receives the products, but rather that the products are available in principle to a plurality of recipients.\n\nForms of mass media\n\nBroadcast \n\nThe sequencing of content in a broadcast is called a schedule. With all technological endeavours a number of technical terms and slang have developed.\n\nRadio and television programs are distributed over frequency bands which are highly regulated in the United States. Such regulation includes determination of the width of the bands, range, licensing, types of receivers and transmitters used, and acceptable content.\n\nCable television programs are often broadcast simultaneously with radio and television programs, but have a more limited audience. By coding signals and requiring a cable converter box at individual recipients' locations, cable also enables subscription-based channels and pay-per-view services.\n\nA broadcasting organisation may broadcast several programs simultaneously, through several channels (frequencies), for example BBC One and Two. On the other hand, two or more organisations may share a channel and each use it during a fixed part of the day, such as the Cartoon Network/Adult Swim. Digital radio and digital television may also transmit multiplexed programming, with several channels compressed into one ensemble.\n\nWhen broadcasting is done via the Internet the term webcasting is often used. In 2004, a new phenomenon occurred when a number of technologies combined to produce podcasting. Podcasting is an asynchronous broadcast/narrowcast medium. Adam Curry and his associates, the Podshow, are principal proponents of podcasting.\n\nFilm \n\nThe term 'film' encompasses motion pictures as individual projects, as well as the field in general. The name comes from the photographic film (also called film stock), historically the primary medium for recording and displaying motion pictures. Many other terms for film exist, such as motion pictures (or just pictures and \"picture\"), the silver screen, photoplays, the cinema, picture shows, flicks and, most commonly, movies.\n\nFilms are produced by recording people and objects with cameras, or by creating them using animation techniques or special effects. Films comprise a series of individual frames, but when these images are shown in rapid succession, an illusion of motion is created. Flickering between frames is not seen because of an effect known as persistence of vision, whereby the eye retains a visual image for a fraction of a second after the source has been removed. Also of relevance is what causes the perception of motion: a psychological effect identified as beta movement.\n\nFilm has emerged as an important art form. They entertain, educate, enlighten and inspire audiences. Any film can become a worldwide attraction, especially with the addition of dubbing or subtitles that translate the original language.\n\nVideo games \n\nA video game is a computer-controlled game in which a video display, such as a monitor or television set, is the primary feedback device. The term \"computer game\" also includes games which display only text or which use other methods, such as sound or vibration, as their primary feedback device. There always must also be some sort of input device, usually in the form of button/joystick combinations (on arcade games), a keyboard and mouse/trackball combination (computer games), a controller (console games), or a combination of any of the above. Also, more esoteric devices have been used for input, e.g., the player's motion. Usually there are rules and goals, but in more open-ended games the player may be free to do whatever they like within the confines of the virtual universe.\n\nIn common usage, an \"arcade game\" refers to a game designed to be played in an establishment in which patrons pay to play on a per-use basis. A \"computer game\" or \"PC game\" refers to a game that is played on a personal computer. A \"Console game\" refers to one that is played on a device specifically designed for the use of such, while interfacing with a standard television set. A \"video game\" (or \"videogame\") has evolved into a catchall phrase that encompasses the aforementioned along with any game made for any other device, including, but not limited to, advanced calculators, mobile phones, PDAs, etc.\n\nAudio recording and reproduction \n\nSound recording and reproduction is the electrical or mechanical re-creation or amplification of sound, often as music. This involves the use of audio equipment such as microphones, recording devices and loudspeakers. From early beginnings with the invention of the phonograph using purely mechanical techniques, the field has advanced with the invention of electrical recording, the mass production of the 78 record, the magnetic wire recorder followed by the tape recorder, the vinyl LP record. The invention of the compact cassette in the 1960s, followed by Sony's Walkman, gave a major boost to the mass distribution of music recordings, and the invention of digital recording and the compact disc in 1983 brought massive improvements in ruggedness and quality. The most recent developments have been in digital audio players.\n\nAn album is a collection of related audio recordings, released together to the public, usually commercially.\n\nThe term record album originated from the fact that 78 RPM phonograph disc records were kept together in a book resembling a photo album. The first collection of records to be called an \"album\" was Tchaikovsky's Nutcracker Suite, release in April 1909 as a four-disc set by Odeon Records. It retailed for 16 shillings\u2014about \u00a315 in modern currency.\n\nA music video (also promo) is a short film or video that accompanies a complete piece of music, most commonly a song. Modern music videos were primarily made and used as a marketing device intended to promote the sale of music recordings. Although the origins of music videos go back much further, they came into their own in the 1980s, when Music Television's format was based on them. In the 1980s, the term \"rock video\" was often used to describe this form of entertainment, although the term has fallen into disuse.\n\nMusic videos can accommodate all styles of filmmaking, including animation, live-action films, documentaries, and non-narrative, abstract film.\n\nInternet \n\nThe Internet (also known simply as \"the Net\" or less precisely as \"the Web\") is a more interactive medium of mass media, and can be briefly described as \"a network of networks\". Specifically, it is the worldwide, publicly accessible network of interconnected computer networks that transmit data by packet switching using the standard Internet Protocol (IP). It consists of millions of smaller domestic, academic, business and governmental networks, which together carry various information and services, such as email, online chat, file transfer, and the interlinked web pages and other documents of the World Wide Web.\n\nContrary to some common usage, the Internet and the World Wide Web are not synonymous: the Internet is the system of interconnected computer networks, linked by copper wires, fibre-optic cables, wireless connections etc.; the Web is the contents, or the interconnected documents, linked by hyperlinks and URLs. The World Wide Web is accessible through the Internet, along with many other services including e-mail, file sharing and others described below.\n\nToward the end of the 20th century, the advent of the World Wide Web marked the first era in which most individuals could have a means of exposure on a scale comparable to that of mass media. Anyone with a web site has the potential to address a global audience, although serving to high levels of web traffic is still relatively expensive. It is possible that the rise of peer-to-peer technologies may have begun the process of making the cost of bandwidth manageable. Although a vast amount of information, imagery, and commentary (i.e. \"content\") has been made available, it is often difficult to determine the authenticity and reliability of information contained in web pages (in many cases, self-published). The invention of the Internet has also allowed breaking news stories to reach around the globe within minutes. This rapid growth of instantaneous, decentralised communication is often deemed likely to change mass media and its relationship to society.\n\n\"Cross-media\" means the idea of distributing the same message through different media channels. A similar idea is expressed in the news industry as \"convergence\". Many authors understand cross-media publishing to be the ability to publish in both print and on the web without manual conversion effort. An increasing number of wireless devices with mutually incompatible data and screen formats make it even more difficult to achieve the objective \"create once, publish many\".\n\nThe Internet is quickly becoming the center of mass media. Everything is becoming accessible via the internet. Rather than picking up a newspaper, or watching the 10 o'clock news, people can log onto the internet to get the news they want, when they want it. For example, many workers listen to the radio through the Internet while sitting at their desk.\n\nEven the education system relies on the Internet. Teachers can contact the entire class by sending one e-mail. They may have web pages on which students can get another copy of the class outline or assignments. Some classes have class blogs in which students are required to post weekly, with students graded on their contributions.\n\nBlogs (web logs) \n\nBlogging, too, has become a pervasive form of media. A blog is a website, usually maintained by an individual, with regular entries of commentary, descriptions of events, or interactive media such as images or video. Entries are commonly displayed in reverse chronological order, with most recent posts shown on top. Many blogs provide commentary or news on a particular subject; others function as more personal online diaries. A typical blog combines text, images and other graphics, and links to other blogs, web pages, and related media. The ability for readers to leave comments in an interactive format is an important part of many blogs. Most blogs are primarily textual, although some focus on art (artlog), photographs (photoblog), sketchblog, videos (vlog), music (MP3 blog) and audio (podcasting), are part of a wider network of social media. Microblogging is another type of blogging which consists of blogs with very short posts.\n\nRSS feeds \n\nRSS is a format for syndicating news and the content of news-like sites, including major news sites like Wired, news-oriented community sites like Slashdot, and personal blogs. It is a family of Web feed formats used to publish frequently updated content such as blog entries, news headlines, and podcasts. An RSS document (which is called a \"feed\" or \"web feed\" or \"channel\") contains either a summary of content from an associated web site or the full text. RSS makes it possible for people to keep up with web sites in an automated manner that can be piped into special programs or filtered displays.\n\nPodcast \n\nA podcast is a series of digital-media files which are distributed over the Internet using syndication feeds for playback on portable media players and computers. The term podcast, like broadcast, can refer either to the series of content itself or to the method by which it is syndicated; the latter is also called podcasting. The host or author of a podcast is often called a podcaster.\n\nMobile \n\nMobile phones were introduced in Japan in 1979 but became a mass media only in 1998 when the first downloadable ringing tones were introduced in Finland. Soon most forms of media content were introduced on mobile phones, tablets and other portable devices, and today the total value of media consumed on mobile vastly exceeds that of internet content, and was worth over $31 billion in 2007 (source Informa). The mobile media content includes over $8 billion worth of mobile music (ringing tones, ringback tones, truetones, MP3 files, karaoke, music videos, music streaming services etc.); over $5 billion worth of mobile gaming; and various news, entertainment and advertising services. In Japan mobile phone books are so popular that five of the ten best-selling printed books were originally released as mobile phone books.\n\nSimilar to the internet, mobile is also an interactive media, but has far wider reach, with 3.3 billion mobile phone users at the end of 2007 to 1.3 billion internet users (source ITU). Like email on the internet, the top application on mobile is also a personal messaging service, but SMS text messaging is used by over 2.4 billion people. Practically all internet services and applications exist or have similar cousins on mobile, from search to multiplayer games to virtual worlds to blogs. Mobile has several unique benefits which many mobile media pundits claim make mobile a more powerful media than either TV or the internet, starting with mobile being permanently carried and always connected. Mobile has the best audience accuracy and is the only mass media with a built-in payment channel available to every user without any credit cards or PayPal accounts or even an age limit. Mobile is often called the 7th Mass Medium and either the fourth screen (if counting cinema, TV and PC screens) or the third screen (counting only TV and PC).\n\nPrint media\n\nMagazine \n\nA magazine is a periodical publication containing a variety of articles, generally financed by advertising or purchase by readers.\n\nMagazines are typically published weekly, biweekly, monthly, bimonthly or quarterly, with a date on the cover that is in advance of the date it is actually published. They are often printed in color on coated paper, and are bound with a soft cover.\n\nMagazines fall into two broad categories: consumer magazines and business magazines. In practice, magazines are a subset of periodicals, distinct from those periodicals produced by scientific, artistic, academic or special interest publishers which are subscription-only, more expensive, narrowly limited in circulation, and often have little or no advertising.\n\nMagazines can be classified as:\n General interest magazines (e.g. Frontline, India Today, The Week, The Sunday Times etc.)\n Special interest magazines (women's, sports, business, scuba diving, etc.)\n\nNewspaper \nA newspaper is a publication containing news and information and advertising, usually printed on low-cost paper called newsprint. It may be general or special interest, most often published daily or weekly. The most important function of newspapers is to inform the public of significant events. Local newspapers inform local communities and include advertisements from local businesses and services, while national newspapers tend to focus on a theme, which can be exampled with The Wall Street Journal as they offer news on finance and business related-topics. The first printed newspaper was published in 1605, and the form has thrived even in the face of competition from technologies such as radio and television. Recent developments on the Internet are posing major threats to its business model, however. Paid circulation is declining in most countries, and advertising revenue, which makes up the bulk of a newspaper's income, is shifting from print to online; some commentators, nevertheless, point out that historically new media such as radio and television did not entirely supplant existing.\n\nThe internet has challenged the press as an alternative source of information and opinion but has also provided a new platform for newspaper organisations to reach new audiences. According to the World Trends Report, between 2012 and 2016, print newspaper circulation continued to fall in almost all regions, with the exception of Asia and the Pacific, where the dramatic increase in sales in a few select countries has offset falls in historically strong Asian markets such as Japan and the Republic of Korea. Most notably, between 2012 and 2016, India's print circulation grew by 89 per cent.\n\nOutdoor media \n\nOutdoor media is a form of mass media which comprises billboards, signs, placards placed inside and outside commercial buildings/objects like shops/buses, flying billboards (signs in tow of airplanes), blimps, skywriting, AR advertising. Many commercial advertisers use this form of mass media when advertising in sports stadiums. Tobacco and alcohol manufacturers used billboards and other outdoor media extensively. However, in 1998, the Master Settlement Agreement between the US and the tobacco industries prohibited the billboard advertising of cigarettes. In a 1994 Chicago-based study, Diana Hackbarth and her colleagues revealed how tobacco- and alcohol-based billboards were concentrated in poor neighbourhoods. In other urban centers, alcohol and tobacco billboards were much more concentrated in African-American neighbourhoods than in white neighbourhoods.\n\nPurposes \nMass media encompasses much more than just news, although it is sometimes misunderstood in this way. It can be used for various purposes:\n Advocacy, both for business and social concerns. This can include advertising, marketing, propaganda, public relations and political communication.\n Entertainment, traditionally through performances of acting, music and TV shows along with light reading; since the late 20th century also through video and computer games.\n Public service announcements and emergency alerts (that can be used as political device to communicate propaganda to the public).\n\nProfessions involving mass media\n\nJournalism \n\nJournalism is the discipline of collecting, analyzing, verifying and presenting information regarding current events, trends, issues and people. Those who practice journalism are known as journalists.\n\nNews-oriented journalism is sometimes described as the \"first rough draft of history\" (attributed to Phil Graham), because journalists often record important events, producing news articles on short deadlines. While under pressure to be first with their stories, news media organisations usually edit and proofread their reports prior to publication, adhering to each organisation's standards of accuracy, quality and style. Many news organisation claim proud traditions of holding government officials and institutions accountable to the public, while media critics have raised questions about holding the press itself accountable to the standards of professional journalism.\n\nPublic relations \n\nPublic relations is the art and science of managing communication between an organisation and its key publics to build, manage and sustain its positive image. Examples include:\n Corporations use marketing public relations to convey information about the products they manufacture or services they provide to potential customers to support their direct sales efforts. Typically, they support sales in the short and long term, establishing and burnishing the corporation's branding for a strong, ongoing market.\n Corporations also use public relations as a vehicle to reach legislators and other politicians, seeking favorable tax, regulatory, and other treatment, and they may use public relations to portray themselves as enlightened employers, in support of human-resources recruiting programs.\n Nonprofit organisations, including schools and universities, hospitals, and human and social service agencies, use public relations in support of awareness programs, fund-raising programs, staff recruiting, and to increase patronage of their services.\n Politicians use public relations to attract votes and raise money, and when successful at the ballot box, to promote and defend their service in office, with an eye to the next election or, at career's end, to their legacy.\n\nPublishing \nPublishing is the industry concerned with the production of literature or information \u2013 the activity of making information available for public view. In some cases, authors may be their own publishers.\nTraditionally, the term refers to the distribution of printed works such as books and newspapers. With the advent of digital information systems and the Internet, the scope of publishing has expanded to include websites, blogs and the like.\n\nAs a business, publishing includes the development, marketing, production, and distribution of newspapers, magazines, books, literary works, musical works, software and other works dealing with information.\n\nPublication is also important as a legal concept; (1) as the process of giving formal notice to the world of a significant intention, for example, to marry or enter bankruptcy, and; (2) as the essential precondition of being able to claim defamation; that is, the alleged libel must have been published.\n\nSoftware publishing \n\nA software publisher is a publishing company in the software industry between the developer and the distributor. In some companies, two or all three of these roles may be combined (and indeed, may reside in a single person, especially in the case of shareware).\n\nSoftware publishers often license software from developers with specific limitations, such as a time limit or geographical region. The terms of licensing vary enormously, and are typically secret.\n\nDevelopers may use publishers to reach larger or foreign markets, or to avoid focussing on marketing. Or publishers may use developers to create software to meet a market need that the publisher has identified.\n\nInternet Based Professions \nA YouTuber is anyone who has made their fame from creating and promoting videos on the public video-sharing site, YouTube. Many YouTube celebrities have made a profession from their site through sponsorships, advertisements, product placement, and network support.\n\nHistory \n\nThe history of mass media can be traced back to the days when dramas were performed in various ancient cultures. This was the first time when a form of media was \"broadcast\" to a wider audience. The first dated printed book known is the \"Diamond Sutra\", printed in China in 868\u00a0AD, although it is clear that books were printed earlier. Movable clay type was invented in 1041 in China. However, due to the slow spread of literacy to the masses in China, and the relatively high cost of paper there, the earliest printed mass-medium was probably European popular prints from about 1400. Although these were produced in huge numbers, very few early examples survive, and even most known to be printed before about 1600 have not survived. The term \"mass media\" was coined with the creation of print media, which is notable for being the first example of mass media, as we use the term today. This form of media started in Europe in the Middle Ages.\n\nJohannes Gutenberg's invention of the printing press allowed the mass production of books to sweep the nation. He printed the first book, a Latin Bible, on a printing press with movable type in 1453. The invention of the printing press gave rise to some of the first forms of mass communication, by enabling the publication of books and newspapers on a scale much larger than was previously possible. The invention also transformed the way the world received printed materials, although books remained too expensive really to be called a mass-medium for at least a century after that. Newspapers developed from about 1612, with the first example in English in 1620; but they took until the 19th century to reach a mass-audience directly. The first high-circulation newspapers arose in London in the early 1800s, such as The Times, and were made possible by the invention of high-speed rotary steam printing presses, and railroads which allowed large-scale distribution over wide geographical areas. The increase in circulation, however, led to a decline in feedback and interactivity from the readership, making newspapers a more one-way medium.\n\nThe phrase \"the media\" began to be used in the 1920s. The notion of \"mass media\" was generally restricted to print media up until the post-Second World War, when radio, television and video were introduced. The audio-visual facilities became very popular, because they provided both information and entertainment, because the colour and sound engaged the viewers/listeners and because it was easier for the general public to passively watch TV or listen to the radio than to actively read. In recent times, the Internet become the latest and most popular mass medium. Information has become readily available through websites, and easily accessible through search engines. One can do many activities at the same time, such as playing games, listening to music and social networking, irrespective of location. Whilst other forms of mass media are restricted in the type of information they can offer, the internet comprises a large percentage of the sum of human knowledge through such things as Google Books. Modern-day mass media includes the internet, mobile phones, blogs, podcasts and RSS feeds.\n\nDuring the 20th century, the growth of mass media was driven by technology, including that which allowed much duplication of material. Physical duplication technologies such as printing, record pressing and film duplication allowed the duplication of books, newspapers and movies at low prices to huge audiences. Radio and television allowed the electronic duplication of information for the first time. Mass media had the economics of linear replication: a single work could make money. An example of Riel and Neil's theory. proportional to the number of copies sold, and as volumes went up, unit costs went down, increasing profit margins further. Vast fortunes were to be made in mass media. In a democratic society, the media can serve the electorate about issues regarding government and corporate entities (see Media influence). Some consider the concentration of media ownership to be a threat to democracy.\n\nMergers and acquisitions \nBetween 1985 and 2018 about 76,720 deals have been announced in the media industry. This sums up to an overall value of around US$5,634 billion. There have been three major waves of M&A in the mass media sector (2000, 2007 and 2015), while the most active year in terms of numbers was 2007 with around 3,808 deals. The United States is the most prominent country in media M&A with 41 of the top 50 deals having an acquirer from the United States.\n\nThe largest deal in history was the acquisition of Time Warner by AOL Inc. for US$164,746.86 million.\n\nInfluence and sociology \n\nLimited-effects theory, originally tested in the 1940s and 1950s, considers that because people usually choose what media to interact with based on what they already believe, media exerts a negligible influence. Class-dominant theory argues that the media reflects and projects the view of a minority elite, which controls it. Culturalist theory, which was developed in the 1980s and 1990s, combines the other two theories and claims that people interact with media to create their own meanings out of the images and messages they receive. This theory states that audience members play an active, rather than passive role in relation to mass media.\n\nThere is an article that argues 90 percent of all mass media including radio broadcast networks and programing, video news, sports entertainment, and others are owned by 6 major companies (GE, News-Corp, Disney, Viacom, Time Warner and CBS). According to Morris Creative Group, these six companies made over $200 billion in revenue in 2010. More diversity is brewing among many companies, but they have recently merged to form an elite which have the power to control the narrative of stories and alter people's beliefs. In the new media-driven age we live in, marketing has more value than ever before because of the various ways it can be implemented. Advertisements can convince citizens to purchase a specific product or have consumers avoid a particular product. The definition of what is acceptable by society can be heavily dictated by the media in regards to the amount of attention it receives.\n\nThe documentary Super Size Me describes how companies like McDonald's have been sued in the past, the plaintiffs claiming that it was the fault of their liminal and subliminal advertising that \"forced\" them to purchase the product. The Barbie and Ken dolls of the 1950s are sometimes cited as the main cause for the obsession in modern-day society for women to be skinny and men to be buff. After the attacks of 9/11, the media gave extensive coverage of the event and exposed Osama Bin Laden's guilt for the attack, information they were told by the authorities. This shaped the public opinion to support the war on terrorism, and later, the war on Iraq. A main concern is that due to this extreme power of the mass media, portraying inaccurate information could lead to an immense public concern. In his book The Commercialization of American Culture, Matthew P. McAllister says that \"a well-developed media system, informing and teaching its citizens, helps democracy move toward its ideal state.\"\n\nIn 1997, J. R. Finnegan Jr. and K. Viswanath identified three main effects or functions of mass media:\n\nThe Knowledge Gap: The mass media influences knowledge gaps due to factors including \"the extent to which the content is appealing, the degree to which information channels are accessible and desirable, and the amount of social conflict and diversity there is in a community\".\nAgenda Setting: People are influenced in how they think about issues due to the selective nature of what media groups choose for public consumption. After publicly disclosing that he had prostate cancer prior to the 2000 New York senatorial election, Rudolph Giuliani, the mayor of New York City (aided by the media) sparked a huge priority elevation of the cancer in people's consciousness. This was because news media began to report on the risks of prostate cancer, which in turn prompted a greater public awareness about the disease and the need for screening. This ability for the media to be able to change how the public thinks and behaves has occurred on other occasions. In mid-1970s when Betty Ford and Happy Rockefeller, wives of the then-President and then-Vice President, respectively, were both diagnosed with breast cancer. J. J. Davis states that \"when risks are highlighted in the media, particularly in great detail, the extent of agenda setting is likely to be based on the degree to which a public sense of outrage and threat is provoked\". When wanting to set an agenda, framing can be invaluably useful to a mass media organisation. Framing involves \"taking a leadership role in the organisation of public discourse about an issue\". The media is influenced by the desire for balance in coverage, and the resulting pressures can come from groups with particular political action and advocacy positions. Finnegan and Viswanath say, \"groups, institutions and advocates compete to identify problems, to move them onto the public agenda, and to define the issues symbolically\" (1997, p.\u00a0324).\nCultivation of Perceptions: The extent to which media exposure shapes audience perceptions over time is known as cultivation. Television is a common experience, especially in places like the United States, to the point where it can be described as a \"homogenising agent\" (S. W. Littlejohn). However, instead of being merely a result of the TV, the effect is often based on socioeconomic factors. Having a prolonged exposure to TV or movie violence might affect a viewer to the extent where they actively think community violence is a problem, or alternatively find it justifiable. The resulting belief is likely to be different depending on where people live, however.\n\nSince the 1950s, when cinema, radio and TV began to be the primary or the only source of information for a larger and larger percentage of the population, these media began to be considered as central instruments of mass control. Up to the point that it emerged the idea that when a country has reached a high level of industrialisation, the country itself \"belongs to the person who controls communications.\"\n\nMass media play a significant role in shaping public perceptions on a variety of important issues, both through the information that is dispensed through them, and through the interpretations they place upon this information. They also play a large role in shaping modern culture, by selecting and portraying a particular set of beliefs, values and traditions (an entire way of life), as reality. That is, by portraying a certain interpretation of reality, they shape reality to be more in line with that interpretation. Mass media also play a crucial role in the spread of civil unrest activities such as anti-government demonstrations, riots and general strikes. That is, the use of radio and television receivers has made the unrest influence among cities not only by the geographic location of cities, but also by proximity within the mass media distribution networks.\n\nRacism and stereotyping \n\nMass media sources, through theories like framing and agenda-setting, can affect the scope of a story as particular facts and information are highlighted (Media influence). This can directly correlate with how individuals may perceive certain groups of people, as the only media coverage a person receives can be very limited and may not reflect the whole story or situation; stories are often covered to reflect a particular perspective to target a specific demographic.\n\nExample \nAccording to Stephen Balkaran, an Instructor of Political Science and African American Studies at Central Connecticut State University, mass media has played a large role in the way white Americans perceive African Americans. The media focus on African American in the contexts of crime, drug use, gang violence and other forms of anti-social behavior has resulted in a distorted and harmful public perception of African Americans.\n\nIn his 1999 article \"Mass Media and Racism\", Balkaran states: \"The media has played a key role in perpetuating the effects of this historical oppression and in contributing to African Americans' continuing status as second-class citizens\". This has resulted in an uncertainty among white Americans as to what the genuine nature of African Americans really is. Despite the resulting racial divide, the fact that these people are undeniably American has \"raised doubts about the white man's value system\". This means that there is a somewhat \"troubling suspicion\" among some Americans that their white America is tainted by the black influence. Mass media as well as propaganda tend to reinforce or introduce stereotypes to the general public.\n\nEthical issues and criticism \n\nLack of local or specific topical focus is a common criticism of mass media. A mass news media outlet is often forced to cover national and international news due to it having to cater for and be relevant for a wide demographic. As such, it has to skip over many interesting or important local stories because they simply do not interest the large majority of their viewers. An example given by the website WiseGeek is that \"the residents of a community might view their fight against development as critical, but the story would only attract the attention of the mass media if the fight became controversial or if precedents of some form were set\".\n\nThe term \"mass\" suggests that the recipients of media products constitute a vast sea of passive, undifferentiated individuals. This is an image associated with some earlier critiques of \"mass culture\" and mass society which generally assumed that the development of mass communication has had a largely negative impact on modern social life, creating a kind of bland and homogeneous culture which entertains individuals without challenging them. However, interactive digital media have also been seen to challenge the read-only paradigm of earlier broadcast media.\n\nWhilst some refer to the mass media as \"opiate of the masses\", others argue that is a vital aspect of human societies. By understanding mass media, one is then able to analyse and find a deeper understanding of one's population and culture. This valuable and powerful ability is one reason why the field of media studies is popular. As WiseGeek says, \"watching, reading, and interacting with a nation's mass media can provide clues into how people think, especially if a diverse assortment of mass media sources are perused\".\n\nSince the 1950s, in the countries that have reached a high level of industrialisation, the mass media of cinema, radio and TV have a key role in political power.\n\nContemporary research demonstrates an increasing level of concentration of media ownership, with many media industries already highly concentrated and dominated by a small number of firms.\n\nCriticism\n\nWhen the study of mass media began the media was compiled of only mass media which is a very different media system than the social media empire of the 21st-century experiences. With this in mind, there are critiques that mass media no longer exists, or at least that it doesn't exist in the same form as it once did. This original form of mass media put filters on what the general public would be exposed to in regards to \"news\" something that is harder to do in a society of social media.\n\nTheorist Lance Bennett explains that excluding a few major events in recent history, it is uncommon for a group big enough to be labeled a mass, to be watching the same news via the same medium of mass production. Bennett's critique of 21st-century mass media argues that today it is more common for a group of people to be receiving different news stories, from completely different sources, and thus, mass media has been re-invented. As discussed above, filters would have been applied to original mass medias when the journalists decided what would or wouldn't be printed.\n\nSocial Media is a large contributor to the change from mass media to a new paradigm because through social media what is mass communication and what is interpersonal communication is confused. Interpersonal/niche communication is an exchange of information and information in a specific genre. In this form of communication, smaller groups of people are consuming news/information/opinions. In contrast, mass media in its original form is not restricted by genre and it is being consumed by the masses.\n\nSee also \n\n Commercial broadcasting\n Concentration of media ownership\n Digital rights management\n Interpersonal communication\n Journalism\n History of journalism\n Media bias\n Media echo chamber\n Media regulation\n Media-system dependency\n Mediatization (media)\n News media\n Newspapers\n History of Newspapers\n Propaganda\n Public relations\n State media\n\nSources\n\nNotes\n\nWorks cited\n\nFurther reading \n\n \n B\u00f6sch, Frank. Mass Media and Historical Change: Germany in International Perspective, 1400 to the Present (Berghahn, 2015). 212 pp. online review\n Cull, Nicholas John, David Culbert and David Welch, eds. Mass Persuasion: A Historical Encyclopedia, 1500 to the Present (2003) 479 pp; worldwide coverage\n Dauber, Cori Elizabeth. \"The shot seen 'round the world': The impact of the images of Mogadishu on American military operations.\" Rhetoric & Public Affairs 4.4 (2001): 653-687 online.\n Folkerts, Jean and Dwight Teeter, eds. Voices of a Nation: A History of Mass Media in the United States (5th Edition, 2008)\n Fourie, Pieter J. Media Studies: Media History, Media and Society (2008)\n\n Graber, Doris A., and Johanna Dunaway. Mass media and American politics;; (CQ Press, 2017) \n\n \n Paneth, Donald, ed. The Encyclopedia of American journalism (1983) online\n\n Ross, Corey. Mass Communications, Society, and Politics from the Empire to the Third Reich (Oxford University press 2010) 448 pp, on Germany\n Vaughn, Stephen L., ed. Encyclopedia of American Journalism (2007) online\n \n\nIn other languages\n Hacker, Violaine \"Citoyennet\u00e9 culturelle et politique europ\u00e9enne des m\u00e9dias: entre comp\u00e9titivit\u00e9 et promotion des valeurs\", Nations, cultures et entreprises en Europe,'' sous la direction de Gilles Rouet, Collection Local et Global, L\u2019Harmattan, Paris, pp.\u00a0163\u201384\n\nExternal links \n\n The Media: Carriers of Contagious Information\n\n Peter Medlin, WNIJ, \"Illinois Is the First State to Have High Schools Teach News Literacy,\" National Public Radio, August 12, 2021\n\n \nPromotion and marketing communications\nMain topic articles",
  "Nature": "Nature, in the broadest sense, is the physical world or universe. \"Nature\" can refer to the phenomena of the physical world, and also to life in general. The study of nature is a large, if not the only, part of science. Although humans are part of nature, human activity is often understood as a separate category from other natural phenomena.\n\nThe word nature is borrowed from the Old French nature and is derived from the Latin word natura, or \"essential qualities, innate disposition\", and in ancient times, literally meant \"birth\". In ancient philosophy, natura is mostly used as the Latin translation of the Greek word physis (\u03c6\u03cd\u03c3\u03b9\u03c2), which originally related to the intrinsic characteristics of plants, animals, and other features of the world to develop of their own accord.\nThe concept of nature as a whole, the physical universe, is one of several expansions of the original notion; it began with certain core applications of the word \u03c6\u03cd\u03c3\u03b9\u03c2 by pre-Socratic philosophers (though this word had a dynamic dimension then, especially for Heraclitus), and has steadily gained currency ever since. \n\nDuring the advent of modern scientific method in the last several centuries, nature became the passive reality, organized and moved by divine laws. With the Industrial revolution, nature increasingly became seen as the part of reality deprived from intentional intervention: it was hence considered as sacred by some traditions (Rousseau, American transcendentalism) or a mere decorum for divine providence or human history (Hegel, Marx). However, a vitalist vision of nature, closer to the presocratic one, got reborn at the same time, especially after Charles Darwin.\n\nWithin the various uses of the word today, \"nature\" often refers to geology and wildlife. Nature can refer to the general realm of living plants and animals, and in some cases to the processes associated with inanimate objects\u2014the way that particular types of things exist and change of their own accord, such as the weather and geology of the Earth. It is often taken to mean the \"natural environment\" or wilderness\u2014wild animals, rocks, forest, and in general those things that have not been substantially altered by human intervention, or which persist despite human intervention. For example, manufactured objects and human interaction generally are not considered part of nature, unless qualified as, for example, \"human nature\" or \"the whole of nature\". This more traditional concept of natural things that can still be found today implies a distinction between the natural and the artificial, with the artificial being understood as that which has been brought into being by a human consciousness or a human mind. Depending on the particular context, the term \"natural\" might also be distinguished from the unnatural or the supernatural.\n\nEarth\n\nEarth is the only planet known to support life, and its natural features are the subject of many fields of scientific research. Within the Solar System, it is third closest to the Sun; it is the largest terrestrial planet and the fifth largest overall. Its most prominent climatic features are its two large polar regions, two relatively narrow temperate zones, and a wide equatorial tropical to subtropical region. Precipitation varies widely with location, from several metres of water per year to less than a millimetre. 71 percent of the Earth's surface is covered by salt-water oceans. The remainder consists of continents and islands, with most of the inhabited land in the Northern Hemisphere.\n\nEarth has evolved through geological and biological processes that have left traces of the original conditions. The outer surface is divided into several gradually migrating tectonic plates. The interior remains active, with a thick layer of plastic mantle and an iron-filled core that generates a magnetic field. This iron core is composed of a solid inner phase, and a fluid outer phase. Convective motion in the core generates electric currents through dynamo action, and these, in turn, generate the geomagnetic field.\n\nThe atmospheric conditions have been significantly altered from the original conditions by the presence of life-forms, which create an ecological balance that stabilizes the surface conditions. Despite the wide regional variations in climate by latitude and other geographic factors, the long-term average global climate is quite stable during interglacial periods, and variations of a degree or two of average global temperature have historically had major effects on the ecological balance, and on the actual geography of the Earth.\n\nGeology\n\nGeology is the science and study of the solid and liquid matter that constitutes the Earth. The field of geology encompasses the study of the composition, structure, physical properties, dynamics, and history of Earth materials, and the processes by which they are formed, moved, and changed. The field is a major academic discipline, and is also important for mineral and hydrocarbon extraction, knowledge about and mitigation of natural hazards, some Geotechnical engineering fields, and understanding past climates and environments.\n\nGeological evolution\n\nThe geology of an area evolves through time as rock units are deposited and inserted and deformational processes change their shapes and locations.\n\nRock units are first emplaced either by deposition onto the surface or intrude into the overlying rock. Deposition can occur when sediments settle onto the surface of the Earth and later lithify into sedimentary rock, or when as volcanic material such as volcanic ash or lava flows, blanket the surface. Igneous intrusions such as batholiths, laccoliths, dikes, and sills, push upwards into the overlying rock, and crystallize as they intrude.\n\nAfter the initial sequence of rocks has been deposited, the rock units can be deformed and/or metamorphosed. Deformation typically occurs as a result of horizontal shortening, horizontal extension, or side-to-side (strike-slip) motion. These structural regimes broadly relate to convergent boundaries, divergent boundaries, and transform boundaries, respectively, between tectonic plates.\n\nHistorical perspective\n\nEarth is estimated to have formed 4.54\u00a0billion years ago from the solar nebula, along with the Sun and other planets. The Moon formed roughly 20\u00a0million years later. Initially molten, the outer layer of the Earth cooled, resulting in the solid crust. Outgassing and volcanic activity produced the primordial atmosphere. Condensing water vapor, most or all of which came from ice delivered by comets, produced the oceans and other water sources. The highly energetic chemistry is believed to have produced a self-replicating molecule around 4\u00a0billion years ago.\n\nContinents formed, then broke up and reformed as the surface of Earth reshaped over hundreds of millions of years, occasionally combining to make a supercontinent. Roughly 750\u00a0million years ago, the earliest known supercontinent Rodinia, began to break apart. The continents later recombined to form Pannotia which broke apart about 540\u00a0million years ago, then finally Pangaea, which broke apart about 180\u00a0million years ago.\n\nDuring the Neoproterozoic era, freezing temperatures covered much of the Earth in glaciers and ice sheets. This hypothesis has been termed the \"Snowball Earth\", and it is of particular interest as it precedes the Cambrian explosion in which multicellular life forms began to proliferate about 530\u2013540\u00a0million years ago.\n\nSince the Cambrian explosion there have been five distinctly identifiable mass extinctions. The last mass extinction occurred some 66 million years ago, when a meteorite collision probably triggered the extinction of the non-avian dinosaurs and other large reptiles, but spared small animals such as mammals. Over the past 66\u00a0million years, mammalian life diversified.\n\nSeveral million years ago, a species of small African ape gained the ability to stand upright. The subsequent advent of human life, and the development of agriculture and further civilization allowed humans to affect the Earth more rapidly than any previous life form, affecting both the nature and quantity of other organisms as well as global climate. By comparison, the Great Oxygenation Event, produced by the proliferation of algae during the Siderian period, required about 300\u00a0million years to culminate.\n\nThe present era is classified as part of a mass extinction event, the Holocene extinction event, the fastest ever to have occurred. Some, such as E. O. Wilson of Harvard University, predict that human destruction of the biosphere could cause the extinction of one-half of all species in the next 100\u00a0years. The extent of the current extinction event is still being researched, debated and calculated by biologists.\n\nAtmosphere, climate, and weather\n\nThe Earth's atmosphere is a key factor in sustaining the ecosystem. The thin layer of gases that envelops the Earth is held in place by gravity. Air is mostly nitrogen, oxygen, water vapor, with much smaller amounts of carbon dioxide, argon, etc. The atmospheric pressure declines steadily with altitude. The ozone layer plays an important role in depleting the amount of ultraviolet (UV) radiation that reaches the surface. As DNA is readily damaged by UV light, this serves to protect life at the surface. The atmosphere also retains heat during the night, thereby reducing the daily temperature extremes.\n\nTerrestrial weather occurs almost exclusively in the lower part of the atmosphere, and serves as a convective system for redistributing heat. Ocean currents are another important factor in determining climate, particularly the major underwater thermohaline circulation which distributes heat energy from the equatorial oceans to the polar regions. These currents help to moderate the differences in temperature between winter and summer in the temperate zones. Also, without the redistributions of heat energy by the ocean currents and atmosphere, the tropics would be much hotter, and the polar regions much colder.\n\nWeather can have both beneficial and harmful effects. Extremes in weather, such as tornadoes or hurricanes and cyclones, can expend large amounts of energy along their paths, and produce devastation. Surface vegetation has evolved a dependence on the seasonal variation of the weather, and sudden changes lasting only a few years can have a dramatic effect, both on the vegetation and on the animals which depend on its growth for their food.\n\nClimate is a measure of the long-term trends in the weather. Various factors are known to influence the climate, including ocean currents, surface albedo, greenhouse gases, variations in the solar luminosity, and changes to the Earth's orbit. Based on historical records, the Earth is known to have undergone drastic climate changes in the past, including ice ages.\n\nThe climate of a region depends on a number of factors, especially latitude. A latitudinal band of the surface with similar climatic attributes forms a climate region. There are a number of such regions, ranging from the tropical climate at the equator to the polar climate in the northern and southern extremes. Weather is also influenced by the seasons, which result from the Earth's axis being tilted relative to its orbital plane. Thus, at any given time during the summer or winter, one part of the Earth is more directly exposed to the rays of the sun. This exposure alternates as the Earth revolves in its orbit. At any given time, regardless of season, the northern and southern hemispheres experience opposite seasons.\n\nWeather is a chaotic system that is readily modified by small changes to the environment, so accurate weather forecasting is limited to only a few days. Overall, two things are happening worldwide: (1) temperature is increasing on the average; and (2) regional climates have been undergoing noticeable changes.\n\nWater on the Earth\n\nWater is a chemical substance that is composed of hydrogen and oxygen (H2O) and is vital for all known forms of life. In typical usage, water refers only to its liquid form or state, but the substance also has a solid state, ice, and a gaseous state, water vapor, or steam. Water covers 71% of the Earth's surface. On Earth, it is found mostly in oceans and other large bodies of water, with 1.6% of water below ground in aquifers and 0.001% in the air as vapor, clouds, and precipitation. Oceans hold 97% of surface water, glaciers, and polar ice caps 2.4%, and other land surface water such as rivers, lakes, and ponds 0.6%. Additionally, a minute amount of the Earth's water is contained within biological bodies and manufactured products.\n\nOceans\n\nAn ocean is a major body of saline water, and a principal component of the hydrosphere. Approximately 71% of the Earth's surface (an area of some 361 million square kilometers) is covered by ocean, a continuous body of water that is customarily divided into several principal oceans and smaller seas. More than half of this area is over  deep. Average oceanic salinity is around 35 parts per thousand (ppt) (3.5%), and nearly all seawater has a salinity in the range of 30 to 38 ppt. Though generally recognized as several 'separate' oceans, these waters comprise one global, interconnected body of salt water often referred to as the World Ocean or global ocean. This concept of a global ocean as a continuous body of water with relatively free interchange among its parts is of fundamental importance to oceanography.\n\nThe major oceanic divisions are defined in part by the continents, various archipelagos, and other criteria: these divisions are (in descending order of size) the Pacific Ocean, the Atlantic Ocean, the Indian Ocean, the Southern Ocean, and the Arctic Ocean. Smaller regions of the oceans are called seas, gulfs, bays and other names. There are also salt lakes, which are smaller bodies of landlocked saltwater that are not interconnected with the World Ocean. Two notable examples of salt lakes are the Aral Sea and the Great Salt Lake.\n\nLakes\n\nA lake (from Latin word lacus) is a terrain feature (or physical feature), a body of liquid on the surface of a world that is localized to the bottom of basin (another type of landform or terrain feature; that is, it is not global) and moves slowly if it moves at all. On Earth, a body of water is considered a lake when it is inland, not part of the ocean, is larger and deeper than a pond, and is fed by a river. The only world other than Earth known to harbor lakes is Titan, Saturn's largest moon, which has lakes of ethane, most likely mixed with methane. It is not known if Titan's lakes are fed by rivers, though Titan's surface is carved by numerous river beds. Natural lakes on Earth are generally found in mountainous areas, rift zones, and areas with ongoing or recent glaciation. Other lakes are found in endorheic basins or along the courses of mature rivers. In some parts of the world, there are many lakes because of chaotic drainage patterns left over from the last Ice Age. All lakes are temporary over geologic time scales, as they will slowly fill in with sediments or spill out of the basin containing them.\n\nPonds\n\nA pond is a body of standing water, either natural or man-made, that is usually smaller than a lake. A wide variety of man-made bodies of water are classified as ponds, including water gardens designed for aesthetic ornamentation, fish ponds designed for commercial fish breeding, and solar ponds designed to store thermal energy. Ponds and lakes are distinguished from streams via current speed. While currents in streams are easily observed, ponds and lakes possess thermally driven micro-currents and moderate wind driven currents. These features distinguish a pond from many other aquatic terrain features, such as stream pools and tide pools.\n\nRivers\n\nA river is a natural watercourse, usually freshwater, flowing towards an ocean, a lake, a sea or another river. In a few cases, a river simply flows into the ground or dries up completely before reaching another body of water. Small rivers may also be called by several other names, including stream, creek, brook, rivulet, and rill; there is no general rule that defines what can be called a river. Many names for small rivers are specific to geographic location; one example is Burn in Scotland and North-east England. Sometimes a river is said to be larger than a creek, but this is not always the case, due to vagueness in the language. A river is part of the hydrological cycle. Water within a river is generally collected from precipitation through surface runoff, groundwater recharge, springs, and the release of stored water in natural ice and snowpacks (i.e., from glaciers).\n\nStreams\n\nA stream is a flowing body of water with a current, confined within a bed and stream banks. In the United States, a stream is classified as a watercourse less than  wide. Streams are important as conduits in the water cycle, instruments in groundwater recharge, and they serve as corridors for fish and wildlife migration. The biological habitat in the immediate vicinity of a stream is called a riparian zone. Given the status of the ongoing Holocene extinction, streams play an important corridor role in connecting fragmented habitats and thus in conserving biodiversity. The study of streams and waterways in general involves many branches of inter-disciplinary natural science and engineering, including hydrology, fluvial geomorphology, aquatic ecology, fish biology, riparian ecology, and others.\n\nEcosystems\n\nEcosystems are composed of a variety of biotic and abiotic components that function in an interrelated way. The structure and composition is determined by various environmental factors that are interrelated. Variations of these factors will initiate dynamic modifications to the ecosystem. Some of the more important components are soil, atmosphere, radiation from the sun, water, and living organisms.\n\nCentral to the ecosystem concept is the idea that living organisms interact with every other element in their local environment. Eugene Odum, a founder of ecology, stated: \"Any unit that includes all of the organisms (ie: the \"community\") in a given area interacting with the physical environment so that a flow of energy leads to clearly defined trophic structure, biotic diversity, and material cycles (i.e.: exchange of materials between living and nonliving parts) within the system is an ecosystem.\" Within the ecosystem, species are connected and dependent upon one another in the food chain, and exchange energy and matter between themselves as well as with their environment. The human ecosystem concept is based on the human/nature dichotomy and the idea that all species are ecologically dependent on each other, as well as with the abiotic constituents of their biotope.\n\nA smaller unit of size is called a microecosystem. For example, a microsystem can be a stone and all the life under it. A macroecosystem might involve a whole ecoregion, with its drainage basin.\n\nWilderness\n\nWilderness is generally defined as areas that have not been significantly modified by human activity. Wilderness areas can be found in preserves, estates, farms, conservation preserves, ranches, national forests, national parks, and even in urban areas along rivers, gulches, or otherwise undeveloped areas. Wilderness areas and protected parks are considered important for the survival of certain species, ecological studies, conservation, and solitude. Some nature writers believe wilderness areas are vital for the human spirit and creativity, and some ecologists consider wilderness areas to be an integral part of the Earth's self-sustaining natural ecosystem (the biosphere). They may also preserve historic genetic traits and that they provide habitat for wild flora and fauna that may be difficult or impossible to recreate in zoos, arboretums, or laboratories.\n\nLife\n\nAlthough there is no universal agreement on the definition of life, scientists generally accept that the biological manifestation of life is characterized by organization, metabolism, growth, adaptation, response to stimuli, and reproduction. Life may also be said to be simply the characteristic state of organisms.\n\nProperties common to terrestrial organisms (plants, animals, fungi, protists, archaea, and bacteria) are that they are cellular, carbon-and-water-based with complex organization, having a metabolism, a capacity to grow, respond to stimuli, and reproduce. An entity with these properties is generally considered life. However, not every definition of life considers all of these properties to be essential. Human-made analogs of life may also be considered to be life.\n\nThe biosphere is the part of Earth's outer shell\u2014including land, surface rocks, water, air and the atmosphere\u2014within which life occurs, and which biotic processes in turn alter or transform. From the broadest geophysiological point of view, the biosphere is the global ecological system integrating all living beings and their relationships, including their interaction with the elements of the lithosphere (rocks), hydrosphere (water), and atmosphere (air). The entire Earth contains over 75\u00a0billion tons (150 trillion pounds or about 6.8\u00d71013\u00a0kilograms) of biomass (life), which lives within various environments within the biosphere.\n\nOver nine-tenths of the total biomass on Earth is plant life, on which animal life depends very heavily for its existence. More than 2 million species of plant and animal life have been identified to date, and estimates of the actual number of existing species range from several million to well over 50\u00a0million. The number of individual species of life is constantly in some degree of flux, with new species appearing and others ceasing to exist on a continual basis. The total number of species is in rapid decline.\n\nEvolution\n\nThe origin of life on Earth is not well understood, but it is known to have occurred at least 3.5\u00a0billion years ago, during the hadean or archean eons on a primordial Earth that had a substantially different environment than is found at present. These life forms possessed the basic traits of self-replication and inheritable traits. Once life had appeared, the process of evolution by natural selection resulted in the development of ever-more diverse life forms.\n\nSpecies that were unable to adapt to the changing environment and competition from other life forms became extinct. However, the fossil record retains evidence of many of these older species. Current fossil and DNA evidence shows that all existing species can trace a continual ancestry back to the first primitive life forms.\n\nWhen basic forms of plant life developed the process of photosynthesis the sun's energy could be harvested to create conditions which allowed for more complex life forms. The resultant oxygen accumulated in the atmosphere and gave rise to the ozone layer. The incorporation of smaller cells within larger ones resulted in the development of yet more complex cells called eukaryotes. Cells within colonies became increasingly specialized, resulting in true multicellular organisms. With the ozone layer absorbing harmful ultraviolet radiation, life colonized the surface of Earth.\n\nMicrobes\n\nThe first form of life to develop on the Earth were microbes, and they remained the only form of life until about a billion years ago when multi-cellular organisms began to appear. Microorganisms are single-celled organisms that are generally microscopic, and smaller than the human eye can see. They include Bacteria, Fungi, Archaea, and Protista.\n\nThese life forms are found in almost every location on the Earth where there is liquid water, including in the Earth's interior.\nTheir reproduction is both rapid and profuse. The combination of a high mutation rate and a horizontal gene transfer ability makes them highly adaptable, and able to survive in new environments, including outer space. They form an essential part of the planetary ecosystem. However, some microorganisms are pathogenic and can post health risk to other organisms.\n\nPlants and animals\n\nOriginally Aristotle divided all living things between plants, which generally do not move fast enough for humans to notice, and animals. In Linnaeus' system, these became the kingdoms Vegetabilia (later Plantae) and Animalia. Since then, it has become clear that the Plantae as originally defined included several unrelated groups, and the fungi and several groups of algae were removed to new kingdoms. However, these are still often considered plants in many contexts. Bacterial life is sometimes included in flora, and some classifications use the term bacterial flora separately from plant flora.\n\nAmong the many ways of classifying plants are by regional floras, which, depending on the purpose of study, can also include fossil flora, remnants of plant life from a previous era. People in many regions and countries take great pride in their individual arrays of characteristic flora, which can vary widely across the globe due to differences in climate and terrain.\n\nRegional floras commonly are divided into categories such as native flora and agricultural and garden flora, the lastly mentioned of which are intentionally grown and cultivated. Some types of \"native flora\" actually have been introduced centuries ago by people migrating from one region or continent to another, and become an integral part of the native, or natural flora of the place to which they were introduced. This is an example of how human interaction with nature can blur the boundary of what is considered nature.\n\nAnother category of plant has historically been carved out for weeds. Though the term has fallen into disfavor among botanists as a formal way to categorize \"useless\" plants, the informal use of the word \"weeds\" to describe those plants that are deemed worthy of elimination is illustrative of the general tendency of people and societies to seek to alter or shape the course of nature. Similarly, animals are often categorized in ways such as domestic, farm animals, wild animals, pests, etc. according to their relationship to human life.\n\nAnimals as a category have several characteristics that generally set them apart from other living things. Animals are eukaryotic and usually multicellular (although see Myxozoa), which separates them from bacteria, archaea, and most protists. They are heterotrophic, generally digesting food in an internal chamber, which separates them from plants and algae. They are also distinguished from plants, algae, and fungi by lacking cell walls.\n\nWith a few exceptions\u2014most notably the two phyla consisting of sponges and placozoans\u2014animals have bodies that are differentiated into tissues. These include muscles, which are able to contract and control locomotion, and a nervous system, which sends and processes signals. There is also typically an internal digestive chamber. The eukaryotic cells possessed by all animals are surrounded by a characteristic extracellular matrix composed of collagen and elastic glycoproteins. This may be calcified to form structures like shells, bones, and spicules, a framework upon which cells can move about and be reorganized during development and maturation, and which supports the complex anatomy required for mobility.\n\nHuman interrelationship\n\nHuman impact\nAlthough humans comprise only a minuscule proportion of the total living biomass on Earth, the human effect on nature is disproportionately large. Because of the extent of human influence, the boundaries between what humans regard as nature and \"made environments\" is not clear cut except at the extremes. Even at the extremes, the amount of natural environment that is free of discernible human influence is diminishing at an increasingly rapid pace. A 2020 study published in Nature found that anthropogenic mass (human-made materials) outweighs all living biomass on earth, with plastic alone exceeding the mass of all land and marine animals combined. And according to a 2021 study published in Frontiers in Forests and Global Change, only about 3% of the planet's terrestrial surface is ecologically and faunally intact, with a low human footprint and healthy populations of native animal species.\n\nThe development of technology by the human race has allowed the greater exploitation of natural resources and has helped to alleviate some of the risk from natural hazards. In spite of this progress, however, the fate of human civilization remains closely linked to changes in the environment. There exists a highly complex feedback loop between the use of advanced technology and changes to the environment that are only slowly becoming understood. Man-made threats to the Earth's natural environment include pollution, deforestation, and disasters such as oil spills. Humans have contributed to the extinction of many plants and animals, with roughly 1 million species threatened with extinction within decades. The loss of biodiversity and ecosystem functions over the last half century have impacted the extent that nature can contribute to human quality of life, and continued declines could pose a major threat to the continued existence of human civilization, unless a rapid course correction is made. The value of natural resources to human society is not reflected in market prices because mostly natural resources are available free of charge. This distorts market pricing of natural resources and at the same time leads to underinvestment in our natural assets. The annual global cost of public subsidies that damage nature is conservatively estimated at $4\u2013$6 trillion (million million). Institutional protections of these natural goods, such as the oceans and rainforests, are lacking. Governments have not prevented these economic externalities.\n\nHumans employ nature for both leisure and economic activities. The acquisition of natural resources for industrial use remains a sizable component of the world's economic system. Some activities, such as hunting and fishing, are used for both sustenance and leisure, often by different people. Agriculture was first adopted around the 9th millennium BCE. Ranging from food production to energy, nature influences economic wealth.\n\nAlthough early humans gathered uncultivated plant materials for food and employed the medicinal properties of vegetation for healing, most modern human use of plants is through agriculture. The clearance of large tracts of land for crop growth has led to a significant reduction in the amount available of forestation and wetlands, resulting in the loss of habitat for many plant and animal species as well as increased erosion.\n\nAesthetics and beauty\n\nBeauty in nature has historically been a prevalent theme in art and books, filling large sections of libraries and bookstores. That nature has been depicted and celebrated by so much art, photography, poetry, and other literature shows the strength with which many people associate nature and beauty. Reasons why this association exists, and what the association consists of, are studied by the branch of philosophy called aesthetics. Beyond certain basic characteristics that many philosophers agree about to explain what is seen as beautiful, the opinions are virtually endless. Nature and wildness have been important subjects in various eras of world history. An early tradition of landscape art began in China during the Tang Dynasty (618\u2013907). The tradition of representing nature as it is became one of the aims of Chinese painting and was a significant influence in Asian art.\n\nAlthough natural wonders are celebrated in the Psalms and the Book of Job, wilderness portrayals in art became more prevalent in the 1800s, especially in the works of the Romantic movement. British artists John Constable and J. M. W. Turner turned their attention to capturing the beauty of the natural world in their paintings. Before that, paintings had been primarily of religious scenes or of human beings. William Wordsworth's poetry described the wonder of the natural world, which had formerly been viewed as a threatening place. Increasingly the valuing of nature became an aspect of Western culture. This artistic movement also coincided with the Transcendentalist movement in the Western world. A common classical idea of beautiful art involves the word mimesis, the imitation of nature. Also in the realm of ideas about beauty in nature is that the perfect is implied through perfect mathematical forms and more generally by patterns in nature. As David Rothenburg writes, \"The beautiful is the root of science and the goal of art, the highest possibility that humanity can ever hope to see\".\n\nMatter and energy\n\nSome fields of science see nature as matter in motion, obeying certain laws of nature which science seeks to understand. For this reason the most fundamental science is generally understood to be \"physics\"\u2014the name for which is still recognizable as meaning that it is the \"study of nature\".\n\nMatter is commonly defined as the substance of which physical objects are composed. It constitutes the observable universe. The visible components of the universe are now believed to compose only 4.9 percent of the total mass. The remainder is believed to consist of 26.8 percent cold dark matter and 68.3 percent dark energy. The exact arrangement of these components is still unknown and is under intensive investigation by physicists.\n\nThe behaviour of matter and energy throughout the observable universe appears to follow well-defined physical laws. These laws have been employed to produce cosmological models that successfully explain the structure and the evolution of the universe we can observe. The mathematical expressions of the laws of physics employ a set of twenty physical constants that appear to be static across the observable universe. The values of these constants have been carefully measured, but the reason for their specific values remains a mystery.\n\nBeyond Earth\n\nOuter space, also simply called space, refers to the relatively empty regions of the Universe outside the atmospheres of celestial bodies. Outer space is used to distinguish it from airspace (and terrestrial locations). There is no discrete boundary between Earth's atmosphere and space, as the atmosphere gradually attenuates with increasing altitude. Outer space within the Solar System is called interplanetary space, which passes over into interstellar space at what is known as the heliopause.\n\nOuter space is sparsely filled with several dozen types of organic molecules discovered to date by microwave spectroscopy, blackbody radiation left over from the Big Bang and the origin of the universe, and cosmic rays, which include ionized atomic nuclei and various subatomic particles. There is also some gas, plasma and dust, and small meteors. Additionally, there are signs of human life in outer space today, such as material left over from previous crewed and uncrewed launches which are a potential hazard to spacecraft. Some of this debris re-enters the atmosphere periodically.\n\nAlthough Earth is the only body within the Solar System known to support life, evidence suggests that in the distant past the planet Mars possessed bodies of liquid water on the surface. For a brief period in Mars' history, it may have also been capable of forming life. At present though, most of the water remaining on Mars is frozen.\nIf life exists at all on Mars, it is most likely to be located underground where liquid water can still exist.\n\nConditions on the other terrestrial planets, Mercury and Venus, appear to be too harsh to support life as we know it. But it has been conjectured that Europa, the fourth-largest moon of Jupiter, may possess a sub-surface ocean of liquid water and could potentially host life.\n\nAstronomers have started to discover extrasolar Earth analogs \u2013 planets that lie in the habitable zone of space surrounding a star, and therefore could possibly host life as we know it.\n\nSee also\n\n Force of nature\n Human nature\n Natural history\n Naturalism\n Natural landscape\n Natural law\n Natural resource\n Natural science\n Natural theology\n Nature reserve\n Nature versus nurture\n Nature worship\n Naturism\n Rewilding\n\nMedia:\n Natural History, by Pliny the Elder\n Nature, by Ralph Waldo Emerson\n Nature, a prominent scientific journal\n National Wildlife, a publication of the National Wildlife Federation\n Nature (TV series)\n Natural World (TV series)\nOrganizations:\n The Nature Conservancy\n Nature Detectives\nPhilosophy:\n Mother Nature\n Nature (philosophy)\n Naturalism, any of several philosophical stances, typically those descended from materialism and pragmatism that do not distinguish the supernatural from nature; this includes the methodological naturalism of natural science, which makes the methodological assumption that observable events in nature are explained only by natural causes, without assuming either the existence or non-existence of the supernatural\n Balance of nature (biological fallacy), a discredited concept of natural equilibrium in predator\u2013prey dynamics\n\nNotes and references\n\nFurther reading \n \n Farber, Paul Lawrence (2000), Finding Order in Nature: The Naturalist Tradition from Linnaeus to E. O. Wilson. Johns Hopkins University Press: Baltimore.\n\nExternal links\n\n The IUCN Red List of Threatened Species (iucnredlist.org)\n \n \n\n \nEnvironmental science\nEnvironmental social science concepts\nMain topic articles",
  "Science": "Science () is a systematic enterprise that builds and organizes knowledge in the form of testable explanations and predictions about the universe.\n\nThe earliest roots of science can be traced to Ancient Egypt and Mesopotamia in around 3000 to 1200 BCE. Their contributions to mathematics, astronomy, and medicine entered and shaped Greek natural philosophy of classical antiquity, whereby formal attempts were made to provide explanations of events in the physical world based on natural causes. After the fall of the Western Roman Empire, knowledge of Greek conceptions of the world deteriorated in Western Europe during the early centuries (400 to 1000 CE) of the Middle Ages, but was preserved in the Muslim world during the Islamic Golden Age. The recovery and assimilation of Greek works and Islamic inquiries into Western Europe from the 10th to 13th century revived \"natural philosophy\", which was later transformed by the Scientific Revolution that began in the 16th century as new ideas and discoveries departed from previous Greek conceptions and traditions. The scientific method soon played a greater role in knowledge creation and it was not until the 19th century that many of the institutional and professional features of science began to take shape; along with the changing of \"natural philosophy\" to \"natural science.\"\n\nModern science is typically divided into three major branches that consist of the natural sciences (e.g., biology, chemistry, and physics), which study nature in the broadest sense; the social sciences (e.g., economics, psychology, and sociology), which study individuals and societies; and the formal sciences (e.g., logic, mathematics, and theoretical computer science), which deal with symbols governed by rules. There is disagreement, however, on whether the formal sciences actually constitute a science as they do not rely on empirical evidence. Disciplines that use existing scientific knowledge for practical purposes, such as engineering and medicine, are described as applied sciences.\n\nNew knowledge in science is advanced by research from scientists who are motivated by curiosity about the world and a desire to solve problems. Contemporary scientific research is highly collaborative and is usually done by teams in academic and research institutions, government agencies, and companies. The practical impact of their work has led to the emergence of science policies that seek to influence the scientific enterprise by prioritizing the development of commercial products, armaments, health care, public infrastructure, and environmental protection.\n\nHistory \n\nScience in a broad sense existed before the modern era and in many historical civilizations. Modern science is distinct in its approach and successful in its results, so it now defines what science is in the strictest sense of the term. Science in its original sense was a word for a type of knowledge, rather than a specialized word for the pursuit of such knowledge. In particular, it was the type of knowledge that people can communicate to each other and share. For example, knowledge about the working of natural things was gathered long before recorded history and led to the development of complex abstract thought. This is shown by the construction of complex calendars, techniques for making poisonous plants edible, public works at a national scale, such as those which harnessed the floodplain of the Yangtse with reservoirs, dams, and dikes, and buildings such as the Pyramids. However, no consistent conscious distinction was made between knowledge of such things, which are true in every community, and other types of communal knowledge, such as mythologies and legal systems. Metallurgy was known in prehistory, and the Vin\u010da culture was the earliest known producer of bronze-like alloys. It is thought that early experimentation with heating and mixing of substances over time developed into alchemy.\n\nEarliest roots\n\nThe earliest roots of science can be traced to Ancient Egypt and Mesopotamia in around 3000 to 1200 BCE. Although the words and concepts of \"science\" and \"nature\" were not part of the conceptual landscape at the time, the ancient Egyptians and Mesopotamians made contributions that would later find a place in Greek and medieval science: mathematics, astronomy, and medicine. Starting in around 3000 BCE, the ancient Egyptians developed a numbering system that was decimal in character and had orientated their knowledge of geometry to solving practical problems such as those of surveyors and builders. They even developed an official calendar that contained twelve months, thirty days each, and five days at the end of the year. Based on the medical papyri written in the 2500-1200 BCE, the ancient Egyptians believed that disease was mainly caused by the invasion of bodies by evil forces or spirits. Thus, in addition to drug treatments, healing therapies would involve prayer, incantation, and ritual.\n\nThe ancient Mesopotamians used knowledge about the properties of various natural chemicals for manufacturing pottery, faience, glass, soap, metals, lime plaster, and waterproofing; they also studied animal physiology, anatomy, and behavior for divinatory purposes and made extensive records of the movements of astronomical objects for their study of astrology. The Mesopotamians had intense interest in medicine and the earliest medical prescriptions appear in Sumerian during the Third Dynasty of Ur ( 2112 BCE \u2013  2004 BCE). Nonetheless, the Mesopotamians seem to have had little interest in gathering information about the natural world for the mere sake of gathering information and mainly only studied scientific subjects which had obvious practical applications or immediate relevance to their religious system.\n\nClassical antiquity\n\nIn classical antiquity, there is no real ancient analog of a modern scientist. Instead, well-educated, usually upper-class, and almost universally male individuals performed various investigations into nature whenever they could afford the time. Before the invention or discovery of the concept of \"nature\" (ancient Greek phusis) by the Pre-Socratic philosophers, the same words tend to be used to describe the natural \"way\" in which a plant grows, and the \"way\" in which, for example, one tribe worships a particular god. For this reason, it is claimed that these men were the first philosophers in the strict sense, and also the first people to clearly distinguish \"nature\" and \"convention.\" Natural philosophy, the precursor of natural science, was thereby distinguished as the knowledge of nature and things which are true for every community, and the name of the specialized pursuit of such knowledge was philosophy\u00a0\u2013 the realm of the first philosopher-physicists. They were mainly speculators or theorists, particularly interested in astronomy. In contrast, trying to use knowledge of nature to imitate nature (artifice or technology, Greek techn\u0113) was seen by classical scientists as a more appropriate interest for artisans of lower social class.\n\nThe early Greek philosophers of the Milesian school, which was founded by Thales of Miletus and later continued by his successors Anaximander and Anaximenes, were the first to attempt to explain natural phenomena without relying on the supernatural. The Pythagoreans developed a complex number philosophy and contributed significantly to the development of mathematical science. The theory of atoms was developed by the Greek philosopher Leucippus and his student Democritus. The Greek doctor Hippocrates established the tradition of systematic medical science and is known as \"The Father of Medicine\".\n\nA turning point in the history of early philosophical science was Socrates' example of applying philosophy to the study of human matters, including human nature, the nature of political communities, and human knowledge itself. The Socratic method as documented by Plato's dialogues is a dialectic method of hypothesis elimination: better hypotheses are found by steadily identifying and eliminating those that lead to contradictions. This was a reaction to the Sophist emphasis on rhetoric. The Socratic method searches for general, commonly held truths that shape beliefs and scrutinizes them to determine their consistency with other beliefs. Socrates criticized the older type of study of physics as too purely speculative and lacking in self-criticism. Socrates was later, in the words of his Apology, accused of corrupting the youth of Athens because he did \"not believe in the gods the state believes in, but in other new spiritual beings\". Socrates refuted these claims, but was sentenced to death.\n\nAristotle later created a systematic programme of teleological philosophy: Motion and change is described as the actualization of potentials already in things, according to what types of things they are. In his physics, the Sun goes around the Earth, and many things have it as part of their nature that they are for humans. Each thing has a formal cause, a final cause, and a role in a cosmic order with an unmoved mover. The Socratics also insisted that philosophy should be used to consider the practical question of the best way to live for a human being (a study Aristotle divided into ethics and political philosophy). Aristotle maintained that man knows a thing scientifically \"when he possesses a conviction arrived at in a certain way, and when the first principles on which that conviction rests are known to him with certainty\".\n\nThe Greek astronomer Aristarchus of Samos (310\u2013230 BCE) was the first to propose a heliocentric model of the universe, with the Sun at the center and all the planets orbiting it. Aristarchus's model was widely rejected because it was believed to violate the laws of physics. The inventor and mathematician Archimedes of Syracuse made major contributions to the beginnings of calculus and has sometimes been credited as its inventor, although his proto-calculus lacked several defining features. Pliny the Elder was a Roman writer and polymath, who wrote the seminal encyclopedia Natural History, dealing with history, geography, medicine, astronomy, earth science, botany, and zoology.\nOther scientists or proto-scientists in Antiquity were Theophrastus, Euclid, Herophilos, Hipparchus, Ptolemy, and Galen.\n\nMedieval science \n\nBecause of the collapse of the Western Roman Empire due to the Migration Period an intellectual decline took place in the western part of Europe in the 400s. In contrast, the Byzantine Empire resisted the attacks from invaders, and preserved and improved upon the learning. John Philoponus, a Byzantine scholar in the 500s, questioned Aristotle's teaching of physics, noting its flaws. John Philoponus' criticism of Aristotelian principles of physics served as an inspiration to medieval scholars as well as to Galileo Galilei who ten centuries later, during the Scientific Revolution, extensively cited Philoponus in his works while making the case for why Aristotelian physics was flawed.\n\nDuring late antiquity and the early Middle Ages, the Aristotelian approach to inquiries on natural phenomena was used. Aristotle's four causes prescribed that the question \"why\" should be answered in four ways in order to explain things scientifically. Some ancient knowledge was lost, or in some cases kept in obscurity, during the fall of the Western Roman Empire and periodic political struggles. However, the general fields of science (or \"natural philosophy\" as it was called) and much of the general knowledge from the ancient world remained preserved through the works of the early Latin encyclopedists like Isidore of Seville. However, Aristotle's original texts were eventually lost in Western Europe, and only one text by Plato was widely known, the Timaeus, which was the only Platonic dialogue, and one of the few original works of classical natural philosophy, available to Latin readers in the early Middle Ages. Another original work that gained influence in this period was Ptolemy's Almagest, which contains a geocentric description of the solar system.\n\nDuring late antiquity, in the Byzantine empire many Greek classical texts were preserved. Many Syriac translations were done by groups such as the Nestorians and Monophysites. They played a role when they translated Greek classical texts into Arabic under the Caliphate, during which many types of classical learning were preserved and in some cases improved upon. In addition, the neighboring Sassanid Empire established the medical Academy of Gondeshapur where Greek, Syriac, and Persian physicians established the most important medical center of the ancient world during the 6th and 7th centuries.\n\nThe House of Wisdom was established in Abbasid-era Baghdad, Iraq,\nwhere the Islamic study of Aristotelianism flourished. Al-Kindi (801\u2013873) was the first of the Muslim Peripatetic philosophers, and is known for his efforts to introduce Greek and Hellenistic philosophy to the Arab world. The Islamic Golden Age flourished from this time until the Mongol invasions of the 13th century. Ibn al-Haytham (Alhazen), as well as his predecessor Ibn Sahl, was familiar with Ptolemy's Optics, and used experiments as a means to gain knowledge. Alhazen disproved Ptolemy's theory of vision, but did not make any corresponding changes to Aristotle's metaphysics. Furthermore, doctors and alchemists such as the Persians Avicenna and Al-Razi also greatly developed the science of Medicine with the former writing the Canon of Medicine, a medical encyclopedia used until the 18th century and the latter discovering multiple compounds like alcohol. Avicenna's canon is considered to be one of the most important publications in medicine and they both contributed significantly to the practice of experimental medicine, using clinical trials and experiments to back their claims.\n\nIn Classical antiquity, Greek and Roman taboos had meant that dissection was usually banned in ancient times, but in Middle Ages it changed: medical teachers and students at Bologna began to open human bodies, and Mondino de Luzzi (c. 1275\u20131326) produced the \ufb01rst known anatomy textbook based on human dissection.\n\nBy the eleventh century, most of Europe had become Christian; stronger monarchies emerged; borders were restored; technological developments and agricultural innovations were made which increased the food supply and population. In addition, classical Greek texts started to be translated from Arabic and Greek into Latin, giving a higher level of scientific discussion in Western Europe.\n\nBy 1088, the first university in Europe (the University of Bologna) had emerged from its clerical beginnings. Demand for Latin translations grew (for example, from the Toledo School of Translators); western Europeans began collecting texts written not only in Latin, but also Latin translations from Greek, Arabic, and Hebrew. Manuscript copies of Alhazen's Book of Optics also propagated across Europe before 1240, as evidenced by its incorporation into Vitello's Perspectiva. Avicenna's Canon was translated into Latin. In particular, the texts of Aristotle, Ptolemy, and Euclid, preserved in the Houses of Wisdom and also in the Byzantine Empire, were sought amongst Catholic scholars. The influx of ancient texts caused the Renaissance of the 12th century and the flourishing of a synthesis of Catholicism and Aristotelianism known as Scholasticism in western Europe, which became a new geographic center of science. An experiment in this period would be understood as a careful process of observing, describing, and classifying. One prominent scientist in this era was Roger Bacon. Scholasticism had a strong focus on revelation and dialectic reasoning, and gradually fell out of favour over the next centuries, as alchemy's focus on experiments that include direct observation and meticulous documentation slowly increased in importance.\n\nRenaissance and early modern science \n\nNew developments in optics played a role in the inception of the Renaissance, both by challenging long-held metaphysical ideas on perception, as well as by contributing to the improvement and development of technology such as the camera obscura and the telescope. Before what we now know as the Renaissance started, Roger Bacon, Vitello, and John Peckham each built up a scholastic ontology upon a causal chain beginning with sensation, perception, and finally apperception of the individual and universal forms of Aristotle. A model of vision later known as perspectivism was exploited and studied by the artists of the Renaissance. This theory uses only three of Aristotle's four causes: formal, material, and final.\n\nIn the sixteenth century, Copernicus formulated a heliocentric model of the solar system unlike the geocentric model of Ptolemy's Almagest. This was based on a theorem that the orbital periods of the planets are longer as their orbs are farther from the centre of motion, which he found not to agree with Ptolemy's model.\n\nKepler and others challenged the notion that the only function of the eye is perception, and shifted the main focus in optics from the eye to the propagation of light. Kepler modelled the eye as a water-filled glass sphere with an aperture in front of it to model the entrance pupil. He found that all the light from a single point of the scene was imaged at a single point at the back of the glass sphere. The optical chain ends on the retina at the back of the eye. Kepler is best known, however, for improving Copernicus' heliocentric model through the discovery of Kepler's laws of planetary motion. Kepler did not reject Aristotelian metaphysics and described his work as a search for the Harmony of the Spheres.\n\nGalileo made innovative use of experiment and mathematics. However, he became persecuted after Pope Urban VIII blessed Galileo to write about the Copernican system. Galileo had used arguments from the Pope and put them in the voice of the simpleton in the work \"Dialogue Concerning the Two Chief World Systems\", which greatly offended Urban VIII.\n\nIn Northern Europe, the new technology of the printing press was widely used to publish many arguments, including some that disagreed widely with contemporary ideas of nature. Ren\u00e9 Descartes and Francis Bacon published philosophical arguments in favor of a new type of non-Aristotelian science. Descartes emphasized individual thought and argued that mathematics rather than geometry should be used in order to study nature. Bacon emphasized the importance of experiment over contemplation. Bacon further questioned the Aristotelian concepts of formal cause and final cause, and promoted the idea that science should study the laws of \"simple\" natures, such as heat, rather than assuming that there is any specific nature, or \"formal cause\", of each complex type of thing. This new science began to see itself as describing \"laws of nature\". This updated approach to studies in nature was seen as mechanistic. Bacon also argued that science should aim for the first time at practical inventions for the improvement of all human life.\n\nAge of Enlightenment \n\nAs a precursor to the Age of Enlightenment, Isaac Newton and Gottfried Wilhelm Leibniz succeeded in developing a new physics, now referred to as classical mechanics, which could be confirmed by experiment and explained using mathematics (Newton (1687), Philosophi\u00e6 Naturalis Principia Mathematica). Leibniz also incorporated terms from Aristotelian physics, but now being used in a new non-teleological way, for example, \"energy\" and \"potential\" (modern versions of Aristotelian \"energeia and potentia\"). This implied a shift in the view of objects: Where Aristotle had noted that objects have certain innate goals that can be actualized, objects were now regarded as devoid of innate goals. In the style of Francis Bacon, Leibniz assumed that different types of things all work according to the same general laws of nature, with no special formal or final causes for each type of thing. It is during this period that the word \"science\" gradually became more commonly used to refer to a type of pursuit of a type of knowledge, especially knowledge of nature\u00a0\u2013 coming close in meaning to the old term \"natural philosophy.\"\n\nDuring this time, the declared purpose and value of science became producing wealth and inventions that would improve human lives, in the materialistic sense of having more food, clothing, and other things. In Bacon's words, \"the real and legitimate goal of sciences is the endowment of human life with new inventions and riches\", and he discouraged scientists from pursuing intangible philosophical or spiritual ideas, which he believed contributed little to human happiness beyond \"the fume of subtle, sublime, or pleasing speculation\".\n\nScience during the Enlightenment was dominated by scientific societies and academies, which had largely replaced universities as centres of scientific research and development. Societies and academies were also the backbones of the maturation of the scientific profession. Another important development was the popularization of science among an increasingly literate population. Philosophes introduced the public to many scientific theories, most notably through the Encyclop\u00e9die and the popularization of Newtonianism by Voltaire as well as by \u00c9milie du Ch\u00e2telet, the French translator of Newton's Principia.\n\nSome historians have marked the 18th century as a drab period in the history of science; however, the century saw significant advancements in the practice of medicine, mathematics, and physics; the development of biological taxonomy; a new understanding of magnetism and electricity; and the maturation of chemistry as a discipline, which established the foundations of modern chemistry.\n\nEnlightenment philosophers chose a short history of scientific predecessors\u00a0\u2013 Galileo, Boyle, and Newton principally\u00a0\u2013 as the guides and guarantors of their applications of the singular concept of nature and natural law to every physical and social field of the day. In this respect, the lessons of history and the social structures built upon it could be discarded.\n\nIdeas on human nature, society, and economics also evolved during the Enlightenment. Hume and other Scottish Enlightenment thinkers developed a \"science of man\", which was expressed historically in works by authors including James Burnett, Adam Ferguson, John Millar and William Robertson, all of whom merged a scientific study of how humans behaved in ancient and primitive cultures with a strong awareness of the determining forces of modernity. Modern sociology largely originated from this movement. In 1776, Adam Smith published The Wealth of Nations, which is often considered the first work on modern economics.\n\n19th century \n\nThe nineteenth century is a particularly important period in the history of science since during this era many distinguishing characteristics of contemporary modern science began to take shape such as: transformation of the life and physical sciences, frequent use of precision instruments, emergence of terms like \"biologist\", \"physicist\", \"scientist\"; slowly moving away from antiquated labels like \"natural philosophy\" and \"natural history\", increased professionalization of those studying nature lead to reduction in amateur naturalists, scientists gained cultural authority over many dimensions of society, economic expansion and industrialization of numerous countries, thriving of popular science writings and emergence of science journals.\n\nEarly in the 19th century, John Dalton suggested the modern atomic theory, based on Democritus's original idea of indivisible particles called atoms.\n\nBoth John Herschel and William Whewell systematized methodology: the latter coined the term scientist.\n\nDuring the mid-19th century, Charles Darwin and Alfred Russel Wallace independently proposed the theory of evolution by natural selection in 1858, which explained how different plants and animals originated and evolved. Their theory was set out in detail in Darwin's book On the Origin of Species, which was published in 1859. Separately, Gregor Mendel presented his paper, \"Versuche \u00fcber Pflanzenhybriden\" (\"Experiments on Plant Hybridization\"), in 1865, which outlined the principles of biological inheritance, serving as the basis for modern genetics.\n\nThe laws of conservation of energy, conservation of momentum and conservation of mass suggested a highly stable universe where there could be little loss of resources. With the advent of the steam engine and the industrial revolution, there was, however, an increased understanding that all forms of energy as defined in physics were not equally useful: they did not have the same energy quality. This realization led to the development of the laws of thermodynamics, in which the free energy of the universe is seen as constantly declining: the entropy of a closed universe increases over time.\n\nThe electromagnetic theory was also established in the 19th century by the works of Hans Christian \u00d8rsted, Andr\u00e9-Marie Amp\u00e8re,  Michael Faraday, James Clerk Maxwell, Oliver Heaviside, and Heinrich Hertz. The new theory raised questions that could not easily be answered using Newton's framework. The phenomena that would allow the deconstruction of the atom were discovered in the last decade of the 19th century: the discovery of X-rays inspired the discovery of radioactivity. In the next year came the discovery of the first subatomic particle, the electron.\n\nDuring the late 19th century, psychology emerged as a separate discipline from philosophy when Wilhelm Wundt founded the first laboratory for psychological research in 1879.\n\n20th century \n\nAlbert Einstein's theory of relativity and the development of quantum mechanics led to the replacement of classical mechanics with a new physics which contains two parts that describe different types of events in nature.\n\nIn the first half of the century, the development of antibiotics and artificial fertilizers made global human population growth possible. At the same time, the structure of the atom and its nucleus was discovered, leading to the release of \"atomic energy\" (nuclear power). In addition, the extensive use of technological innovation stimulated by the wars of this century led to revolutions in transportation (automobiles and aircraft), the development of ICBMs, a space race, and a nuclear arms race.\n\nEvolution became a unified theory in the early 20th-century when the modern synthesis reconciled Darwinian evolution with classical genetics. The molecular structure of DNA was discovered by James Watson and Francis Crick in 1953.\n\nThe discovery of the cosmic microwave background radiation in 1964 led to a rejection of the Steady State theory of the universe in favor of the Big Bang theory of Georges Lema\u00eetre.\n\nThe development of spaceflight in the second half of the century allowed the first astronomical measurements done on or near other objects in space, including six crewed landings on the Moon. Space telescopes lead to numerous discoveries in astronomy and cosmology.\n\nWidespread use of integrated circuits in the last quarter of the 20th century combined with communications satellites led to a revolution in information technology and the rise of the global internet and mobile computing, including smartphones. The need for mass systematization of long, intertwined causal chains and large amounts of data led to the rise of the fields of systems theory and computer-assisted scientific modelling, which are partly based on the Aristotelian paradigm.\n\nHarmful environmental issues such as ozone depletion, acidification, eutrophication and climate change came to the public's attention in the same period, and caused the onset of environmental science and environmental technology.\n\n21st century \n\nThe Human Genome Project was completed in 2003, determining the sequence of nucleotide base pairs that make up human DNA, and identifying and mapping all of the genes of the human genome. Induced pluripotent stem cells were developed in 2006, a technology allowing adult cells to be transformed into stem cells capable of giving rise to any cell type found in the body, potentially of huge importance to the field of regenerative medicine.\n\nWith the discovery of the Higgs boson in 2012, the last particle predicted by the Standard Model of particle physics was found. In 2015, gravitational waves, predicted by general relativity a century before, were first observed.\n\nIn 2019, the Event Horizon Telescope Observatory announced its first results in simultaneous press conferences around the world on April 10, 2019.\u00a0Press conferences presented the first direct image of a black hole, where the supermassive black hole appeared in the heart of the galaxy Messier 87, which is 55 million light-years away from Earth.\n\nBranches of science \n\nModern science is commonly divided into three major branches: natural science, social science, and formal science. Each of these branches comprises various specialized yet overlapping scientific disciplines that often possess their own nomenclature and expertise. Both natural and social sciences are empirical sciences, as their knowledge is based on empirical observations and is capable of being tested for its validity by other researchers working under the same conditions.\n\nThere are also closely related disciplines that use science, such as engineering and medicine, which are sometimes described as applied sciences. The relationships between the branches of science are summarized by the following table.\n\nNatural science \n\nNatural science is the study of the physical world. It can be divided into two main branches: life science (or biological science) and physical science. These two branches may be further divided into more specialized disciplines. For example, physical science can be subdivided into physics, chemistry, astronomy, and earth science. Modern natural science is the successor to the natural philosophy that began in Ancient Greece. Galileo, Descartes, Bacon, and Newton debated the benefits of using approaches which were more mathematical and more experimental in a methodical way. Still, philosophical perspectives, conjectures, and presuppositions, often overlooked, remain necessary in natural science. Systematic data collection, including discovery science, succeeded natural history, which emerged in the 16th century by describing and classifying plants, animals, minerals, and so on. Today, \"natural history\" suggests observational descriptions aimed at popular audiences.\n\nSocial science \n\nSocial science is the study of human behavior and functioning of societies. It has many disciplines that include, but are not limited to anthropology, economics, history, human geography, political science, psychology, and sociology. In the social sciences, there are many competing theoretical perspectives, many of which are extended through competing research programs such as the functionalists, conflict theorists, and interactionists in sociology. Due to the limitations of conducting controlled experiments involving large groups of individuals or complex situations, social scientists may adopt other research methods such as the historical method, case studies, and cross-cultural studies. Moreover, if quantitative information is available, social scientists may rely on statistical approaches to better understand social relationships and processes.\n\nFormal science \n\nFormal science is an area of study that generates knowledge using formal systems. It includes mathematics, systems theory, and theoretical computer science. The formal sciences share similarities with the other two branches by relying on objective, careful, and systematic study of an area of knowledge. They are, however, different from the empirical sciences as they rely exclusively on deductive reasoning, without the need for empirical evidence, to verify their abstract concepts. The formal sciences are therefore a priori disciplines and because of this, there is disagreement on whether they actually constitute a science. Nevertheless, the formal sciences play an important role in the empirical sciences. Calculus, for example, was initially invented to understand motion in physics. Natural and social sciences that rely heavily on mathematical applications include mathematical physics, mathematical chemistry, mathematical biology, mathematical finance, and mathematical economics.\n\nApplied science \n\nApplied science is the use of the scientific method and knowledge to attain practical goals and includes a broad range of disciplines such as engineering and medicine. Engineering is the use of scientific principles to design and build machines, structures, and other items, including bridges, tunnels, roads, vehicles, and buildings. Engineering itself encompasses a range of more specialized fields of engineering, each with a more specific emphasis on particular areas of applied mathematics, science, and types of application. Medicine is the practice of caring for patients by maintaining and restoring health through the prevention, diagnosis, and treatment of injury or disease. Contemporary medicine applies biomedical sciences, medical research, genetics, and medical technology to prevent, diagnose, and treat injury and disease, typically through the use of medications, medical devices, surgery, and non-pharmacological interventions. The applied sciences are often contrasted with the basic sciences, which are focused on advancing scientific theories and laws that explain and predict events in the natural world.\n\nScientific research \n\nScientific research can be labeled as either basic or applied research. Basic research is the search for knowledge and applied research is the search for solutions to practical problems using this knowledge. Although some scientific research is applied research into specific problems, a great deal of our understanding comes from the curiosity-driven undertaking of basic research. This leads to options for technological advances that were not planned or sometimes even imaginable. This point was made by Michael Faraday when allegedly in response to the question \"what is the  of basic research?\" he responded: \"Sir, what is the use of a new-born child?\". For example, research into the effects of red light on the human eye's rod cells did not seem to have any practical purpose; eventually, the discovery that our night vision is not troubled by red light would lead search and rescue teams (among others) to adopt red light in the cockpits of jets and helicopters. Finally, even basic research can take unexpected turns, and there is some sense in which the scientific method is built to harness luck.\n\nScientific method \n\nScientific research involves using the scientific method, which seeks to objectively explain the events of nature in a reproducible way. An explanatory thought experiment or hypothesis is put forward as explanation using principles such as parsimony (also known as \"Occam's Razor\") and are generally expected to seek consilience\u00a0\u2013 fitting well with other accepted facts related to the phenomena. This new explanation is used to make falsifiable predictions that are testable by experiment or observation. The predictions are to be posted before a confirming experiment or observation is sought, as proof that no tampering has occurred. Disproof of a prediction is evidence of progress. This is done partly through observation of natural phenomena, but also through experimentation that tries to simulate natural events under controlled conditions as appropriate to the discipline (in the observational sciences, such as astronomy or geology, a predicted observation might take the place of a controlled experiment). Experimentation is especially important in science to help establish causal relationships (to avoid the correlation fallacy).\n\nWhen a hypothesis proves unsatisfactory, it is either modified or discarded. If the hypothesis survived testing, it may become adopted into the framework of a scientific theory, a logically reasoned, self-consistent model or framework for describing the behavior of certain natural phenomena. A theory typically describes the behavior of much broader sets of phenomena than a hypothesis; commonly, a large number of hypotheses can be logically bound together by a single theory. Thus a theory is a hypothesis explaining various other hypotheses. In that vein, theories are formulated according to most of the same scientific principles as hypotheses. In addition to testing hypotheses, scientists may also generate a model, an attempt to describe or depict the phenomenon in terms of a logical, physical or mathematical representation and to generate new hypotheses that can be tested, based on observable phenomena.\n\nWhile performing experiments to test hypotheses, scientists may have a preference for one outcome over another, and so it is important to ensure that science as a whole can eliminate this bias. This can be achieved by careful experimental design, transparency, and a thorough peer review process of the experimental results as well as any conclusions. After the results of an experiment are announced or published, it is normal practice for independent researchers to double-check how the research was performed, and to follow up by performing similar experiments to determine how dependable the results might be. Taken in its entirety, the scientific method allows for highly creative problem solving while minimizing any effects of subjective bias on the part of its users (especially the confirmation bias).\n\nVerifiability \nJohn Ziman points out that intersubjective verifiability is fundamental to the creation of all scientific knowledge. Ziman shows how scientists can identify patterns to each other across centuries; he refers to this ability as \"perceptual consensibility.\" He then makes consensibility, leading to consensus, the touchstone of reliable knowledge.\n\nRole of mathematics \n\nMathematics is essential in the formation of hypotheses, theories, and laws in the natural and social sciences. For example, it is used in quantitative scientific modeling, which can generate new hypotheses and predictions to be tested. It is also used extensively in observing and collecting measurements. Statistics, a branch of mathematics, is used to summarize and analyze data, which allow scientists to assess the reliability and variability of their experimental results.\n\nComputational science applies computing power to simulate real-world situations, enabling a better understanding of scientific problems than formal mathematics alone can achieve. The use of machine learning (also artificial intelligence) is becoming a central feature of computational contributions to science for example in agent-based computational economics, random forests, topic modelling and various forms of prediction. According to the Society for Industrial and Applied Mathematics, computation is now as important as theory and experiment in advancing scientific knowledge. However, machines alone rarely advance knowledge as they require human guidance and capacity to reason; and they can introduce bias against certain social groups or sometimes underperform compared to humans. Thus, machine learning is often used in science as prediction in the service of estimation.\n\nPhilosophy of science \n\nScientists usually take for granted a set of basic assumptions that are needed to justify the scientific method: (1) that there is an objective reality shared by all rational observers; (2) that this objective reality is governed by natural laws; (3) that these laws can be discovered by means of systematic observation and experimentation. The philosophy of science seeks a deep understanding of what these underlying assumptions mean and whether they are valid.\n\nThe belief that scientific theories should and do represent metaphysical reality is known as realism. It can be contrasted with anti-realism, the view that the success of science does not depend on it being accurate about unobservable entities such as electrons. One form of anti-realism is idealism, the belief that the mind or consciousness is the most basic essence, and that each mind generates its own reality. In an idealistic world view, what is true for one mind need not be true for other minds.\n\nThere are different schools of thought in the philosophy of science. The most popular position is empiricism, which holds that knowledge is created by a process involving observation and that scientific theories are the result of generalizations from such observations. Empiricism generally encompasses inductivism, a position that tries to explain the way general theories can be justified by the finite number of observations humans can make and hence the finite amount of empirical evidence available to confirm scientific theories. This is necessary because the number of predictions those theories make is infinite, which means that they cannot be known from the finite amount of evidence using deductive logic only. Many versions of empiricism exist, with the predominant ones being Bayesianism and the hypothetico-deductive method.\n\nEmpiricism has stood in contrast to rationalism, the position originally associated with Descartes, which holds that knowledge is created by the human intellect, not by observation. Critical rationalism is a contrasting 20th-century approach to science, first defined by Austrian-British philosopher Karl Popper. Popper rejected the way that empiricism describes the connection between theory and observation. He claimed that theories are not generated by observation, but that observation is made in the light of theories and that the only way a theory can be affected by observation is when it comes in conflict with it. Popper proposed replacing verifiability with falsifiability as the landmark of scientific theories and replacing induction with falsification as the empirical method. Popper further claimed that there is actually only one universal method, not specific to science: the negative method of criticism, trial and error. It covers all products of the human mind, including science, mathematics, philosophy, and art.\n\nAnother approach, instrumentalism, emphasizes the utility of theories as instruments for explaining and predicting phenomena. It views scientific theories as black boxes with only their input (initial conditions) and output (predictions) being relevant. Consequences, theoretical entities, and logical structure are claimed to be something that should simply be ignored and that scientists should not make a fuss about (see interpretations of quantum mechanics). Close to instrumentalism is constructive empiricism, according to which the main criterion for the success of a scientific theory is whether what it says about observable entities is true.\n\nThomas Kuhn argued that the process of observation and evaluation takes place within a paradigm, a logically consistent \"portrait\" of the world that is consistent with observations made from its framing. He characterized normal science as the process of observation and \"puzzle solving\" which takes place within a paradigm, whereas revolutionary science occurs when one paradigm overtakes another in a paradigm shift. Each paradigm has its own distinct questions, aims, and interpretations. The choice between paradigms involves setting two or more \"portraits\" against the world and deciding which likeness is most promising. A paradigm shift occurs when a significant number of observational anomalies arise in the old paradigm and a new paradigm makes sense of them. That is, the choice of a new paradigm is based on observations, even though those observations are made against the background of the old paradigm. For Kuhn, acceptance or rejection of a paradigm is a social process as much as a logical process. Kuhn's position, however, is not one of relativism.\n\nFinally, another approach often cited in debates of scientific skepticism against controversial movements like \"creation science\" is methodological naturalism. Its main point is that a difference between natural and supernatural explanations should be made and that science should be restricted methodologically to natural explanations. That the restriction is merely methodological (rather than ontological) means that science should not consider supernatural explanations itself, but should not claim them to be wrong either. Instead, supernatural explanations should be left a matter of personal belief outside the scope of science. Methodological naturalism maintains that proper science requires strict adherence to empirical study and independent verification as a process for properly developing and evaluating explanations for observable phenomena. The absence of these standards, arguments from authority, biased observational studies and other common fallacies are frequently cited by supporters of methodological naturalism as characteristic of the non-science they criticize.\n\nCertainty and science \nA scientific theory is empirical and is always open to falsification if new evidence is presented. That is, no theory is ever considered strictly certain as science accepts the concept of fallibilism. The philosopher of science Karl Popper sharply distinguished truth from certainty. He wrote that scientific knowledge \"consists in the search for truth,\" but it \"is not the search for certainty\u00a0... All human knowledge is fallible and therefore uncertain.\"\n\nNew scientific knowledge rarely results in vast changes in our understanding. According to psychologist Keith Stanovich, it may be the media's overuse of words like \"breakthrough\" that leads the public to imagine that science is constantly proving everything it thought was true to be false. While there are such famous cases as the theory of relativity that required a complete reconceptualization, these are extreme exceptions. Knowledge in science is gained by a gradual synthesis of information from different experiments by various researchers across different branches of science; it is more like a climb than a leap. Theories vary in the extent to which they have been tested and verified, as well as their acceptance in the scientific community. For example, heliocentric theory, the theory of evolution, relativity theory, and germ theory still bear the name \"theory\" even though, in practice, they are considered factual.\nPhilosopher Barry Stroud adds that, although the best definition for \"knowledge\" is contested, being skeptical and entertaining the possibility that one is incorrect is compatible with being correct. Therefore, scientists adhering to proper scientific approaches will doubt themselves even once they possess the truth. The fallibilist C.\u00a0S. Peirce argued that inquiry is the struggle to resolve actual doubt and that merely quarrelsome, verbal, or hyperbolic doubt is fruitless\u00a0\u2013 but also that the inquirer should try to attain genuine doubt rather than resting uncritically on common sense. He held that the successful sciences trust not to any single chain of inference (no stronger than its weakest link) but to the cable of multiple and various arguments intimately connected.\n\nStanovich also asserts that science avoids searching for a \"magic bullet\"; it avoids the single-cause fallacy. This means a scientist would not ask merely \"What is  cause of\u00a0...\", but rather \"What  the most significant  of\u00a0...\". This is especially the case in the more macroscopic fields of science (e.g. psychology, physical cosmology). Research often analyzes few factors at once, but these are always added to the long list of factors that are most important to consider. For example, knowing the details of only a person's genetics, or their history and upbringing, or the current situation may not explain a behavior, but a deep understanding of all these variables combined can be very predictive.\n\nScientific literature \n\nScientific research is published in an enormous range of scientific literature. Scientific journals communicate and document the results of research carried out in universities and various other research institutions, serving as an archival record of science. The first scientific journals, Journal des S\u00e7avans followed by the Philosophical Transactions, began publication in 1665. Since that time the total number of active periodicals has steadily increased. In 1981, one estimate for the number of scientific and technical journals in publication was 11,500. The United States National Library of Medicine currently indexes 5,516 journals that contain articles on topics related to the life sciences. Although the journals are in 39 languages, 91 percent of the indexed articles are published in English.\n\nMost scientific journals cover a single scientific field and publish the research within that field; the research is normally expressed in the form of a scientific paper. Science has become so pervasive in modern societies that it is generally considered necessary to communicate the achievements, news, and ambitions of scientists to a wider populace.\n\nScience magazines such as New Scientist, Science & Vie, and Scientific American cater to the needs of a much wider readership and provide a non-technical summary of popular areas of research, including notable discoveries and advances in certain fields of research. Science books engage the interest of many more people. Tangentially, the science fiction genre, primarily fantastic in nature, engages the public imagination and transmits the ideas, if not the methods, of science.\n\nRecent efforts to intensify or develop links between science and non-scientific disciplines such as literature or more specifically, poetry, include the Creative Writing Science resource developed through the Royal Literary Fund.\n\nPractical impacts \nDiscoveries in fundamental science can be world-changing. For example:\n{| class=\"wikitable\" style=\"font-size:90%\"\n|-\n! Research !! Impact\n|-\n| Static electricity and magnetism (c. 1600)Electric current (18th century) || All electric appliances, dynamos, electric power stations, modern electronics, including electric lighting, television, electric heating, transcranial magnetic stimulation, deep brain stimulation, magnetic tape, loudspeaker, and the compass and lightning rod.\n|-\n| Diffraction (1665) || Optics, hence fiber optic cable (1840s), modern intercontinental communications, and cable TV and internet.\n|-\n| Germ theory (1700) || Hygiene, leading to decreased transmission of infectious diseases; antibodies, leading to techniques for disease diagnosis and targeted anticancer therapies.\n|-\n| Vaccination (1798) || Leading to the elimination of most infectious diseases from developed countries and the worldwide eradication of smallpox.\n|-\n| Photovoltaic effect (1839) || Solar cells (1883), hence solar power, solar powered watches, calculators and other devices.\n|-\n| leading to special (1905) and general relativity (1916) || Satellite-based technology such as GPS (1973), satnav and satellite communications.\n|-\n| Radio waves (1887) || Radio had become used in innumerable ways beyond its better-known areas of telephony, and broadcast television (1927) and radio (1906) entertainment. Other uses included\u00a0\u2013 emergency services, radar (navigation and weather prediction), medicine, astronomy, wireless communications, geophysics, and networking. Radio waves also led researchers to adjacent frequencies such as microwaves, used worldwide for heating and cooking food.\n|-\n| Radioactivity (1896) and antimatter (1932) || Cancer treatment (1896), Radiometric dating (1905), nuclear reactors (1942) and weapons (1945), mineral exploration, PET scans (1961), and medical research (via isotopic labeling).\n|-\n|X-rays (1896)|| Medical imaging, including computed tomography.\n|-\n| Crystallography and quantum mechanics (1900) || Semiconductor devices (1906), hence modern computing and telecommunications including the integration with wireless devices: the mobile phone, LED lamps and lasers.\n|-\n|Plastics (1907)||Starting with Bakelite, many types of artificial polymers for numerous applications in industry and daily life.\n|-\n|Antibiotics (1880s, 1928) || Salvarsan, Penicillin, doxycycline, etc.\n|-\n|Nuclear magnetic resonance (1930s) || Nuclear magnetic resonance spectroscopy (1946), magnetic resonance imaging (1971), functional magnetic resonance imaging (1990s).\n|}\n\nChallenges\n\nReplication crisis\n\nThe replication crisis is an ongoing methodological crisis primarily affecting parts of the social and life sciences in which scholars have found that the results of many scientific studies are difficult or impossible to replicate or reproduce on subsequent investigation, either by independent researchers or by the original researchers themselves. The crisis has long-standing roots; the phrase was coined in the early 2010s as part of a growing awareness of the problem. The replication crisis represents an important body of research in metascience, which aims to improve the quality of all scientific research while reducing waste.\n\nFringe science, pseudoscience, and junk science \nAn area of study or speculation that masquerades as science in an attempt to claim a legitimacy that it would not otherwise be able to achieve is sometimes referred to as pseudoscience, fringe science, or junk science. Physicist Richard Feynman coined the term \"cargo cult science\" for cases in which researchers believe they are doing science because their activities have the outward appearance of science but actually lack the \"kind of utter honesty\" that allows their results to be rigorously evaluated. Various types of commercial advertising, ranging from hype to fraud, may fall into these categories. Science has been described as \"the most important tool\" for separating valid claims from invalid ones.\n\nThere can also be an element of political or ideological bias on all sides of scientific debates. Sometimes, research may be characterized as \"bad science,\" research that may be well-intended but is actually incorrect, obsolete, incomplete, or over-simplified expositions of scientific ideas. The term \"scientific misconduct\" refers to situations such as where researchers have intentionally misrepresented their published data or have purposely given credit for a discovery to the wrong person.\n\nScientific community \nThe scientific community is a group of all interacting scientists, along with their respective societies and institutions.\n\nScientists \n\nScientists are individuals who conduct scientific research to advance knowledge in an area of interest. The term scientist was coined by William Whewell in 1833. In modern times, many professional scientists are trained in an academic setting and upon completion, attain an academic degree, with the highest degree being a doctorate such as a Doctor of Philosophy (PhD). Many scientists pursue careers in various sectors of the economy such as academia, industry, government, and nonprofit organizations.\n\nScientists exhibit a strong curiosity about reality, with some scientists having a desire to apply scientific knowledge for the benefit of health, nations, environment, or industries. Other motivations include recognition by their peers and prestige. The Nobel Prize, a widely regarded prestigious award, is awarded annually to those who have achieved scientific advances in the fields of medicine, physics, chemistry, and economics.\n\nWomen in science \n\nScience has historically been a male-dominated field, with some notable exceptions. Women faced considerable discrimination in science, much as they did in other areas of male-dominated societies, such as frequently being passed over for job opportunities and denied credit for their work. For example, Christine Ladd (1847\u20131930) was able to enter a Ph.D. program as \"C. Ladd\"; Christine \"Kitty\" Ladd completed the requirements in 1882, but was awarded her degree only in 1926, after a career which spanned the algebra of logic (see truth table), color vision, and psychology. Her work preceded notable researchers like Ludwig Wittgenstein and Charles Sanders Peirce. The achievements of women in science have been attributed to the defiance of their traditional role as laborers within the domestic sphere.\n\nIn the late 20th century, active recruitment of women and elimination of institutional discrimination on the basis of sex greatly increased the number of women scientists, but large gender disparities remain in some fields; in the early 21st century over half of the new biologists were female, while 80% of PhDs in physics are given to men. In the early part of the 21st century, women in the United States earned 50.3% of bachelor's degrees, 45.6% of master's degrees, and 40.7% of PhDs in science and engineering fields. They earned more than half of the degrees in psychology (about 70%), social sciences (about 50%), and biology (about 50\u201360%) but earned less than half the degrees in the physical sciences, earth sciences, mathematics, engineering, and computer science. Lifestyle choice also plays a major role in female engagement in science; women with young children are 28% less likely to take tenure-track positions due to work-life balance issues, and female graduate students' interest in careers in research declines dramatically over the course of graduate school, whereas that of their male colleagues remains unchanged.\n\nLearned societies \n\nLearned societies for the communication and promotion of scientific thought and experimentation have existed since the Renaissance. Many scientists belong to a learned society that promotes their respective scientific discipline, profession, or group of related disciplines. Membership may be open to all, may require possession of some scientific credentials, or may be an honor conferred by election. Most scientific societies are non-profit organizations, and many are professional associations. Their activities typically include holding regular conferences for the presentation and discussion of new research results and publishing or sponsoring academic journals in their discipline. Some also act as professional bodies, regulating the activities of their members in the public interest or the collective interest of the membership. Scholars in the sociology of science argue that learned societies are of key importance and their formation assists in the emergence and development of new disciplines or professions.\n\nThe professionalization of science, begun in the 19th century, was partly enabled by the creation of distinguished academy of sciences in a number of countries such as the Italian  in 1603, the British Royal Society in 1660, the French  in 1666, the American National Academy of Sciences in 1863, the German Kaiser Wilhelm Institute in 1911, and the Chinese Academy of Sciences in 1928. International scientific organizations, such as the International Council for Science, have since been formed to promote cooperation between the scientific communities of different nations.\n\nScience and the public\n\nScience policy \n\nScience policy is an area of public policy concerned with the policies that affect the conduct of the scientific enterprise, including research funding, often in pursuance of other national policy goals such as technological innovation to promote commercial product development, weapons development, health care, and environmental monitoring. Science policy also refers to the act of applying scientific knowledge and consensus to the development of public policies. Science policy thus deals with the entire domain of issues that involve the natural sciences. In accordance with public policy being concerned about the well-being of its citizens, science policy's goal is to consider how science and technology can best serve the public.\n\nState policy has influenced the funding of public works and science for thousands of years, particularly within civilizations with highly organized governments such as imperial China and the Roman Empire. Prominent historical examples include the Great Wall of China, completed over the course of two millennia through the state support of several dynasties, and the Grand Canal of the Yangtze River, an immense feat of hydraulic engineering begun by Sunshu Ao (\u5b6b\u53d4\u6556 7th cent. BCE), Ximen Bao (\u897f\u9580\u8c79 5th cent. BCE), and Shi Chi (4th cent. BCE). This construction dates from the 6th century BCE under the Sui Dynasty and is still in use today. In China, such state-supported infrastructure and scientific research projects date at least from the time of the Mohists, who inspired the study of logic during the period of the Hundred Schools of Thought and the study of defensive fortifications like the Great Wall of China during the Warring States period.\n\nPublic policy can directly affect the funding of capital equipment and intellectual infrastructure for industrial research by providing tax incentives to those organizations that fund research. Vannevar Bush, director of the Office of Scientific Research and Development for the United States government, the forerunner of the National Science Foundation, wrote in July 1945 that \"Science is a proper concern of government.\"\n\nFunding of science \n\nScientific research is often funded through a competitive process in which potential research projects are evaluated and only the most promising receive funding. Such processes, which are run by government, corporations, or foundations, allocate scarce funds. Total research funding in most developed countries is between 1.5% and 3% of GDP. In the OECD, around two-thirds of research and development in scientific and technical fields is carried out by industry, and 20% and 10% respectively by universities and government. The government funding proportion in certain industries is higher, and it dominates research in social science and humanities. Similarly, with some exceptions (e.g. biotechnology) government provides the bulk of the funds for basic scientific research. Many governments have dedicated agencies to support scientific research. Prominent scientific organizations include the National Science Foundation in the United States, the National Scientific and Technical Research Council in Argentina, Commonwealth Scientific and Industrial Research Organisation (CSIRO) in Australia,  in France, the Max Planck Society and  in Germany, and CSIC in Spain. In commercial research and development, all but the most research-oriented corporations focus more heavily on near-term commercialisation possibilities rather than \"blue-sky\" ideas or technologies (such as nuclear fusion).\n\nPublic awareness of science\n\nThe public awareness of science relates to the attitudes, behaviors, opinions, and activities that make up the relations between science and the general public. It integrates various themes and activities such as science communication, science museums, science festivals, science fairs, citizen science, and science in popular culture. Social scientists have devised various metrics to measure the public understanding of science such as factual knowledge, self-reported knowledge, and structural knowledge.\n\nScience journalism\n\nThe mass media face a number of pressures that can prevent them from accurately depicting competing scientific claims in terms of their credibility within the scientific community as a whole. Determining how much weight to give different sides in a scientific debate may require considerable expertise regarding the matter. Few journalists have real scientific knowledge, and even beat reporters who know a great deal about certain scientific issues may be ignorant about other scientific issues that they are suddenly asked to cover.\n\nPoliticization of science \n\nPoliticization of science occurs when government, business, or advocacy groups use legal or economic pressure to influence the findings of scientific research or the way it is disseminated, reported, or interpreted. Many factors can act as facets of the politicization of science such as populist anti-intellectualism, perceived threats to religious beliefs, postmodernist subjectivism, and fear for business interests. Politicization of science is usually accomplished when scientific information is presented in a way that emphasizes the uncertainty associated with the scientific evidence. Tactics such as shifting conversation, failing to acknowledge facts, and capitalizing on doubt of scientific consensus have been used to gain more attention for views that have been undermined by scientific evidence. Examples of issues that have involved the politicization of science include the global warming controversy, health effects of pesticides, and health effects of tobacco.\n\nSee also \n\n Antiquarian science books\n Antiscience\n Criticism of science\n Index of branches of science\n List of scientific occupations\n Normative science\n Outline of science\n Pathological science\n Protoscience\n Science in popular culture\n Science wars\n Scientific dissent\n Scientism\n Sociology of scientific knowledge\n Wissenschaft \u2013 all areas of scholarly study\n\nNotes\n\nReferences\n\nWorks cited\n\nFurther reading \n\n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n Riskin, Jessica, \"Just Use Your Thinking Pump!\" (review of Henry M. Cowles, The Scientific Method: An Evolution of Thinking from Darwin to Dewey, Harvard University Press, 372 pp.), The New York Review of Books, vol. LXVII, no. 11 (2 July 2020), pp.\u00a048\u201350.\n\nExternal links \nPublications\n \n\nResources\n Euroscience\n Classification of the Sciences in Dictionary of the History of Ideas. (Dictionary's new electronic format is badly botched, entries after \"Design\" are inaccessible. Internet Archive old version).\n United States Science Initiative Selected science information provided by US Government agencies, including research & development results\n How science works University of California Museum of Paleontology\n \"How Do We Know What Is True?\" (animated video; 2:52)\n \"Science\", an overview of the concept, plantspeopleplanet.org.au\n  Science ISKO Encyclopedia of Knowledge Organization\n\n \nObservation\nMain topic articles",
  "Spirituality": "The meaning of spirituality has developed and expanded over time, and various connotations can be found alongside each other. Traditionally, spirituality referred to a religious process of re-formation which \"aims to recover the original shape of man\", oriented at \"the image of God\" as exemplified by the founders and sacred texts of the religions of the world. The term was used within early Christianity to refer to a life oriented toward the Holy Spirit and broadened during the Late Middle Ages to include mental aspects of life.\n\nIn modern times, the term both spread to other religious traditions and broadened to refer to a wider range of experience, including a range of esoteric traditions and religious traditions. Modern usages tend to refer to a subjective experience of a sacred dimension and the \"deepest values and meanings by which people live\", often in a context separate from organized religious institutions. This may involve belief in a supernatural realm beyond the ordinarily observable world, personal growth, a quest for an ultimate or sacred meaning, religious experience,  or an encounter with one's own \"inner dimension\".\n\nEtymology\nThe term spirit means \"animating or vital principle in man and animals\". It is derived from the Old French espirit, which comes from the Latin word spiritus (soul, ghost, courage, vigor, breath) and is related to spirare (to breathe). In the Vulgate the Latin word spiritus is used to translate the Greek pneuma and Hebrew ruach.\n\nThe term \"spiritual\", matters \"concerning the spirit\", is derived from Old French spirituel (12c.), which is derived from Latin spiritualis, which comes from spiritus or \"spirit\".\n\nThe term \"spirituality\" is derived from Middle French spiritualit\u00e9, from Late Latin \"spiritualitatem\" (nominative spiritualitas), which is also derived from Latin spiritualis.\n\nDefinition\nThere is no single, widely agreed-upon definition of spirituality. Surveys of the definition of the term, as used in scholarly research, show a broad range of definitions with limited overlap. A survey of reviews by McCarroll each dealing with the topic of spirituality gave twenty-seven explicit definitions, among which \"there was little agreement\". This impedes the systematic study of spirituality and the capacity to communicate findings meaningfully. Furthermore, many of spirituality's core features are not unique to spirituality; for example self-transcendence, asceticism and the recognition of one's connection to all were regarded by the atheist Arthur Schopenhauer as key to ethical life.\n\nThere is a key distinction which needs to be made between the religious and the spiritual. William James in his study of The Varieties of Religious Experience makes the distinction early in this lecture series that there exists \"one great partition which divides the religious field. On the one side of it lies institutional, on the other personal religion.\" This personal religion is spirituality, what he defines as, \"the feelings, acts, and experiences of individual men in their solitude, so far as they apprehend themselves to stand in relation to whatever they may consider the divine\". Here as well, this notion of the divine is non-sectarian and non-institutional. The divine can be found, according to William James, in spiritual spaces without a Godhead, such as \"Buddhism\", for instance, and he even claims that this notion of divinity is found in \"modern transcendental idealism\" and in what he terms \"Emmersoniamism\", both of which \"seem to let God evaporate into abstract Ideality. Not a deity in concreto, not a superhuman person, but the immanent divinity in things, the essentially spiritual structure of the universe [...]\". In this sense we can understand that the spiritual is not necessarily the religious, but rather, it is the experience and understanding of divinity (divinity in its broadest notion \u2013 deified or godless) which forms the elemental substrate of institutional religion as we know it today.  \n\nAccording to Kees Waaijman, the traditional meaning of spirituality is a process of re-formation which \"aims to recover the original shape of man, the image of God. To accomplish this, the re-formation is oriented at a mold, which represents the original shape: in Judaism the Torah, in Christianity there is Christ, for Buddhism, Buddha, and in Islam, Muhammad.\" Houtman and Aupers suggest that modern spirituality is a blend of humanistic psychology, mystical and esoteric traditions, and Eastern religions.\n\nIn modern times the emphasis is on subjective experience  and the \"deepest values and meanings by which people live\", incorporating personal growth or transformation, usually in a context separate from organized religious institutions. Spirituality can be defined generally as an individual's search for ultimate or sacred meaning and purpose in life. Additionally it can mean to seek out or search for personal growth, religious experience, belief in a supernatural realm or afterlife, or to make sense of one's own \"inner dimension\".\n\nDevelopment of the meaning of spirituality\n\nClassical, medieval and early modern periods\nBergomi detects \"an enlightened form of non-religious spirituality\" in late antiquity.\n\nWords translatable as \"spirituality\" first began to arise in the 5th century and only entered common use toward the end of the Middle Ages. In a Biblical context the term means being animated by God. The New Testament offers the concept of being driven by the Holy Spirit, as opposed to living a life in which one rejects this influence.\n\nIn the 11th century this meaning changed. \"Spirituality\" began to denote the mental aspect of life, as opposed to the material and sensual aspects of life, \"the ecclesiastical sphere of light against the dark world of matter\". In the 13th century \"spirituality\" acquired a social and psychological meaning. Socially it denoted the territory of the clergy: \"the ecclesiastical against the temporary possessions, the ecclesiastical against the secular authority, the clerical class against the secular class\". Psychologically, it denoted the realm of the inner life: \"the purity of motives, affections, intentions, inner dispositions, the psychology of the spiritual life, the analysis of the feelings\".\n\nIn the 17th and 18th centuries a distinction was made between higher and lower forms of spirituality: \"A spiritual man is one who is Christian 'more abundantly and deeper than others'.\" The word was also associated with mysticism and quietism, and acquired a negative meaning.\n\nModern spirituality\n\nModern notions of spirituality developed throughout the 19th and 20th century, mixing Christian ideas with Western esoteric traditions and elements of Asian, especially Indian, religions. Spirituality became increasingly disconnected from traditional religious organisations and institutions. It is sometimes associated today with philosophical, social, or political movements such as liberalism, feminist theology, and green politics.\n\nTranscendentalism and Unitarian Universalism\nRalph Waldo Emerson (1803\u20131882) was a pioneer of the idea of spirituality as a distinct field. He was one of the major figures in Transcendentalism, an early 19th-century liberal Protestant movement, which was rooted in English and German Romanticism, the Biblical criticism of Johann Gottfried Herder and Friedrich Schleiermacher, the skepticism of Hume, and Neoplatonism.\nThe Transcendentalists emphasised an intuitive, experiential approach of religion. Following Schleiermacher, an individual's intuition of truth was taken as the criterion for truth. In the late 18th and early 19th century, the first translations of Hindu texts appeared, which were also read by the Transcendentalists, and influenced their thinking. They also endorsed universalist and Unitarianist ideas, leading to Unitarian Universalism, the idea that there must be truth in other religions as well, since a loving God would redeem all living beings, not just Christians.\n\nTheosophy, anthroposophy, and the perennial philosophy\n\nA major influence on modern spirituality was the Theosophical Society, which searched for 'secret teachings' in Asian religions. It has been influential on modernist streams in several Asian religions, notably Neo-Vedanta, the revival of Theravada Buddhism, and Buddhist modernism, which have taken over modern western notions of personal experience and universalism and integrated them in their religious concepts. A second, related influence was Anthroposophy, whose founder, Rudolf Steiner, was particularly interested in developing a genuine Western spirituality, and in the ways that such a spirituality could transform practical institutions such as education, agriculture, and medicine. More independently, the spiritual science of Martinus was an influence, especially in Scandinavia.\n\nThe influence of Asian traditions on western modern spirituality was also furthered by the perennial philosophy, whose main proponent Aldous Huxley was deeply influenced by Swami Vivekananda's Neo-Vedanta and universalism, and the spread of social welfare, education and mass travel after World War II.\n\nNeo-Vedanta\n\nAn important influence on western spirituality was Neo-Vedanta, also called neo-Hinduism and Hindu Universalism, a modern interpretation of Hinduism which developed in response to western colonialism and orientalism. It aims to present Hinduism as a \"homogenized ideal of Hinduism\" with Advaita Vedanta as its central doctrine. Due to the colonisation of Asia by the western world, since the 19th century an exchange of ideas has been taking place between the western world and Asia, which also influenced western religiosity. Unitarianism, and the idea of Universalism, was brought to India by missionaries, and had a major influence on neo-Hinduism via Ram Mohan Roy's Brahmo Samaj and Brahmoism. Roy attempted to modernise and reform Hinduism, from the idea of Universalism. This universalism was further popularised, and brought back to the west as neo-Vedanta, by Swami Vivekananda.\n\n\"Spiritual but not religious\"\n\nAfter the Second World War, spirituality and theistic religion became increasingly disconnected, and spirituality became more oriented on subjective experience, instead of \"attempts to place the self within a broader ontological context\". A new discourse developed, in which (humanistic) psychology, mystical and esoteric traditions and eastern religions are being blended, to reach the true self by self-disclosure, free expression, and meditation.\n\nThe distinction between the spiritual and the religious became more common in the popular mind during the late 20th century with the rise of secularism and the advent of the New Age movement.  Authors such as Chris Griscom and Shirley MacLaine explored it in numerous ways in their books. Paul Heelas noted the development within New Age circles of what he called \"seminar spirituality\": structured offerings complementing consumer choice with spiritual options.\n\nAmong other factors, declining membership of organized religions and the growth of secularism in the western world have given rise to this broader view of spirituality. The term \"spiritual\" is now frequently used in contexts in which the term \"religious\" was formerly employed. Both theists and atheists have criticized this development.\n\nTraditional spirituality\n\nAbrahamic faiths\n\nJudaism\nSpirituality in Judaism may involve practices of Jewish ethics, Jewish prayer, Jewish meditation, Shabbat and holiday observance, Torah study, dietary laws, teshuvah, and other practices. It may involve practices ordained by halakhah or other practices.\n\nKabbalah (literally \"receiving\") is an esoteric method, discipline and school of thought of Judaism. Kabbalah is a set of esoteric teachings meant to explain the relationship between an unchanging, eternal and mysterious Ein Sof (no end) and the mortal and finite universe (his creation). Interpretations of Kabbalistic spirituality are found within Hasidic Judaism, a branch of Orthodox Judaism founded in 18th-century Eastern Europe by Rabbi Israel Baal Shem Tov. Hasidism often emphasizes the Immanent Divine presence and focuses on emotion, fervour, and the figure of the Tzadik. This movement included an elite ideal of nullification to paradoxical Divine Panentheism.\n\nThe Musar movement is a Jewish spiritual movement that has focused on developing character traits such as faith, humility, and love.  The Musar movement, first founded in the 19th century by Israel Salanter and developed in the 21st century by Alan Morinis and Ira F. Stone, has encouraged spiritual practices of Jewish meditation, Jewish prayer, Jewish ethics, tzedakah, teshuvah, and the study of musar (ethical) literature.\n\nReform Judaism and Conservative Judaism have often emphasized the spirituality of Jewish ethics and tikkun olam, feminist spirituality, Jewish prayer, Torah study, ritual, and musar.\n\nChristianity\n\nCatholic spirituality is the spiritual practice of living out a personal act of faith (fides qua creditur) following the acceptance of faith (fides quae creditur). Although all Catholics are expected to pray together at Mass, there are many different forms of spirituality and private prayer which have developed over the centuries. Each of the major religious orders of the Catholic Church and other lay groupings have their own unique spirituality \u2013 its own way of approaching God in prayer and in living out the Gospel.\n\nChristian mysticism refers to the development of mystical practices and theory within Christianity. It has often been connected to mystical theology, especially in the Catholic and Eastern Orthodox traditions. The attributes and means by which Christian mysticism is studied and practiced are varied and range from ecstatic visions of the soul's mystical union with God to simple prayerful contemplation of Holy Scripture (i.e., Lectio Divina).\n\nProgressive Christianity is a contemporary movement which seeks to remove the supernatural claims of the faith and replace them with a post-critical understanding of biblical spirituality based on historical and scientific research. It focuses on the lived experience of spirituality over historical dogmatic claims, and accepts that the faith is both true and a human construction, and that spiritual experiences are psychologically and neurally real and useful.\n\nIslam\nAn inner spiritual struggle and an outer physical struggle are two commonly accepted meanings of the Arabic word jihad: The \"greater jihad\" is the inner struggle by a believer to fulfill his religious duties. This non-violent meaning is stressed by both Muslim and non-Muslim authors.\n\nAl-Khatib al-Baghdadi, an 11th-century Islamic scholar, referenced a statement by the companion of Muhammad, Jabir ibn Abd-Allah:\n\nSufism\n\nThe best known form of Islamic mystic spirituality is the Sufi tradition (famous through Rumi and Hafiz) in which a Sheikh or pir transmits spiritual discipline to students.\n\nSufism or  () is defined by its adherents as the inner, mystical dimension of Islam. A practitioner of this tradition is generally known as a  (). Sufis believe they are practicing ihsan (perfection of worship) as revealed by Gabriel to Muhammad,\n\nSufis consider themselves as the original true proponents of this pure original form of Islam. They are strong adherents to the principal of tolerance, peace and against any form of violence. The Sufi have suffered severe persecution by more rigid and fundamentalist groups such as the Wahhabi and Salafi movement. In 1843 the Senussi Sufi were forced to flee Mecca and Medina and head to Sudan and Libya.\n\nClassical Sufi scholars have defined Sufism as \"a science whose objective is the reparation of the heart and turning it away from all else but God\". Alternatively, in the words of the Darqawi Sufi teacher Ahmad ibn Ajiba, \"a science through which one can know how to travel into the presence of the Divine, purify one's inner self from filth, and beautify it with a variety of praiseworthy traits\".\n\nAsian traditions\n\nBuddhism\n\nBuddhist practices are known as Bhavana, which literally means \"development\" or \"cultivating\" or \"producing\" in the sense of \"calling into existence.\" It is an important concept in Buddhist praxis (Patipatti). The word bhavana normally appears in conjunction with another word forming a compound phrase such as citta-bhavana (the development or cultivation of the heart/mind) or metta-bhavana (the development/cultivation of loving kindness). When used on its own bhavana signifies 'spiritual cultivation' generally.\n\nVarious Buddhist Paths to liberation developed throughout the ages. Best-known is the Noble Eightfold Path, but others include the Bodhisattva Path and Lamrim.\n\nHinduism\nHinduism has no traditional ecclesiastical order, no centralized religious authorities, no governing body, no prophet(s) nor any binding holy book; Hindus can choose to be polytheistic, pantheistic, monistic, or atheistic. Within this diffuse and open structure, spirituality in Hindu philosophy is an individual experience, and referred to as ksaitraj\u00f1a (Sanskrit: \u0915\u094d\u0937\u0948\u0924\u094d\u0930\u091c\u094d\u091e). It defines spiritual practice as one's journey towards moksha, awareness of self, the discovery of higher truths, true nature of reality, and a consciousness that is liberated and content.\n\nFour paths\n\nTraditionally, Hinduism identifies three m\u0101rga (ways) of spiritual practice, namely J\u00f1\u0101na(\u091c\u094d\u091e\u093e\u0928), the way of knowledge; Bhakti, the way of devotion; and Karma yoga, the way of selfless action. In the 19th century Vivekananda, in his neo-Vedanta synthesis of Hinduism, added R\u0101ja yoga, the way of contemplation and meditation, as a fourth way, calling all of them \"yoga\".\n\nJ\u00f1\u0101na marga is a path often assisted by a guru (teacher) in one's spiritual practice. Bhakti marga is a path of faith and devotion to deity or deities; the spiritual practice often includes chanting, singing and music \u2013 such as in kirtans \u2013 in front of idols, or images of one or more deity, or a devotional symbol of the holy. Karma marga is the path of one's work, where diligent practical work or vartta (Sanskrit: \u0935\u093e\u0930\u094d\u0924\u094d\u0924\u093e, profession) becomes in itself a spiritual practice, and work in daily life is perfected as a form of spiritual liberation and not for its material rewards. R\u0101ja marga is the path of cultivating necessary virtues, self-discipline, tapas (meditation), contemplation and self-reflection sometimes with isolation and renunciation of the world, to a pinnacle state called sam\u0101dhi. This state of sam\u0101dhi has been compared to peak experience.\n\nThere is a rigorous debate in Indian literature on relative merits of these theoretical spiritual practices. For example, Chandogyopanishad suggests that those who engage in ritualistic offerings to gods and priests will fail in their spiritual practice, while those who engage in tapas will succeed; Svetasvataropanishad suggests that a successful spiritual practice requires a longing for truth, but warns of becoming 'false ascetic' who go through the mechanics of spiritual practice without meditating on the nature of Self and universal Truths. In the practice of Hinduism, suggest modern era scholars such as Vivekananda, the choice between the paths is up to the individual and a person's proclivities. Other scholars suggest that these Hindu spiritual practices are not mutually exclusive, but overlapping. These four paths of spirituality are also known in Hinduism outside India, such as in Balinese Hinduism, where it is called Catur Marga (literally: four paths).\n\nSchools and spirituality\nDifferent schools of Hinduism encourage different spiritual practices. In Tantric school for example, the spiritual practice has been referred to as s\u0101dhan\u0101. It involves initiation into the school, undergoing rituals, and achieving moksha liberation by experiencing union of cosmic polarities. The Hare Krishna school emphasizes bhakti yoga as spiritual practice. In Advaita Vedanta school, the spiritual practice emphasizes j\u00f1\u0101na yoga in stages: samnyasa (cultivate virtues), sravana (hear, study), manana (reflect) and dhyana (nididhyasana, contemplate).\n\nJainism \nJainism, traditionally known as Jain Dharma, is an ancient Indian religion. The three main pillars of Jainism are ahi\u1e43s\u0101 (non-violence), anek\u0101ntav\u0101da (non-absolutism), and aparigraha (non-attachment). Jains take five main vows: ahi\u1e43s\u0101 (non-violence), satya (truth), asteya (not stealing), brahmacharya (sexual continence), and aparigraha (non-possessiveness). These principles have affected Jain culture in many ways, such as leading to a predominantly vegetarian lifestyle. Parasparopagraho j\u012bv\u0101n\u0101m (the function of souls is to help one another) is the faith's motto and the \u1e46am\u014dk\u0101ra mantra is its most common and basic prayer.\n\nJainism traces its spiritual ideas and history through a succession of twenty-four leaders or Tirthankaras, with the first in the current time cycle being Rishabhadeva, whom the tradition holds to have lived millions of years ago; the twenty-third tirthankara Parshvanatha, whom historians date to 9th century BCE; and the twenty-fourth tirthankara, Mahavira around 600 BCE. Jainism is considered to be an eternal dharma with the tirthankaras guiding every time cycle of the cosmology.\n\nSikhism\n\nSikhism considers spiritual life and secular life to be intertwined: \"In the Sikh Weltanschauung...the temporal world is part of the Infinite Reality and partakes of its characteristics.\" Guru Nanak described living an \"active, creative, and practical life\" of \"truthfulness, fidelity, self-control and purity\" as being higher than a purely contemplative life.\n\nThe 6th Sikh Guru Guru Hargobind re-affirmed that the political/temporal (Miri) and spiritual (Piri) realms are mutually coexistent.  According to the 9th Sikh Guru, Tegh Bahadhur, the ideal Sikh should have both Shakti (power that resides in the temporal), and Bhakti (spiritual meditative qualities). This was developed into the concept of the Saint Soldier by the 10th Sikh Guru, Gobind Singh.\n\nAccording to Guru Nanak, the goal is to attain the \"attendant balance of separation-fusion, self-other, action-inaction, attachment-detachment, in the course of daily life\", the polar opposite to a self-centered existence. Nanak talks further about the one God or akal (timelessness) that permeates all life). and which must be seen with 'the inward eye', or the 'heart', of a human being.\n\nIn Sikhism there is no dogma, priests, monastics or yogis.\n\nAfrican spirituality\n\nIn some African contexts, spirituality is considered a belief system that guides the welfare of society and the people therein, and eradicates sources of unhappiness occasioned by evil.\nIn traditional society prior to colonization and extensive introduction to Christianity or Islam, religion was the strongest element in society influencing the thinking and actions of the people.  Hence spirituality was a sub-domain of religion. Despite the rapid social, economic and political changes of the last century, traditional religion remains the essential background for many African people. And that religion is a communal given, not an individual choice. Religion gives all of life its meaning and provides ground for action. Each person is \"a living creed of his religion.\" There is no concern for spiritual matters apart from ones physical and communal life. Life continues after death but remains focused on pragmatic family and community matters.\n\nContemporary spirituality\n\nThe term spiritual has frequently become used in contexts in which the term religious was formerly employed. Contemporary spirituality is also called \"post-traditional spirituality\" and \"New Age spirituality\". Hanegraaf makes a distinction between two \"New Age\" movements: New Age in a restricted sense, which originated primarily in mid-twentieth century England and had its roots in Theosophy and anthroposophy, and \"New Age\" in a general sense, which emerged in the later 1970s\n\nThose who speak of spirituality outside of religion often define themselves as spiritual but not religious and generally believe in the existence of different \"spiritual paths\", emphasizing the importance of finding one's own individual path to spirituality. According to one 2005 poll, about 24% of the United States population identifies itself as \"spiritual but not religious\".\n\nLockwood draws attention to the variety of spiritual experience in the contemporary West:\n\nThe new Western spiritual landscape, characterised by consumerism and choice abundance, is scattered with novel religious manifestations based in psychology and the Human Potential Movement, each offering participants a pathway to the Self.\n\nCharacteristics\nModern spirituality centers on the \"deepest values and meanings by which people live\". It often embraces the idea of an ultimate or an alleged immaterial reality. It envisions an inner path enabling a person to discover the essence of his or her being.\n\nNot all modern notions of spirituality embrace transcendental ideas. Secular spirituality emphasizes humanistic ideas on moral character (qualities such as love, compassion, patience, tolerance, forgiveness, contentment, responsibility, harmony, and a concern for others). These are aspects of life and human experience which go beyond a purely materialist view of the world without necessarily accepting belief in a supernatural reality or any divine being. Nevertheless, many humanists (e.g. Bertrand Russell, Jean-Paul Sartre) who clearly value the non-material, communal, and virtuous aspects of life reject this usage of the term \"spirituality\" as being overly-broad (i.e. it effectively amounts to saying \"everything and anything that is good and virtuous is necessarily spiritual\"). In 1930 Russell, a self-described agnostic renowned as an atheist, wrote \"... one's ego is no very large part of the world. The man who can centre his thoughts and hopes upon something transcending self can find a certain peace in the ordinary troubles of life which is impossible to the pure egoist.\"\nSimilarly, Aristotle\u00a0\u2013 one of the first known Western thinkers to demonstrate that morality, virtue and goodness can be derived without appealing to supernatural forces\u00a0\u2013 argued that \"men create Gods in their own image\" (not the other way around). Moreover, theistic and atheistic critics alike dismiss the need for the \"secular spirituality\" label on the basis that it appears to be nothing more than obscurantism in that:\n\n the term \"spirit\" is commonly taken as denoting the existence of unseen / otherworldly / life-giving forces; and\n words such as \"morality\", \"philanthropy\" and \"humanism\" already efficiently and succinctly describe the prosocial-orientation and civility that the phrase \"secular spirituality\" is meant to convey but without risking confusion that one is referring to something supernatural.\n\nAlthough personal well-being, both physical and psychological, is said to be an important aspect of modern spirituality, this does not imply spirituality is essential to achieving happiness (e.g. see).  Free-thinkers who reject notions that the numinous/non-material is important to living well can be just as happy as more spiritually-oriented individuals (see)\n\nContemporary proponents of spirituality may suggest that spirituality develops inner peace and forms a foundation for happiness. For example, meditation and similar practices are suggested to help the practitioner cultivate her/his inner life and character.  Ellison and Fan (2008) assert that spirituality causes a wide array of positive health outcomes, including \"morale, happiness, and life satisfaction.\". However, Schuurmans-Stekhoven (2013) actively attempted to replicate this research and found more \"mixed\" results. Nevertheless, spirituality has played a central role in some self-help movements such as Alcoholics Anonymous:\n\nSuch spiritually-informed treatment approaches have been challenged as pseudoscience.\n\nSpiritual experience\n\nSpiritual experiences play a central role in modern spirituality. Both western and Asian authors have popularised this notion. Important early-20th century Western writers who studied the phenomenon of spirituality, and their works, include William James, The Varieties of Religious Experience (1902) and Rudolph Otto, especially The Idea of the Holy (1917)\n\nJames' notions of  \"spiritual experience\" had a further influence on the modernist streams in Asian traditions, making them even further recognisable for a western audience.\n\nWilliam James popularized the use of the term \"religious experience\" in his The Varieties of Religious Experience. He has also influenced the understanding of mysticism as a distinctive experience which allegedly grants knowledge.\n\nWayne Proudfoot traces the roots of the notion of \"religious experience\" further back to the German theologian Friedrich Schleiermacher (1768\u20131834), who argued that religion is based on a feeling of the infinite. Schleiermacher used the idea of \"religious experience\" to defend religion against the growing scientific and secular critique. Many scholars of religion, of whom William James was the most influential, adopted the concept.\n\nMajor Asian influences on contemporary spirituality have included Swami Vivekananda (1863\u20131902) and D.T. Suzuki. (1870\u20131966) Vivekananda popularised a modern syncretic Hinduism, in which an emphasis on personal experience replaced the authority of scriptures. Suzuki had a major influence on the popularisation of Zen in the west and popularized the idea of enlightenment as insight into a timeless, transcendent reality. Other influences came through Paul Brunton's A Search in Secret India (1934), which introduced Ramana Maharshi (1879\u20131950) and Meher Baba (1894\u20131969) to a western audience.\n\nSpiritual experiences can include being connected to a larger reality, yielding a more comprehensive self; joining with other individuals or the human community; with nature or the cosmos; or with the divine realm.\n\nSpiritual practices\n\nKees Waaijman discerns four forms of spiritual practices:\n Somatic practices, especially deprivation and diminishment. Deprivation aims to purify the body. Diminishment concerns the repulsement of ego-oriented impulses. Examples include fasting and poverty.\n Psychological practices, for example meditation.\n Social practices. Examples include the practice of obedience and communal ownership, reforming ego-orientedness into other-orientedness.\n Spiritual. All practices aim at purifying ego-centeredness, and direct the abilities at the divine reality.\n\nSpiritual practices may include meditation, mindfulness, prayer, the contemplation of sacred texts, ethical development,\nand spiritual retreats in a convent. Love and/or compassion are often described as the mainstay of spiritual development.\n\nWithin spirituality is also found \"a common emphasis on the value of thoughtfulness, tolerance for breadth and practices and beliefs, and appreciation for the insights of other religious communities, as well as other sources of authority within the social sciences.\"\n\nScience\n\nRelation to science\n\nSince the scientific revolution of the 18th-century Enlightenment, the relationship of science to religion and to spirituality has developed in complex ways. Historian John Hedley Brooke describes wide variations:\n\nBrooke has proposed that the currently held popular notion of antagonisms between science and religion has historically originated with \"thinkers with a social or political axe to grind\" rather than with the natural philosophers themselves. Though physical and biological scientists today see no need for supernatural explanations to describe reality, some scientists continue to regard science and spirituality as complementary, not contradictory, and are willing to debate,\nrather than simply classifying spirituality and science as non-overlapping magisteria.\n\nWilliam James, one of the preeminent philosophers of religious experience & spirituality termed the general critique of religious experience by Science as the \"Survival Theory\". He writes, \"There is a notion in the air about us that religion is probably only an anachronism, a case of 'survival,' an atavistic relapse into a mode of thought which humanity in its more enlightened examples has outgrown; and this notion our religious anthropologists at present do little to counteract\". He makes the claim that theology, or the science of religion will never truly understand its subject matter, \"just as Al Ghazzali told us [...] that to understand the causes of drunkenness, as a physician understands them, is not to be drunk. A science may come to understand everything about the causes and elements of religion, and might even decide which elements were qualified, by their general harmony with other branches of knowledge, to be considered true; and yet the best man at this science might be the man who found it hardest to be personally devout\".\n\nA few religious leaders have shown openness to modern science and its methods. The 14th Dalai Lama, for example, has proposed that if a scientific analysis conclusively showed certain claims in Buddhism to be false, then the claims must be abandoned and the findings of science accepted.\n\nQuantum mysticism\n\nDuring the twentieth century the relationship between science and spirituality has been influenced both by Freudian psychology, which has accentuated the boundaries between the two areas by accentuating individualism and secularism, and by developments in particle physics, which reopened the debate about complementarity between scientific and religious discourse and rekindled for many an interest in holistic conceptions of reality. These conceptions were championed by New Age spiritualists in a type of quantum mysticism that they claim justifies their spiritual beliefs, though quantum physicists themselves on the whole reject such attempts as being pseudoscientific.\n\nScientific research\n\nHealth and well-being\n\nVarious studies (most  originating from North America) have reported a positive correlation between spirituality and mental well-being in both healthy people and those encountering a range of physical illnesses or psychological disorders. Although spiritual individuals tend to be optimistic, report greater social support, and experience higher intrinsic meaning in life, strength, and inner peace, whether the correlation represents a causal link remains contentious. Both supporters and opponents of this claim agree that past statistical findings are difficult to interpret, in large part because of the ongoing disagreement over how spirituality should be defined and measured. There is also evidence that an agreeable/positive temperament and/or a tendency toward sociability (which all correlate with spirituality) might actually be the key psychological features that predispose people to subsequently adopt a spiritual orientation and that these characteristics, not spiritually per se, add to well-being. There is also some suggestion that the benefits associated with spirituality and religiosity might arise from being a member of a close-knit community. Social bonds available via secular sources (i.e.,  not unique to spirituality or faith-based groups) might just as effectively raise well-being. In sum, spirituality may not be the \"active ingredient\" (i.e., past association with psychological well-being measures might reflect a reverse causation or effects from other variables that correlate with spirituality), and that the effects of agreeableness, conscientiousness, or virtue\u00a0\u2013 personality traits common in many non-spiritual people yet known to be slightly more common among the spiritual\u00a0\u2013 may better account for spirituality's apparent correlation with mental health and social support.\n\nIntercessionary prayer\nMasters and Spielmans conducted a meta-analysis of all the available and reputable research examining the effects of distant intercessory prayer.  They found no discernible health effects from being prayed for by others. In fact, one large and scientifically rigorous study by Herbert Benson and colleagues revealed that intercessory prayer had no effect on recovery from cardiac arrest, but patients told people were praying for them actually had an increased risk of medical complications.  Knowing others are praying for you could actually be medically detrimental.\n\nSpiritual care in health care professions\n\nIn the health-care professions there is growing interest in \"spiritual care\", to complement the medical-technical approaches and to improve the outcomes of medical treatments. Puchalski et al. argue for \"compassionate systems of care\" in a spiritual context.\n\nSpiritual experiences\nNeuroscientists have examined brain functioning during reported spiritual experiences finding that certain neurotransmitters and specific areas of the brain are involved.  Moreover, experimenters have also successfully induced spiritual experiences in individuals by administering psychoactive agents known to elicit euphoria and perceptual distortions. Conversely, religiosity and spirituality can also be dampened by electromagnetic stimulation of the brain. These results have motivated some leading theorists to speculate that spirituality may be a benign subtype of psychosis \u2013 benign in the sense that the same aberrant sensory perceptions that those suffering clinical psychoses evaluate as distressingly incongruent and inexplicable are instead interpreted by spiritual individuals as positive (personal and meaningful transcendent experiences).\n\nMeasurement\nConsiderable debate persists about \u2014 among other factors \u2014 spirituality's relation to religion, the number and content of its dimensions, its relation to concepts of well-being, and its universality. (ref) A number of research groups have developed instruments which attempt to measure spirituality quantitatively, including the Spiritual Transcendence Scale (STS), the Brief Multidimensional Measure of Religiousness/Spirituality (BMMRS) and the Daily Spiritual Experiences Scale. MacDonald et al. gave an \"Expressions of Spirituality Inventory\" (ESI-R) measuring five dimensions of spirituality to over 4000 persons across eight countries. The study results and interpretation highlighted the complexity and challenges of measurement of spirituality cross-culturally.\n\nSee also\n\n Anthroposophy\n Esotericism\n Glossary of spirituality terms\n ietsism\n Interspirituality\n New Age\n Numinous\n Outline of spirituality\n Perennial philosophy\n Reason\n Relationship between religion and science\n Religion\n Spiritual intelligence\n Sacred\u2013profane dichotomy\n Secular spirituality\n Self-actualization\n Self-help\n Skepticism\n Spiritual but not religious\n Spiritism\n Sublime (philosophy)\n Syncretism\n Theosophy\n Spiritual activism\n\nNotes\n\nReferences\n\nSources\n\nPublished sources\n\nWeb-sources\n\nFurther reading\n Downey, Michael. Understanding Christian Spirituality. New York: Paulist Press, 1997.\n Charlene Spretnak, The Spiritual Dynamic in Modern Art : Art History Reconsidered, 1800 to the Present, 1986.\n Eck, Diana L. A New Religious America. San Francisco: Harper, 2001.\n \n \n Schmidt, Leigh Eric. Restless Souls : The Making of American Spirituality. San Francisco: Harper, 2005.\n\nExternal links\n\n Sociology of Religion Resources\n\n \nBelief\nMetaphysics of mind\nNew Age\nPhilosophy of mind",
  "Time": "Time is the continued sequence of existence and events that occurs in an apparently irreversible succession from the past, through the present, into the future. It is a component quantity of various measurements used to sequence events, to compare the duration of events or the intervals between them, and to quantify rates of change of quantities in material reality or in the conscious experience. Time is often referred to as a fourth dimension, along with three spatial dimensions.\n\nTime has long been an important subject of study in religion, philosophy, and science, but defining it in a manner applicable to all fields without circularity has consistently eluded scholars.\nNevertheless, diverse fields such as business, industry, sports, the sciences, and the performing arts all incorporate some notion of time into their respective measuring systems.\n\nTime in physics is operationally defined as \"what a clock reads\". \n\nThe physical nature of time is addressed by general relativity with respect to events in spacetime. Examples of events are the collision of two particles, the explosion of a supernova, or the arrival of a rocket ship. Every event can be assigned four numbers representing its time and position (the event's coordinates). However, the numerical values are different for different observers. In general relativity, the question of what time it is now only has meaning relative to a particular observer. Distance and time are intimately related, and the time required for light to travel a specific distance is the same for all observers, as first publicly demonstrated by Michelson and Morley. General relativity does not address the nature of time for extremely small intervals where quantum mechanics holds. At this time, there is no generally accepted theory of quantum general relativity.\n\nTime is one of the seven fundamental physical quantities in both the International System of Units (SI) and International System of Quantities. The SI base unit of time is the second. Time is used to define other quantities, such as velocity, so defining time in terms of such quantities would result in circularity of definition. An operational definition of time, wherein one says that observing a certain number of repetitions of one or another standard cyclical event (such as the passage of a free-swinging pendulum) constitutes one standard unit such as the second, is highly useful in the conduct of both advanced experiments and everyday affairs of life. To describe observations of an event, a location (position in space) and time are typically noted.\n\nThe operational definition of time does not address what the fundamental nature of it is. It does not address why events can happen forward and backward in space, whereas events only happen in the forward progress of time. Investigations into the relationship between space and time led physicists to define the spacetime continuum. General relativity is the primary framework for understanding how spacetime works. Through advances in both theoretical and experimental investigations of spacetime, it has been shown that time can be distorted and dilated, particularly at the edges of black holes.\n\nTemporal measurement has occupied scientists and technologists and was a prime motivation in navigation and astronomy. Periodic events and periodic motion have long served as standards for units of time. Examples include the apparent motion of the sun across the sky, the phases of the moon, the swing of a pendulum, and the beat of a heart. Currently, the international unit of time, the second, is defined by measuring the electronic transition frequency of caesium atoms (see below). Time is also of significant social importance, having economic value (\"time is money\") as well as personal value, due to an awareness of the limited time in each day and in human life spans.\n\nThere are many systems for determining what time it is, including the Global Positioning System, other satellite systems, Coordinated Universal Time and mean solar time. In general, the numbers obtained from different time systems differ from one another.\n\nMeasurement \n\nGenerally speaking, methods of temporal measurement, or chronometry, take two distinct forms: the calendar, a mathematical tool for organising intervals of time,\nand the clock, a physical mechanism that counts the passage of time. In day-to-day life, the clock is consulted for periods less than a day, whereas the calendar is consulted for periods longer than a day. Increasingly, personal electronic devices display both calendars and clocks simultaneously. The number (as on a clock dial or calendar) that marks the occurrence of a specified event as to hour or date is obtained by counting from a fiducial epoch\u00a0\u2013 a central reference point.\n\nHistory of the calendar \n\nArtifacts from the Paleolithic suggest that the moon was used to reckon time as early as 6,000 years ago. Lunar calendars were among the first to appear, with years of either 12 or 13 lunar months (either 354 or 384 days). Without intercalation to add days or months to some years, seasons quickly drift in a calendar based solely on twelve lunar months. Lunisolar calendars have a thirteenth month added to some years to make up for the difference between a full year (now known to be about 365.24 days) and a year of just twelve lunar months. The numbers twelve and thirteen came to feature prominently in many cultures, at least partly due to this relationship of months to years. Other early forms of calendars originated in Mesoamerica, particularly in ancient Mayan civilization. These calendars were religiously and astronomically based, with 18 months in a year and 20 days in a month, plus five epagomenal days at the end of the year.\n\nThe reforms of Julius Caesar in 45 BC put the Roman world on a solar calendar. This Julian calendar was faulty in that its intercalation still allowed the astronomical solstices and equinoxes to advance against it by about 11 minutes per year. Pope Gregory XIII introduced a correction in 1582; the Gregorian calendar was only slowly adopted by different nations over a period of centuries, but it is now by far the most commonly used calendar around the world.\n\nDuring the French Revolution, a new clock and calendar were invented in an attempt to de-Christianize time and create a more rational system in order to replace the Gregorian calendar. The French Republican Calendar's days consisted of ten hours of a hundred minutes of a hundred seconds, which marked a deviation from the base 12 (duodecimal) system used in many other devices by many cultures. The system was abolished in 1806.\n\nHistory of other devices\n\nA large variety of devices have been invented to measure time. The study of these devices is called horology.\n\nAn Egyptian device that dates to c. 1500 BC, similar in shape to a bent T-square, measured the passage of time from the shadow cast by its crossbar on a nonlinear rule. The T was oriented eastward in the mornings. At noon, the device was turned around so that it could cast its shadow in the evening direction.\n\nA sundial uses a gnomon to cast a shadow on a set of markings calibrated to the hour. The position of the shadow marks the hour in local time. The idea to separate the day into smaller parts is credited to Egyptians because of their sundials, which operated on a duodecimal system. The importance of the number 12 is due to the number of lunar cycles in a year and the number of stars used to count the passage of night.\n\nThe most precise timekeeping device of the ancient world was the water clock, or clepsydra, one of which was found in the tomb of Egyptian pharaoh Amenhotep I. They could be used to measure the hours even at night but required manual upkeep to replenish the flow of water. The ancient Greeks and the people from Chaldea (southeastern Mesopotamia) regularly maintained timekeeping records as an essential part of their astronomical observations. Arab inventors and engineers, in particular, made improvements on the use of water clocks up to the Middle Ages. In the 11th century, Chinese inventors and engineers invented the first mechanical clocks driven by an escapement mechanism.\n\nThe hourglass uses the flow of sand to measure the flow of time. They were used in navigation. Ferdinand Magellan used 18 glasses on each ship for his circumnavigation of the globe (1522).\n\nIncense sticks and candles were, and are, commonly used to measure time in temples and churches across the globe. Waterclocks, and later, mechanical clocks, were used to mark the events of the abbeys and monasteries of the Middle Ages. Richard of Wallingford (1292\u20131336), abbot of St. Alban's abbey, famously built a mechanical clock as an astronomical orrery about 1330.\n\nGreat advances in accurate time-keeping were made by Galileo Galilei and especially Christiaan Huygens with the invention of pendulum-driven clocks along with the invention of the minute hand by Jost Burgi.\n\nThe English word clock probably comes from the Middle Dutch word klocke which, in turn, derives from the medieval Latin word clocca, which ultimately derives from Celtic and is cognate with French, Latin, and German words that mean bell. The passage of the hours at sea was marked by bells and denoted the time (see ship's bell). The hours were marked by bells in abbeys as well as at sea.\n\nClocks can range from watches to more exotic varieties such as the Clock of the Long Now. They can be driven by a variety of means, including gravity, springs, and various forms of electrical power, and regulated by a variety of means such as a pendulum.\n\nAlarm clocks first appeared in ancient Greece around 250 BC with a water clock that would set off a whistle. This idea was later mechanized by Levi Hutchins and Seth E. Thomas.\n\nA chronometer is a portable timekeeper that meets certain precision standards. Initially, the term was used to refer to the marine chronometer, a timepiece used to determine longitude by means of celestial navigation, a precision firstly achieved by John Harrison. More recently, the term has also been applied to the chronometer watch, a watch that meets precision standards set by the Swiss agency COSC.\n\nThe most accurate timekeeping devices are atomic clocks, which are accurate to seconds in many millions of years, and are used to calibrate other clocks and timekeeping instruments.\n\nAtomic clocks use the frequency of electronic transitions in certain atoms to measure the second. One of the atoms used is caesium, most modern atomic clocks probe caesium with microwaves to determine the frequency of these electron vibrations. Since 1967, the International System of Measurements bases its unit of time, the second, on the properties of caesium atoms. SI defines the second as 9,192,631,770 cycles of the radiation that corresponds to the transition between two electron spin energy levels of the ground state of the 133Cs atom.\n\nToday, the Global Positioning System in coordination with the Network Time Protocol can be used to synchronize timekeeping systems across the globe.\n\nIn medieval philosophical writings, the atom was a unit of time referred to as the smallest possible division of time. The earliest known occurrence in English is in Byrhtferth's Enchiridion (a science text) of 1010\u20131012, where it was defined as 1/564 of a momentum (1\u00bd minutes), and thus equal to 15/94 of a second. It was used in the computus, the process of calculating the date of Easter.\n\n, the smallest time interval uncertainty in direct measurements is on the order of 12 attoseconds (1.2 \u00d7 10\u221217 seconds), about 3.7 \u00d7 1026 Planck times.\n\nUnits \n\nThe second (s) is the SI base unit. A minute (min) is 60 seconds in length, and an hour is 60 minutes or 3600 seconds in length. A day is usually 24 hours or 86,400 seconds in length; however, the duration of a calendar day can vary due to Daylight saving time and Leap seconds.\n\nDefinitions and standards  \n\nThe Mean Solar Time system defines the second as 1/86,400 of the mean solar day, which is the year-average of the solar day. The solar day is the time interval between two successive solar noons, i.e., the time interval between two successive passages of the Sun across the local meridian. The local meridian is an imaginary line that runs from celestial north pole to celestial south pole passing directly over the head of the observer. At the local meridian, the Sun reaches its highest point on its daily arc across the sky.\n\nIn 1874 the British Association for the Advancement of Science introduced the CGS (centimetre/gramme/second system) combining fundamental units of length, mass and time. The second is \"elastic\", because tidal friction is slowing the earth's rotation rate. For use in calculating ephemerides of celestial motion, therefore, in 1952 astronomers introduced the \"ephemeris second\", currently defined as\n\nThe CGS system has been superseded by the Syst\u00e8me international. The SI base unit for time is the SI second. The International System of Quantities, which incorporates the SI, also defines larger units of time equal to fixed integer multiples of one second (1 s), such as the minute, hour and day. These are not part of the SI, but may be used alongside the SI. Other units of time such as the month and the year are not equal to fixed multiples of 1 s, and instead exhibit significant variations in duration.\n\nThe official SI definition of the second is as follows:\n\nAt its 1997 meeting, the CIPM affirmed that this definition refers to a caesium atom in its ground state at a temperature of 0 K.\n\nThe current definition of the second, coupled with the current definition of the meter, is based on the special theory of relativity, which affirms our spacetime to be a Minkowski space. The definition of the second in mean solar time, however, is unchanged.\n\nUTC \n\nWhile in theory, the concept of a single worldwide universal time-scale may have been conceived of many centuries ago, in practicality the technical ability to create and maintain such a time-scale did not become possible until the mid-19th century. The timescale adopted was Greenwich Mean Time, created in 1847. A few countries have replaced it with Coordinated Universal Time, UTC.\n\nHistory of development \nWith the advent of the industrial revolution, a greater understanding and agreement on the nature of time itself became increasingly necessary and helpful. In 1847 in Britain, Greenwich Mean Time (GMT) was first created for use by the British railways, the British navy, and the British shipping industry. Using telescopes, GMT was calibrated to the mean solar time at the Royal Observatory, Greenwich in the UK.\n\nAs international commerce continued to increase throughout Europe, in order to achieve a more efficiently functioning modern society, an agreed-upon, and highly accurate international standard of time measurement became necessary. In order to find or determine such a time-standard, three steps had to be followed:\n An internationally agreed-upon time-standard had to be defined.\n This new time-standard then had to be consistently and accurately measured.\n The new time-standard then had to be freely shared and distributed around the world.\n\nThe development of what is now known as UTC time began as a collaboration between 41 nations, officially agreed and signed at the International Meridian Conference, in Washington D.C. in 1884. At this conference, the local mean solar time at the Royal Observatory, Greenwich in England was chosen to define the \"universal day\", counted from 0 hours at Greenwich mean midnight. This agreed with the civil Greenwich Mean Time used on the island of Great Britain since 1847. In contrast, astronomical GMT began at mean noon, i.e. astronomical day X began at noon of civil day X. The purpose of this was to keep one night's observations under one date. The civil system was adopted as of 0 hours (civil) 1 January 1925. Nautical GMT began 24 hours before astronomical GMT, at least until 1805 in the Royal Navy, but persisted much later elsewhere because it was mentioned at the 1884 conference. In 1884, the Greenwich meridian was used for two-thirds of all charts and maps as their Prime Meridian.\n\nAmong the 41 nations represented at the conference, the advanced time-technologies that had already come into use in Britain were fundamental components of the agreed method of arriving at a universal and agreed international time. In 1928 Greenwich Mean Time was rebranded for scientific purposes by the International Astronomical Union as Universal Time (UT). This was to avoid confusion with the previous system in which the day had begun at noon. As the general public had always begun the day at midnight, the timescale continued to be presented to them as Greenwich Mean Time. By 1956, universal time had been split into various versions: UT2, which smoothed for polar motion and seasonal effects, was presented to the public as Greenwich Mean Time. Later, UT1 (which smooths only for polar motion) became the default form of UT used by astronomers and hence the form used in navigation, sunrise and sunset and moonrise and moonset tables where the name Greenwich Mean Time continues to be employed. Greenwich Mean Time is also the preferred method of describing the timescale used by legislators. Even to the present day, UT is still based on an international telescopic system. Observations at the Greenwich Observatory itself ceased in 1954, though the location is still used as the basis for the coordinate system. Because the rotational period of Earth is not perfectly constant, the duration of a second would vary if calibrated to a telescope-based standard like GMT, where the second is defined as 1/86 400 of the mean solar day.\n\nUntil 1960, the methods and definitions of time-keeping that had been laid out at the International Meridian Conference proved to be adequate to meet the time tracking needs of science. Still, with the advent of the \"electronic revolution\" in the latter half of the 20th century, the technologies that had been available at the time of the Convention of the Metre proved to be in need of further refinement in order to meet the needs of the ever-increasing precision that the \"electronic revolution\" had begun to require.\n\nEphemeris second \nAn invariable second (the \"ephemeris second\") had been defined, use of which removed the errors in ephemerides resulting from the use of the variable mean solar second as the time argument. In 1960 this ephemeris second was made the basis of the \"coordinated universal time\" which was being derived from atomic clocks. It is a specified fraction of the mean tropical year as at 1900 and, being based on historical telescope observations, corresponds roughly to the mean solar second of the early nineteenth century.\n\nSI second \nIn 1967 a further step was taken with the introduction of the SI second, essentially the ephemeris second as measured by atomic clocks and formally defined in atomic terms.\nThe SI second (Standard Internationale second) is based directly on the measurement of the atomic-clock observation of the frequency oscillation of caesium atoms. It is the basis of all atomic timescales, e.g. coordinated universal time, GPS time, International Atomic Time, etc. Atomic clocks do not measure nuclear decay rates (a common misconception) but rather measure a certain natural vibrational frequency of caesium-133. Coordinated universal time is subject to one constraint which does not affect the other atomic timescales. As it has been adopted as the civil timescale by some countries (most countries have opted to retain mean solar time) it is not permitted to deviate from GMT by more than 0.9 second. This is achieved by the occasional insertion of a leap second.\n\nCurrent application \n\nMost countries use mean solar time. Australia, Canada (Quebec only), Colombia, France, Germany, New Zealand, Papua New Guinea (Bougainville only), Paraguay, Portugal, Switzerland, the United States and Venezuela use UTC. However, UTC is widely used by the scientific community in countries where mean solar time is official. UTC time is based on the SI second, which was first defined in 1967, and is based on the use of atomic clocks. Some other less used but closely related time-standards include International Atomic Time (TAI), Terrestrial Time, and Barycentric Dynamical Time.\n\nBetween 1967 and 1971, UTC was periodically adjusted by fractional amounts of a second in order to adjust and refine for variations in mean solar time, with which it is aligned. After 1 January 1972, UTC time has been defined as being offset from atomic time by a whole number of seconds, changing only when a leap second is added to keep radio-controlled clocks synchronized with the rotation of the Earth.\n\nThe Global Positioning System also broadcasts a very precise time signal worldwide, along with instructions for converting GPS time to UTC. GPS-time is based on, and regularly synchronized with or from, UTC-time.\n\nThe surface of the Earth is split up into a number of time zones. Most time zones are exactly one hour apart, and by convention compute their local time as an offset from GMT. For example, time zones at sea are based on GMT. In many locations (but not at sea) these offsets vary twice yearly due to daylight saving time transitions.\n\nConversions \nThese conversions are accurate at the millisecond level for time systems based on the rotation of the Earth (UT1 and TT). Conversions between atomic time systems (TAI, GPS, and UTC) are accurate at the microsecond level.\n\nDefinitions:\n LS = TAI \u2013 UTC = Leap Seconds from TAI to UTC\n DUT1 = UT1 \u2013 UTC from UT1 to UTC or http://maia.usno.navy.mil/search/search.html\n\nSidereality\n\nUnlike solar time, which is relative to the apparent position of the Sun, sidereal time is the measurement of time relative to that of a distant star. In astronomy, sidereal time is used to predict when a star will reach its highest point in the sky. Due to Earth's orbital motion around the Sun, a mean solar day is about 3 minutes 56 seconds longer than a mean sidereal day, or  more than a mean sidereal day.\n\nChronology \n\nAnother form of time measurement consists of studying the past. Events in the past can be ordered in a sequence (creating a chronology), and can be put into chronological groups (periodization). One of the most important systems of periodization is the geologic time scale, which is a system of periodizing the events that shaped the Earth and its life. Chronology, periodization, and interpretation of the past are together known as the study of history.\n\nTerminology \nThe term \"time\" is generally used for many close but different concepts, including:\n instant as an object\u00a0\u2013 one point on the time axes. Being an object, it has no value;\n date as a quantity characterising an instant. As a quantity, it has a value which may be expressed in a variety of ways, for example \"2014-04-26T09:42:36,75\" in ISO standard format, or more colloquially such as \"today, 9:42\u00a0a.m.\";\n time interval as an object\u00a0\u2013 part of the time axes limited by two instants. Being an object, it has no value;\n duration as a quantity characterizing a time interval. As a quantity, it has a value, such as a number of minutes, or may be described in terms of the quantities (such as times and dates) of its beginning and end.\n\nPhilosophy\n\nReligion\n\nLinear and cyclical \n\nAncient cultures such as Incan, Mayan, Hopi, and other Native American Tribes \u2013 plus the Babylonians, ancient Greeks, Hinduism, Buddhism, Jainism, and others \u2013 have a concept of a wheel of time: they regard time as cyclical and quantic, consisting of repeating ages that happen to every being of the Universe between birth and extinction.\n\nIn general, the Islamic and Judeo-Christian world-view regards time as linear\nand directional,\nbeginning with the act of creation by God. The traditional Christian view sees time ending, teleologically,\nwith the eschatological end of the present order of things, the \"end time\".\n\nIn the Old Testament book Ecclesiastes, traditionally ascribed to Solomon (970\u2013928 BC), time (as the Hebrew word \u05e2\u05d9\u05d3\u05df, \u05d6\u05de\u05df iddan (age, as in \"Ice age\") z\u0115man(time) is often translated) was traditionally regarded as a medium for the passage of predestined events. (Another word, \u0632\u0645\u0627\u0646\" \u05d6\u05de\u05df\" zam\u0101n, meant time fit for an event, and is used as the modern Arabic, Persian, and Hebrew equivalent to the English word \"time\".)\n\nTime in Greek mythology \nThe Greek language denotes two distinct principles, Chronos and Kairos. The former refers to numeric, or chronological, time. The latter, literally \"the right or opportune moment\", relates specifically to metaphysical or Divine time. In theology, Kairos is qualitative, as opposed to quantitative.\n\nIn Greek mythology, Chronos (ancient Greek: \u03a7\u03c1\u03cc\u03bd\u03bf\u03c2) is identified as the Personification of Time. His name in Greek means \"time\" and is alternatively spelled Chronus (Latin spelling) or Khronos. Chronos is usually portrayed as an old, wise man with a long, gray beard, such as \"Father Time\". Some English words whose etymological root is khronos/chronos include chronology, chronometer, chronic, anachronism, synchronise, and chronicle.\n\nTime in Kabbalah \nAccording to Kabbalists, \"time\" is a paradox and an illusion. Both the future and the past are recognised to be combined and simultaneously present.\n\nIn Western philosophy \n\nTwo contrasting viewpoints on time divide prominent philosophers. One view is that time is part of the fundamental structure of the universe\u00a0\u2013 a dimension independent of events, in which events occur in sequence. Isaac Newton subscribed to this realist view, and hence it is sometimes referred to as Newtonian time.\nThe opposing view is that time does not refer to any kind of \"container\" that events and objects \"move through\", nor to any entity that \"flows\", but that it is instead part of a fundamental intellectual structure (together with space and number) within which humans sequence and compare events. This second view, in the tradition of Gottfried Leibniz and Immanuel Kant, holds that time is neither an event nor a thing, and thus is not itself measurable nor can it be travelled.\n\nFurthermore, it may be that there is a subjective component to time, but whether or not time itself is \"felt\", as a sensation, or is a judgment, is a matter of debate.\n\nIn Philosophy, time was questioned throughout the centuries; what time is and if it is real or not. Ancient Greek philosophers asked if time was linear or cyclical and if time was endless or finite. These philosophers had different ways of explaining time; for instance, ancient Indian philosophers had something called the Wheel of Time. It is believed that there was repeating ages over the lifespan of the universe. This led to beliefs like cycles of rebirth and reincarnation. The Greek philosophers believe that the universe was infinite, and was an illusion to humans. Plato believed that time was made by the Creator at the same instant as the heavens. He also says that time is a period of motion of the heavenly bodies. Aristotle believed that time correlated to movement, that time did not exist on its own but was relative to motion of objects. he also believed that time was related to the motion of celestial bodies; the reason that humans can tell time was because of orbital periods and therefore there was a duration on time.\n\nThe Vedas, the earliest texts on Indian philosophy and Hindu philosophy dating back to the late 2nd millennium BC, describe ancient Hindu cosmology, in which the universe goes through repeated cycles of creation, destruction and rebirth, with each cycle lasting 4,320\u00a0million years.\nAncient Greek philosophers, including Parmenides and Heraclitus, wrote essays on the nature of time.\nPlato, in the Timaeus, identified time with the period of motion of the heavenly bodies. Aristotle, in Book IV of his Physica defined time as 'number of movement in respect of the before and after'.\n\nIn Book 11 of his Confessions, St. Augustine of Hippo ruminates on the nature of time, asking, \"What then is time? If no one asks me, I know: if I wish to explain it to one that asketh, I know not.\" He begins to define time by what it is not rather than what it is,\nan approach similar to that taken in other negative definitions. However, Augustine ends up calling time a \"distention\" of the mind (Confessions 11.26) by which we simultaneously grasp the past in memory, the present by attention, and the future by expectation.\n\nIsaac Newton believed in absolute space and absolute time; Leibniz believed that time and space are relational.\nThe differences between Leibniz's and Newton's interpretations came to a head in the famous Leibniz\u2013Clarke correspondence.\n\nPhilosophers in the 17th and 18th century questioned if time was real and absolute, or if it was an intellectual concept that humans use to understand and sequence events. These questions lead to realism vs anti-realism; the realists believed that time is a fundamental part of the universe, and be perceived by events happening in a sequence, in a dimension. Isaac Newton said that we are merely occupying time, he also says that humans can only understand relative time. Relative time is a measurement of objects in motion. The anti-realists believed that time is merely a convenient intellectual concept for humans to understand events. This means that time was useless unless there were objects that it could interact with, this was called relational time. Ren\u00e9 Descartes, John Locke, and David Hume said that one's mind needs to acknowledge time, in order to understand what time is. Immanuel Kant believed that we can not know what something is unless we experience it first hand.\n\nImmanuel Kant, in the Critique of Pure Reason, described time as an a priori intuition that allows us (together with the other a priori intuition, space) to comprehend sense experience.\nWith Kant, neither space nor time are conceived as substances, but rather both are elements of a systematic mental framework that necessarily structures the experiences of any rational agent, or observing subject. Kant thought of time as a fundamental part of an abstract conceptual framework, together with space and number, within which we sequence events, quantify their duration, and compare the motions of objects. In this view, time does not refer to any kind of entity that \"flows,\" that objects \"move through,\" or that is a \"container\" for events. Spatial measurements are used to quantify the extent of and distances between objects, and temporal measurements are used to quantify the durations of and between events. Time was designated by Kant as the purest possible schema of a pure concept or category.\n\nHenri Bergson believed that time was neither a real homogeneous medium nor a mental construct, but possesses what he referred to as Duration. Duration, in Bergson's view, was creativity and memory as an essential component of reality.\n\nAccording to Martin Heidegger we do not exist inside time, we are time. Hence, the relationship to the past is a present awareness of having been, which allows the past to exist in the present. The relationship to the future is the state of anticipating a potential possibility, task, or engagement. It is related to the human propensity for caring and being concerned, which causes \"being ahead of oneself\" when thinking of a pending occurrence. Therefore, this concern for a potential occurrence also allows the future to exist in the present. The present becomes an experience, which is qualitative instead of quantitative. Heidegger seems to think this is the way that a linear relationship with time, or temporal existence, is broken or transcended.\nWe are not stuck in sequential time. We are able to remember the past and project into the future\u00a0\u2013 we have a kind of random access to our representation of temporal existence; we can, in our thoughts, step out of (ecstasis) sequential time.\n\nModern era philosophers asked: is time real or unreal, is time happening all at once or a duration, If time tensed or tenseless, and is there a future to be? There is a theory called the tenseless or B-theory; this theory says that any tensed terminology can be replaced with tenseless terminology. For example, \"we will win the game\" can be replaced with \"we do win the game\", taking out the future tense. On the other hand, there is a theory called the tense or A-theory; this theory says that our language has tense verbs for a reason and that the future can not be determined. There is also something called imaginary time, this was from Stephen Hawking, he says that space and imaginary time are finite but have no boundaries. Imaginary time is not real or unreal, it is something that is hard to visualize. Philosophers can agree that physical time exists outside of the human mind and is objective, and psychological time is mind-dependent and subjective.\n\nUnreality \nIn 5th century BC Greece, Antiphon the Sophist, in a fragment preserved from his chief work On Truth, held that: \"Time is not a reality (hypostasis), but a concept (no\u00eama) or a measure (metron).\" Parmenides went further, maintaining that time, motion, and change were illusions, leading to the paradoxes of his follower Zeno. Time as an illusion is also a common theme in Buddhist thought.\n\nJ. M. E. McTaggart's 1908 The Unreality of Time argues that, since every event has the characteristic of being both present and not present (i.e., future or past), that time is a self-contradictory idea (see also The flow of time).\n\nThese arguments often center on what it means for something to be unreal. Modern physicists generally believe that time is as real as space\u00a0\u2013 though others, such as Julian Barbour in his book The End of Time, argue that quantum equations of the universe take their true form when expressed in the timeless realm containing every possible now or momentary configuration of the universe, called \"platonia\" by Barbour.\n\nA modern philosophical theory called presentism views the past and the future as human-mind interpretations of movement instead of real parts of time (or \"dimensions\") which coexist with the present. This theory rejects the existence of all direct interaction with the past or the future, holding only the present as tangible. This is one of the philosophical arguments against time travel. This contrasts with eternalism (all time: present, past and future, is real) and the growing block theory (the present and the past are real, but the future is not).\n\nPhysical definition \n\nUntil Einstein's reinterpretation of the physical concepts associated with time and space in 1907, time was considered to be the same everywhere in the universe, with all observers measuring the same time interval for any event.\nNon-relativistic classical mechanics is based on this Newtonian idea of time.\n\nEinstein, in his special theory of relativity,\npostulated the constancy and finiteness of the speed of light for all observers. He showed that this postulate, together with a reasonable definition for what it means for two events to be simultaneous, requires that distances appear compressed and time intervals appear lengthened for events associated with objects in motion relative to an inertial observer.\n\nThe theory of special relativity finds a convenient formulation in Minkowski spacetime, a mathematical structure that combines three dimensions of space with a single dimension of time. In this formalism, distances in space can be measured by how long light takes to travel that distance, e.g., a light-year is a measure of distance, and a meter is now defined in terms of how far light travels in a certain amount of time. Two events in Minkowski spacetime are separated by an invariant interval, which can be either space-like, light-like, or time-like. Events that have a time-like separation cannot be simultaneous in any frame of reference, there must be a temporal component (and possibly a spatial one) to their separation. Events that have a space-like separation will be simultaneous in some frame of reference, and there is no frame of reference in which they do not have a spatial separation. Different observers may calculate different distances and different time intervals between two events, but the invariant interval between the events is independent of the observer (and his or her velocity).\n\nClassical mechanics \nIn non-relativistic classical mechanics, Newton's concept of \"relative, apparent, and common time\" can be used in the formulation of a prescription for the synchronization of clocks. Events seen by two different observers in motion relative to each other produce a mathematical concept of time that works sufficiently well for describing the everyday phenomena of most people's experience. In the late nineteenth century, physicists encountered problems with the classical understanding of time, in connection with the behavior of electricity and magnetism. Einstein resolved these problems by invoking a method of synchronizing clocks using the constant, finite speed of light as the maximum signal velocity. This led directly to the conclusion that observers in motion relative to one another measure different elapsed times for the same event.\n\nSpacetime \n\nTime has historically been closely related with space, the two together merging into spacetime in Einstein's special relativity and general relativity. According to these theories, the concept of time depends on the spatial reference frame of the observer, and the human perception, as well as the measurement by instruments such as clocks, are different for observers in relative motion. For example, if a spaceship carrying a clock flies through space at (very nearly) the speed of light, its crew does not notice a change in the speed of time on board their vessel because everything traveling at the same speed slows down at the same rate (including the clock, the crew's thought processes, and the functions of their bodies). However, to a stationary observer watching the spaceship fly by, the spaceship appears flattened in the direction it is traveling and the clock on board the spaceship appears to move very slowly.\n\nOn the other hand, the crew on board the spaceship also perceives the observer as slowed down and flattened along the spaceship's direction of travel, because both are moving at very nearly the speed of light relative to each other. Because the outside universe appears flattened to the spaceship, the crew perceives themselves as quickly traveling between regions of space that (to the stationary observer) are many light years apart. This is reconciled by the fact that the crew's perception of time is different from the stationary observer's; what seems like seconds to the crew might be hundreds of years to the stationary observer. In either case, however, causality remains unchanged: the past is the set of events that can send light signals to an entity and the future is the set of events to which an entity can send light signals.\n\nDilation \n\nEinstein showed in his thought experiments that people travelling at different speeds, while agreeing on cause and effect, measure different time separations between events, and can even observe different chronological orderings between non-causally related events. Though these effects are typically minute in the human experience, the effect becomes much more pronounced for objects moving at speeds approaching the speed of light. Subatomic particles exist for a well-known average fraction of a second in a lab relatively at rest, but when travelling close to the speed of light they are measured to travel farther and exist for much longer than when at rest. According to the special theory of relativity, in the high-speed particle's frame of reference, it exists, on the average, for a standard amount of time known as its mean lifetime, and the distance it travels in that time is zero, because its velocity is zero. Relative to a frame of reference at rest, time seems to \"slow down\" for the particle. Relative to the high-speed particle, distances seem to shorten. Einstein showed how both temporal and spatial dimensions can be altered (or \"warped\") by high-speed motion.\n\nEinstein (The Meaning of Relativity): \"Two events taking place at the points A and B of a system K are simultaneous if they appear at the same instant when observed from the middle point, M, of the interval AB. Time is then defined as the ensemble of the indications of similar clocks, at rest relative to K, which register the same simultaneously.\"\n\nEinstein wrote in his book, Relativity, that simultaneity is also relative, i.e., two events that appear simultaneous to an observer in a particular inertial reference frame need not be judged as simultaneous by a second observer in a different inertial frame of reference.\n\nRelativistic versus Newtonian \n\nThe animations visualise the different treatments of time in the Newtonian and the relativistic descriptions. At the heart of these differences are the Galilean and Lorentz transformations applicable in the Newtonian and relativistic theories, respectively.\n\nIn the figures, the vertical direction indicates time. The horizontal direction indicates distance (only one spatial dimension is taken into account), and the thick dashed curve is the spacetime trajectory (\"world line\") of the observer. The small dots indicate specific (past and future) events in spacetime.\n\nThe slope of the world line (deviation from being vertical) gives the relative velocity to the observer. Note how in both pictures the view of spacetime changes when the observer accelerates.\n\nIn the Newtonian description these changes are such that time is absolute: the movements of the observer do not influence whether an event occurs in the 'now' (i.e., whether an event passes the horizontal line through the observer).\n\nHowever, in the relativistic description the observability of events is absolute: the movements of the observer do not influence whether an event passes the \"light cone\" of the observer. Notice that with the change from a Newtonian to a relativistic description, the concept of absolute time is no longer applicable: events move up and down in the figure depending on the acceleration of the observer.\n\nArrow \n\nTime appears to have a direction\u00a0\u2013 the past lies behind, fixed and immutable, while the future lies ahead and is not necessarily fixed. Yet for the most part, the laws of physics do not specify an arrow of time, and allow any process to proceed both forward and in reverse. This is generally a consequence of time being modelled by a parameter in the system being analysed, where there is no \"proper time\": the direction of the arrow of time is sometimes arbitrary. Examples of this include the cosmological arrow of time, which points away from the Big Bang, CPT symmetry, and the radiative arrow of time, caused by light only travelling forwards in time (see light cone). In particle physics, the violation of CP symmetry implies that there should be a small counterbalancing time asymmetry to preserve CPT symmetry as stated above. The standard description of measurement in quantum mechanics is also time asymmetric (see Measurement in quantum mechanics). The second law of thermodynamics states that entropy must increase over time (see Entropy). This can be in either direction \u2013 Brian Greene theorizes that, according to the equations, the change in entropy occurs symmetrically whether going forward or backward in time. So entropy tends to increase in either direction, and our current low-entropy universe is a statistical aberration, in a similar manner as tossing a coin often enough that eventually heads will result ten times in a row. However, this theory is not supported empirically in local experiment.\n\nQuantization \n\nTime quantization is a hypothetical concept. In the modern established physical theories (the Standard Model of Particles and Interactions and General Relativity) time is not quantized.\n\nPlanck time (~ 5.4 \u00d7 10\u221244 seconds) is the unit of time in the system of natural units known as Planck units. Current established physical theories are believed to fail at this time scale, and many physicists expect that the Planck time might be the smallest unit of time that could ever be measured, even in principle. Tentative physical theories that describe this time scale exist; see for instance loop quantum gravity.\n\nTravel \n\nTime travel is the concept of moving backwards or forwards to different points in time, in a manner analogous to moving through space, and different from the normal \"flow\" of time to an earthbound observer. In this view, all points in time (including future times) \"persist\" in some way. Time travel has been a plot device in fiction since the 19th century. Travelling backwards or forwards in time has never been verified as a process, and doing so presents many theoretical problems and contradictive logic which to date have not been overcome. Any technological device, whether fictional or hypothetical, that is used to achieve time travel is known as a time machine.\n\nA central problem with time travel to the past is the violation of causality; should an effect precede its cause, it would give rise to the possibility of a temporal paradox. Some interpretations of time travel resolve this by accepting the possibility of travel between branch points, parallel realities, or universes.\n\nAnother solution to the problem of causality-based temporal paradoxes is that such paradoxes cannot arise simply because they have not arisen. As illustrated in numerous works of fiction, free will either ceases to exist in the past or the outcomes of such decisions are predetermined. As such, it would not be possible to enact the grandfather paradox because it is a historical fact that one's grandfather was not killed before his child (one's parent) was conceived. This view does not simply hold that history is an unchangeable constant, but that any change made by a hypothetical future time traveller would already have happened in his or her past, resulting in the reality that the traveller moves from. More elaboration on this view can be found in the Novikov self-consistency principle.\n\nPerception \n\nThe specious present refers to the time duration wherein one's perceptions are considered to be in the present. The experienced present is said to be 'specious' in that, unlike the objective present, it is an interval and not a durationless instant. The term specious present was first introduced by the psychologist E.R. Clay, and later developed by William James.\n\nBiopsychology \nThe brain's judgment of time is known to be a highly distributed system, including at least the cerebral cortex, cerebellum and basal ganglia as its components. One particular component, the suprachiasmatic nuclei, is responsible for the circadian (or daily) rhythm, while other cell clusters appear capable of shorter-range (ultradian) timekeeping.\n\nPsychoactive drugs can impair the judgment of time. Stimulants can lead both humans and rats to overestimate time intervals, while depressants can have the opposite effect. The level of activity in the brain of neurotransmitters such as dopamine and norepinephrine may be the reason for this. Such chemicals will either excite or inhibit the firing of neurons in the brain, with a greater firing rate allowing the brain to register the occurrence of more events within a given interval (speed up time) and a decreased firing rate reducing the brain's capacity to distinguish events occurring within a given interval (slow down time).\n\nMental chronometry is the use of response time in perceptual-motor tasks to infer the content, duration, and temporal sequencing of cognitive operations.\n\nEarly childhood education \nChildren's expanding cognitive abilities allow them to understand time more clearly. Two- and three-year-olds' understanding of time is mainly limited to \"now and not now\". Five- and six-year-olds can grasp the ideas of past, present, and future. Seven- to ten-year-olds can use clocks and calendars.\n\nAlterations \nIn addition to psychoactive drugs, judgments of time can be altered by temporal illusions (like the kappa effect), age, and hypnosis. The sense of time is impaired in some people with neurological diseases such as Parkinson's disease and attention deficit disorder.\n\nPsychologists assert that time seems to go faster with age, but the literature on this age-related perception of time remains controversial. Those who support this notion argue that young people, having more excitatory neurotransmitters, are able to cope with faster external events.\n\nSpatial conceptualization \nAlthough time is regarded as an abstract concept, there is increasing evidence that time is conceptualized in the mind in terms of space. That is, instead of thinking about time in a general, abstract way, humans think about time in a spatial way and mentally organize it as such. Using space to think about time allows humans to mentally organize temporal events in a specific way.\n\nThis spatial representation of time is often represented in the mind as a Mental Time Line (MTL). Using space to think about time allows humans to mentally organize temporal order. These origins are shaped by many environmental factors\u2013\u2013for example, literacy appears to play a large role in the different types of MTLs, as reading/writing direction provides an everyday temporal orientation that differs from culture to culture. In western cultures, the MTL may unfold rightward (with the past on the left and the future on the right) since people read and write from left to right. Western calendars also continue this trend by placing the past on the left with the future progressing toward the right. Conversely, Arabic, Farsi, Urdu and Israeli-Hebrew speakers read from right to left, and their MTLs unfold leftward (past on the right with future on the left), and evidence suggests these speakers organize time events in their minds like this as well.\n\nThis linguistic evidence that abstract concepts are based in spatial concepts also reveals that the way humans mentally organize time events varies across cultures\u2013\u2013that is, a certain specific mental organization system is not universal. So, although Western cultures typically associate past events with the left and future events with the right according to a certain MTL, this kind of horizontal, egocentric MTL is not the spatial organization of all cultures. Although most developed nations use an egocentric spatial system, there is recent evidence that some cultures use an allocentric spatialization, often based on environmental features.\n\nA recent study of the indigenous Yupno people of Papua New Guinea focused on the directional gestures used when individuals used time-related words. When speaking of the past (such as \"last year\" or \"past times\"), individuals gestured downhill, where the river of the valley flowed into the ocean. When speaking of the future, they gestured uphill, toward the source of the river. This was common regardless of which direction the person faced, revealing that the Yupno people may use an allocentric MTL, in which time flows uphill.\n\nA similar study of the Pormpuraawans, an aboriginal group in Australia, revealed a similar distinction in which when asked to organize photos of a man aging \"in order,\" individuals consistently placed the youngest photos to the east and the oldest photos to the west, regardless of which direction they faced. This directly clashed with an American group that consistently organized the photos from left to right. Therefore, this group also appears to have an allocentric MTL, but based on the cardinal directions instead of geographical features.\n\nThe wide array of distinctions in the way different groups think about time leads to the broader question that different groups may also think about other abstract concepts in different ways as well, such as causality and number.\n\nUse \n\nIn sociology and anthropology, time discipline is the general name given to social and economic rules, conventions, customs, and expectations governing the measurement of time, the social currency and awareness of time measurements, and people's expectations concerning the observance of these customs by others. Arlie Russell Hochschild and Norbert Elias have written on the use of time from a sociological perspective.\n\nThe use of time is an important issue in understanding human behavior, education, and travel behavior. Time-use research is a developing field of study. The question concerns how time is allocated across a number of activities (such as time spent at home, at work, shopping, etc.). Time use changes with technology, as the television or the Internet created new opportunities to use time in different ways. However, some aspects of time use are relatively stable over long periods of time, such as the amount of time spent traveling to work, which despite major changes in transport, has been observed to be about 20\u201330 minutes one-way for a large number of cities over a long period.\n\nTime management is the organization of tasks or events by first estimating how much time a task requires and when it must be completed, and adjusting events that would interfere with its completion so it is done in the appropriate amount of time. Calendars and day planners are common examples of time management tools.\n\nSequence of events \nA sequence of events, or series of events, is a sequence of items, facts, events, actions, changes, or procedural steps, arranged in time order (chronological order), often with causality relationships among the items.\nBecause of causality, cause precedes effect, or cause and effect may appear together in a single item, but effect never precedes cause. A sequence of events can be presented in text, tables, charts, or timelines. The description of the items or events may include a timestamp. A sequence of events that includes the time along with place or location information to describe a sequential path may be referred to as a world line.\n\nUses of a sequence of events include stories,\nhistorical events (chronology), directions and steps in procedures,\nand timetables for scheduling activities. A sequence of events may also be used to help describe processes in science, technology, and medicine. A sequence of events may be focused on past events (e.g., stories, history, chronology), on future events that must be in a predetermined order (e.g., plans, schedules, procedures, timetables), or focused on the observation of past events with the expectation that the events will occur in the future (e.g., processes, projections). The use of a sequence of events occurs in fields as diverse as machines (cam timer), documentaries (Seconds From Disaster), law (choice of law), finance (directional-change intrinsic time), computer simulation (discrete event simulation), and electric power transmission\n(sequence of events recorder). A specific example of a sequence of events is the timeline of the Fukushima Daiichi nuclear disaster.\n\nSee also \n List of UTC timing centers\n Time metrology\n\nOrganizations \n Antiquarian Horological Society\u00a0\u2013 AHS (United Kingdom)\n Chronometrophilia (Switzerland)\n Deutsche Gesellschaft f\u00fcr Chronometrie\u00a0\u2013 DGC (Germany)\n National Association of Watch and Clock Collectors\u00a0\u2013 NAWCC (United States)\n\nMiscellaneous arts and sciences \n Date and time representation by country\n List of cycles\n Nonlinear narrative\n Philosophy of physics\n Rate (mathematics)\n\nMiscellaneous units\n Fiscal year\n Half-life\n Hexadecimal time\n Tithi\n Unix epoch\n\nReferences\n\nFurther reading \n \n Craig Callendar, Introducing Time, Icon Books, 2010, \n  \u2013 Research bibliography\n \n \n \n Benjamin Gal-Or, Cosmology, Physics and Philosophy, Springer Verlag, 1981, 1983, 1987, .\n Charlie Gere, (2005) Art, Time and Technology: Histories of the Disappearing Body, Berg\n \n \n \n \n \n \n \n \n \n \n Stiegler, Bernard, Technics and Time, 1: The Fault of Epimetheus\n Roberto Mangabeira Unger and Lee Smolin, The Singular Universe and the Reality of Time, Cambridge University Press, 2014, .\n\nExternal links \n\n Different systems of measuring time\n \n Time in the Internet Encyclopedia of Philosophy, by Bradley Dowden.\n \n\n \nMain topic articles\nConcepts in aesthetics\nConcepts in epistemology\nConcepts in metaphysics\nConcepts in the philosophy of mind\nConcepts in the philosophy of science\nMetaphysical theories\nOntology\nPerception\nPhilosophy of time\nPhysical phenomena\nQualia\nReality\nScalar physical quantities\nSI base quantities\nSpacetime",
  "Universe": "The universe () is all of space and time and their contents, including planets, stars, galaxies, and all other forms of matter and energy. The Big Bang theory is the prevailing cosmological description of the development of the universe. According to this theory, space and time emerged together  ago, and the universe has been expanding ever since. While the spatial size of the entire universe is unknown, the cosmic inflation equation indicates that it must have a minimum diameter of 23 trillion light years, and it is possible to measure the size of the observable universe, which is approximately 93 billion light-years in diameter at the present day.\n\nThe earliest cosmological models of the universe were developed by ancient Greek and Indian philosophers and were geocentric, placing Earth at the center. Over the centuries, more precise astronomical observations led Nicolaus Copernicus to develop the heliocentric model with the Sun at the center of the Solar System. In developing the law of universal gravitation, Isaac Newton built upon Copernicus's work as well as Johannes Kepler's laws of planetary motion and observations by Tycho Brahe.\n\nFurther observational improvements led to the realization that the Sun is one of hundreds of billions of stars in the Milky Way, which is one of a few hundred billion galaxies in the universe. Many of the stars in a galaxy have planets. At the largest scale, galaxies are distributed uniformly and the same in all directions, meaning that the universe has neither an edge nor a center. At smaller scales, galaxies are distributed in clusters and superclusters which form immense filaments and voids in space, creating a vast foam-like structure. Discoveries in the early 20th century have suggested that the universe had a beginning and that space has been expanding since then at an increasing rate.\n\nAccording to the Big Bang theory, the energy and matter initially present have become less dense as the universe expanded. After an initial accelerated expansion called the inflationary epoch at around 10\u221232 seconds, and the separation of the four known fundamental forces, the universe gradually cooled and continued to expand, allowing the first subatomic particles and simple atoms to form. Dark matter gradually gathered, forming a foam-like structure of filaments and voids under the influence of gravity. Giant clouds of hydrogen and helium were gradually drawn to the places where dark matter was most dense, forming the first galaxies, stars, and everything else seen today.\n\nFrom studying the movement of galaxies, it has been discovered that the universe contains much more matter than is accounted for by visible objects; stars, galaxies, nebulas and interstellar gas. This unseen matter is known as dark matter (dark means that there is a wide range of strong indirect evidence that it exists, but we have not yet detected it directly). The \u039bCDM model is the most widely accepted model of the universe. It suggests that about  [2015] of the mass and energy in the universe is a cosmological constant (or, in extensions to \u039bCDM, other forms of dark energy, such as a scalar field) which is responsible for the current expansion of space, and about  [2015] is dark matter. Ordinary ('baryonic') matter is therefore only  [2015] of the physical universe. Stars, planets, and visible gas clouds only form about 6% of the ordinary matter.\n\nThere are many competing hypotheses about the ultimate fate of the universe and about what, if anything, preceded the Big Bang, while other physicists and philosophers refuse to speculate, doubting that information about prior states will ever be accessible. Some physicists have suggested various multiverse hypotheses, in which our universe might be one among many universes that likewise exist.\n\nDefinition \n\nThe physical universe is defined as all of space and time (collectively referred to as spacetime) and their contents. Such contents comprise all of energy in its various forms, including electromagnetic radiation and matter, and therefore planets, moons, stars, galaxies, and the contents of intergalactic space. The universe also includes the physical laws that influence energy and matter, such as conservation laws, classical mechanics, and relativity.\n\nThe universe is often defined as \"the totality of existence\", or everything that exists, everything that has existed, and everything that will exist. In fact, some philosophers and scientists support the inclusion of ideas and abstract concepts\u2014such as mathematics and logic\u2014in the definition of the universe. The word universe may also refer to concepts such as the cosmos, the world, and nature.\n\nEtymology \nThe word universe derives from the Old French word , which in turn derives from the Latin word . The Latin word was used by Cicero and later Latin authors in many of the same senses as the modern English word is used.\n\nSynonyms \nA term for universe among the ancient Greek philosophers from Pythagoras onwards was  () 'the all', defined as all matter and all space, and  () 'all things', which did not necessarily include the void. Another synonym was  () meaning 'the world, the cosmos'. Synonyms are also found in Latin authors (, , ) and survive in modern languages, e.g., the German words , , and  for universe. The same synonyms are found in English, such as everything (as in the theory of everything), the cosmos (as in cosmology), the world (as in the many-worlds interpretation), and nature (as in natural laws or natural philosophy).\n\nChronology and the Big Bang \n\nThe prevailing model for the evolution of the universe is the Big Bang theory. The Big Bang model states that the earliest state of the universe was an extremely hot and dense one, and that the universe subsequently expanded and cooled. The model is based on general relativity and on simplifying assumptions such as the homogeneity and isotropy of space. A version of the model with a cosmological constant (Lambda) and cold dark matter, known as the Lambda-CDM model, is the simplest model that provides a reasonably good account of various observations about the universe. The Big Bang model accounts for observations such as the correlation of distance and redshift of galaxies, the ratio of the number of hydrogen to helium atoms, and the microwave radiation background.\n\nThe initial hot, dense state is called the Planck epoch, a brief period extending from time zero to one Planck time unit of approximately 10\u221243 seconds. During the Planck epoch, all types of matter and all types of energy were concentrated into a dense state, and gravity\u2014currently the weakest by far of the four known forces\u2014is believed to have been as strong as the other fundamental forces, and all the forces may have been unified. Since the Planck epoch, space has been expanding to its present scale, with a very short but intense period of cosmic inflation believed to have occurred within the first 10\u221232 seconds. This was a kind of expansion different from those we can see around us today. Objects in space did not physically move; instead the metric that defines space itself changed. Although objects in spacetime cannot move faster than the speed of light, this limitation does not apply to the metric governing spacetime itself. This initial period of inflation is believed to explain why space appears to be very flat, and much larger than light could travel since the start of the universe.\n\nWithin the first fraction of a second of the universe's existence, the four fundamental forces had separated. As the universe continued to cool down from its inconceivably hot state, various types of subatomic particles were able to form in short periods of time known as the quark epoch, the hadron epoch, and the lepton epoch. Together, these epochs encompassed less than 10 seconds of time following the Big Bang. These elementary particles associated stably into ever larger combinations, including stable protons and neutrons, which then formed more complex atomic nuclei through nuclear fusion. This process, known as Big Bang nucleosynthesis, only lasted for about 17 minutes and ended about 20 minutes after the Big Bang, so only the fastest and simplest reactions occurred. About 25% of the protons and all the neutrons in the universe, by mass, were converted to helium, with small amounts of deuterium (a form of hydrogen) and traces of lithium. Any other element was only formed in very tiny quantities. The other 75% of the protons remained unaffected, as hydrogen nuclei.\n\nAfter nucleosynthesis ended, the universe entered a period known as the photon epoch. During this period, the universe was still far too hot for matter to form neutral atoms, so it contained a hot, dense, foggy plasma of negatively charged electrons, neutral neutrinos and positive nuclei. After about 377,000 years, the universe had cooled enough that electrons and nuclei could form the first stable atoms. This is known as recombination for historical reasons; in fact electrons and nuclei were combining for the first time. Unlike plasma, neutral atoms are transparent to many wavelengths of light, so for the first time the universe also became transparent. The photons released (\"decoupled\") when these atoms formed can still be seen today; they form the cosmic microwave background (CMB).\n\nAs the universe expands, the energy density of electromagnetic radiation decreases more quickly than does that of matter because the energy of a photon decreases with its wavelength. At around 47,000 years, the energy density of matter became larger than that of photons and neutrinos, and began to dominate the large scale behavior of the universe. This marked the end of the radiation-dominated era and the start of the matter-dominated era.\n\nIn the earliest stages of the universe, tiny fluctuations within the universe's density led to concentrations of dark matter gradually forming. Ordinary matter, attracted to these by gravity, formed large gas clouds and eventually, stars and galaxies, where the dark matter was most dense, and voids where it was least dense. After around 100 - 300 million years, the first stars formed, known as Population III stars. These were probably very massive, luminous, non metallic and short-lived. They were responsible for the gradual reionization of the universe between about 200-500 million years and 1 billion years, and also for seeding the universe with elements heavier than helium, through stellar nucleosynthesis. The universe also contains a mysterious energy\u2014possibly a scalar field\u2014called dark energy, the density of which does not change over time. After about 9.8 billion years, the universe had expanded sufficiently so that the density of matter was less than the density of dark energy, marking the beginning of the present dark-energy-dominated era. In this era, the expansion of the universe is accelerating due to dark energy.\n\nPhysical properties \n\nOf the four fundamental interactions, gravitation is the dominant at astronomical length scales. Gravity's effects are cumulative; by contrast, the effects of positive and negative charges tend to cancel one another, making electromagnetism relatively insignificant on astronomical length scales. The remaining two interactions, the weak and strong nuclear forces, decline very rapidly with distance; their effects are confined mainly to sub-atomic length scales.\n\nThe universe appears to have much more matter than antimatter, an asymmetry possibly related to the CP violation. This imbalance between matter and antimatter is partially responsible for the existence of all matter existing today, since matter and antimatter, if equally produced at the Big Bang, would have completely annihilated each other and left only photons as a result of their interaction. The universe also appears to have neither net momentum nor angular momentum, which follows accepted physical laws if the universe is finite. These laws are Gauss's law and the non-divergence of the stress-energy-momentum pseudotensor.\n\nSize and regions \n\nAccording to the general theory of relativity, far regions of space may never interact with ours even in the lifetime of the universe due to the finite speed of light and the ongoing expansion of space. For example, radio messages sent from Earth may never reach some regions of space, even if the universe were to exist forever: space may expand faster than light can traverse it.\n\nThe spatial region that can be observed with telescopes is called the observable universe, which depends on the location of the observer.\nThe proper distance\u2014the distance as would be measured at a specific time, including the present\u2014between Earth and the edge of the observable universe is 46 billion light-years (14 billion parsecs), making the diameter of the observable universe about 93 billion light-years (28 billion parsecs). The distance the light from the edge of the observable universe has travelled is very close to the age of the universe times the speed of light, , but this does not represent the distance at any given time because the edge of the observable universe and the Earth have since moved further apart. For comparison, the diameter of a typical galaxy is 30,000 light-years (9,198 parsecs), and the typical distance between two neighboring galaxies is 3 million light-years (919.8 kiloparsecs). As an example, the Milky Way is roughly 100,000\u2013180,000 light-years in diameter, and the nearest sister galaxy to the Milky Way, the Andromeda Galaxy, is located roughly 2.5 million light-years away.\n\nBecause we cannot observe space beyond the edge of the observable universe, it is unknown whether the size of the universe in its totality is finite or infinite. Estimates suggest that the whole universe, if finite, must be more than 250 times larger than the observable universe. Some disputed estimates for the total size of the universe, if finite, reach as high as  megaparsecs, as implied by a suggested resolution of the No-Boundary Proposal.\n\nAge and expansion \n\nAstronomers calculate the age of the universe by assuming that the Lambda-CDM model accurately describes the evolution of the Universe from a very uniform, hot, dense primordial state to its present state and measuring the cosmological parameters which constitute the model. This model is well understood theoretically and supported by recent high-precision astronomical observations such as WMAP and Planck. Commonly, the set of observations fitted includes the cosmic microwave background anisotropy, the brightness/redshift relation for Type Ia supernovae, and large-scale galaxy clustering including the baryon acoustic oscillation feature. Other observations, such as the Hubble constant, the abundance of galaxy clusters, weak gravitational lensing and globular cluster ages, are generally consistent with these, providing a check of the model, but are less accurately measured at present. Assuming that the Lambda-CDM model is correct, the measurements of the parameters using a variety of techniques by numerous experiments yield a best value of the age of the universe as of 2015 of 13.799 \u00b1 0.021 billion years.\n\nOver time, the universe and its contents have evolved; for example, the relative population of quasars and galaxies has changed and space itself has expanded. Due to this expansion, scientists on Earth can observe the light from a galaxy 30 billion light-years away even though that light has traveled for only 13 billion years; the very space between them has expanded. This expansion is consistent with the observation that the light from distant galaxies has been redshifted; the photons emitted have been stretched to longer wavelengths and lower frequency during their journey. Analyses of Type Ia supernovae indicate that the spatial expansion is accelerating.\n\nThe more matter there is in the universe, the stronger the mutual gravitational pull of the matter. If the universe were too dense then it would re-collapse into a gravitational singularity. However, if the universe contained too little matter then the self-gravity would be too weak for astronomical structures, like galaxies or planets, to form. Since the Big Bang, the universe has expanded monotonically. Perhaps unsurprisingly, our universe has just the right mass-energy density, equivalent to about 5 protons per cubic metre, which has allowed it to expand for the last 13.8 billion years, giving time to form the universe as observed today.\n\nThere are dynamical forces acting on the particles in the universe which affect the expansion rate. Before 1998, it was expected that the expansion rate would be decreasing as time went on due to the influence of gravitational interactions in the universe; and thus there is an additional observable quantity in the universe called the deceleration parameter, which most cosmologists expected to be positive and related to the matter density of the universe. In 1998, the deceleration parameter was measured by two different groups to be negative, approximately -0.55, which technically implies that the second derivative of the cosmic scale factor  has been positive in the last 5-6 billion years. This acceleration does not, however, imply that the Hubble parameter is currently increasing; see deceleration parameter for details.\n\nSpacetime \n\nSpacetimes are the arenas in which all physical events take place. The basic elements of spacetimes are events. In any given spacetime, an event is defined as a unique position at a unique time. A spacetime is the union of all events (in the same way that a line is the union of all of its points), formally organized into a manifold.\n\nEvents, such as matter and energy, bend spacetime. Curved spacetime, on the other hand, forces matter and energy to behave in a certain way. There is no point in considering one without the other.\n\nThe universe appears to be a smooth spacetime continuum consisting of three spatial dimensions and one temporal (time) dimension (an event in the spacetime of the physical universe can therefore be identified by a set of four coordinates: (x, y, z, t) ). On average, space is observed to be very nearly flat (with a curvature close to zero), meaning that Euclidean geometry is empirically true with high accuracy throughout most of the Universe. Spacetime also appears to have a simply connected topology, in analogy with a sphere, at least on the length-scale of the observable universe. However, present observations cannot exclude the possibilities that the universe has more dimensions (which is postulated by theories such as the string theory) and that its spacetime may have a multiply connected global topology, in analogy with the cylindrical or toroidal topologies of two-dimensional spaces. The spacetime of the universe is usually interpreted from a Euclidean perspective, with space as consisting of three dimensions, and time as consisting of one dimension, the \"fourth dimension\". By combining space and time into a single manifold called Minkowski space, physicists have simplified a large number of physical theories, as well as described in a more uniform way the workings of the universe at both the supergalactic and subatomic levels.\n\nSpacetime events are not absolutely defined spatially and temporally but rather are known to be relative to the motion of an observer. Minkowski space approximates the universe without gravity; the pseudo-Riemannian manifolds of general relativity describe spacetime with matter and gravity.\n\nShape \n\nGeneral relativity describes how spacetime is curved and bent by mass and energy (gravity). The topology or geometry of the universe includes both local geometry in the observable universe and global geometry. Cosmologists often work with a given space-like slice of spacetime called the comoving coordinates. The section of spacetime which can be observed is the backward light cone, which delimits the cosmological horizon. The cosmological horizon (also called the particle horizon or the light horizon) is the maximum distance from which particles can have traveled to the observer in the age of the universe. This horizon represents the boundary between the observable and the unobservable regions of the universe. The existence, properties, and significance of a cosmological horizon depend on the particular cosmological model.\n\nAn important parameter determining the future evolution of the universe theory is the density parameter, Omega (\u03a9), defined as the average matter density of the universe divided by a critical value of that density. This selects one of three possible geometries depending on whether \u03a9 is equal to, less than, or greater than 1. These are called, respectively, the flat, open and closed universes.\n\nObservations, including the Cosmic Background Explorer (COBE), Wilkinson Microwave Anisotropy Probe (WMAP), and Planck maps of the CMB, suggest that the universe is infinite in extent with a finite age, as described by the Friedmann\u2013Lema\u00eetre\u2013Robertson\u2013Walker (FLRW) models. These FLRW models thus support inflationary models and the standard model of cosmology, describing a flat, homogeneous universe presently dominated by dark matter and dark energy.\n\nSupport of life \n\nThe universe may be fine-tuned; the Fine-tuned universe hypothesis is the proposition that the conditions that allow the existence of observable life in the universe can only occur when certain universal fundamental physical constants lie within a very narrow range of values, so that if any of several fundamental constants were only slightly different, the universe would have been unlikely to be conducive to the establishment and development of matter, astronomical structures, elemental diversity, or life as it is understood. The proposition is discussed among philosophers, scientists, theologians, and proponents of creationism.\n\nComposition \n\nThe universe is composed almost completely of dark energy, dark matter, and ordinary matter. Other contents are electromagnetic radiation (estimated to constitute from 0.005% to close to 0.01% of the total mass-energy of the universe) and antimatter.\n\nThe proportions of all types of matter and energy have changed over the history of the universe. The total amount of electromagnetic radiation generated within the universe has decreased by 1/2 in the past 2 billion years. Today, ordinary matter, which includes atoms, stars, galaxies, and life, accounts for only 4.9% of the contents of the Universe. The present overall density of this type of matter is very low, roughly 4.5 \u00d7 10\u221231 grams per cubic centimetre, corresponding to a density of the order of only one proton for every four cubic metres of volume. The nature of both dark energy and dark matter is unknown. Dark matter, a mysterious form of matter that has not yet been identified, accounts for 26.8% of the cosmic contents. Dark energy, which is the energy of empty space and is causing the expansion of the universe to accelerate, accounts for the remaining 68.3% of the contents.\n\nMatter, dark matter, and dark energy are distributed homogeneously throughout the universe over length scales longer than 300 million light-years or so. However, over shorter length-scales, matter tends to clump hierarchically; many atoms are condensed into stars, most stars into galaxies, most galaxies into clusters, superclusters and, finally, large-scale galactic filaments. The observable universe contains as many as 200 billion galaxies and, overall, as many as an estimated  stars (more stars than all the grains of sand on planet Earth). Typical galaxies range from dwarfs with as few as ten million (107) stars up to giants with one trillion (1012) stars. Between the larger structures are voids, which are typically 10\u2013150 Mpc (33 million\u2013490 million ly) in diameter. The Milky Way is in the Local Group of galaxies, which in turn is in the Laniakea Supercluster. This supercluster spans over 500 million light-years, while the Local Group spans over 10 million light-years. The Universe also has vast regions of relative emptiness; the largest known void measures 1.8 billion ly (550 Mpc) across.\n\nThe observable universe is isotropic on scales significantly larger than superclusters, meaning that the statistical properties of the universe are the same in all directions as observed from Earth. The universe is bathed in highly isotropic microwave radiation that corresponds to a thermal equilibrium blackbody spectrum of roughly 2.72548 kelvins. The hypothesis that the large-scale universe is homogeneous and isotropic is known as the cosmological principle. A universe that is both homogeneous and isotropic looks the same from all vantage points and has no center.\n\nDark energy \n\nAn explanation for why the expansion of the universe is accelerating remains elusive. It is often attributed to \"dark energy\", an unknown form of energy that is hypothesized to permeate space. On a mass\u2013energy equivalence basis, the density of dark energy (~ 7 \u00d7 10\u221230 g/cm3) is much less than the density of ordinary matter or dark matter within galaxies. However, in the present dark-energy era, it dominates the mass\u2013energy of the universe because it is uniform across space.\n\nTwo proposed forms for dark energy are the cosmological constant, a constant energy density filling space homogeneously, and scalar fields such as quintessence or moduli, dynamic quantities whose energy density can vary in time and space. Contributions from scalar fields that are constant in space are usually also included in the cosmological constant. The cosmological constant can be formulated to be equivalent to vacuum energy. Scalar fields having only a slight amount of spatial inhomogeneity would be difficult to distinguish from a cosmological constant.\n\nDark matter \n\nDark matter is a hypothetical kind of matter that is invisible to the entire electromagnetic spectrum, but which accounts for most of the matter in the universe. The existence and properties of dark matter are inferred from its gravitational effects on visible matter, radiation, and the large-scale structure of the universe. Other than neutrinos, a form of hot dark matter, dark matter has not been detected directly, making it one of the greatest mysteries in modern astrophysics. Dark matter neither emits nor absorbs light or any other electromagnetic radiation at any significant level. Dark matter is estimated to constitute 26.8% of the total mass\u2013energy and 84.5%  of the total matter in the universe.\n\nOrdinary matter \n\nThe remaining 4.9% of the mass\u2013energy of the universe is ordinary matter, that is, atoms, ions, electrons and the objects they form. This matter includes stars, which produce nearly all of the light we see from galaxies, as well as interstellar gas in the interstellar and intergalactic media, planets, and all the objects from everyday life that we can bump into, touch or squeeze. As a matter of fact, the great majority of ordinary matter in the universe is unseen, since visible stars and gas inside galaxies and clusters account for less than 10 per cent of the ordinary matter contribution to the mass-energy density of the universe.\n\nOrdinary matter commonly exists in four states (or phases): solid, liquid, gas, and plasma. However, advances in experimental techniques have revealed other previously theoretical phases, such as Bose\u2013Einstein condensates and fermionic condensates.\n\nOrdinary matter is composed of two types of elementary particles: quarks and leptons. For example, the proton is formed of two up quarks and one down quark; the neutron is formed of two down quarks and one up quark; and the electron is a kind of lepton. An atom consists of an atomic nucleus, made up of protons and neutrons, and electrons that orbit the nucleus. Because most of the mass of an atom is concentrated in its nucleus, which is made up of baryons, astronomers often use the term baryonic matter to describe ordinary matter, although a small fraction of this \"baryonic matter\" is electrons.\n\nSoon after the Big Bang, primordial protons and neutrons formed from the quark\u2013gluon plasma of the early universe as it cooled below two trillion degrees. A few minutes later, in a process known as Big Bang nucleosynthesis, nuclei formed from the primordial protons and neutrons. This nucleosynthesis formed lighter elements, those with small atomic numbers up to lithium and beryllium, but the abundance of heavier elements dropped off sharply with increasing atomic number. Some boron may have been formed at this time, but the next heavier element, carbon, was not formed in significant amounts. Big Bang nucleosynthesis shut down after about 20 minutes due to the rapid drop in temperature and density of the expanding universe. Subsequent formation of heavier elements resulted from stellar nucleosynthesis and supernova nucleosynthesis.\n\nParticles \n\nOrdinary matter and the forces that act on matter can be described in terms of elementary particles. These particles are sometimes described as being fundamental, since they have an unknown substructure, and it is unknown whether or not they are composed of smaller and even more fundamental particles. Of central importance is the Standard Model, a theory that is concerned with electromagnetic interactions and the weak and strong nuclear interactions. The Standard Model is supported by the experimental confirmation of the existence of particles that compose matter: quarks and leptons, and their corresponding \"antimatter\" duals, as well as the force particles that mediate interactions: the photon, the W and Z bosons, and the gluon. The Standard Model predicted the existence of the recently discovered Higgs boson, a particle that is a manifestation of a field within the universe that can endow particles with mass. Because of its success in explaining a wide variety of experimental results, the Standard Model is sometimes regarded as a \"theory of almost everything\". The Standard Model does not, however, accommodate gravity. A true force-particle \"theory of everything\" has not been attained.\n\nHadrons \n\nA hadron is a composite particle made of quarks held together by the strong force. Hadrons are categorized into two families: baryons (such as protons and neutrons) made of three quarks, and mesons (such as pions) made of one quark and one antiquark. Of the hadrons, protons are stable, and neutrons bound within atomic nuclei are stable. Other hadrons are unstable under ordinary conditions and are thus insignificant constituents of the modern universe. From approximately 10\u22126 seconds after the Big Bang, during a period is known as the hadron epoch, the temperature of the universe had fallen sufficiently to allow quarks to bind together into hadrons, and the mass of the universe was dominated by hadrons. Initially, the temperature was high enough to allow the formation of hadron/anti-hadron pairs, which kept matter and antimatter in thermal equilibrium. However, as the temperature of the universe continued to fall, hadron/anti-hadron pairs were no longer produced. Most of the hadrons and anti-hadrons were then eliminated in particle-antiparticle annihilation reactions, leaving a small residual of hadrons by the time the universe was about one second old.\n\nLeptons \n\nA lepton is an elementary, half-integer spin particle that does not undergo strong interactions but is subject to the Pauli exclusion principle; no two leptons of the same species can be in exactly the same state at the same time. Two main classes of leptons exist: charged leptons (also known as the electron-like leptons), and neutral leptons (better known as neutrinos). Electrons are stable and the most common charged lepton in the universe, whereas muons and taus are unstable particle that quickly decay after being produced in high energy collisions, such as those involving cosmic rays or carried out in particle accelerators. Charged leptons can combine with other particles to form various composite particles such as atoms and positronium. The electron governs nearly all of chemistry, as it is found in atoms and is directly tied to all chemical properties. Neutrinos rarely interact with anything, and are consequently rarely observed. Neutrinos stream throughout the universe but rarely interact with normal matter.\n\nThe lepton epoch was the period in the evolution of the early universe in which the leptons dominated the mass of the universe. It started roughly 1 second after the Big Bang, after the majority of hadrons and anti-hadrons annihilated each other at the end of the hadron epoch. During the lepton epoch the temperature of the universe was still high enough to create lepton/anti-lepton pairs, so leptons and anti-leptons were in thermal equilibrium. Approximately 10 seconds after the Big Bang, the temperature of the universe had fallen to the point where lepton/anti-lepton pairs were no longer created. Most leptons and anti-leptons were then eliminated in annihilation reactions, leaving a small residue of leptons. The mass of the universe was then dominated by photons as it entered the following photon epoch.\n\nPhotons \n\nA photon is the quantum of light and all other forms of electromagnetic radiation. It is the force carrier for the electromagnetic force, even when static via virtual photons. The effects of this force are easily observable at the microscopic and at the macroscopic level because the photon has zero rest mass; this allows long distance interactions. Like all elementary particles, photons are currently best explained by quantum mechanics and exhibit wave\u2013particle duality, exhibiting properties of waves and of particles.\n\nThe photon epoch started after most leptons and anti-leptons were annihilated at the end of the lepton epoch, about 10 seconds after the Big Bang. Atomic nuclei were created in the process of nucleosynthesis which occurred during the first few minutes of the photon epoch. For the remainder of the photon epoch the universe contained a hot dense plasma of nuclei, electrons and photons. About 380,000 years after the Big Bang, the temperature of the Universe fell to the point where nuclei could combine with electrons to create neutral atoms. As a result, photons no longer interacted frequently with matter and the universe became transparent. The highly redshifted photons from this period form the cosmic microwave background. Tiny variations in temperature and density detectable in the CMB were the early \"seeds\" from which all subsequent structure formation took place.\n\nCosmological models\n\nModel of the universe based on general relativity \n\nGeneral relativity is the geometric theory of gravitation published by Albert Einstein in 1915 and the current description of gravitation in modern physics. It is the basis of current cosmological models of the universe. General relativity generalizes special relativity and Newton's law of universal gravitation, providing a unified description of gravity as a geometric property of space and time, or spacetime. In particular, the curvature of spacetime is directly related to the energy and momentum of whatever matter and radiation are present. The relation is specified by the Einstein field equations, a system of partial differential equations. In general relativity, the distribution of matter and energy determines the geometry of spacetime, which in turn describes the acceleration of matter. Therefore, solutions of the Einstein field equations describe the evolution of the universe. Combined with measurements of the amount, type, and distribution of matter in the universe, the equations of general relativity describe the evolution of the universe over time.\n\nWith the assumption of the cosmological principle that the universe is homogeneous and isotropic everywhere, a specific solution of the field equations that describes the universe is the metric tensor called the Friedmann\u2013Lema\u00eetre\u2013Robertson\u2013Walker metric,\n\nwhere (r, \u03b8, \u03c6) correspond to a spherical coordinate system. This metric has only two undetermined parameters. An overall dimensionless length scale factor R describes the size scale of the universe as a function of time; an increase in R is the expansion of the universe. A curvature index k describes the geometry. The index k is defined so that it can take only one of three values: 0, corresponding to flat Euclidean geometry; 1, corresponding to a space of positive curvature; or \u22121, corresponding to a space of positive or negative curvature. The value of R as a function of time t depends upon k and the cosmological constant \u039b. The cosmological constant represents the energy density of the vacuum of space and could be related to dark energy. The equation describing how R varies with time is known as the Friedmann equation after its inventor, Alexander Friedmann.\n\nThe solutions for R(t) depend on k and \u039b, but some qualitative features of such solutions are general. First and most importantly, the length scale R of the universe can remain constant only if the universe is perfectly isotropic with positive curvature (k=1) and has one precise value of density everywhere, as first noted by Albert Einstein. However, this equilibrium is unstable: because the universe is inhomogeneous on smaller scales, R must change over time. When R changes, all the spatial distances in the universe change in tandem; there is an overall expansion or contraction of space itself. This accounts for the observation that galaxies appear to be flying apart; the space between them is stretching. The stretching of space also accounts for the apparent paradox that two galaxies can be 40 billion light-years apart, although they started from the same point 13.8 billion years ago and never moved faster than the speed of light.\n\nSecond, all solutions suggest that there was a gravitational singularity in the past, when R went to zero and matter and energy were infinitely dense. It may seem that this conclusion is uncertain because it is based on the questionable assumptions of perfect homogeneity and isotropy (the cosmological principle) and that only the gravitational interaction is significant. However, the Penrose\u2013Hawking singularity theorems show that a singularity should exist for very general conditions. Hence, according to Einstein's field equations, R grew rapidly from an unimaginably hot, dense state that existed immediately following this singularity (when R had a small, finite value); this is the essence of the Big Bang model of the universe. Understanding the singularity of the Big Bang likely requires a quantum theory of gravity, which has not yet been formulated.\n\nThird, the curvature index k determines the sign of the mean spatial curvature of spacetime averaged over sufficiently large length scales (greater than about a billion light-years). If k=1, the curvature is positive and the universe has a finite volume. A universe with positive curvature is often visualized as a three-dimensional sphere embedded in a four-dimensional space. Conversely, if k is zero or negative, the universe has an infinite volume. It may seem counter-intuitive that an infinite and yet infinitely dense universe could be created in a single instant at the Big Bang when R=0, but exactly that is predicted mathematically when k does not equal 1. By analogy, an infinite plane has zero curvature but infinite area, whereas an infinite cylinder is finite in one direction and a torus is finite in both. A toroidal universe could behave like a normal universe with periodic boundary conditions.\n\nThe ultimate fate of the universe is still unknown because it depends critically on the curvature index k and the cosmological constant \u039b. If the universe were sufficiently dense, k would equal +1, meaning that its average curvature throughout is positive and the universe will eventually recollapse in a Big Crunch, possibly starting a new universe in a Big Bounce. Conversely, if the universe were insufficiently dense, k would equal 0 or \u22121 and the universe would expand forever, cooling off and eventually reaching the Big Freeze and the heat death of the universe. Modern data suggests that the rate of expansion of the universe is not decreasing, as originally expected, but increasing; if this continues indefinitely, the universe may eventually reach a Big Rip. Observationally, the universe appears to be flat (k = 0), with an overall density that is very close to the critical value between recollapse and eternal expansion.\n\nMultiverse hypothesis \n\nSome speculative theories have proposed that our universe is but one of a set of disconnected universes, collectively denoted as the multiverse, challenging or enhancing more limited definitions of the universe. Scientific multiverse models are distinct from concepts such as alternate planes of consciousness and simulated reality.\n\nMax Tegmark developed a four-part classification scheme for the different types of multiverses that scientists have suggested in response to various Physics problems. An example of such multiverses is the one resulting from the chaotic inflation model of the early universe. Another is the multiverse resulting from the many-worlds interpretation of quantum mechanics. In this interpretation, parallel worlds are generated in a manner similar to quantum superposition and decoherence, with all states of the wave functions being realized in separate worlds. Effectively, in the many-worlds interpretation the multiverse evolves as a universal wavefunction. If the Big Bang that created our multiverse created an ensemble of multiverses, the wave function of the ensemble would be entangled in this sense.\n\nThe least controversial, but still highly disputed, category of multiverse in Tegmark's scheme is Level I. The multiverses of this level are composed by distant spacetime events \"in our own universe\". Tegmark and others have argued that, if space is infinite, or sufficiently large and uniform, identical instances of the history of Earth's entire Hubble volume occur every so often, simply by chance. Tegmark calculated that our nearest so-called doppelg\u00e4nger, is 1010115 metres away from us (a double exponential function larger than a googolplex). However, the arguments used are of speculative nature. Additionally, it would be impossible to scientifically verify the existence of an identical Hubble volume.\n\nIt is possible to conceive of disconnected spacetimes, each existing but unable to interact with one another. An easily visualized metaphor of this concept is a group of separate soap bubbles, in which observers living on one soap bubble cannot interact with those on other soap bubbles, even in principle. According to one common terminology, each \"soap bubble\" of spacetime is denoted as a universe, whereas our particular spacetime is denoted as the universe, just as we call our moon the Moon. The entire collection of these separate spacetimes is denoted as the multiverse. With this terminology, different universes are not causally connected to each other. In principle, the other unconnected universes may have different dimensionalities and topologies of spacetime, different forms of matter and energy, and different physical laws and physical constants, although such possibilities are purely speculative. Others consider each of several bubbles created as part of chaotic inflation to be separate universes, though in this model these universes all share a causal origin.\n\nHistorical conceptions \n\nHistorically, there have been many ideas of the cosmos (cosmologies) and its origin (cosmogonies). Theories of an impersonal universe governed by physical laws were first proposed by the Greeks and Indians. Ancient Chinese philosophy encompassed the notion of the universe including both all of space and all of time. Over the centuries, improvements in astronomical observations and theories of motion and gravitation led to ever more accurate descriptions of the universe. The modern era of cosmology began with Albert Einstein's 1915 general theory of relativity, which made it possible to quantitatively predict the origin, evolution, and conclusion of the universe as a whole. Most modern, accepted theories of cosmology are based on general relativity and, more specifically, the predicted Big Bang.\n\nMythologies \n\nMany cultures have stories describing the origin of the world and universe. Cultures generally regard these stories as having some truth. There are however many differing beliefs in how these stories apply amongst those believing in a supernatural origin, ranging from a god directly creating the universe as it is now to a god just setting the \"wheels in motion\" (for example via mechanisms such as the big bang and evolution).\n\nEthnologists and anthropologists who study myths have developed various classification schemes for the various themes that appear in creation stories. For example, in one type of story, the world is born from a world egg; such stories include the Finnish epic poem Kalevala, the Chinese story of Pangu or the Indian Brahmanda Purana. In related stories, the universe is created by a single entity emanating or producing something by him- or herself, as in the Tibetan Buddhism concept of Adi-Buddha, the ancient Greek story of Gaia (Mother Earth), the Aztec goddess Coatlicue myth, the ancient Egyptian god Atum story, and the Judeo-Christian Genesis creation narrative in which the Abrahamic God created the universe. In another type of story, the universe is created from the union of male and female deities, as in the Maori story of Rangi and Papa. In other stories, the universe is created by crafting it from pre-existing materials, such as the corpse of a dead god\u2014as from Tiamat in the Babylonian epic Enuma Elish or from the giant Ymir in Norse mythology\u2014or from chaotic materials, as in Izanagi and Izanami in Japanese mythology. In other stories, the universe emanates from fundamental principles, such as Brahman and Prakrti, the creation myth of the Serers, or the yin and yang of the Tao.\n\nPhilosophical models \n\nThe pre-Socratic Greek philosophers and Indian philosophers developed some of the earliest philosophical concepts of the universe. The earliest Greek philosophers noted that appearances can be deceiving, and sought to understand the underlying reality behind the appearances. In particular, they noted the ability of matter to change forms (e.g., ice to water to steam) and several philosophers proposed that all the physical materials in the world are different forms of a single primordial material, or arche. The first to do so was Thales, who proposed this material to be water. Thales' student, Anaximander, proposed that everything came from the limitless apeiron. Anaximenes proposed the primordial material to be air on account of its perceived attractive and repulsive qualities that cause the arche to condense or dissociate into different forms. Anaxagoras proposed the principle of Nous (Mind), while Heraclitus proposed fire (and spoke of logos). Empedocles proposed the elements to be earth, water, air and fire. His four-element model became very popular. Like Pythagoras, Plato believed that all things were composed of number, with Empedocles' elements taking the form of the Platonic solids. Democritus, and later philosophers\u2014most notably Leucippus\u2014proposed that the universe is composed of indivisible atoms moving through a void (vacuum), although Aristotle did not believe that to be feasible because air, like water, offers resistance to motion. Air will immediately rush in to fill a void, and moreover, without resistance, it would do so indefinitely fast.\n\nAlthough Heraclitus argued for eternal change, his contemporary Parmenides made the radical suggestion that all change is an illusion, that the true underlying reality is eternally unchanging and of a single nature. Parmenides denoted this reality as  (The One). Parmenides' idea seemed implausible to many Greeks, but his student Zeno of Elea challenged them with several famous paradoxes. Aristotle responded to these paradoxes by developing the notion of a potential countable infinity, as well as the infinitely divisible continuum. Unlike the eternal and unchanging cycles of time, he believed that the world is bounded by the celestial spheres and that cumulative stellar magnitude is only finitely multiplicative.\n\nThe Indian philosopher Kanada, founder of the Vaisheshika school, developed a notion of atomism and proposed that light and heat were varieties of the same substance. In the 5th century AD, the Buddhist atomist philosopher Dign\u0101ga proposed atoms to be point-sized, durationless, and made of energy. They denied the existence of substantial matter and proposed that movement consisted of momentary flashes of a stream of energy.\n\nThe notion of temporal finitism was inspired by the doctrine of creation shared by the three Abrahamic religions: Judaism, Christianity and Islam. The Christian philosopher, John Philoponus, presented the philosophical arguments against the ancient Greek notion of an infinite past and future. Philoponus' arguments against an infinite past were used by the early Muslim philosopher, Al-Kindi (Alkindus); the Jewish philosopher, Saadia Gaon (Saadia ben Joseph); and the Muslim theologian, Al-Ghazali (Algazel).\n\nAstronomical concepts \n\nAstronomical models of the universe were proposed soon after astronomy began with the Babylonian astronomers, who viewed the universe as a flat disk floating in the ocean, and this forms the premise for early Greek maps like those of Anaximander and Hecataeus of Miletus.\n\nLater Greek philosophers, observing the motions of the heavenly bodies, were concerned with developing models of the universe-based more profoundly on empirical evidence. The first coherent model was proposed by Eudoxus of Cnidos. According to Aristotle's physical interpretation of the model, celestial spheres eternally rotate with uniform motion around a stationary Earth. Normal matter is entirely contained within the terrestrial sphere.\n\nDe Mundo (composed before 250 BC or between 350 and 200 BC), stated, \"Five elements, situated in spheres in five regions, the less being in each case surrounded by the greater\u2014namely, earth surrounded by water, water by air, air by fire, and fire by ether\u2014make up the whole universe\".\n\nThis model was also refined by Callippus and after concentric spheres were abandoned, it was brought into nearly perfect agreement with astronomical observations by Ptolemy. The success of such a model is largely due to the mathematical fact that any function (such as the position of a planet) can be decomposed into a set of circular functions (the Fourier modes). Other Greek scientists, such as the Pythagorean philosopher Philolaus, postulated (according to Stobaeus account) that at the center of the universe was a \"central fire\" around which the Earth, Sun, Moon and planets revolved in uniform circular motion.\n\nThe Greek astronomer Aristarchus of Samos was the first known individual to propose a heliocentric model of the universe. Though the original text has been lost, a reference in Archimedes' book The Sand Reckoner describes Aristarchus's heliocentric model. Archimedes wrote:\n\nYou, King Gelon, are aware the universe is the name given by most astronomers to the sphere the center of which is the center of the Earth, while its radius is equal to the straight line between the center of the Sun and the center of the Earth. This is the common account as you have heard from astronomers. But Aristarchus has brought out a book consisting of certain hypotheses, wherein it appears, as a consequence of the assumptions made, that the universe is many times greater than the universe just mentioned. His hypotheses are that the fixed stars and the Sun remain unmoved, that the Earth revolves about the Sun on the circumference of a circle, the Sun lying in the middle of the orbit, and that the sphere of fixed stars, situated about the same center as the Sun, is so great that the circle in which he supposes the Earth to revolve bears such a proportion to the distance of the fixed stars as the center of the sphere bears to its surface\n\nAristarchus thus believed the stars to be very far away, and saw this as the reason why stellar parallax had not been observed, that is, the stars had not been observed to move relative each other as the Earth moved around the Sun. The stars are in fact much farther away than the distance that was generally assumed in ancient times, which is why stellar parallax is only detectable with precision instruments. The geocentric model, consistent with planetary parallax, was assumed to be an explanation for the unobservability of the parallel phenomenon, stellar parallax. The rejection of the heliocentric view was apparently quite strong, as the following passage from Plutarch suggests (On the Apparent Face in the Orb of the Moon):\n\nCleanthes [a contemporary of Aristarchus and head of the Stoics] thought it was the duty of the Greeks to indict Aristarchus of Samos on the charge of impiety for putting in motion the Hearth of the Universe [i.e. the Earth], ... supposing the heaven to remain at rest and the Earth to revolve in an oblique circle, while it rotates, at the same time, about its own axis\n\nThe only other astronomer from antiquity known by name who supported Aristarchus's heliocentric model was Seleucus of Seleucia, a Hellenistic astronomer who lived a century after Aristarchus. According to Plutarch, Seleucus was the first to prove the heliocentric system through reasoning, but it is not known what arguments he used. Seleucus' arguments for a heliocentric cosmology were probably related to the phenomenon of tides. According to Strabo (1.1.9), Seleucus was the first to state that the tides are due to the attraction of the Moon, and that the height of the tides depends on the Moon's position relative to the Sun. Alternatively, he may have proved heliocentricity by determining the constants of a geometric model for it, and by developing methods to compute planetary positions using this model, like what Nicolaus Copernicus later did in the 16th century. During the Middle Ages, heliocentric models were also proposed by the Indian astronomer Aryabhata, and by the Persian astronomers Albumasar and Al-Sijzi.\n\nThe Aristotelian model was accepted in the Western world for roughly two millennia, until Copernicus revived Aristarchus's perspective that the astronomical data could be explained more plausibly if the Earth rotated on its axis and if the Sun were placed at the center of the universe.\n\nAs noted by Copernicus himself, the notion that the Earth rotates is very old, dating at least to Philolaus (c. 450 BC), Heraclides Ponticus (c. 350 BC) and Ecphantus the Pythagorean. Roughly a century before Copernicus, the Christian scholar Nicholas of Cusa also proposed that the Earth rotates on its axis in his book, On Learned Ignorance (1440). Al-Sijzi also proposed that the Earth rotates on its axis. Empirical evidence for the Earth's rotation on its axis, using the phenomenon of comets, was given by Tusi (1201\u20131274) and Ali Qushji (1403\u20131474).\n\nThis cosmology was accepted by Isaac Newton, Christiaan Huygens and later scientists. Edmund Halley (1720) and Jean-Philippe de Ch\u00e9seaux (1744) noted independently that the assumption of an infinite space filled uniformly with stars would lead to the prediction that the nighttime sky would be as bright as the Sun itself; this became known as Olbers' paradox in the 19th century. Newton believed that an infinite space uniformly filled with matter would cause infinite forces and instabilities causing the matter to be crushed inwards under its own gravity. This instability was clarified in 1902 by the Jeans instability criterion. One solution to these paradoxes is the Charlier Universe, in which the matter is arranged hierarchically (systems of orbiting bodies that are themselves orbiting in a larger system, ad infinitum) in a fractal way such that the universe has a negligibly small overall density; such a cosmological model had also been proposed earlier in 1761 by Johann Heinrich Lambert. A significant astronomical advance of the 18th century was the realization by Thomas Wright, Immanuel Kant and others of nebulae.\n\nIn 1919, when the Hooker Telescope was completed, the prevailing view still was that the universe consisted entirely of the Milky Way Galaxy. Using the Hooker Telescope, Edwin Hubble identified Cepheid variables in several spiral nebulae and in 1922\u20131923 proved conclusively that Andromeda Nebula and Triangulum among others, were entire galaxies outside our own, thus proving that universe consists of a multitude of galaxies.\n\nThe modern era of physical cosmology began in 1917, when Albert Einstein first applied his general theory of relativity to model the structure and dynamics of the universe.\n\nSee also \n\n Chronology of the universe\n Cosmic Calendar (scaled down timeline)\n Cosmic latte\n Cosmos\n Detailed logarithmic timeline\n Earth's location in the universe\n False vacuum\n Future of an expanding universe\n Galaxy And Mass Assembly survey\n Heat death of the universe\n History of the center of the Universe\n Illustris project\n Multiverse (set theory) (Hyperverse, Megaverse or Omniverse)\n Non-standard cosmology\n Nucleocosmochronology\n Panspermia\n Rare Earth hypothesis\n Religious cosmology\n Space and survival\n Terasecond and longer\n Timeline of the early universe\n Timeline of the far future\n Timeline of the near future\n Zero-energy universe\n\nReferences \nFootnotes\n\nCitations\n\nBibliography\n\nExternal links \n\n NASA/IPAC Extragalactic Database (NED) / (NED-Distances).\n There are about 1082 atoms in the observable universe \u2013 LiveScience, July 2021.\n This is why we will never know everything about our universe \u2013 Forbes, May 2019.\n\n \nAstronomical dynamical systems\nEnvironments\nPhysical cosmology\nConcepts in astronomy\nMain topic articles\nArticles containing video clips",
  "Humanities": "Humanities are academic disciplines that study aspects of human society and culture. In the Renaissance, the term contrasted with divinity and referred to what is now called classics, the main area of secular study in universities at the time. Today, the humanities are more frequently defined as any fields of study outside of professional training, mathematics, and the natural and  social sciences.\n\nThe humanities use methods that are primarily critical, or speculative, and have a significant historical element\u2014as distinguished from the mainly empirical approaches of the natural sciences, yet, unlike the sciences, it has no central discipline.\nThe humanities include the study of ancient and modern languages, literature, philosophy, history, archaeology, anthropology, human geography, law, religion, and art.\n\nScholars in the humanities are \"humanities scholars\" or humanists. The term \"humanist\" also describes the philosophical position of humanism, which some \"antihumanist\" scholars in the humanities reject. The Renaissance scholars and artists are also known as humanists. Some secondary schools offer humanities classes usually consisting of literature, global studies and art.\n\nHuman disciplines like history, folkloristics, and cultural anthropology study subject matters that the manipulative experimental method does not apply to\u2014and instead mainly use the comparative method and comparative research. Other methods used in the humanities include hermeneutics and source criticism.\n\nFields\n\nAnthropology\n\nAnthropology is the holistic \"science of humans\", a science of the totality of human existence. The discipline deals with the integration of different aspects of the social and natural sciences, as well as the humanities. In the twentieth century, academic disciplines have often been institutionally divided into three broad domains:\n The natural sciences seek to derive general laws through reproducible and verifiable experiments. \n The humanities generally study local traditions, through their history, literature, music, and arts, with an emphasis on understanding particular individuals, events, or eras. \n The social sciences have generally attempted to develop scientific methods to understand social phenomena in a generalizable way, though usually with methods distinct from those of the natural sciences.\n\nThe anthropological social sciences often develop nuanced descriptions rather than the general laws derived in physics or chemistry, or they may explain individual cases through more general principles, as in many fields of psychology. Anthropology (like some fields of history) does not easily fit into one of these categories, and different branches of anthropology draw on one or more of these domains. Within the United States, anthropology is divided into four sub-fields: archaeology, physical or biological anthropology, anthropological linguistics, and cultural anthropology. It is an area that is offered at most undergraduate institutions. The word  () is the Ancient Greek word for \"human being\" or \"person\". Eric Wolf described sociocultural anthropology as \"the most scientific of the humanities, and the most humanistic of the sciences\".\n\nThe goal of anthropology is to provide a holistic account of humans and human nature. This means that, though anthropologists generally specialize in only one sub-field, they always keep in mind the biological, linguistic, historic and cultural aspects of any problem. Since anthropology arose as a science in Western societies that were complex and industrial, a major trend within anthropology has been a methodological drive to study peoples in societies with more simple social organization, sometimes called \"primitive\" in anthropological literature, but without any connotation of \"inferior\". Today, anthropologists use terms such as \"less complex\" societies, or refer to specific modes of subsistence or production, such as \"pastoralist\" or \"forager\" or \"horticulturalist\", to discuss humans living in non-industrial, non-Western cultures, such people or folk (ethnos) remaining of great interest within anthropology.\n\nThe quest for holism leads most anthropologists to study a people in detail, using biogenetic, archaeological, and linguistic data alongside direct observation of contemporary customs. In the 1990s and 2000s, calls for clarification of what constitutes a culture, of how an observer knows where his or her own culture ends and another begins, and other crucial topics in writing anthropology were heard. It is possible to view all human cultures as part of one large, evolving global culture. Integrating research evidence in depth (detailed social behaviours of, how such are actually embedded in and the ways these are understood by a particular culture), breadth (select human aspects' varying manifestations across a wide range of peoples in differing environments), growth (adoption, persistence, change, abandonment and migration of material resources and products of traditions over eras) and evolution (development of societies, peoples, humanity, hominin species, and the hominid family throughout their existence in time) remains fundamental to any kind of anthropology, whether cultural, biological, linguistic or archaeological.\n\nArchaeology\n\nArchaeology is the study of human activity through the recovery and analysis of material culture. The archaeological record consists of artifacts, architecture, biofacts or ecofacts, and cultural landscapes. Archaeology can be considered both a social science and a branch of the humanities. It has various goals, which range from understanding culture history to reconstructing past lifeways to documenting and explaining changes in human societies through time.\n\nArchaeology is thought of as a branch of anthropology in the United States, while in Europe, it is viewed as a discipline in its own right, or grouped under other related disciplines such as history.\n\nClassics\n\nClassics, in the Western academic tradition, refers to the studies of the cultures of classical antiquity, namely Ancient Greek and Latin and the Ancient Greek and Roman cultures. Classical studies is considered one of the cornerstones of the humanities; however, its popularity declined during the 20th century. Nevertheless, the influence of classical ideas on many humanities disciplines, such as philosophy and literature, remains strong.\n\nHistory\n\nHistory is systematically collected information about the past. When used as the name of a field of study, history refers to the study and interpretation of the record of humans, societies, institutions, and any topic that has changed over time.\n\nTraditionally, the study of history has been considered a part of the humanities. In modern academia, history is occasionally classified as a social science.\n\nLinguistics and languages\n\nWhile the scientific study of language is known as linguistics and is generally considered a social science, a natural science or a cognitive science, the study of languages is still central to the humanities. A good deal of twentieth-century and twenty-first-century philosophy has been devoted to the analysis of language and to the question of whether, as Wittgenstein claimed, many of our philosophical confusions derive from the vocabulary we use; literary theory has explored the rhetorical, associative, and ordering features of language; and historical linguists have studied the development of languages across time. Literature, covering a variety of uses of language including prose forms (such as the novel), poetry and drama, also lies at the heart of the modern humanities curriculum. College-level programs in a foreign language usually include study of important works of the literature in that language, as well as the language itself.\n\nLaw and politics\n\n In common parlance, law means a rule that (unlike a rule of ethics) is enforceable through institutions. The study of law crosses the boundaries between the social sciences and humanities, depending on one's view of research into its objectives and effects. Law is not always enforceable, especially in the international relations context. It has been defined as a \"system of rules\", as an \"interpretive concept\" to achieve justice, as an \"authority\" to mediate people's interests, and even as \"the command of a sovereign, backed by the threat of a sanction\". However one likes to think of law, it is a completely central social institution. Legal policy incorporates the practical manifestation of thinking from almost every social science and discipline of the humanities. Laws are politics, because politicians create them. Law is philosophy, because moral and ethical persuasions shape their ideas. Law tells many of history's stories, because statutes, case law and codifications build up over time. And law is economics, because any rule about contract, tort, property law, labour law, company law and many more can have long-lasting effects on how productivity is organised and the distribution of wealth. The noun law derives from the late Old English lagu, meaning something laid down or fixed, and the adjective legal comes from the Latin word LEX.\n\nLiterature\n\n Literature is a term that does not have a universally accepted definition, but which has variably included all written work; writing that possesses literary merit; and language that foregrounds literariness, as opposed to ordinary language. Etymologically the term derives from Latin literatura/litteratura \"writing formed with letters\", although some definitions include spoken or sung texts. Literature can be classified according to whether it is fiction or non-fiction, and whether it is poetry or prose; it can be further distinguished according to major forms such as the novel, short story or drama; and works are often categorised according to historical periods, or according to their adherence to certain aesthetic features or expectations (genre).\n\nPhilosophy\n\nPhilosophy\u2014etymologically, the \"love of wisdom\"\u2014is generally the study of problems concerning matters such as existence, knowledge, justification, truth, justice, right and wrong, beauty, validity, mind, and language. Philosophy is distinguished from other ways of addressing these issues by its critical, generally systematic approach and its reliance on reasoned argument, rather than experiments (experimental philosophy being an exception).\n\nPhilosophy used to be a very comprehensive term, including what have subsequently become separate disciplines, such as physics. (As Immanuel Kant noted, \"Ancient Greek philosophy was divided into three sciences: physics, ethics, and logic.\") Today, the main fields of philosophy are logic, ethics, metaphysics, and epistemology. Still, it continues to overlap with other disciplines. The field of semantics, for example, brings philosophy into contact with linguistics.\n\nSince the early twentieth century, philosophy in English-speaking universities has moved away from the humanities and closer to the formal sciences, becoming much more analytic. Analytic philosophy is marked by emphasis on the use of logic and formal methods of reasoning, conceptual analysis, and the use of symbolic and/or mathematical logic, as contrasted with the Continental style of philosophy. This method of inquiry is largely indebted to the work of philosophers such as Gottlob Frege, Bertrand Russell, G.E. Moore and Ludwig Wittgenstein.\n\nReligion\n\n At present, we do not know of any people or tribe, either from history or the present day, which may be said altogether devoid of \u201creligion.\u201d Religion may be characterized with a community since humans are social animals. Rituals are used to bound the community together. Social animals require rules. Ethics is a requirement of society, but not a requirement of religion. Shinto, Daoism, and other folk or natural religions do not have ethical codes. The supernatural may or may not include deities since not all religions have deities. (Theravada Buddhism and Daoism). Magical thinking creates explanations not available for empirical verification. Stories or myths are narratives being both didactic and entertaining. They are necessary for understanding the human predicament. Some other possible characteristics of religion are pollutions and purification, the sacred and the profane, sacred texts, religious institutions and organizations, and sacrifice and prayer. Some of the major problems that religions confront, and attempts to answer are chaos, suffering, evil, and death.\n\nThe non-founder religions are Hinduism, Shinto, and native or folk religions.  Founder religions are Judaism, Christianity, Islam, Confucianism, Daoism, Mormonism, Jainism, Zoroastrianism, Buddhism, Sikhism, and the Baha\u2019i faith. Religions must adapt and change through the generations because they must remain relevant to the adherents. When traditional religions fail to address new concerns, then new religions will emerge.\n\nThe humanities uses various mediums attempting to articulate the human predicament and prescribe meanings to the human situation. They are products of the human imagination. They are not discovered but created. If creations characterize the humanities, then religion is the greatest creation of humankind.\n\nPerforming arts\n\nThe performing arts differ from the visual arts in so far as the former uses the artist's own body, face, and presence as a medium, and the latter uses materials such as clay, metal, or paint, which can be molded or transformed to create some art object. Performing arts include acrobatics, busking, comedy, dance, film, magic, music, opera, juggling, marching arts, such as brass bands, and theatre.\n\nArtists who participate in these arts in front of an audience are called performers, including actors, comedians, dancers, musicians, and singers. Performing arts are also supported by workers in related fields, such as songwriting and stagecraft. Performers often adapt their appearance, such as with costumes and stage makeup, etc. There is also a specialized form of fine art in which the artists perform their work live to an audience. This is called Performance art. Most performance art also involves some form of plastic art, perhaps in the creation of props. Dance was often referred to as a plastic art during the Modern dance era.\n\nMusicology\n\nMusicology as an academic discipline can take a number of different paths, including historical musicology, music literature, ethnomusicology and music theory. Undergraduate music majors generally take courses in all of these areas, while graduate students focus on a particular path. In the liberal arts tradition, musicology is also used to broaden skills of non-musicians by teaching skills such as concentration and listening.\n\nTheatre\nTheatre (or theater) (Greek \"theatron\", \u03b8\u03ad\u03b1\u03c4\u03c1\u03bf\u03bd) is the branch of the performing arts concerned with acting out stories in front of an audience using combinations of speech, gesture, music, dance, sound and spectacle \u2014 indeed any one or more elements of the other performing arts. In addition to the standard narrative dialogue style, theatre takes such forms as opera, ballet, mime, kabuki, classical Indian dance, Chinese opera, mummers' plays, and pantomime.\n\nDance\nDance (from Old French dancier, perhaps from Frankish) generally refers to human movement either used as a form of expression or presented in a social, spiritual or performance setting. Dance is also used to describe methods of non-verbal communication (see body language) between humans or animals (bee dance, mating dance), and motion in inanimate objects (the leaves danced in the wind). Choreography is the art of creating dances, and the person who does this is called a choreographer.\n\nDefinitions of what constitutes dance are dependent on social, cultural, aesthetic, artistic, and moral constraints and range from functional movement (such as Folk dance) to codified, virtuoso techniques such as ballet.\n\nVisual arts\n\nHistory of visual arts\n\nThe great traditions in art have a foundation in the art of one of the ancient civilizations, such as Ancient Japan, Greece and Rome, China, India, Greater Nepal, Mesopotamia and Mesoamerica.\n\nAncient Greek art saw a veneration of the human physical form and the development of equivalent skills to show musculature, poise, beauty and anatomically correct proportions. Ancient Roman art depicted gods as idealized humans, shown with characteristic distinguishing features (e.g., Zeus' thunderbolt).\n\nIn Byzantine and Gothic art of the Middle Ages, the dominance of the church insisted on the expression of biblical and not material truths. The Renaissance saw the return to valuation of the material world, and this shift is reflected in art forms, which show the corporeality of the human body, and the three-dimensional reality of landscape.\n\nEastern art has generally worked in a style akin to Western medieval art, namely a concentration on surface patterning and local colour (meaning the plain colour of an object, such as basic red for a red robe, rather than the modulations of that colour brought about by light, shade and reflection). A characteristic of this style is that the local colour is often defined by an outline (a contemporary equivalent is the cartoon). This is evident in, for example, the art of India, Tibet and Japan.\n\nReligious Islamic art forbids iconography, and expresses religious ideas through geometry instead. The physical and rational certainties depicted by the 19th-century Enlightenment were shattered not only by new discoveries of relativity by Einstein and of unseen psychology by Freud, but also by unprecedented technological development. Increasing global interaction during this time saw an equivalent influence of other cultures into Western art.\n\nMedia types\n\nDrawing\nDrawing is a means of making a picture, using any of a wide variety of tools and techniques. It generally involves making marks on a surface by applying pressure from a tool, or moving a tool across a surface. Common tools are graphite pencils, pen and ink, inked brushes, wax color pencils, crayons, charcoals, pastels, and markers. Digital tools that simulate the effects of these are also used. The main techniques used in drawing are: line drawing, hatching, crosshatching, random hatching, scribbling, stippling, and blending. A computer aided designer who excels in technical drawing is referred to as a draftsman or draughtsman.\n\nPainting\n\nPainting taken literally is the practice of applying pigment suspended in a carrier (or medium) and a binding agent (a glue) to a surface (support) such as paper, canvas or a wall. However, when used in an artistic sense it means the use of this activity in combination with drawing, composition and other aesthetic considerations in order to manifest the expressive and conceptual intention of the practitioner. Painting is also used to express spiritual motifs and ideas; sites of this kind of painting range from artwork depicting mythological figures on pottery to The Sistine Chapel to the human body itself.\n\nColour is highly subjective, but has observable psychological effects, although these can differ from one culture to the next. Black is associated with mourning in the West, but elsewhere white may be. Some painters, theoreticians, writers and scientists, including Goethe, Kandinsky, Isaac Newton, have written their own colour theories. Moreover, the use of language is only a generalization for a colour equivalent. The word \"red\", for example, can cover a wide range of variations on the pure red of the spectrum. There is not a formalized register of different colours in the way that there is agreement on different notes in music, such as C or C# in music, although the Pantone system is widely used in the printing and design industry for this purpose.\n\nModern artists have extended the practice of painting considerably to include, for example, collage. This began with cubism and is not painting in strict sense. Some modern painters incorporate different materials such as sand, cement, straw or wood for their texture. Examples of this are the works of Jean Dubuffet or Anselm Kiefer. Modern and contemporary art has moved away from the historic value of craft in favour of concept; this has led some  to say that painting, as a serious art form, is dead, although this has not deterred the majority of artists from continuing to practise it either as whole or part of their work.\n\nSculpture involves creating three-dimensional forms out of various materials. These typically include moldable substances like clay and metal but may also extend to material that is cut or shaved down to the desired form, like stone and wood.\n\nOrigin of the term\nThe word \"humanities\" is derived from the Renaissance Latin expression studia humanitatis, or \"study of humanitas\" (a classical Latin word meaning\u2014in addition to \"humanity\"\u2014\"culture, refinement, education\" and, specifically, an \"education befitting a cultivated man\"). In its usage in the early 15th century, the studia humanitatis was a course of studies that consisted of grammar, poetry, rhetoric, history, and moral philosophy, primarily derived from the study of Latin and Greek classics. The word humanitas also gave rise to the Renaissance Italian neologism umanisti, whence \"humanist\", \"Renaissance humanism\".\n\nHistory\nIn the West, the history of the humanities can be traced to ancient Greece, as the basis of a broad education for citizens. During Roman times, the concept of the seven liberal arts evolved, involving grammar, rhetoric and logic (the trivium), along with arithmetic, geometry, astronomy and music (the quadrivium). These subjects formed the bulk of medieval education, with the emphasis being on the humanities as skills or \"ways of doing\".\n\nA major shift occurred with the Renaissance humanism of the fifteenth century, when the humanities began to be regarded as subjects to study rather than practice, with a corresponding shift away from traditional fields into areas such as literature and history. In the 20th century, this view was in turn challenged by the postmodernist movement, which sought to redefine the humanities in more egalitarian terms suitable for a democratic society since the Greek and Roman societies in which the humanities originated were not at all democratic.\n\nToday\n\nEducation and employment \nFor many decades, there has been a growing public perception that a humanities education inadequately prepares graduates for employment. The common belief is that graduates from such programs face underemployment and incomes too low for a humanities education to be worth the investment.\n\nIn fact, humanities graduates find employment in a wide variety of management and professional occupations. In Britain, for example, over 11,000 humanities majors found employment in the following occupations:\n Education (25.8%)\n Management (19.8%)\n Media/Literature/Arts (11.4%)\n Law (11.3%)\n Finance (10.4%)\n Civil service (5.8%)\n Not-for-profit (5.2%)\n Marketing (2.3%)\n Medicine (1.7%)\n Other (6.4%)\nMany humanities graduates finish university with no career goals in mind. Consequently, many spend the first few years after graduation deciding what to do next, resulting in lower incomes at the start of their career; meanwhile, graduates from career-oriented programs experience more rapid entry into the labour market. However, usually within five years of graduation, humanities graduates find an occupation or career path that appeals to them.\n\nThere is empirical evidence that graduates from humanities programs earn less than graduates from other university programs. However, the empirical evidence also shows that humanities graduates still earn notably higher incomes than workers with no postsecondary education, and have job satisfaction levels comparable to their peers from other fields. Humanities graduates also earn more as their careers progress; ten years after graduation, the income difference between humanities graduates and graduates from other university programs is no longer statistically significant. Humanities graduates can boost their incomes if they obtain advanced or professional degrees.\n\nIn the United States\n\nThe Humanities Indicators\nThe Humanities Indicators, unveiled in 2009 by the American Academy of Arts and Sciences, are the first comprehensive compilation of data about the humanities in the United States, providing scholars, policymakers and the public with detailed information on humanities education from primary to higher education, the humanities workforce, humanities funding and research, and public humanities activities. Modeled after the National Science Board's Science and Engineering Indicators, the Humanities Indicators are a source of reliable benchmarks to guide analysis of the state of the humanities in the United States.\n\nIf \"The STEM Crisis Is a Myth\", statements about a \"crisis\" in the humanities are also misleading and ignore data of the sort collected by the Humanities Indicators.\n\nThe Humanities in American Life\nThe 1980 United States Rockefeller Commission on the Humanities described the humanities in its report, The Humanities in American Life:\nThrough the humanities we reflect on the fundamental question: What does it mean to be human? The humanities offer clues but never a complete answer. They reveal how people have tried to make moral, spiritual, and intellectual sense of a world where irrationality, despair, loneliness, and death are as conspicuous as birth, friendship, hope, and reason.\n\nAs a major\n\nIn 1950, a little over 1 percent of 22-year-olds in the United States had earned a humanities degrees (defined as a degree in English, language, history, philosophy); in 2010, this had doubled to about 2 and a half percent. In part, this is because there was an overall rise in the number of Americans who have any kind of college degree. (In 1940, 4.6 percent had a four-year degree; in 2016, 33.4 percent had one.) As a percentage of the type of degrees awarded, however, the humanities seem to be declining. Harvard University provides one example. In 1954, 36 percent of Harvard undergraduates majored in the humanities, but in 2012, only 20 percent took that course of study. Professor Benjamin Schmidt of Northeastern University has documented that between 1990 and 2008, degrees in English, history, foreign languages, and philosophy have decreased from 8 percent to just under 5 percent of all U.S. college degrees.\n\nIn liberal arts education\nThe Commission on the Humanities and Social Sciences 2013 report The Heart of the Matter supports the notion of a broad \"liberal arts education\", which includes study in disciplines from the natural sciences to the arts as well as the humanities.\n\nMany colleges provide such an education; some require it. The University of Chicago and Columbia University were among the first schools to require an extensive core curriculum in philosophy, literature, and the arts for all students. Other colleges with nationally recognized, mandatory programs in the liberal arts are Fordham University, St. John's College, Saint Anselm College and Providence College. Prominent proponents of liberal arts in the United States have included Mortimer J. Adler and E. D. Hirsch, Jr.\n\nIn the digital age\nResearchers in the humanities have developed numerous large- and small-scale digital corporation, such as digitized collections of historical texts, along with the digital tools and methods to analyze them. Their aim is both to uncover new knowledge about corpora and to visualize research data in new and revealing ways. Much of this activity occurs in a field called the digital humanities.\n\nSTEM\nPoliticians in the United States currently espouse a need for increased funding of the STEM fields, science, technology, engineering, mathematics. Federal funding represents a much smaller fraction of funding for humanities than other fields such as STEM or medicine. The result was a decline of quality in both college and pre-college education in the humanities field.\n\nThree-term Louisiana Governor Edwin Edwards acknowledged the importance of the humanities in a 2014 video address to the academic conference, Revolutions in Eighteenth-Century Sociability. Edwards said:\nWithout the humanities to teach us how history has succeeded or failed in directing the fruits of technology and science to the betterment of our tribe of homo sapiens, without the humanities to teach us how to frame the discussion and to properly debate the uses-and the costs-of technology, without the humanities to teach us how to safely debate how to create a more just society with our fellow man and woman, technology and science would eventually default to the  ownership of\u2014and misuse by\u2014the most influential, the most powerful, the most feared among us.\n\nIn Europe\n\nThe value of the humanities debate\n\nThe contemporary debate in the field of critical university studies centers around the declining value of the humanities. As in America, there is a perceived decline in interest within higher education policy in research that is qualitative and does not produce marketable products. This threat can be seen in a variety of forms across Europe, but much critical attention has been given to the field of research assessment in particular. For example, the UK [Research Excellence Framework] has been subject to criticism due to its assessment criteria from across the humanities, and indeed, the social sciences. In particular, the notion of \"impact\" has generated significant debate.\n\nPhilosophical history\n\nCitizenship and self-reflection\n\nSince the late 19th century, a central justification for the humanities has been that it aids and encourages self-reflection\u2014a self-reflection that, in turn, helps develop personal consciousness or an active sense of civic duty.\n\nWilhelm Dilthey and Hans-Georg Gadamer centered the humanities' attempt to distinguish itself from the natural sciences in humankind's urge to understand its own experiences. This understanding, they claimed, ties like-minded people from similar cultural backgrounds together and provides a sense of cultural continuity with the philosophical past.\n\nScholars in the late 20th and early 21st centuries extended that \"narrative imagination\" to the ability to understand the records of lived experiences outside of one's own individual social and cultural context. Through that narrative imagination, it is claimed, humanities scholars and students develop a conscience more suited to the multicultural world we live in. That conscience might take the form of a passive one that allows more effective self-reflection or extend into active empathy that facilitates the dispensation of civic duties a responsible world citizen must engage in. There is disagreement, however, on the level of influence humanities study can have on an individual and whether or not the understanding produced in humanistic enterprise can guarantee an \"identifiable positive effect on people.\"\n\nHumanistic theories and practices\nThere are three major branches of knowledge: natural sciences, social sciences, and the humanities. Technology is the practical extension  of the natural sciences, as politics is the extension of the social sciences. Similarly, the humanities have their own practical extension, sometimes called \"transformative humanities\" (transhumanities) or \"culturonics\" (Mikhail Epstein's term):\n Nature \u2013 natural sciences \u2013 technology \u2013\u00a0\u00a0transformation of nature\n \n Society \u2013 social sciences \u2013\u00a0\u00a0politics\u00a0\u2013\u00a0transformation of society\n \n Culture \u2013 human sciences \u2013\u00a0culturonics\u00a0\u2013 transformation of culture\nTechnology, politics and culturonics are designed to transform what their respective disciplines study: nature, society, and culture. The field of transformative humanities includes various   practicies and technologies, for example, language planning, the construction of new languages, like Esperanto, and invention of new artistic and literary genres and movements in the genre of manifesto, like Romanticism, Symbolism, or Surrealism.  Humanistic invention in the sphere of culture, as a practice complementary to scholarship, is an important aspect of the humanities.\n\nTruth and meaning\n\nThe divide between humanistic study and natural sciences informs arguments of meaning in humanities as well. What distinguishes the humanities from the natural sciences is not a certain subject matter, but rather the mode of approach to any question. Humanities focuses on understanding meaning, purpose, and goals and furthers the appreciation of singular historical and social phenomena\u2014an interpretive method of finding \"truth\"\u2014rather than explaining the causality of events or uncovering the truth of the natural world. Apart from its societal application, narrative imagination is an important tool in the (re)production of understood meaning in history, culture and literature.\n\nImagination, as part of the tool kit of artists or scholars, helps create meaning that invokes a response from an audience. Since a humanities scholar is always within the nexus of lived experiences, no \"absolute\" knowledge is theoretically possible; knowledge is instead a ceaseless procedure of inventing and reinventing the context a text is read in. Poststructuralism has problematized an approach to the humanistic study based on questions of meaning, intentionality, and authorship. In the wake of the death of the author proclaimed by Roland Barthes, various theoretical currents such as deconstruction and discourse analysis seek to expose the ideologies and rhetoric operative in producing both the purportedly meaningful objects and the hermeneutic subjects of humanistic study. This exposure has opened up the interpretive structures of the humanities to criticism that humanities scholarship is \"unscientific\" and therefore unfit for inclusion in modern university curricula because of the very nature of its changing contextual meaning.\n\nPleasure, the pursuit of knowledge and scholarship\n\nSome, like Stanley Fish, have claimed that the humanities can defend themselves best by refusing to make any claims of utility. (Fish may well be thinking primarily of literary study, rather than history and philosophy.) Any attempt to justify the humanities in terms of outside benefits such as social usefulness (say increased productivity) or in terms of ennobling effects on the individual (such as greater wisdom or diminished prejudice) is ungrounded, according to Fish, and simply places impossible demands on the relevant academic departments. Furthermore, critical thinking, while arguably a result of humanistic training, can be acquired in other contexts. And the humanities do not even provide any more the kind of social cachet (what sociologists sometimes call \"cultural capital\") that was helpful to succeed in Western society before the age of mass education following World War II.\n\nInstead, scholars like Fish suggest that the humanities offer a unique kind of pleasure, a pleasure based on the common pursuit of knowledge (even if it is only disciplinary knowledge). Such pleasure contrasts with the increasing privatization of leisure and instant gratification characteristic of Western culture; it thus meets J\u00fcrgen Habermas' requirements for the disregard of social status and rational problematization of previously unquestioned areas necessary for an endeavor which takes place in the bourgeois public sphere. In this argument, then, only the academic pursuit of pleasure can provide a link between the private and the public realm in modern Western consumer society and strengthen that public sphere that, according to many theorists, is the foundation for modern democracy.\n\nOthers, like Mark Bauerlein, argue that professors in the humanities have increasingly abandoned proven methods of epistemology (I care only about the quality of your arguments, not your conclusions.) in favor of indoctrination (I care only about your conclusions, not the quality of your arguments.). The result is that professors and their students adhere rigidly to a limited set of viewpoints, and have little interest in, or understanding of, opposing viewpoints. Once they obtain this intellectual self-satisfaction, persistent lapses in learning, research, and evaluation are common.\n\nRomanticization and rejection\n\nImplicit in many of these arguments supporting the humanities are the makings of arguments against public support of the humanities. Joseph Carroll asserts that we live in a changing world, a world where \"cultural capital\" is replaced with scientific literacy, and in which the romantic notion of a Renaissance humanities scholar is obsolete. Such arguments appeal to judgments and anxieties about the essential uselessness of the humanities, especially in an age when it is seemingly vitally important for scholars of literature, history and the arts to engage in \"collaborative work with experimental scientists or even simply to make \"intelligent use of the findings from empirical science.\"\n\nDespite many humanities based arguments against the humanities some within the exact sciences have called for their return. In 2017, Science popularizer Bill Nye retracted previous claims about the supposed 'uselessness' of philosophy. As Bill Nye states, \u201cPeople allude to Socrates and Plato and Aristotle all the time, and I think many of us who make those references don\u2019t have a solid grounding,\u201d he said. \u201cIt\u2019s good to know the history of philosophy.\u201d Scholars, such as biologist Scott F. Gilbert, make the claim that it is in fact the increasing predominance, leading to exclusivity, of scientific ways of thinking that need to be tempered by historical and social context. Gilbert worries that the commercialization that may be inherent in some ways of conceiving science (pursuit of funding, academic prestige etc.) need to be examined externally. Gilbert argues \"First of all, there is a very successful alternative to science as a commercialized march to \u201cprogress.\u201d This is the approach taken by the liberal arts college, a model that takes pride in seeing science in context and in integrating science with the humanities and social sciences.\"\n\nSee also\n\n Discourse analysis\n Outline of the humanities (humanities topics)\n Great Books\n Great Books programs in Canada\n Liberal arts\n Social sciences\n Humanities, arts, and social sciences\n Human science\n The Two Cultures\n List of academic disciplines\n Public humanities\n STEAM fields\n Tinbergen's four questions\n Environmental humanities\n\nReferences\n\nExternal links \n\nSociety for the History of the Humanities\nInstitute for Comparative Research in Human and Social Sciences (ICR) \u2013 Japan\nThe American Academy of Arts and Sciences \u2013 US\nHumanities Indicators \u2013 US\nNational Humanities Center \u2013 US\nThe Humanities Association \u2013 UK\nNational Humanities Alliance\nNational Endowment for the Humanities \u2013 US\nAustralian Academy of the Humanities\nNational \nAmerican Academy Commission on the Humanities and Social Sciences \n\"Games and Historical Narratives\" by Jeremy Antley \u2013 Journal of Digital Humanities\nFilm about the Value of the Humanities\n\n \nMain topic articles",
  "Knowledge": "Knowledge is a familiarity or awareness, of someone or something, such as facts (descriptive knowledge), skills (procedural knowledge), or objects (acquaintance knowledge) contributing to ones understanding. By most accounts, knowledge can be acquired in many different ways and from many sources, including but not limited to perception, reason, memory, testimony, scientific inquiry, education, and practice. The philosophical study of knowledge is called epistemology.\n\nThe term \"knowledge\" can refer to a theoretical or practical understanding of a subject. It can be implicit (as with practical skill or expertise) or explicit (as with the theoretical understanding of a subject); formal or informal; systematic or particular. The philosopher Plato argued that there was a distinction between knowledge and true belief in the Theaetetus, leading many to attribute to him a definition of knowledge as \"justified true belief\". The difficulties with this definition raised by the Gettier problem have been the subject of extensive debate in epistemology for more than half a century.\n\nTheories of knowledge \n\nKnowledge is the primary subject of the field of epistemology, which studies what we know, how we come to know it, and what it means to know something. Defining knowledge is an important aspect of epistemology, because it does not suffice to have a belief; one must also have good reasons for that belief, because otherwise there would be no reason to prefer one belief over another.\n\nThe definition of knowledge is a matter of ongoing debate among epistemologists. The classical definition, described but not ultimately endorsed by Plato, specifies that a statement must meet three criteria in order to be considered knowledge: it must be justified, true, and believed. Epistemologists today generally agree that these conditions are not sufficient, as various Gettier cases are thought to demonstrate. There are a number of alternative definitions which have been proposed, including Robert Nozick's proposal that all instances of knowledge must 'track the truth' and Simon Blackburn's proposal that those who have a justified true belief 'through a defect, flaw, or failure' fail to have knowledge. Richard Kirkham suggests that our definition of knowledge requires that the evidence for the belief necessitates its truth.\n\nIn contrast to this approach, Ludwig Wittgenstein observed, following Moore's paradox, that one can say \"He believes it, but it isn't so,\" but not \"He knows it, but it isn't so.\" He goes on to argue that these do not correspond to distinct mental states, but rather to distinct ways of talking about conviction. What is different here is not the mental state of the speaker, but the activity in which they are engaged. For example, on this account, to know that the kettle is boiling is not to be in a particular state of mind, but to perform a particular task with the statement that the kettle is boiling. Wittgenstein sought to bypass the difficulty of definition by looking to the way \"knowledge\" is used in natural languages. He saw knowledge as a case of a family resemblance. Following this idea, \"knowledge\" has been reconstructed as a cluster concept that points out relevant features but that is not adequately captured by any definition.\n\nSelf-knowledge \n\n\u201cSelf-knowledge\u201d usually refers to a person's knowledge of their own sensations, thoughts, beliefs, and other mental states. A number of questions regarding self-knowledge have been the subject of extensive debates in philosophy, including whether self-knowledge differs from other types of knowledge, whether we have privileged self-knowledge compared to knowledge of other minds, and the nature of our acquaintance with ourselves. David Hume expressed skepticism about whether we could ever have self-knowledge over and above our immediate awareness of a \"bundle of perceptions\", which was part of his broader skepticism about personal identity.\n\nThe value of knowledge \n\nIt is generally assumed that knowledge is more valuable than mere true belief. If so, what is the explanation? A formulation of the value problem in epistemology first occurs in Plato's Meno. Socrates points out to Meno that a man who knew the way to Larissa could lead others there correctly. But so, too, could a man who had true beliefs about how to get there, even if he had not gone there or had any knowledge of Larissa. Socrates says that it seems that both knowledge and true opinion can guide action. Meno then wonders why knowledge is valued more than true belief and why knowledge and true belief are different. Socrates responds that knowledge is more valuable than mere true belief because it is tethered or justified. Justification, or working out the reason for a true belief, locks down true belief.\n\nThe problem is to identify what (if anything) makes knowledge more valuable than mere true belief, or that makes knowledge more valuable than a mere minimal conjunction of its components, such as justification, safety, sensitivity, statistical likelihood, and anti-Gettier conditions, on a particular analysis of knowledge that conceives of knowledge as divided into components (to which knowledge-first epistemological theories, which posit knowledge as fundamental, are notable exceptions). The value problem re-emerged in the philosophical literature on epistemology in the twenty-first century following the rise of virtue epistemology in the 1980s, partly because of the obvious link to the concept of value in ethics.\n\nIn contemporary philosophy, epistemologists including Ernest Sosa, John Greco, Jonathan Kvanvig, Linda Zagzebski, and Duncan Pritchard have defended virtue epistemology as a solution to the value problem. They argue that epistemology should also evaluate the \"properties\" of people as epistemic agents (i.e. intellectual virtues), rather than merely the properties of propositions and propositional mental attitudes.\n\nScientific knowledge \n\nThe development of the scientific method has made a significant contribution to how knowledge of the physical world and its phenomena is acquired. To be termed scientific, a method of inquiry must be based on gathering observable and measurable evidence subject to specific principles of reasoning and experimentation. The scientific method consists of the collection of data through observation and experimentation, and the formulation and testing of hypotheses. Science, and the nature of scientific knowledge have also become the subject of philosophy. As science itself has developed, scientific knowledge now includes a broader usage in the soft sciences such as biology and the social sciences \u2013 discussed elsewhere as meta-epistemology, or genetic epistemology, and to some extent related to \"theory of cognitive development\". Note that \"epistemology\" is the study of knowledge and how it is acquired. Science is \"the process used everyday to logically complete thoughts through inference of facts determined by calculated experiments.\" Sir Francis Bacon was critical in the historical development of the scientific method; his works established and popularized an inductive methodology for scientific inquiry. His aphorism, \"knowledge is power\", is found in the Meditations Sacrae (1597).\n\nUntil recent times, at least in the Western tradition, it was simply taken for granted that knowledge was something possessed only by humans \u2013 and probably adult humans at that. Sometimes the notion might stretch to Society-as-such, as in (e.\u00a0g.) \"the knowledge possessed by the Coptic culture\" (as opposed to its individual members), but that was not assured either. Nor was it usual to consider unconscious knowledge in any systematic way until this approach was popularized by Freud.\n\nSituated knowledge \n\nSituated knowledge is knowledge specific to a particular situation. It was used by Donna Haraway as an extension of the feminist approaches of \"successor science\" suggested by Sandra Harding, one which \"offers a more adequate, richer, better account of a world, in order to live in it well and in critical, reflexive relation to our own as well as others' practices of domination and the unequal parts of privilege and oppression that makes up all positions.\" This situation partially transforms science into a narrative, which Arturo Escobar explains as, \"neither fictions nor supposed facts.\" This narrative of situation is historical textures woven of fact and fiction, and as Escobar explains further, \"even the most neutral scientific domains are narratives in this sense,\" insisting that rather than a purpose dismissing science as a trivial matter of contingency, \"it is to treat (this narrative) in the most serious way, without succumbing to its mystification as 'the truth' or to the ironic skepticism common to many critiques.\"\n\nHaraway's argument stems from the limitations of the human perception, as well as the overemphasis of the sense of vision in science. According to Haraway, vision in science has been, \"used to signify a leap out of the marked body and into a conquering gaze from nowhere.\" This is the \"gaze that mythically inscribes all the marked bodies, that makes the unmarked category claim the power to see and not be seen, to represent while escaping representation.\" This causes a limitation of views in the position of science itself as a potential player in the creation of knowledge, resulting in a position of \"modest witness\". This is what Haraway terms a \"god trick\", or the aforementioned representation while escaping representation. In order to avoid this, \"Haraway perpetuates a tradition of thought which emphasizes the importance of the subject in terms of both ethical and political accountability\".\n\nSome methods of generating knowledge, such as trial and error, or learning from experience, tend to create highly situational knowledge.\nSituational knowledge is often embedded in language, culture, or traditions. This integration of situational knowledge is an allusion to the community, and its attempts at collecting subjective perspectives into an embodiment \"of views from somewhere.\" Knowledge is also said to be related to the capacity of acknowledgement in human beings.\n\nEven though Haraway's arguments are largely based on feminist studies, this idea of different worlds, as well as the skeptic stance of situated knowledge is present in the main arguments of post-structuralism. Fundamentally, both argue the contingency of knowledge on the presence of history; power, and geography, as well as the rejection of universal rules or laws or elementary structures; and the idea of power as an inherited trait of objectification.\n\nPartial knowledge \n\nOne discipline of epistemology focuses on partial knowledge. In most cases, it is not possible to understand an information domain exhaustively; our knowledge is always incomplete or partial. Most real problems have to be solved by taking advantage of a partial understanding of the problem context and problem data, unlike the typical math problems one might solve at school, where all data is given and one is given a complete understanding of formulas necessary to solve them (False consensus effect).\n\nThis idea is also present in the concept of bounded rationality which assumes that in real-life situations people often have a limited amount of information and make decisions accordingly.\n\nReligious concepts of knowledge\n\nChristianity \nIn many expressions of Christianity, such as Catholicism and Anglicanism, knowledge is one of the seven gifts of the Holy Spirit.\n\n\"The knowledge that comes from the Holy Spirit, however, is not limited to human knowledge; it is a special gift, which leads us to grasp, through creation, the greatness and love of God and his profound relationship with every creature.\" (Pope Francis, papal audience May 21, 2014)\n\nGnosticism \nIn Gnostic beliefs, everyone is said to possess a piece of the highest good or Ultimate God deep within themselves that had fallen from the spiritual world into the bodies of humans, sometimes called a divine spark. It is trapped in their material bodies created by the inferior God or Demiurge unless secret knowledge from the outside universe called gnosis is achieved. The one who brings such knowledge is considered the savior or redeemer.\n\nHinduism \n\u0935\u093f\u0926\u094d\u092f\u093e \u0926\u093e\u0928 (Vidya Daan) i.e. knowledge sharing is a major part of Daan, a tenet of all Dharmic Religions.\nHindu Scriptures present two kinds of knowledge, Paroksh Gyan and Prataksh Gyan. Paroksh Gyan (also spelled Paroksha-Jnana) is secondhand knowledge: knowledge obtained from books, hearsay, etc. Pratyaksh Gyan (also spelled Pratyaksha-Jnana) is the knowledge borne of direct experience, i.e., knowledge that one discovers for oneself. Jnana yoga (\"path of knowledge\") is one of three main types of yoga expounded by Krishna in the Bhagavad Gita. (It is compared and contrasted with Bhakti Yoga and Karma yoga.)\n\nIslam \nIn Islam, knowledge (Arabic: \u0639\u0644\u0645, \u02bfilm) is given great significance. \"The Knowing\" (al-\u02bfAl\u012bm) is one of the 99 names reflecting distinct attributes of God. The Qur'an asserts that knowledge comes from God () and various hadith encourage the acquisition of knowledge. Muhammad is reported to have said \"Seek knowledge from the cradle to the grave\" and \"Verily the men of knowledge are the inheritors of the prophets\". Islamic scholars, theologians and jurists are often given the title alim, meaning \"knowledgeble\".\n\nJudaism \nIn Jewish tradition, knowledge (Hebrew: \u05d3\u05e2\u05ea da'ath) is considered one of the most valuable traits a person can acquire. Observant Jews recite three times a day in the Amidah \"Favor us with knowledge, understanding and discretion that come from you. Exalted are you, Existent-One, the gracious giver of knowledge.\" The Tanakh states, \"A wise man gains power, and a man of knowledge maintains power\", and \"knowledge is chosen above gold\".\n\nThe Old Testament's tree of the knowledge of good and evil contained the knowledge that separated Man from God: \"And the LORD God said, Behold, the man is become as one of us, to know good and evil...\" ()\n\nSee also \n\n Omniscience\n Outline of knowledge \u2013 guide to the subject of knowledge presented as a tree structured list of its subtopics.\n Outline of human intelligence - list of subtopics in tree structure \n Analytic-synthetic distinction\n Decolonization of knowledge\n Desacralization of knowledge\n Descriptive knowledge\n Epistemic modal logic\n Gnosticism\n Inductive inference\n Inductive probability\n Intelligence\n Knowledge transfer\n Metaknowledge\n Procedural knowledge\n Society for the Diffusion of Useful Knowledge\n\nReferences\n\nExternal links \n\n \n \n \n \n \n \n\nKnowledge\nConcepts in epistemology\nIntelligence\nMental content\nVirtue\nMain topic articles",
  "Human behavior": "Human behavior is the potential and expressed capacity (mentally, physically, and socially) of human individuals or groups to respond to internal and external stimuli throughout their life. While specific traits of one's personality, temperament, and genetics may be more consistent, other behaviors change as one moves between life stages\u2014i.e., from birth through adolescence, adulthood, and, for example, parenthood and retirement.\n\nBehavior is also driven, in part, by thoughts and feelings, which provide insight into individual psyche, revealing such things as attitudes and values. Human behavior is shaped by psychological traits, as personality types vary from person to person, producing different actions and behavior. Extraverted people, for instance, are more likely than introverted people to participate in social activities like parties.\n\nThe behavior of humans (just as of other organisms) falls upon a spectrum, whereby some behaviors are common while others unusual, and some are acceptable while others beyond acceptable limits. The acceptability of behavior depends heavily upon social norms and is regulated by various means of social control, partly due to the inherently conformist nature of human society in general. Thus, social norms also condition behavior, whereby humans are pressured into following certain rules and displaying certain behaviors that are deemed acceptable or unacceptable depending on the given society or culture.\n\nHuman behavior is studied by the social sciences, which include psychology, sociology, economics, and anthropology. In sociology, behavior may broadly refer to all basic human actions, including those that possess no meaning\u2014actions directed at no person. Behavior in this general sense should not be mistaken with social behavior. Social behavior, a subset of human behavior that accounts for actions directed at others, is concerned with the considerable influence of social interaction and culture, as well as ethics, social environment, authority, persuasion, and coercion.\n\nFactors\n\nGenetics\n\nLong before Charles Darwin published On the Origin of Species in 1858, animal breeders knew that patterns of behavior are somehow influenced by inheritance from parents. Studies of identical twins as compared to less-closely-related human beings, and of children brought up in adoptive homes, have helped scientists understand the influence of genetics on human behavior. The study of human behavioral genetics is still developing steadily with new methods such as genome-wide association studies.\n\nEvolutionary psychology studies behavior as the product of natural selection, whereby both human behavior and psychology are shaped by our evolutionary past. According to this field, humans attempt to increase their social status as much as possible, which increases their chances of reproductive success. They may do this by fighting, amassing wealth, or helping others with their problems.\n\nSocial norms\n\nSocial norms, the often unspoken rules of a group, shape not only our behaviors but also our attitudes.\nAn individual's behavior varies depending on the group(s) they are a part of, a characteristic of society that allows their norms to heavily impact society. Without social norms, human society would not function as it currently does. Humans would have to be more abstract in their behavior, as there would not be a pre-tested 'normal' standardized lifestyle, and individuals would have to make many more choices for themselves. The institutionalization of norms is, however, inherent in human society perhaps as a direct result of the desire to be accepted by others, which leads humans to manipulate their own behavior to 'fit in' with others. Depending on their nature and upon one's perspective, norms can impact different sections of society both positively (e.g. attending birthday celebrations, dressing warm in the winter) and negatively (e.g. racism, drug use).\n\nCreativity\n\nCreativity is a fundamental human trait. It can be seen in tribes' adaptation of natural objects to make tools, and in the uniquely human pursuits of art and music.\nThis creative impulse explains the constant change in fashion, technology, and food in modern society. People use creative endeavors, like art and literature, to distinguish themselves within their social group. They also use their creativity to make money and persuade others of the value of their ideas.\n\nReligion and spirituality\nAnother important aspect of human behavior is religion and spirituality. According to a Pew Research Center report, 54% of adults around the world state that religion is very important in their lives. Religion plays a large role in the lives of many people around the world, and it affects their behavior towards others. For example, one of the five pillars of Islam is zakat. This is the practice whereby Muslims who can afford to are required to donate 2.5% of their wealth to those in need. Many religious people regularly attend services with other members of their religion. They may take part in religious rituals, and festivals like Diwali and Easter.\n\nAttitude\n\nAn attitude is an expression of favor or disfavor toward a person, place, thing, or event. It alters between each individual, as everyone holds different attitudes towards different things. A main factor that determines attitude is likes and dislikes: the more one likes something or someone, the more one is willing to open up and accept what they have to offer; one dislikes something, they are more likely to get defensive and shut down.\n\nAn example of how one's attitude affects one's human behavior could be as simple as taking a child to the park or to the doctor. Children know they have fun at the park so their attitude becomes willing and positive, but when a doctor is mentioned, they shut down and become upset with the thought of pain. Attitudes can sculpt personalities and the way people view who we are. People with similar attitudes tend to stick together as interests and hobbies are common. This does not mean that people with different attitudes do not interact, the fact is they do. What it means is that specific attitudes can bring people together (e.g., religious groups). The way a human behaves depends a lot on how they look at the situation and what they expect to gain from it.\n\nWeather and climate\nThe weather and climate have a significant influence on human behavior. The average temperature of a country affects its traditions and people's everyday routines. For example, Spain was once a primarily agrarian country, with much of its labour force working in the fields. Spaniards developed the tradition of the siesta, an after-lunch nap, to cope with the intense midday heat. The siesta persists despite the increased use of air conditioning and the move from farming to office jobs. However, it is less common today than in the past. Norway is a northern country with cold average temperatures and short hours of daylight in winter. This has shaped its lunchtime habits. Norwegians have a fixed half an hour lunch break. This enables them to go home earlier, with many leaving work at three o'clock in the afternoon. This allows them to make the most of the remaining daylight. There is a correlation between higher temperatures and increased levels of violent crime. There are a number of theories for why this is. According to the theory, people are more inclined to go outside during warmer weather, and this increases the number of opportunities for criminals. Another is that high temperatures cause a physiological response that increases people's irritability, and therefore their likeliness to escalate perceived slights into violence.\n\nSee also\n\n Behavioral modernity\n Behaviorism\n Behavioral economics\n Feminine psychology\n Human behavioral ecology\n Human communication\n Human ethology\n Human sexual behavior\n Mathematical principles of reinforcement\n Motivation\n Nature versus nurture\n\nReferences\n\nFurther reading \nArdrey, Robert. 1970. The Social Contract: A Personal Inquiry into the Evolutionary Sources of Order and Disorder. Atheneum. .\n Edwords, Frederick. 1989. \"What is humanism?.\" American Humanist Association.\n\nExternal links\n \n \n\n \nBehavior\nMain topic articles",
  "People": "A people is any plurality of persons considered as a whole.\n\nUsed in politics and law it is a term to refer to the collective or community of an ethnic group, a nation, to the public or common mass of people of a polity. As such it is a concept of human rights law, international law as well as constitutional law, particularly used for claims of popular sovereignty.\n\nConcepts\n\nLegal \n\nChapter One, Article One of the Charter of the United Nations states that \"peoples\" have the right to self-determination. Though the mere status as peoples and the right to self-determination, as for example in the case of Indigenous peoples (peoples, as in all peoples of indigenous people, not merely all indigenous persons as in indigenous people), does not automatically provide for independent sovereignty.\nParticularly through international Indigenous peoples rights, it was defined what a people constitutes (e.g. shared culture etc.).\n\nConstitutional \nBoth the Roman Republic and the Roman Empire used the Latin term Senatus Populusque Romanus, (the Senate and People of Rome). This term was fixed abbreviated (SPQR) to Roman legionary standards, and even after the Roman Emperors achieved a state of total personal autarchy, they continued to wield their power in the name of the Senate and People of Rome.\n\nThe term People's Republic, used since late modernity, is a name used by states, which particularly  identify constitutionally with a form of socialism.\n\nJudicial \nIn criminal law, in certain jurisdictions, criminal prosecutions are brought in the name of the People. Several U.S. states, including California, Illinois, and New York, use this style. Citations outside the jurisdictions in question usually substitute the name of the state for the words \"the People\" in the case captions. Four states\u00a0\u2014 Massachusetts, Virginia, Pennsylvania, and Kentucky\u00a0\u2014 refer to themselves as the Commonwealth in case captions and legal process.  Other states, such as Indiana, typically refer to themselves as the State in case captions and legal process.\n\nOutside the United States, criminal trials in Ireland and the Philippines are prosecuted in the name of the people of their respective states.\n\nThe political theory underlying this format is that criminal prosecutions are brought in the name of the sovereign; thus, in these U.S. states, the \"people\" are judged to be the sovereign, even as in the United Kingdom and other dependencies of the British Crown, criminal prosecutions are typically brought in the name of the Crown. \"The people\" identifies the entire body of the citizens of a jurisdiction invested with political power or gathered for political purposes.\n\nSee also \n\n Civitas\n Clan\n Collective\n Community\n Kinship\n Tribe\n List of contemporary ethnic groups\n List of indigenous peoples\n Volk\n National identity\n Nationality\n Public\n Republic\n Republicanism\n Democracy\n People's republic\n Populism\n\nReferences\n\n \nHumans\n\nde:Staatsvolk",
  "Information": "Information is processed, organized and structured data. It provides context for data and enables decision making process. For example, a single customer\u2019s sale at a restaurant is data \u2013 this becomes information when the business is able to identify the most popular or least popular dish.\n\nMore technically, information can be thought of as the resolution of uncertainty; it answers the question of \"What an entity is\" and thus defines both its essence and the nature of its characteristics. The concept of information has different meanings in different contexts. Thus the concept becomes synonymous to notions of constraint, communication, control, data, form, education, knowledge, meaning, understanding, mental stimuli, pattern, perception, proposition, representation, and entropy.\n\nInformation is associated with data. The difference is that information resolves uncertainty. Data can represent redundant symbols, but approaches information through optimal data compression.\n\nInformation can be transmitted in time, via data storage, and space, via communication and telecommunication. Information is expressed either as the content of a message or through direct or indirect observation. That which is perceived can be construed as a message in its own right, and in that sense, information is always conveyed as the content of a message.\n\nInformation can be encoded into various forms for transmission and interpretation (for example, information may be encoded into a sequence of signs, or transmitted via a signal). It can also be encrypted for safe storage and communication.\n\nThe uncertainty of an event is measured by its probability of occurrence. Uncertainty is inversely proportional to the probability of occurrence. Information theory takes advantage of this fact by concluding that more uncertain events require more information to resolve their uncertainty. The bit is a typical unit of information. It is 'that which reduces uncertainty by half'. Other units such as the nat may be used. For example, the information encoded in one \"fair\" coin flip is log2(2/1) = 1 bit, and in two fair coin flips is log2(4/1) = 2 bits. A 2011 Science article estimated that 97% of technologically stored information was already in digital bits in 2007, and that the year 2002 was the beginning of the digital age for information storage (with digital storage capacity bypassing analog for the first time).\n\nEtymology \n\nThe English word \"information\" comes from Middle French enformacion/informacion/information 'a criminal investigation' and its etymon, Latin informati\u014d(n) 'conception, teaching, creation'.\n\nIn English, \"information\" is an uncountable mass noun.\n\nInformation theory\n\nInformation theory is the scientific study of the quantification, storage, and communication of information. The field was fundamentally established by the works of Harry Nyquist and Ralph Hartley in the 1920s, and Claude Shannon in the 1940s. The field is at the intersection of probability theory, statistics, computer science, statistical mechanics, information engineering, and electrical engineering.\n\nA key measure in information theory is entropy. Entropy quantifies the amount of uncertainty involved in the value of a random variable or the outcome of a random process. For example, identifying the outcome of a fair coin flip (with two equally likely outcomes) provides less information (lower entropy) than specifying the outcome from a roll of a die (with six equally likely outcomes). Some other important measures in information theory are mutual information, channel capacity, error exponents, and relative entropy. Important sub-fields of information theory include source coding, algorithmic complexity theory, algorithmic information theory, and information-theoretic security.\n\nApplications of fundamental topics of information theory include source coding/data compression (e.g. for ZIP files), and channel coding/error detection and correction (e.g. for DSL). Its impact has been crucial to the success of the Voyager missions to deep space, the invention of the compact disc, the feasibility of mobile phones and the development of the Internet. The theory has also found applications in other areas, including statistical inference, cryptography, neurobiology, perception, linguistics, the evolution and function of molecular codes (bioinformatics), thermal physics, quantum computing, black holes, information retrieval, intelligence gathering, plagiarism detection, pattern recognition, anomaly detection and even art creation.\n\nAs sensory input \nOften information can be viewed as a type of input to an organism or system. Inputs are of two kinds; some inputs are important to the function of the organism (for example, food) or system (energy) by themselves. In his book Sensory Ecology biophysicist David B. Dusenbery called these causal inputs. Other inputs (information) are important only because they are associated with causal inputs and can be used to predict the occurrence of a causal input at a later time (and perhaps another place). Some information is important because of association with other information but eventually there must be a connection to a causal input.\n\nIn practice, information is usually carried by weak stimuli that must be detected by specialized sensory systems and amplified by energy inputs before they can be functional to the organism or system. For example, light is mainly (but not only, e.g. plants can grow in the direction of the lightsource) a causal input to plants but for animals it only provides information. The colored light reflected from a flower is too weak for photosynthesis but the visual system of the bee detects it and the bee's nervous system uses the information to guide the bee to the flower, where the bee often finds nectar or pollen, which are causal inputs, serving a nutritional function.\n\nAs representation and complexity \nThe cognitive scientist and applied mathematician Ronaldo Vigo argues that information is a concept that requires at least two related entities to make quantitative sense. These are, any dimensionally defined category of objects S, and any of its subsets R. R, in essence, is a representation of S, or, in other words, conveys representational (and hence, conceptual) information about S. Vigo then defines the amount of information that R conveys about S as the rate of change in the complexity of S whenever the objects in R are removed from S. Under \"Vigo information\", pattern, invariance, complexity, representation, and information\u2014five fundamental constructs of universal science\u2014are unified under a novel mathematical framework. Among other things, the framework aims to overcome the limitations of Shannon-Weaver information when attempting to characterize and measure subjective information.\n\nAs an influence that leads to transformation \nInformation is any type of pattern that influences the formation or transformation of other patterns. In this sense, there is no need for a conscious mind to perceive, much less appreciate, the pattern. Consider, for example, DNA. The sequence of nucleotides is a pattern that influences the formation and development of an organism without any need for a conscious mind. One might argue though that for a human to consciously define a pattern, for example a nucleotide, naturally involves conscious information processing.\n\nSystems theory at times seems to refer to information in this sense, assuming information does not necessarily involve any conscious mind, and patterns circulating (due to feedback) in the system can be called information. In other words, it can be said that information in this sense is something potentially perceived as representation, though not created or presented for that purpose. For example, Gregory Bateson defines \"information\" as a \"difference that makes a difference\".\n\nIf, however, the premise of \"influence\" implies that information has been perceived by a conscious mind and also interpreted by it, the specific context associated with this interpretation may cause the transformation of the information into knowledge. Complex definitions of both \"information\" and \"knowledge\" make such semantic and logical analysis difficult, but the condition of \"transformation\" is an important point in the study of information as it relates to knowledge, especially in the business discipline of knowledge management. In this practice, tools and processes are used to assist a knowledge worker in performing research and making decisions, including steps such as:\n\n Review information to effectively derive value and meaning\n Reference metadata if available\n Establish relevant context, often from many possible contexts\n Derive new knowledge from the information\n Make decisions or recommendations from the resulting knowledge\n\nStewart (2001) argues that transformation of information into knowledge is critical, lying at the core of value creation and competitive advantage for the modern enterprise.\n\nThe Danish Dictionary of Information Terms argues that information only provides an answer to a posed question. Whether the answer provides knowledge depends on the informed person. So a generalized definition of the concept should be: \"Information\" = An answer to a specific question\".\n\nWhen Marshall McLuhan speaks of media and their effects on human cultures, he refers to the structure of artifacts that in turn shape our behaviors and mindsets. Also, pheromones are often said to be \"information\" in this sense.\n\nTechnologically mediated information \n\nThese sections are using measurements of data rather than information as information cannot be directly measured.\n\nAs of 2007 \nIt is estimated that the world's technological capacity to store information grew from 2.6 (optimally compressed) exabytes in 1986 \u2013 which is the informational equivalent to less than one 730-MB CD-ROM per person (539 MB per person) \u2013 to 295 (optimally compressed) exabytes in 2007. This is the informational equivalent of almost 61 CD-ROM per person in 2007.\n\nThe world's combined technological capacity to receive information through one-way broadcast networks was the informational equivalent of 174 newspapers per person per day in 2007.\n\nThe world's combined effective capacity to exchange information through two-way telecommunication networks was the informational equivalent of 6 newspapers per person per day in 2007.\n\nAs of 2007, an estimated 90% of all new information is digital, mostly stored on hard drives.\n\nAs of 2020 \nThe total amount of data created, captured, copied, and consumed globally is forecast to increase rapidly, reaching 64.2 zettabytes in 2020. Over the next five years up to 2025, global data creation is projected to grow to more than 180 zettabytes.\n\nAs records \nRecords are specialized forms of information. Essentially, records are information produced consciously or as by-products of business activities or transactions and retained because of their value. Primarily, their value is as evidence of the activities of the organization but they may also be retained for their informational value. Sound records management ensures that the integrity of records is preserved for as long as they are required.\n\nThe international standard on records management, ISO 15489, defines records as \"information created, received, and maintained as evidence and information by an organization or person, in pursuance of legal obligations or in the transaction of business\". The International Committee on Archives (ICA) Committee on electronic records defined a record as, \"recorded information produced or received in the initiation, conduct or completion of an institutional or individual activity and that comprises content, context and structure sufficient to provide evidence of the activity\".\n\nRecords may be maintained to retain corporate memory of the organization or to meet legal, fiscal or accountability requirements imposed on the organization. Willis expressed the view that sound management of business records and information delivered \"...six key requirements for good corporate governance...transparency; accountability; due process; compliance; meeting statutory and common law requirements; and security of personal and corporate information.\"\n\nSemiotics \nMichael Buckland has classified \"information\" in terms of its uses: \"information as process\", \"information as knowledge\", and \"information as thing\".\n\nBeynon-Davies explains the multi-faceted concept of information in terms of signs and signal-sign systems. Signs themselves can be considered in terms of four inter-dependent levels, layers or branches of semiotics: pragmatics, semantics, syntax, and empirics. These four layers serve to connect the social world on the one hand with the physical or technical world on the other.\n\nPragmatics is concerned with the purpose of communication. Pragmatics links the issue of signs with the context within which signs are used. The focus of pragmatics is on the intentions of living agents underlying communicative behaviour. In other words, pragmatics link language to action.\n\nSemantics is concerned with the meaning of a message conveyed in a communicative act. Semantics considers the content of communication. Semantics is the study of the meaning of signs - the association between signs and behaviour. Semantics can be considered as the study of the link between symbols and their referents or concepts \u2013 particularly the way that signs relate to human behavior.\n\nSyntax is concerned with the formalism used to represent a message. Syntax as an area studies the form of communication in terms of the logic and grammar of sign systems. Syntax is devoted to the study of the form rather than the content of signs and sign-systems.\n\nNielsen (2008) discusses the relationship between semiotics and information in relation to dictionaries. He introduces the concept of lexicographic information costs and refers to the effort a user of a dictionary must make to first find, and then understand data so that they can generate information.\n\nCommunication normally exists within the context of some social situation. The social situation sets the context for the intentions conveyed (pragmatics) and the form of communication. In a communicative situation intentions are expressed through messages that comprise collections of inter-related signs taken from a language mutually understood by the agents involved in the communication. Mutual understanding implies that agents involved understand the chosen language in terms of its agreed syntax (syntactics) and semantics. The sender codes the message in the language and sends the message as signals along some communication channel (empirics). The chosen communication channel has inherent properties that determine outcomes such as the speed at which communication can take place, and over what distance.\n\nThe application of information study \nThe information cycle (addressed as a whole or in its distinct components) is of great concern to information technology, information systems, as well as information science. These fields deal with those processes and techniques pertaining to information capture (through sensors) and generation (through computation, formulation or composition), processing (including encoding, encryption, compression, packaging), transmission (including all telecommunication methods), presentation (including visualization / display methods), storage (such as magnetic or optical, including holographic methods), etc.\n\nInformation visualization (shortened as InfoVis) depends on the computation and digital representation of data, and assists users in pattern recognition and anomaly detection.\n\nInformation security (shortened as InfoSec) is the ongoing process of exercising due diligence to protect information, and information systems, from unauthorized access, use, disclosure, destruction, modification, disruption or distribution, through algorithms and procedures focused on monitoring and detection, as well as incident response and repair.\n\nInformation analysis is the process of inspecting, transforming, and modelling information, by converting raw data into actionable knowledge, in support of the decision-making process.\n\nInformation quality (shortened as InfoQ) is the potential of a dataset to achieve a specific (scientific or practical) goal using a given empirical analysis method.\n\nInformation communication represents the convergence of informatics, telecommunication and audio-visual media & content.\n\nSee also \n\n Abstraction\n Accuracy and precision\n Classified information\n Complex adaptive system\n Complex system\n Cybernetics\n Data storage device#Recording media\n Engram\n Exformation\n Free Information Infrastructure\n Freedom of information\n Informatics\n Information and communication technologies\n Information architecture\n Information broker\n Information continuum\n Information ecology\n Information engineering\n Information geometry\n Information inequity\n Information infrastructure\n Information management\n Information mapping\n Information metabolism \n Information overload\n Information processor\n Information quality (InfoQ)\n Information science\n Information sensitivity\n Information superhighway\n Information technology\n Information theory\n Information warfare\n Infosphere\n Internet forum\n Lexicographic information cost\n Library science\n Meme\n Philosophy of information\n Propaganda model\n Quantum information\n Receiver operating characteristic\n Satisficing\n\nReferences\n\nFurther reading\n\nExternal links\n\n Semantic Conceptions of Information Review by Luciano Floridi for the Stanford Encyclopedia of Philosophy\n Principia Cybernetica entry on negentropy\n Fisher Information, a New Paradigm for Science: Introduction, Uncertainty principles, Wave equations, Ideas of Escher, Kant, Plato and Wheeler. This essay is continually revised in the light of ongoing research.\n How Much Information? 2003 an attempt to estimate how much new information is created each year (study was produced by faculty and students at the School of Information Management and Systems at the University of California at Berkeley)\n  Informationsordbogen.dk The Danish Dictionary of Information Terms / Informationsordbogen\n\n \nConcepts in metaphysics\nInformation science\nMain topic articles",
  "Love": "Love encompasses a range of strong and positive emotional and mental states, from the most sublime virtue or good habit, the deepest interpersonal affection, to the simplest pleasure. An example of this range of meanings is that the love of a mother differs from the love of a spouse, which differs from the love for food. Most commonly, love refers to a feeling of a strong attraction and emotional attachment.\n\nLove is considered to be both positive and negative, with its virtue representing human kindness, compassion, and affection, as \"the unselfish loyal and benevolent concern for the good of another\" and its vice representing human moral flaw, akin to vanity, selfishness, amour-propre, and egotism, as potentially leading people into a type of mania, obsessiveness or codependency. It may also describe compassionate and affectionate actions towards other humans, one's self, or animals. In its various forms, love acts as a major facilitator of interpersonal relationships and, owing to its central psychological importance, is one of the most common themes in the creative arts. Love has been postulated to be a function that keeps human beings together against menaces and to facilitate the continuation of the species.\n\nAncient Greek philosophers identified six forms of love: essentially, familial love (in Greek, ), friendly love or platonic love (), romantic love (), self-love (), guest love (), and divine love (). Modern authors have distinguished further varieties of love: unrequited love, empty love, companionate love, consummate love, infatuated love, self-love, and courtly love. Numerous cultures have also distinguished , , , , , , , , , , ,  (and other variants or symbioses of these states), as culturally unique words, definitions, or expressions of love in regards to a specified \"moments\" currently lacking in the English language.\n\nScientific research on emotion has increased significantly over the past two decades. The color wheel theory of love defines three primary, three secondary and nine tertiary love styles, describing them in terms of the traditional color wheel. The triangular theory of love suggests \"intimacy, passion and commitment\" are core components of love. Love has additional religious or spiritual meaning. This diversity of uses and meanings combined with the complexity of the feelings involved makes love unusually difficult to consistently define, compared to other emotional states.\n\nDefinitions\n\nThe word \"love\" can have a variety of related but distinct meanings in different contexts. Many other languages use multiple words to express some of the different concepts that in English are denoted as \"love\"; one example is the plurality of Greek concepts for \"love\" (agape, eros, philia, storge) . Cultural differences in conceptualizing love thus doubly impede the establishment of a universal definition.\n\nAlthough the nature or essence of love is a subject of frequent debate, different aspects of the word can be clarified by determining what isn't love (antonyms of \"love\"). Love as a general expression of positive sentiment (a stronger form of like) is commonly contrasted with hate (or neutral apathy). As a less-sexual and more-emotionally intimate form of romantic attachment, love is commonly contrasted with lust. As an interpersonal relationship with romantic overtones, love is sometimes contrasted with friendship, although the word love is often applied to close friendships or platonic love. (Further possible ambiguities come with usages \"girlfriend\", \"boyfriend\", \"just good friends\").\n\n Abstractly discussed, love usually refers to an experience one person feels for another. Love often involves caring for, or identifying with, a person or thing (cf. vulnerability and care theory of love), including oneself (cf. narcissism). In addition to cross-cultural differences in understanding love, ideas about love have also changed greatly over time. Some historians date modern conceptions of romantic love to courtly Europe during or after the Middle Ages, although the prior existence of romantic attachments is attested by ancient love poetry.\n\nThe complex and abstract nature of love often reduces discourse of love to a thought-terminating clich\u00e9. Several common proverbs regard love, from Virgil's \"Love conquers all\" to The Beatles' \"All You Need Is Love\". St. Thomas Aquinas, following Aristotle, defines love as \"to will the good of another.\" Bertrand Russell describes love as a condition of \"absolute value,\" as opposed to relative value. Philosopher Gottfried Leibniz said that love is \"to be delighted by the happiness of another.\" Meher Baba stated that in love there is a \"feeling of unity\" and an \"active appreciation of the intrinsic worth of the object of love.\" Biologist Jeremy Griffith defines love as \"unconditional selflessness\".\n\nImpersonal\nPeople can be said to love an object, principle, or goal to which they are deeply committed and greatly value. For example, compassionate outreach and volunteer workers' \"love\" of their cause may sometimes be born not of interpersonal love but impersonal love, altruism, and strong spiritual or political convictions. People can also \"love\" material objects, animals, or activities if they invest themselves in bonding or otherwise identifying with those things. If sexual passion is also involved, then this feeling is called paraphilia.\n\nInterpersonal\n\nInterpersonal love refers to love between human beings. It is a much more potent sentiment than a simple liking for a person. Unrequited love refers to those feelings of love that are not reciprocated. Interpersonal love is most closely associated with Interpersonal relationships. Such love might exist between family members, friends, and couples. There are also a number of psychological disorders related to love, such as erotomania.\nThroughout history, philosophy and religion have done the most speculation on the phenomenon of love. In the 20th century, the science of psychology has written a great deal on the subject. In recent years, the sciences of psychology, anthropology, neuroscience, and biology have added to the understanding of the concept of love.\n\nBiological basis\n\nBiological models of sex tend to view love as a mammalian drive, much like hunger or thirst. Helen Fisher, an anthropologist and human behavior researcher, divides the experience of love into three partly overlapping stages: lust, attraction, and attachment. Lust is the feeling of sexual desire; romantic attraction determines what partners mates find attractive and pursue, conserving time and energy by choosing; and attachment involves sharing a home, parental duties, mutual defense, and in humans involves feelings of safety and security. Three distinct neural circuitries, including neurotransmitters, and three behavioral patterns, are associated with these three romantic styles.\n\nLust is the initial passionate sexual desire that promotes mating, and involves the increased release of chemicals such as testosterone and estrogen. These effects rarely last more than a few weeks or months. Attraction is the more individualized and romantic desire for a specific candidate for mating, which develops out of lust as commitment to an individual mate forms. Recent studies in neuroscience have indicated that as people fall in love, the brain consistently releases a certain set of chemicals, including the neurotransmitter hormones, dopamine, norepinephrine, and serotonin, the same compounds released by amphetamine, stimulating the brain's pleasure center and leading to side effects such as increased heart rate, loss of appetite and sleep, and an intense feeling of excitement. Research has indicated that this stage generally lasts from one and a half to three years.\n\nSince the lust and attraction stages are both considered temporary, a third stage is needed to account for long-term relationships. Attachment is the bonding that promotes relationships lasting for many years and even decades. Attachment is generally based on commitments such as marriage and children, or mutual friendship based on things like shared interests. It has been linked to higher levels of the chemicals oxytocin and vasopressin to a greater degree than short-term relationships have. Enzo Emanuele and coworkers reported the protein molecule known as the nerve growth factor (NGF) has high levels when people first fall in love, but these return to previous levels after one year.\n\nPsychological basis\n\nPsychology depicts love as a cognitive and social phenomenon. Psychologist Robert Sternberg formulated a triangular theory of love and argued that love has three different components: intimacy, commitment, and passion. Intimacy is a form in which two people share confidences and various details of their personal lives, and is usually shown in friendships and romantic love affairs. Commitment, on the other hand, is the expectation that the relationship is permanent. The last form of love is sexual attraction and passion. Passionate love is shown in infatuation as well as romantic love. All forms of love are viewed as varying combinations of these three components. Non-love does not include any of these components. Liking only includes intimacy. Infatuated love only includes passion. Empty love only includes commitment. Romantic love includes both intimacy and passion. Companionate love includes intimacy and commitment. Fatuous love includes passion and commitment. Lastly, consummate love includes all three components. American psychologist Zick Rubin sought to define love by psychometrics in the 1970s. His work states that three factors constitute love: attachment, caring, and intimacy.\n\nFollowing developments in electrical theories such as Coulomb's law, which showed that positive and negative charges attract, analogs in human life were developed, such as \"opposites attract\". Over the last century, research on the nature of human mating has generally found this not to be true when it comes to character and personality\u2014people tend to like people similar to themselves. However, in a few unusual and specific domains, such as immune systems, it seems that humans prefer others who are unlike themselves (e.g., with an orthogonal immune system), since this will lead to a baby that has the best of both worlds. In recent years, various human bonding theories have been developed, described in terms of attachments, ties, bonds, and affinities.\nSome Western authorities disaggregate into two main components, the altruistic and the narcissistic. This view is represented in the works of Scott Peck, whose work in the field of applied psychology explored the definitions of love and evil. Peck maintains that love is a combination of the \"concern for the spiritual growth of another,\" and simple narcissism. In combination, love is an activity, not simply a feeling.\n\nPsychologist Erich Fromm maintained in his book The Art of Loving that love is not merely a feeling but is also actions, and that in fact, the \"feeling\" of love is superficial in comparison to one's commitment to love via a series of loving actions over time. In this sense, Fromm held that love is ultimately not a feeling at all, but rather is a commitment to, and adherence to, loving actions towards another, oneself, or many others, over a sustained duration. Fromm also described love as a conscious choice that in its early stages might originate as an involuntary feeling, but which then later no longer depends on those feelings, but rather depends only on conscious commitment.\n\nEvolutionary basis\n\nEvolutionary psychology has attempted to provide various reasons for love as a survival tool. Humans are dependent on parental help for a large portion of their lifespans compared to other mammals. Love has therefore been seen as a mechanism to promote parental support of children for this extended time period. Furthermore, researchers as early as Charles Darwin himself identified unique features of human love compared to other mammals and credit love as a major factor for creating social support systems that enabled the development and expansion of the human species. Another factor may be that sexually transmitted diseases can cause, among other effects, permanently reduced fertility, injury to the fetus, and increase complications during childbirth. This would favor monogamous relationships over polygamy.\n\nAdaptive benefit\nInterpersonal love between a male and a female is considered to provide an evolutionary adaptive benefit since it facilitates mating and sexual reproduction. However, some organisms can reproduce asexually without mating.  Thus understanding the adaptive benefit of interpersonal love depends on understanding the adaptive benefit of sexual reproduction as opposed to asexual reproduction.  Michod has reviewed evidence that love, and consequently sexual reproduction, provides two major adaptive advantages.  First, love leading to sexual reproduction facilitates repair of damages in the DNA that is passed from parent to progeny (during meiosis, a key stage of the sexual process).   Second, a gene in either parent may contain a harmful mutation, but in the progeny produced by sex reproduction, expression of a harmful mutation introduced by one parent is likely to be masked by expression of the unaffected homologous gene from the other parent.\n\nComparison of scientific models\nBiological models of love tend to see it as a mammalian drive, similar to hunger or thirst. Psychology sees love as more of a social and cultural phenomenon. Certainly, love is influenced by hormones (such as oxytocin), neurotrophins (such as NGF), and pheromones, and how people think and behave in love is influenced by their conceptions of love. The conventional view in biology is that there are two major drives in love: sexual attraction and attachment. Attachment between adults is presumed to work on the same principles that lead an infant to become attached to its mother. The traditional psychological view sees love as being a combination of companionate love and passionate love. Passionate love is intense longing, and is often accompanied by physiological arousal (shortness of breath, rapid heart rate); companionate love is affection and a feeling of intimacy not accompanied by physiological arousal.\n\nCultural views\n\nAncient Greek\n\nGreek distinguishes several different senses in which the word \"love\" is used. Ancient Greeks identified four forms of love: kinship or familiarity (in Greek, storge), friendship and/or platonic desire (philia), sexual and/or romantic desire (eros), and self-emptying or divine love (agape). Modern authors have distinguished further varieties of romantic love. However, with Greek (as with many other languages), it has been historically difficult to separate the meanings of these words totally. At the same time, the Ancient Greek text of the Bible has examples of the verb agapo having the same meaning as phileo.\n\nAgape ( ag\u00e1p\u0113) means love in modern-day Greek. The term s'agapo means I love you in Greek. The word agapo is the verb I love. It generally refers to a \"pure,\" ideal type of love, rather than the physical attraction suggested by eros. However, there are some examples of agape used to mean the same as eros. It has also been translated as \"love of the soul.\"\n\nEros ( \u00e9r\u014ds) (from the Greek deity Eros) is passionate love, with sensual desire and longing. The Greek word erota means in love. Plato refined his own definition. Although eros is initially felt for a person, with contemplation it becomes an appreciation of the beauty within that person, or even becomes appreciation of beauty itself. Eros helps the soul recall knowledge of beauty and contributes to an understanding of spiritual truth. Lovers and philosophers are all inspired to seek truth by eros. Some translations list it as \"love of the body\".\n\nPhilia ( phil\u00eda), a dispassionate virtuous love, was a concept addressed and developed by Aristotle in his Nicomachean Ethics Book VIII. It includes loyalty to friends, family, and community, and requires virtue, equality, and familiarity. Philia is motivated by practical reasons; one or both of the parties benefit from the relationship. It can also mean \"love of the mind.\"\n\nStorge ( storg\u0113) is natural affection, like that felt by parents for offspring.\n\nXenia (\u03be\u03b5\u03bd\u03af\u03b1 xen\u00eda), hospitality, was an extremely important practice in ancient Greece. It was an almost ritualized friendship formed between a host and his guest, who could previously have been strangers. The host fed and provided quarters for the guest, who was expected to repay only with gratitude. The importance of this can be seen throughout Greek mythology\u2014in particular, Homer's Iliad and Odyssey.\n\nAncient Roman (Latin)\nThe Latin language has several different verbs corresponding to the English word \"love.\" am\u014d is the basic verb meaning I love, with the infinitive amare (\"to love\") as it still is in Italian today. The Romans used it both in an affectionate sense as well as in a romantic or sexual sense. From this verb come amans\u2014a lover, amator, \"professional lover,\" often with the accessory notion of lechery\u2014and amica, \"girlfriend\" in the English sense, often being applied euphemistically to a prostitute. The corresponding noun is amor (the significance of this term for the Romans is well illustrated in the fact, that the name of the city, Rome\u2014in Latin: Roma\u2014can be viewed as an anagram for amor, which was used as the secret name of the City in wide circles in ancient times), which is also used in the plural form to indicate love affairs or sexual adventures. This same root also produces amicus\u2014\"friend\"\u2014and amicitia, \"friendship\" (often based to mutual advantage, and corresponding sometimes more closely to \"indebtedness\" or \"influence\"). Cicero wrote a treatise called On Friendship (de Amicitia), which discusses the notion at some length. Ovid wrote a guide to dating called Ars Amatoria (The Art of Love), which addresses, in depth, everything from extramarital affairs to overprotective parents.\n\nLatin sometimes uses am\u0101re where English would simply say to like. This notion, however, is much more generally expressed in Latin by the terms placere or delect\u0101re, which are used more colloquially, the latter used frequently in the love poetry of Catullus. Diligere often has the notion \"to be affectionate for,\" \"to esteem,\" and rarely if ever is used for romantic love. This word would be appropriate to describe the friendship of two men. The corresponding noun diligentia, however, has the meaning of \"diligence\" or \"carefulness,\" and has little semantic overlap with the verb. Observare is a synonym for diligere; despite the cognate with English, this verb and its corresponding noun, observantia, often denote \"esteem\" or \"affection.\" Caritas is used in Latin translations of the Christian Bible to mean \"charitable love\"; this meaning, however, is not found in Classical pagan Roman literature. As it arises from a conflation with a Greek word, there is no corresponding verb.\n\nChinese and other Sinic\n\nTwo philosophical underpinnings of love exist in the Chinese tradition, one from Confucianism which emphasized actions and duty while the other came from Mohism which championed a universal love. A core concept to Confucianism is  (Ren, \"benevolent love\"), which focuses on duty, action, and attitude in a relationship rather than love itself. In Confucianism, one displays benevolent love by performing actions such as filial piety from children, kindness from parents, loyalty to the king and so forth.\n\nThe concept of  (Mandarin: \u00e0i) was developed by the Chinese philosopher Mozi in the 4th century BC in reaction to Confucianism's benevolent love. Mozi tried to replace what he considered to be the long-entrenched Chinese over-attachment to family and clan structures with the concept of \"universal love\" (, ji\u0101n'\u00e0i). In this, he argued directly against Confucians who believed that it was natural and correct for people to care about different people in different degrees. Mozi, by contrast, believed people in principle should care for all people equally. Mohism stressed that rather than adopting different attitudes towards different people, love should be unconditional and offered to everyone without regard to reciprocation; not just to friends, family and other Confucian relations. Later in Chinese Buddhism, the term Ai () was adopted to refer to a passionate, caring love and was considered a fundamental desire. In Buddhism, Ai was seen as capable of being either selfish or selfless, the latter being a key element towards enlightenment.\n\nIn Mandarin Chinese,  (\u00e0i) is often used as the equivalent of the Western concept of love.  (\u00e0i) is used as both a verb (e.g. , W\u01d2 \u00e0i n\u01d0, or \"I love you\") and a noun (such as  \u00e0iq\u00edng, or \"romantic love\"). However, due to the influence of Confucian  (r\u00e9n), the phrase  (W\u01d2 \u00e0i n\u01d0, I love you) carries with it a very specific sense of responsibility, commitment and loyalty. Instead of frequently saying \"I love you\" as in some Western societies, the Chinese are more likely to express feelings of affection in a more casual way. Consequently, \"I like you\" (, W\u01d2 x\u01d0huan n\u01d0) is a more common way of expressing affection in Mandarin; it is more playful and less serious. This is also true in Japanese (suki da, ).\n\nJapanese\n\nThe Japanese language uses three words to convey the English equivalent of \"love\". Because \"love\" covers a wide range of emotions and behavioral phenomena, there are nuances distinguishing the three terms. The term , which is often associated with maternal love or selfless love, originally referred to beauty and was often used in a religious context. Following the Meiji Restoration 1868, the term became associated with \"love\" in order to translate Western literature. Prior to Western influence, the term  generally represented romantic love, and was often the subject of the popular Man'y\u014dsh\u016b Japanese poetry collection. Koi describes a longing for a member of the opposite sex and is typically interpreted as selfish and wanting. The term's origins come from the concept of lonely solitude as a result of separation from a loved one. Though modern usage of koi focuses on sexual love and infatuation, the Many\u014d used the term to cover a wider range of situations, including tenderness, benevolence, and material desire. The third term, , is a more modern construction that combines the kanji characters for both ai and koi, though its usage more closely resembles that of koi in the form of romantic love.\n\nIndian\n\nIn contemporary literature, the Sanskrit words for love is \"sneha\". Other terms such as Priya refers to innocent love, Prema refers to spiritual love, and Kama refers usually to sexual desire. However, the term also refers to any sensory enjoyment, emotional attraction and aesthetic pleasure such as from arts, dance, music, painting, sculpture and nature.\n\nThe concept of kama is found in some of the earliest known verses in Vedas. For example, Book 10 of Rig Veda describes the creation of the universe from nothing by the great heat. There in hymn 129, it states:\n\nPersian\n\nRumi, Hafiz,and Sa'di are icons of the passion and love that the Persian culture and language present. The Persian word for love is Ishq, which is derived from Arabic language; however, it is considered by most to be too stalwart a term for interpersonal love and is more commonly substituted for \"doost dashtan\" (\"liking\"). In the Persian culture, everything is encompassed by love and all is for love, starting from loving friends and family, husbands and wives, and eventually reaching the divine love that is the ultimate goal in life.\n\nReligious views\n\nAbrahamic\n\nJudaism\n\nIn Hebrew,  (ahava) is the most commonly used term for both interpersonal love and love between God and God's creations. Chesed, often translated as loving-kindness, is used to describe many forms of love between human beings.\n\nThe commandment to love other people is given in the Torah, which states, \"Love your neighbor like yourself\" (Leviticus 19:18). The Torah's commandment to love God \"with all your heart, with all your soul and with all your might\" (Deuteronomy 6:5) is taken by the Mishnah (a central text of the Jewish oral law) to refer to good deeds, willingness to sacrifice one's life rather than commit certain serious transgressions, willingness to sacrifice all of one's possessions, and being grateful to the Lord despite adversity (tractate Berachoth 9:5). Rabbinic literature differs as to how this love can be developed, e.g., by contemplating divine deeds or witnessing the marvels of nature.\n\nAs for love between marital partners, this is deemed an essential ingredient to life: \"See life with the wife you love\" (Ecclesiastes 9:9). Rabbi David Wolpe writes that \"...love is not only about the feelings of the lover...It is when one person believes in another person and shows it.\" He further states that \"...love...is a feeling that expresses itself in action. What we really feel is reflected in what we do.\" The biblical book Song of Solomon is considered a romantically phrased metaphor of love between God and his people, but in its plain reading, reads like a love song. The 20th-century rabbi Eliyahu Eliezer Dessler is frequently quoted as defining love from the Jewish point of view as \"giving without expecting to take\" (from his Michtav me-Eliyahu, Vol.\u00a01).\n\nChristianity\n\nThe Christian understanding is that love comes from God, who is himself Love (1 Jn 4:8). The love of man and woman\u2014eros in Greek\u2014and the unselfish love of others (agape), are often contrasted as \"descending\" and \"ascending\" love, respectively, but are ultimately the same thing.\n\nThere are several Greek words for \"love\" that are regularly referred to in Christian circles.\n Agape: In the New Testament, agap\u0113 is charitable, selfless, altruistic, and unconditional. It is parental love, seen as creating goodness in the world; it is the way God is seen to love humanity, and it is seen as the kind of love that Christians aspire to have for one another.\n Phileo: Also used in the New Testament, phileo is a human response to something that is found to be delightful. Also known as \"brotherly love.\"\n Two other words for love in the Greek language, eros (sexual love) and storge (child-to-parent love), were never used in the New Testament.\n\nChristians believe that to Love God with all your heart, mind, and strength and Love your neighbor as yourself are the two most important things in life (the greatest commandment of the Jewish Torah, according to Jesus; cf. Gospel of Mark chapter 12, verses 28\u201334). Saint Augustine summarized this when he wrote \"Love God, and do as thou wilt.\"\n\nThe Apostle Paul glorified love as the most important virtue of all. Describing love in the famous poetic interpretation in 1 Corinthians, he wrote, \"Love is patient, love is kind. It does not envy, it does not boast, it is not proud. It is not rude, it is not self-seeking, it is not easily angered, it keeps no record of wrongs. Love does not delight in evil but rejoices with the truth. It always protects, always trusts, always hopes, and always perseveres.\" (1 Cor. 13:4\u20137, NIV)\n\nThe Apostle John wrote, \"For God so loved the world that he gave his one and only Son, that whoever believes in him shall not perish but have eternal life. For God did not send his Son into the world to condemn the world, but to save the world through him.\" (John 3:16\u201317, NIV) John also wrote, \"Dear friends, let us love one another for love comes from God. Everyone who loves has been born of God and knows God. Whoever does not love does not know God, because God is love.\" (1 John 4:7\u20138, NIV)\n\nSaint Augustine wrote that one must be able to decipher the difference between love and lust. Lust, according to Saint Augustine, is an overindulgence, but to love and be loved is what he has sought for his entire life. He even says, \"I was in love with love.\" Finally, he does fall in love and is loved back, by God. Saint Augustine says the only one who can love you truly and fully is God, because love with a human only allows for flaws such as \"jealousy, suspicion, fear, anger, and contention.\" According to Saint Augustine, to love God is \"to attain the peace which is yours.\" (Saint Augustine's Confessions)\n\nAugustine regards the duplex commandment of love in Matthew 22 as the heart of Christian faith and the interpretation of the Bible. After the review of Christian doctrine, Augustine treats the problem of love in terms of use and enjoyment until the end of Book I of De Doctrina Christiana (1.22.21\u20131.40.44;).\n\nChristian theologians see God as the source of love, which is mirrored in humans and their own loving relationships. Influential Christian theologian C. S. Lewis wrote a book called The Four Loves. Benedict XVI named his first encyclical God is love. He said that a human being, created in the image of God, who is love, is able to practice love; to give himself to God and others (agape) and by receiving and experiencing God's love in contemplation (eros). This life of love, according to him, is the life of the saints such as Teresa of Calcutta and Mary, the mother of Jesus and is the direction Christians take when they believe that God loves them.\n\nPope Francis taught that \"True love is both loving and letting oneself be loved...what is important in love is not our loving, but allowing ourselves to be loved by God.\" And so, in the analysis of a Catholic theologian, for Pope Francis, \"the key to love...is not our activity. It is the activity of the greatest, and the source, of all the powers in the universe: God's.\"\n\nIn Christianity the practical definition of love is summarised by Thomas Aquinas, who defined love as \"to will the good of another,\" or to desire for another to succeed. This is an explanation of the Christian need to love others, including their enemies. As Thomas Aquinas explains, Christian love is motivated by the need to see others succeed in life, to be good people.\n\nRegarding love for enemies, Jesus is quoted in the Gospel of Matthew chapter five:\n\n\"You have heard that it was said, 'Love your neighbor and hate your enemy.' But I tell you, love your enemies and pray for those who persecute you, that you may be children of your Father in heaven. He causes his sun to rise on the evil and the good, and sends rain on the righteous and the unrighteous. If you love those who love you, what reward will you get? Are not even the tax collectors doing that? And if you greet only your own people, what are you doing more than others? Do not even pagans do that? Be perfect, therefore, as your heavenly Father is perfect.\"\n\u2013 Matthew 5: 43\u201348.\n\nDo not forget to love with forgiveness, Christ saved an adulterous woman from those who would stone her. A world of wronged hypocrites needs forgiving love. Mosaic Law would hold Deuteronomy 22:22-24 \"If a man is found lying with a woman married to a husband, then both of them shall die\u2014the man that lay with the woman, and the woman; so you shall put away the evil from Israel. If a young woman who is a virgin is betrothed to a husband, and a man finds her in the city and lies with her, then you shall bring them both out to the gate of that city, and you shall stone them to death with stones, the young woman because she did not cry out in the city, and the man because he humbled his neighbor's wife; so you shall put away the evil from among you.\"\n\nTertullian wrote regarding love for enemies: \"Our individual, extraordinary, and perfect goodness consists in loving our enemies. To love one's friends is common practice, to love one's enemies only among Christians.\"\n\nIslam\n\nLove encompasses the Islamic view of life as universal brotherhood that applies to all who hold faith. Amongst the 99 names of God (Allah), there is the name Al-Wadud, or \"the Loving One,\" which is found in Surah  as well as Surah . God is also referenced at the beginning of every chapter in the Qur'an as Ar-Rahman and Ar-Rahim, or the \"Most Compassionate\" and the \"Most Merciful\", indicating that nobody is more loving, compassionate and benevolent than God. The Qur'an refers to God as being \"full of loving kindness.\"\n\nThe Qur'an exhorts Muslim believers to treat all people, those who have not persecuted them, with birr or \"deep kindness\" as stated in Surah . Birr is also used by the Qur'an in describing the love and kindness that children must show to their parents.Ishq, or divine love, is the emphasis of Sufism in the Islamic tradition. Practitioners of Sufism believe that love is a projection of the essence of God to the universe. God desires to recognize beauty, and as if one looks at a mirror to see oneself, God \"looks\" at himself within the dynamics of nature. Since everything is a reflection of God, the school of Sufism practices seeing  the beauty inside the apparently ugly. Sufism is often referred to as the religion of love. God in Sufism is referred to in three main terms, which are the Lover, Loved, and Beloved, with the last of these terms being often seen in Sufi poetry. A common viewpoint of Sufism is that through love, humankind can get back to its inherent purity and grace. The saints of Sufism are infamous for being \"drunk\" due to their love of God; hence, the constant reference to wine in Sufi poetry and music.\n\nBah\u00e1'\u00ed Faith\nIn his Paris Talks, `Abdu'l-Bah\u00e1 described four types of love: the love that flows from God to human beings; the love that flows from human beings to God; the love of God towards the Self or Identity of God; and the love of human beings for human beings.\n\nIndian\nBuddhism\nIn Buddhism, K\u0101ma is sensuous, sexual love. It is an obstacle on the path to enlightenment, since it is selfish. Karu\u1e47\u0101 is compassion and mercy, which reduces the suffering of others. It is complementary to wisdom and is necessary for enlightenment. Adve\u1e63a and mett\u0101 are benevolent love. This love is unconditional and requires considerable self-acceptance. This is quite different from ordinary love, which is usually about attachment and sex and which rarely occurs without self-interest. Instead, in Buddhism it refers to detachment and unselfish interest in others' welfare.\n\nThe Bodhisattva ideal in Mahayana Buddhism involves the complete renunciation of oneself in order to take on the burden of a suffering world.\n\nHinduism\n\nIn Hinduism, k\u0101ma is pleasurable, sexual love, personified by the god Kamadeva. For many Hindu schools, it is the third end (Kama) in life. Kamadeva is often pictured holding a bow of sugar cane and an arrow of flowers; he may ride upon a great parrot. He is usually accompanied by his consort Rati and his companion Vasanta, lord of the spring season. Stone images of Kamadeva and Rati can be seen on the door of the Chennakeshava temple at Belur, in Karnataka, India. Maara is another name for k\u0101ma.\n\nIn contrast to k\u0101ma, premaor premrefers to elevated love. Karuna is compassion and mercy, which impels one to help reduce the suffering of others. Bhakti is a Sanskrit term, meaning \"loving devotion to the supreme God.\" A person who practices bhakti is called a bhakta. Hindu writers, theologians, and philosophers have distinguished nine forms of bhakti, which can be found in the Bhagavata Purana and works by Tulsidas. The philosophical work Narada Bhakti Sutras, written by an unknown author (presumed to be Narada), distinguishes eleven forms of love.\n\nIn certain Vaishnava sects within Hinduism, attaining unadulterated, unconditional and incessant love for Godhead is considered the foremost goal of life. Gaudiya Vaishnavas who worship Krishna as the Supreme Personality of Godhead and the cause of all causes consider Love for Godhead (Prema) to act in two ways: sambhoga and vipralambha (union and separation)\u2014two opposites.\n\nIn the condition of separation, there is an acute yearning for being with the beloved and in the condition of union, there is supreme happiness and nectarean. Gaudiya Vaishnavas consider that Krishna-prema (Love for Godhead) is not fire but that it still burns away one's material desires. They consider that K\u1e5b\u1e63\u1e47a-prema is not a weapon, but it still pierces the heart. It is not water, but it washes away everything\u2014one's pride, religious rules, and one's shyness. Krishna-prema is considered to make one drown in the ocean of transcendental ecstasy and pleasure. The love of Radha, a cowherd girl, for Krishna is often cited as the supreme example of love for Godhead by Gaudiya Vaishnavas. Radha is considered to be the internal potency of Krishna, and is the supreme lover of Godhead. Her example of love is considered to be beyond the understanding of material realm as it surpasses any form of selfish love or lust that is visible in the material world. The reciprocal love between Radha (the supreme lover) and Krishna (God as the Supremely Loved) is the subject of many poetic compositions in India such as the Gita Govinda and Hari Bhakti Shuddhodhaya.In the Bhakti tradition within Hinduism, it is believed that execution of devotional service to God leads to the development of Love for God (taiche bhakti-phale krsne prema upajaya), and as love for God increases in the heart, the more one becomes free from material contamination (krishna-prema asvada haile, bhava nasa paya). Being perfectly in love with God or Krishna makes one perfectly free from material contamination. and this is the ultimate way of salvation or liberation. In this tradition, salvation or liberation is considered inferior to love, and just an incidental by-product. Being absorbed in Love for God is considered to be the perfection of life.\n\nPolitical views\n\nFree love\n\nThe term \"free love\" has been used to describe a social movement that rejects marriage, which is seen as a form of social bondage. The Free Love movement's initial goal was to separate the state from sexual matters such as marriage, birth control, and adultery. It claimed that such issues were the concern of the people involved, and no one else.\n\nMany people in the early 19th century believed that marriage was an important aspect of life to \"fulfill earthly human happiness.\" Middle-class Americans wanted the home to be a place of stability in an uncertain world. This mentality created a vision of strongly defined gender roles, which provoked the advancement of the free love movement as a contrast.\n\nThe term \"sex radical\" has been used interchangeably with the term \"free lover\". By whatever name, advocates had two strong beliefs: opposition to the idea of forceful sexual activity in a relationship and advocacy for a woman to use her body in any way that she pleases. These are also beliefs of Feminism.\n\nPhilosophical views\n\nThe philosophy of love is a field of social philosophy and ethics that attempts to explain the nature of love. The philosophical investigation of love includes the tasks of distinguishing between the various kinds of personal love, asking if and how love is or can be justified, asking what the value of love is, and what impact love has on the autonomy of both the lover and the beloved.\n\nSee also\n\n Color wheel theory of love\n Human bonding\n Love at first sight\n Pair bond\n Polyamory\n Romance (love)\n Self-love\n Social connection\n Traditional forms, Agape, Philia, Philautia, Storge, Eros: Greek terms for love\nRelationship Science\n\nReferences\n\nSources\n\n \n \n \n \n \n \n \n \n \n \n\nFurther reading\n \n\nExternal links\n\n History of Love, Internet Encyclopedia of Philosophy''\n \n \n \n\n \nEmotions\nEthical principles\nFruit of the Holy Spirit\nPersonal life\nVirtue",
  "Sex": "Sex is a trait that determines an individual's reproductive function, male or female, in animals and plants that propagate their species through sexual reproduction. The type of gametes produced by an organism defines its sex. Commonly in plants and animals, male organisms produce smaller gametes (spermatozoa, sperm) while female organisms produce larger gametes (ova, often called egg cells). Organisms that produce both types of gametes are called hermaphrodites.  During sexual reproduction, male and female gametes fuse to form zygotes that develop into offspring that inherit a selection of the traits of each parent.\n\nMales and females of a species may be similar (sexual monomorphism), or have physical differences (sexual dimorphism). The differences reflect the different reproductive pressures the sexes experience. For instance, mate choice and sexual selection can accelerate the evolution of physical differences between the sexes.\n\nThe terms male and female typically do not apply in sexually undifferentiated species in which the individuals are isomorphic (look the same) and the gametes are isogamous (indistinguishable in size and shape), such as the green alga Ulva lactuca. If there are instead functional differences between gametes, such as in fungi, they may be referred to as mating types.\n\nSex is genetically determined in most mammals by the XY sex-determination system, where male mammals carry an X and a Y chromosome (XY), whereas female mammals carry two X chromosomes (XX). Other chromosomal sex-determination systems in animals include the ZW system in birds, and the X0 system in insects. Various environmental systems include temperature-dependent sex determination in reptiles and crustaceans.\n\nReproduction \n\n \n\nSexual reproduction is production of offspring by the fusion of haploid gametes. The codes for genetic traits are contained within the deoxyribonucleic acid (DNA) of chromosomes. By combining one set of chromosomes from each parent, an organism is formed containing a double set of chromosomes. This double-chromosome stage is called \"diploid\" while the single-chromosome stage is \"haploid\". Diploid organisms can, in turn, produce haploid cells (gametes) that randomly contain one of each of the chromosome pairs, via meiosis. Meiosis also involves a stage of chromosomal crossover in which regions of DNA are exchanged between matched types of chromosomes, to form new pairs of mixed chromosomes, each of which is a blend of the genes of both parents. This process is followed by a mitotic division, producing haploid gametes that contain one set of chromosomes. Crossing over to make new recombinant chromosomes and fertilization (the fusion of two gametes) result in the new organism containing a different set of genetic traits from either parent.\n\nGametes may be externally similar (isogamy) or may differ in size and other aspects (anisogamy). Oogamy is an extreme example of anisogamy, in which a large, non-motile gamete is fused with a smaller, usually motile one. Isogamy is very common in unicellular organisms while anisogamy is common in multicellular organisms. Individuals that exclusively produce large gametes are females, and those that exclusively produce small gametes are males.\n\nAn individual that produces both types of gametes is a hermaphrodite. Some hermaphrodites such as the roundworm Caenorhabditis elegans are able to self-fertilize and produce offspring on their own, without a second organism. Some hermaphrodite animals such as Helix pomatia and Cepaea cannot self-fertilize.\n\nSome hermaphroditic plants are self-fertile, but plants have evolved multiple different mechanisms to avoid self-fertilization, involving sequential hermaphroditism (dichogamy), self-incompatibility or morphological mechanisms such as heterostyly (herkogamy).\n\nIn the life-cycle of plants and multicellular algae, diploid and haploid multicellular phases alternate. The diploid organism is called the sporophyte because it produces haploid spores by meiosis, which, on germination, undergo mitotic cell division to produce multicellular haploid organisms, the gametophytes that produce gametes by mitosis.\n\nAnimals\n\nSexually reproducing animals are diploid, and their single-celled gametes are the only haploid cells in their life cycles. Animals have two gamete types: male spermatozoa (sperm) and female ova (egg cells).\n\nA spermatozoon, produced in vertebrates within the testes, is a small cell containing a single long flagellum which propels it. Egg cells (ova) are produced within the ovaries. In oviparous species such as birds, the fertilized egg cell or zygote is provided with yolk, a nutrient supply which supports the development of the embryo.\n\nAll animals that live outside of water use internal fertilization to transfer sperm directly into the female, thereby preventing the gametes from drying up. Intromittent organs are the male copulation organs which help transport of sperm.\n\nMammals\n\nIn mammals the female reproductive tract, called the vagina, connects with the uterus, an organ which directly supports the development of a fertilized embryo within, a process called gestation. In humans and other mammals the equivalent male organ is the penis, which enters the vagina to achieve insemination in a process called sexual intercourse. The penis contains a tube through which semen (a fluid containing sperm) travels. In Marsupials and placental mammals the fertilized egg develops within the female, receiving nutrition directly from its mother via a specialized organ called the placenta.\n\nBirds\n\nIn 97% of bird species, males do not have a penis. Instead in most birds, both excretion and reproduction are done through a single posterior opening called the cloaca. Male and female birds touch cloacae to transfer sperm, a process called \"cloacal kissing\".\n\nAquatic animals\n\nMost aquatic animals such as fish and corals mate using external fertilization, where the eggs and sperm are released into, and combine within, the surrounding water. However, some species like crustaceans use internal fertilization.  In seahorses, females use their ovipositors to deliver eggs into the males\u2019 underside for fertilization and gestation. Pipefish and seahorses are the only species that entail male pregnancy.\n\nInsects\n\nMost insects reproduce through oviparity, where a female mates with a male and the females lays the egg outside of her body. A few groups of insects such as the Strepsiptera reproduce through traumatic insemination, where a male pierces a female's exoskeleton with his aedeagus. In some harvester ants, a queen needs to mate with two types of males: one to reproduce queens and another to reproduce worker ants; these ants may be considered to have three or four sexes.\n\nPlants\n\nIn the green seaweed genus Ulva, there is no sexual specialization among the isomorphic individual plants, their sexual organs, or their isogamous gametes. However, the majority of plants have specialized male and female gametes.\n\nThe male gametes are the only cells in plants and green algae that have flagella. They are motile, able to swim to the egg cells of female gametophyte plants in films of water. Seed plants other than Cycads and Ginkgo have lost flagella entirely and are unable to swim in water. Once their pollen is delivered to the stigma of flowering plants, or the micropyle of gymnosperm ovules, their gametes are delivered to the egg cell by means of pollen tubes produced by one of the cells of the microgametophyte. Many plants, including conifers and grasses, are anemophilous producing lightweight pollen which is carried by wind to neighboring plants. Other plants, such as orchids, have heavier, sticky pollen that is specialized for zoophily, transportation by animals. Plants attract insects such as bees or larger animals such as humming birds and bats with flowers containing rewards of nectar or resin. These animals transport the pollen as they move to other flowers, which also contain female reproductive organs, resulting in cross-pollination.\n\nSpermatophytes \n\nIn seed plants, male gametes are produced by extremely reduced multicellular microgametophytes known as pollen. The female gametes (egg cells) of seed plants are produced by larger megagametophytes contained within ovules. Once the egg cells are fertilized by male gametes produced by pollen, the ovules develop into seeds which contain the nutrients necessary for the initial development of the embryonic plant.\n\nConifers \n\nIn pines and other conifers, the sex organs are contained in the cones. The female cones (seed cones) produce seeds and male cones (pollen cones) produce pollen. The female cones are longer lived and typically much larger and more durable. The ovules attached to the cone scales are not enclosed in an ovary, giving rise to the name gymnosperm meaning 'naked seed'. The smaller male cones produce pollen which is transported by wind to land in female cones. Naked seeds form after pollination, protected by the scales of the female cone.\n\nAngiosperms \n\nThe sex organs of flowering plants are contained in flowers. The male parts of the flower are the stamens, which consist of the filaments supporting the anthers that produce the pollen. The female parts in the flower, are the pistils, composed of one or more carpels. Carpels consist of an ovary, a style and a stigma. Within the ovary are ovules, which contain haploid megagametophytes that produce egg cells. When a pollen grain lands upon the stigma on top of a carpel's style, it germinates to produce a pollen tube that grows down through the tissues of the style into the carpel, where it delivers male gamete nuclei to fertilize the egg cell in an ovule that eventually develops into a seed. At the same time the ovary develops into a fruit.\n\nThe majority of flowers are hermaphroditic (bisexual) and produce both male and female gametophytes in the same flowers. The male gametophytes form inside pollen grains and produce male gametes. The female gametophytes form inside ovules and produce female gametes.\nBisexual flowers that contain both male and female sexual organs are said to be perfect.\n\nAngiosperms may also have imperfect flowers, on the same or different plants, that lack one or other type of sex organs. Sometimes, as in the tree of heaven (Ailanthus altissima) and the European ash (Fraxinus excelsior) the panicles can produce different mixtures of functionally unisexual and functionally bisexual flowers on the same or different trees.\n\nBecause flowering plants are immobile, they evolved flowers to attract animals such as insects to help in fertilization.\n\nFungi\n\nMost fungi are able to reproduce sexually and asexually and have both haploid and diploid stages in their life cycles. Many fungi are isogamous, lacking male and female specialization. Even fungi that are anisogamous are all hermaphroditic, which is why even anisogamous fungi are considered to be mating types rather than sexes.\n\nFungi may have complex allelic mating systems and many species of fungi have two mating types. However, Coprinellus disseminatus  has been estimated to have about 123 mating types, and in some species there are thousands of mating types. For example, Schizophyllum commune has about 28,000 or more mating types.\n\nSome fungi, including that used as baker's yeast, have mating types that create a duality similar to male and female roles. Yeast with the same mating type do not fuse to form diploid cells, only with yeast carrying another mating type.\n\nMany species of higher fungi produce mushrooms as part of their sexual reproduction. Within the mushroom diploid cells are formed, later dividing into haploid spores.\n\nProtozoa \nSexual reproduction is common among parasitic protozoa but rare among free-living protozoa, which usually reproduce asexually unless food is scarce or the environment changes drastically. Both anisogamy and isogamy are found in free-living protozoa. Ciliates are all isogamous such as Tetrahymena thermophila, which has 7 mating types.\n\nSexual systems \nA sexual system is a distribution of male and female functions across organisms in a species.\n\nAnimals \nApproximately 95% of animal species are gonochoric (also known as dioecious) and about 5% are hermaphroditic. This low percentage is due to the very large number of insect species, in which hermaphroditism is absent. Hermaphroditism nevertheless occurs in 70% of animal phyla.\n\nGonochoric individuals are either male or female throughout their lives. Gonochorism is very common in vertebrates, about 99% of which gonochoric. The remaining 1% that are hermaphroditic are almost all fishes. All birds and mammals are gonochoric.\n\nPlants \nRoughly 5 to 6% of flowering plants are dioecious, resulting from between 871 and 5000 independent origins. Consequently the majority are bisexual, either hermaphrodite (with both stamens and pistil in the same flower) or monoecious (with separate male and female flowers on the same plant). In dioecious species male and female sexes are on separate plants. Dioecy is common in gymnosperms, in which 65% of species are dioecious, but most conifers are monoecious.\n\nEvolution of sex\n\nSexual conflict underlies the evolutionary distinction between male and female with the distinction starting from anisogamy, the form of sexual reproduction that involves the union or fusion of two gametes that differ in size or form. The evolution of anisogamy is also synonymous to the evolution of male and female sexes, as well the starting point toward sexual dimorphism, and lead to the evolution of many sex differences.\n\nIt is generally accepted that anisogamy has evolved from isogamy several times independently in different groups of eukaryotes, including protists, algae, plants and animals, but its evolution has left no fossil evidence. Until 2006 there was no genetic evidence for the evolutionary link between sexes and mating types due to plants and animals having no isogamous relatives.\n\nAnisogamy evolves due to disruptive selection leading to small gametes and large gametes. In anisogamous species an intermediate gamete is unable to persist. There should always be two gamete types, with all analyses showing that intermediate gamete sizes are eliminated due to selection. As of 2016, it remains unclear if anisogamy first led to the evolution of gonochorism or the evolution of hermaphroditism.\n\nSex-determination systems \n\nThe biological cause of an organism developing into one sex or the other is called sex determination.  The cause may be genetic, environmental, haplodiploidy, or multiple factors.  Within animals and other organisms that have genetic sex-determination systems, the determining factor may be the presence of a sex chromosome. In plants that are sexually dimorphic, such as Ginkgo biloba, the liverwort Marchantia polymorpha or the dioecious species in the flowering plant genus Silene, sex may also be determined by sex chromosomes. Non-genetic systems may use environmental cues, such as the temperature during early development in crocodiles, to determine the sex of the offspring.\n\nSex determination is often distinct from sex differentiation, sex determination is the designation for the development stage towards either male or female while sex differentiation is the pathway towards the development of the phenotype.\n\nGenetic\n\nXY sex determination \nHumans and most other mammals have an XY sex-determination system: the Y chromosome carries factors responsible for triggering male development, making XY sex determination mostly based on the presence or absence of the Y chromosome. It is the male gamete that determines the sex of the offspring. In this system XX mammals typically are female and XY typically are male. However, individuals with XXY or XYY are males, while individuals with X and XXX are females.\n\nXY sex determination is found in other organisms, including insects like the common fruit fly, and some plants. In some cases, it is the number of X chromosomes that determines sex rather than the presence of a Y chromosome. In the fruit fly individuals with XY are male and individuals with XX are female; however, individuals with XXY or XXX can also be female, and individuals with X can be males.\n\nZW sex determination \nIn birds, which have a ZW sex-determination system, the W chromosome carries factors responsible for female development, and default development is male. In this case, ZZ individuals are male and ZW are female. It is the female gamete that determines the sex of the offspring. This system is used by birds, some fish, and some crustaceans.\n\nThe majority of butterflies and moths also have a ZW sex-determination system. In groups like the Lepidoptera, females can have Z, ZZW, and even ZZWW.\n\nXO sex determination \nIn the X0 sex-determination system, males have one X chromosome (X0) while females have two (XX). All other chromosomes in these diploid organisms are paired, but organisms may inherit one or two X chromosomes. This system is found in most arachnids, insects such as silverfish (Apterygota), dragonflies (Paleoptera) and grasshoppers (Exopterygota), and some nematodes, crustaceans, and gastropods.\n\nIn field crickets, for example, insects with a single X chromosome develop as male, while those with two develop as female.\n\nIn the nematode Caenorhabditis elegans, most worms are self-fertilizing hermaphrodites with an XX karyotype, but occasional abnormalities in chromosome inheritance can give rise to individuals with only one X chromosome\u2014these X0 individuals are fertile males (and half their offspring are male).\n\nZO sex determination \n\nIn the Z0 sex-determination system, males have two Z chromosomes whereas females have one. This system is found in several species of moths.\n\nEnvironmental\n\nFor many species, sex is not determined by inherited traits, but instead by environmental factors such as temperature experienced during development or later in life.\n\nThe bonelliidae larvae can only develop as males when they encounter a female.\n\nIn the fern Ceratopteris and other homosporous fern species, the default sex is hermaphrodite, but individuals which grow in soil that has previously supported hermaphrodites are influenced by the pheromone antheridiogen to develop as male.\n\nSequential hermaphroditism \n\nSome species can change sex over the course of their lifespan, a phenomenon called sequential hermaphroditism. Teleost fishes are the only vertebrate lineage where sequential hermaphroditism occurs. In clownfish, smaller fish are male, and the dominant and largest fish in a group becomes female; when a dominant female is absent, then her partner changes sex. In many wrasses the opposite is true\u2014the fish are initially female and become male when they reach a certain size. Sequential hermaphroditism also occurs in plants such as Arisaema triphyllum.\n\nTemperature-dependent sex determination \nMany reptiles, including all crocodiles and most turtles, have temperature-dependent sex determination. In these species, the temperature experienced by the embryos during their development determines their sex. In some turtles, for example, males are produced at lower temperatures than females; but Macroclemys females are produced at temperatures lower than 22\u00a0\u00b0C or above 28\u00a0\u00b0C, while males are produced in between those temperatures.\n\nHaplodiploidy\nOther insects, including honey bees and ants, use a haplodiploid sex-determination system. Diploid bees and ants are generally female, and haploid individuals (which develop from unfertilized eggs) are male. This sex-determination system results in highly biased sex ratios, as the sex of offspring is determined by fertilization (arrhenotoky or pseudo-arrhenotoky resulting in males) rather than the assortment of chromosomes during meiosis.\n\nSex ratio\n\nSex differences\n\nAnisogamy is the fundamental difference between male and female. Richard Dawkins has stated that it is possible to interpret all the differences between the sexes as stemming from this.\n\nSex differences in humans include a generally larger size and more body hair in men, while women have larger breasts, wider hips, and a higher body fat percentage. In other species, there may be differences in coloration or other features, and may be so pronounced that the different sexes may be mistaken for two entirely different taxa.\n\nSex differences in behavior \n\nThe sexes across gonochoric species usually differ in behavior. In most animal species females invest more in parental care, although in some species, such as some coucals, the males invest more parental care. Females also tend to be more choosy for who they mate with, such as most bird species. Males tend to be more competitive for mating than females.\n\nSexual dimorphism \n\nIn many animals and some plants, individuals of male and female sex differ in size and appearance, a phenomenon called sexual dimorphism. Sexual dimorphism in animals is often associated with sexual selection\u2014the mating competition between individuals of one sex vis-\u00e0-vis the opposite sex. In many cases, the male of a species is larger than the female. Mammal species with extreme sexual size dimorphism tend to have highly polygynous mating systems\u2014presumably due to selection for success in competition with other males\u2014such as the elephant seals. Other examples demonstrate that it is the preference of females that drives sexual dimorphism, such as in the case of the stalk-eyed fly.\n\nFemales are the larger sex in a majority of animals. For instance, female southern black widow spiders are typically twice as long as the males. This size disparity may be associated with the cost of producing egg cells, which requires more nutrition than producing sperm: larger females are able to produce more eggs.\n\nSexual dimorphism can be extreme, with males, such as some anglerfish, living parasitically on the female. Some plant species also exhibit dimorphism in which the females are significantly larger than the males, such as in the moss genus Dicranum and the liverwort genus Sphaerocarpos. There is some evidence that, in these genera, the dimorphism may be tied to a sex chromosome, or to chemical signalling from females.\n\nIn birds, males often have a more colourful appearance and may have features (like the long tail of male peacocks) that would seem to put them at a disadvantage (e.g. bright colors would seem to make a bird more visible to predators). One proposed explanation for this is the handicap principle. This hypothesis argues that, by demonstrating he can survive with such handicaps, the male is advertising his genetic fitness to females\u2014traits that will benefit daughters as well, who will not be encumbered with such handicaps.\n\nSexual monomorphism \nSexual monomorphism is when both sexes are similar in appearance and structure. In primary sexual monomorphism both sexes have similar traits, and possibly similar genes, while in secondary sexual monomorphism both sexes have a trait that was historically in one sex. In sexually monomorphic species both parents invest the same amount in their offspring and both sexes are choosy for whom to mate with. Sexual monomorphism is also related to low levels of sexual selection.\n\nMonogamous species tend to be sexually monomorphic. All pair bonded primates are sexually monomorphic, including the tarsier family. However, not all monogamous primates are sexually monomorphic, there being only a few primate taxa where sexual monomorphism is associated with socially monogamous groups.\n\nMany bird species are sexually monomorphic. Birds that are larger in size are more sexually monomorphic than smaller birds.\n\nIn plants many sexually monomorphic species are hermaphrodites.\n\nSex characteristics \n\nPrimary sex characteristics are organs directly involved in reproduction such as the testes or ovaries, while secondary sex characteristics in humans for example are body hair, breasts, and distribution of fat.\n\nOrganisms that have intermediate sex characteristics between male and female are called intersex, this can be caused by extra sex chromosomes or by hormonal abnormality during fetal development. The term intersex typically applies to abnormal members of gonochoric species rather than to hermaphroditic species. Some species, such as the fruit fly (Drosophila melanogaster), and some crustaceans may have gynandromorphs.\n\nSee also \n Sex and gender distinction\nMating types\nSex organ\nSex allocation\nSex assignment\nSexing\n\nReferences\n\nFurther reading \n\n \n \n  N.B.: One of many books by this pioneering authority on aspects of human sexuality.\n\nExternal links \n\n Human Sexual Differentiation  by P. C. Sizonenko\n\n \nBiological processes"
}